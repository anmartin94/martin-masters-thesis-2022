<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SENSEVAL-2 Japanese Dictionary Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Kiyoaki</forename><surname>Shirai</surname></persName>
							<email>kshirai@jaist.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Science</orgName>
								<orgName type="institution">Japan Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SENSEVAL-2 Japanese Dictionary Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports an overview of the SENSEVAL-2 Japanese dictionary task. It was a lexical sample task, and word senses are defined according to a Japanese dictionary, the Iwanami Kokugo Jiten. The Iwanami Kokugo Jiten and a training corpus were distributed to all participants. The number of target words was 100, 50 nouns and 50 verbs. One hundred instances of each target word were provided, making for a total of 10,000 instances for evaluation. Seven systems of three organizations participated in this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In SENSEVAL-2, there are two Japanese tasks, a translation task and a dictionary task. This paper describes the details of the dictionary task.</p><p>First of all, let me introduce an overview of the Japanese dictionary task. This task is a lexical sample task. Word senses were defined according to the Iwanami Kokugo Jiten <ref type="bibr" target="#b2">(Nishio et aL, 1994)</ref>, a Japanese dictionary published by Iwanami Shoten. It was distributed to all participants as a sense inventory. Training data, a corpus consisting of 3,000 newspaper articles and manually annotated with sense IDs, was also distributed to participants. For evaluation, we distributed newspaper articles with marked target words as test documents. Participants were required to assign one or more sense IDs to each target word, optionally with associated probabilities. The number of target words was 100, 50 nouns and 50 verbs. One hundred instances of each target word were provided, making for a total of 10,000 instances.</p><p>In what follows, Section 2 describes details of data used in the Japanese dictionary task. Section 3 describes the process to construct the 33 gold standard data, including the analysis of inter-tagger agreement. Section 4 briefly introduces participating systems and their results. Finally, Section 5 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>In the Japanese dictionary task, three data were distributed to all participants: sense inventory, training data and evaluation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sense Inventory</head><p>As described in Section 1, word senses are defined according to a Japanese dictionary, the Iwanami Kokugo Jiten. The number of headwords and word senses in the I wanami Kokugo Jiten is 60,321 and 85,870, respectively. Figure <ref type="figure" target="#fig_0">1</ref> shows an example of word sense descriptions in the Iwanami Kokugo Jiten, the sense set of the Japanese noun "MURI  As shown in Figure <ref type="figure" target="#fig_0">1</ref>, there are hierarchical structures in word sense descriptions. For example, word sense 1 subsumes 1-a and 1-b. The number of layers of hierarchy in the I wanami Kokugo Jiten is at most 3. Word sense distinctions in the lowest level are rather fine or subtle. Furthermore, a word sense description sometimes contains example sentences including a headword, indicated by italics in Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>The Iwanami Kokugo Jiten was provided to all participants. For each sense description, a corresponding sense ID and morphological information were supplied. All morphological information, which included word segmentation, part-of-speech (POS) tag, base form and reading, was manually post-edited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training Data</head><p>An annotated corpus was distributed as the training data. It was made up of 3,000 newspaper articles extracted from the 1994 Mainichi Shimbun, consisting of 888,000 words. The annotated information in the training corpus was as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Morphological information</head><p>The text was annotated with morphological information (word segmentation, POS tag, base form and reading) for all words. All morphological information was manually post-edited.</p><p>• UDC code Each article was assigned a code representing the text class. The classification code system was the third version <ref type="bibr" target="#b1">(INFOSTA, 1994)</ref> of Universal Decimal Classification (UDC) code <ref type="bibr">(Organization, 1993)</ref>.</p><p>• Word sense IDs Only 148,558 words in the text were annotated for sense. Words assigned with sense IDs satisfied the following conditions:</p><p>1. Their FOSs were noun, verb or adjective.</p><p>2. The Iwanami Kokugo Jiten gave sense descriptions for them.</p><p>3. They were ambiguous, i.e. there are more than two word senses in the dictionary.</p><p>Word sense IDs were manually annotated. However, only one annotator assigned a sen~e ID for each word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Evaluation Data</head><p>The evaluation data was made up of 2,130 newspaper articles extracted from the 1994 Mainichi Shimbun. The articles used for the training and evaluation data were mutually exclusive. The annotated information in the evaluation data was as follows:</p><p>• Morphological information The text was annotated with morphological information (word segmentation, POE tag, base form and reading) for all words Note that morphological information in thE training data was manually post-edited: but not in the evaluation data. So participants might ignore morphological information in the evaluation data.</p><p>• </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Gold Standard Data</head><p>Except for the gold standard data, the data described in Section 2 have been developed by Real World Computing Partnership <ref type="bibr" target="#b0">(Hasida et al., 1998;</ref><ref type="bibr" target="#b4">Shirai et al., 2001)</ref> and already released to public domain 2 . On the other hand, the gold standard data was newly developed for the SENSEVAL-2. This section presents the process of preparing the gold standard data, and the analysis of inter-tagger agreement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sampling Target Words</head><p>When we chose target words, we considered the following:</p><p>• POSs of target words were either nouns or verbs.</p><p>• Words were chosen which occurred more than 50 times in the training data. • The relative "difficulty" in disambiguating the sense of words was considered. Difficulty of the word w was defined by the entropy of the word sense distribution E(w) in the training data. Obviously, the higher E(w) was, the more difficult the WSD for w was. We set up three word classes, Da (E(w) ~ 1), Db (0.5 ~ E(w) &lt; 1) and De (E(w) &lt; 0.5), and chose target words evenly from them.</p><p>Table <ref type="table" target="#tab_2">1</ref> reveals details of numbers of target words. Average polysemy (i.e. average number of word senses per headword) and average entropy are also indicated.</p><p>One hundred instances of each target word were selected from newspaper articles, making for a total of 10,000 instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Manual Annotation</head><p>Six annotators assigned the correct word sense IDs for 10,000 instances. They were not experts, but had knowledge of linguistics or lexicography to some degree. The process of manual annotating was as follows:</p><p>Step 1. Two annotators chose a sense ID for each instance separately in accordance with the following guidelines:</p><p>• Only one sense ID was to be chosen for each instance.</p><p>• Sense IDs at any layers in hierarchical structures could be assignable.</p><p>• The "UNASSIGNABLE" tag was to be chosen only when all sense IDs weren't absolutely applicable. Otherwise, choose one of sense IDs in the dictionary.</p><p>35 Step 2. If the sense IDs selected by 2 annotators agreed, we considered it to be a correct sense ID for an instance.</p><p>Step 3. If they did not agree, the third annotator chose the correct sense ID between them. If the third annotator judged both of them to be wrong and chose another sense ID as correct, we considered that all 3 word sense IDs were correct.</p><p>According to Step 3., the number of words for which 3 annotators assigned different sense IDs from one another was a quite few, 28 (0.3%).</p><p>Table <ref type="table" target="#tab_3">2</ref> indicates the inter-tagger agreement of two annotators in Step 1. Agreement ratio for all 10,000 instances was 86.3%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results for Participating Systems</head><p>In the Japanese dictionary task, the following 7 systems of 3 organizations submitted answers. Notice that all systems used supervised learning techniques.</p><p>• Communications Research Laboratory and New York University (CRL1 "" CRL4)</p><p>The learning schemes were simple Bayes and support vector machine (SVM), and two kinds of hybrid models of simple Bayes and SVM.</p><p>• Tokyo Institute of Technology (Titech1, Titech2) Decision lists were learned from the training data. The features used in the decision lists were content words and POS tags in a window, and content words in example sentences contained in word sense descriptions in the Iwanami Kokugo Jiten.</p><p>• Nara Institute of Science and Technology (Naist)</p><p>The learning algorithm was SVM. The feature space was reconstructed using Principle Component Analysis(PCA) and Independent Component Analysis(ICA). The results of all systems are shown in Figure <ref type="figure">2</ref>. "Baseline" indicates the system which always selects the most frequent word sense ID, while "Agreement" indicates the agreement ratio between two annotators. All systems outperformed the baseline, and there was no remarkable difference between their scores (differences were 3 % at most).</p><p>Figure <ref type="figure">3</ref> indicates the mixed-grained scores for nouns and verbs. Comparing baseline system scores, the score for verbs was greater than that for nouns, even though the average entropy of verbs was higher than that of nouns (Table <ref type="table" target="#tab_2">1</ref>).</p><p>The situation was the same in CRL systems, bt not in Titech and Naist. The reason why them erage entropy was not coincident with the scor of the baseline was that the entropy of som verbs was so great that it raised the average er tropy disproportionately. Actually, the entrop of 7 verbs was greater than the maximum er tropy of nouns.</p><p>Figure <ref type="figure" target="#fig_1">4</ref> indicates the mixed-grained score for each word class. For word class De, ther was hardly any difference among scores of a: systems, including Baseline system and Agree ment. On the other hand, appreciable differenc was found for Da and Db.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper reports an overview of th SENSEVAL-2 Japanese dictionary task. Th data used in this task are available on th SENSEVAL-2 web site. I hope this valuabl, data helps all researchers to improve their WSI systems.</p><p>Acknowledgment I wish to express my gratitude to Mainich Newspapers for providing articles. I would als&lt; like to thank Prof. Takenobu Tokunaga (Toky&lt; Institute of Technology) and Prof. Sadao Kuro hashi (University of Tokyo) for valuable advisi about task organization, the annotators for con• structing gold standard data, and all partici• pants.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sense set of "MURI"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Figure 2: Results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Number of Target Words</figDesc><table><row><cell></cell><cell>Da</cell><cell>Db</cell><cell>De</cell><cell>all</cell></row><row><cell cols="5">10 nouns (9.1/1.19) (3.7 /0.723) (3.3/0.248) (4.6/0.627) 20 20 50</cell></row><row><cell>verbs</cell><cell cols="4">10 (18/1.77) (6.7 /0.728) (5.2/0.244) (8.3/0.743) 20 20 50</cell></row><row><cell>all</cell><cell cols="4">20 (14/1.48) (5.2/0. 725) ( 4.2/0.246) (6.5/0.685) ~ 40 40 100</cell></row><row><cell></cell><cell cols="3">(average polysemy j average entropy)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Inter-tagger Agreement    </figDesc><table><row><cell></cell><cell>Da</cell><cell>Db</cell><cell>De</cell><cell>(all)</cell></row><row><cell cols="5">nouns 0.809 0.786 0.957 0.859</cell></row><row><cell cols="5">verbs 0.699 0.896 0.922 0.867</cell></row><row><cell>all</cell><cell cols="4">0.754 0.841 0.939 0.863</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">They were hidden from participants at the contest.2  Notice that the training data had been released to the public before the contest began. This violated the SENSEVAL-2 schedule constraint that answer submission should not occur more than 21 days after downloading the training data.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The RWC texi databases</title>
		<author>
			<persName><forename type="first">Koiti</forename><surname>Hasida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the the firs, International Conference on Language Re• sources and Evaluation</title>
				<meeting>the the firs, International Conference on Language Re• sources and Evaluation</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="457" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Universal Decimal Classification</title>
		<author>
			<persName><surname>Infosta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>Maruzen, Tokyo</pubPlace>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Iwanami Kokugo Jiten Da\ Go Han</title>
		<author>
			<persName><forename type="first">Minoru</forename><surname>Nishio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etsutaro</forename><surname>Iwabuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizuc</forename><surname>Mizutani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Iwanami Publisher</publisher>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Guide tc the Universal Decimal Classification (UDC)</title>
		<imprint>
			<date type="published" when="1993" />
			<publisher>BSI</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
	<note>British Standards Organization</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Text database with word sense tags defined by I wanami Japanese dictionary. BIG notes of Information Processing Society of Japan</title>
		<author>
			<persName><forename type="first">Kiyoaki</forename><surname>Shirai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="117" to="122" />
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
