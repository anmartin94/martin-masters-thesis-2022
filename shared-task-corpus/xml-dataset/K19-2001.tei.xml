<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MRP 2019: Cross-Framework Meaning Representation Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Informatics</orgName>
								<orgName type="department" key="dep2">School of Computer Science and Engineering</orgName>
								<orgName type="department" key="dep3">Faculty of Mathematics and Physics</orgName>
								<orgName type="department" key="dep4">Institute of Formal and Applied Linguistics</orgName>
								<orgName type="institution" key="instit1">University of Oslo</orgName>
								<orgName type="institution" key="instit2">The Hebrew University of Jerusalem</orgName>
								<orgName type="institution" key="instit3">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Department of Computer and Information Science</orgName>
								<orgName type="department" key="dep3">Department of Linguistics</orgName>
								<orgName type="department" key="dep4">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">University of Copenhagen</orgName>
								<orgName type="institution" key="instit2">Linköping University</orgName>
								<orgName type="institution" key="instit3">University of Colorado at Boulder</orgName>
								<orgName type="institution" key="instit4">Brandeis University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Tim</forename><surname>O'gorman</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Zdeňka</forename><surname>Urešová</surname></persName>
						</author>
						<title level="a" type="main">MRP 2019: Cross-Framework Meaning Representation Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/K19-2001</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The 2019 Shared Task at the Conference for Computational Language Learning (CoNLL) was devoted to Meaning Representation Parsing (MRP) across frameworks. Five distinct approaches to the representation of sentence meaning in the form of directed graphs were represented in the training and evaluation data for the task, packaged in a uniform graph abstraction and serialization. The task received submissions from eighteen teams, of which five do not participate in the official ranking because they arrived after the closing deadline, made use of extra training data, or involved one of the task co-organizers. All technical information regarding the task, including system submissions, official results,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Background and Motivation</head><p>All things semantic are receiving heightened attention in recent years, and despite remarkable advances in vector-based (continuous and distributed) encodings of meaning, 'classic' (discrete and hierarchically structured) semantic representations will continue to play an important role in 'making sense' of natural language. While parsing has long been dominated by tree-structured target representations, there is now growing interest in general graphs as more expressive and arguably more adequate target structures for sentence-level analysis beyond surface syntax, and in particular for the representation of semantic structure.</p><p>The 2019 Conference on Computational Language Learning (CoNLL) hosts a shared task (or 'system bake-off') on Cross-Framework Meaning Representation Parsing <ref type="bibr">(MRP 2019)</ref>. The goal of the task is to advance data-driven parsing into graph-structured representations of sentence meaning. For the first time, this task combines formally and linguistically different approaches to meaning representation in graph form in a uniform training and evaluation setup. Participants were invited to develop parsing systems that support five distinct semantic graph frameworks (see §3 below)which all encode core predicate-argument structure, among other things-in the same implementation. Ideally, these parsers predict sentence-level meaning representations in all frameworks in parallel. Architectures utilizing complementary knowledge sources (e.g. via parameter sharing) were encouraged, though not required. Learning from multiple flavors of meaning representation in tandem has hardly been explored (with notable exceptions, e.g. the parsers of <ref type="bibr" target="#b69">Peng et al., 2017;</ref><ref type="bibr" target="#b33">Hershcovich et al., 2018;</ref><ref type="bibr" target="#b79">or Stanovsky and Dagan, 2018)</ref>.</p><p>Training and evaluation data were provided for all five frameworks. The task design aims to reduce framework-specific 'balkanization' in the field of meaning representation parsing. Its contributions include (a) a unifying formal model over different semantic graph banks ( §2), (b) uniform representations and scoring ( §4 and §6), (c) contrastive evaluation across frameworks ( §5), and (d) increased cross-fertilization via transfer and multi-task learning ( §7). Thus, the task engages the combined community of parser developers for graph-structured output representations, including from prior framework-specific tasks at the Semantic Evaluation (SemEval) exercises between 2014 and 2019 <ref type="bibr" target="#b52">May, 2016;</ref><ref type="bibr" target="#b53">May and Priyadarshi, 2017;</ref>. Owing to the scarcity of semantic anno-tations across frameworks, the MRP 2019 shared task is regrettably limited to parsing English for the time being.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Definitions: Graphs and Flavors</head><p>Reflecting different traditions and communities, there is wide variation in how individual meaning representation frameworks think (and talk) about semantic graphs, down to the level of visual conventions used in rendering graph structures. The following paragraphs provide semi-formal definitions of core graph-theoretic concepts that can be meaningfully applied across the range of frameworks represented in the shared task.</p><p>Basic Terminology Semantic graphs (across different frameworks) can be viewed as directed graphs or digraphs. A semantic digraph is a triple (T, N, E) where N is a set of nodes and E ⊆ N × N is a set of edges. The inand outdegree of a node count the number of edges arriving at or leaving from the node, respectively. In contrast to the unique root node in trees, graphs can have multiple (structural) roots, which we define as nodes with in-degree zero. The majority of semantic graphs are structurally multi-rooted. Thus, we distinguish one or several nodes in each graph as top nodes, T ⊂ N ; the top(s) correspond(s) to the most central semantic entities in the graph, usually the main predication(s).</p><p>In a tree, every node except the root has indegree one. In semantic graphs, nodes can have in-degree two or higher (indicating shared arguments), which constitutes a reentrancy in the graph. In contrast to trees, general digraphs may contain cycles, i.e. a directed path leading from a node to itself. Another central property of trees is that they are connected, meaning that there exists an undirected path between any pair of nodes. In contrast, semantic graphs need not generally be connected.</p><p>Finally, in some semantic graph frameworks there is a (total) linear order on the nodes, typically induced by the surface order of corresponding tokens. Such graphs are conventionally called bi-lexical dependencies and formally constitute ordered graphs. A natural way to visualize a bilexical dependency graph is to draw its edges as semicircles in the halfplane above the sentence. An ordered graph is called noncrossing if in such a drawing, the semicircles intersect only at their endpoints (this property is a natural generalization of projectivity as it is known from dependency trees).</p><p>A natural generalization of the noncrossing property, where one is allowed to also use the halfplane below the sentence for drawing edges is a property called pagenumber two. <ref type="bibr" target="#b45">Kuhlmann and Oepen (2016)</ref> provide additional definitions and a quantitative summary of various formal graph properties across frameworks.</p><p>Hierarchy of Formal Flavors In the context of the shared task, we distinguish different flavors of semantic graphs based on the nature of the relationship they assume between the linguistic surface signal (typically a written sentence, i.e. a string) and the nodes of the graph. We refer to this relation as anchoring (of nodes onto sub-strings); other commonly used terms include alignment, correspondence, or lexicalization.</p><p>Flavor (0) is the strongest form of anchoring, obtained in bi-lexical dependency graphs, where graph nodes injectively correspond to surface lexical units (i.e. tokens or 'words'). In such graphs, each node is directly linked to one specific token (conversely, there may be semantically empty tokens), and the nodes inherit the linear order of their corresponding tokens.</p><p>Flavor (1) includes a more general form of anchored semantic graphs, characterized by relaxing the correspondence between nodes and tokens, allowing arbitrary parts of the sentence (e.g. subtoken or multi-token sequences) as node anchors, as well as multiple nodes anchored to overlapping sub-strings. These graphs afford greater flexibility in the representation of meaning contributed by, for example, (derivational) affixes or phrasal constructions and facilitate lexical decomposition (e.g. of causatives or comparatives).</p><p>Finally, Flavor (2) semantic graphs do not consider the correspondence between nodes and the surface string as part of the representation of meaning (thus backgrounding notions of derivation and compositionality). Such semantic graphs are simply unanchored.</p><p>While different flavors refer to formally defined sub-classes of semantic graphs, we reserve the term framework for specific linguistic approaches to graph-based meaning representation (typically encoded in a particular graph flavor, of course).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Meaning Representation Frameworks</head><p>The shared task combines five frameworks for graph-based meaning representation, each with its specific formal and linguistic assumptions. This  <ref type="bibr" target="#b51">Marcus et al., 1993)</ref>:</p><p>(1) A similar technique is almost impossible to apply to other crops, such as cotton, soybeans and rice.</p><p>The example exhibits some interesting linguistic complexity, including what is called a tough adjective (impossible), a scopal adverb (almost), a tripartite coordinate structure, and apposition. The example graphs in Figures 1 through 3 are presented in order of (arguably) increasing 'abstraction' from the surface string, i.e. ranging from ordered Flavor (0) to unanchored Flavor (2).</p><p>Two of the frameworks in the shared task present simplifications into bi-lexical semantic dependencies (i.e. lossy reductions) of independently developed syntactico-semantic annotations. These representations were first prepared for the Semantic Dependency Parsing (SDP) tasks at the 2014 and 2015 SemEval campaigns . The SDP graph banks were originally released through the Linguistic Data Consortium (as catalogue entry LDC 2016T10); they comprise four distinct bi-lexical semantic dependency frameworks, from which the MRP 2019 shared task selects two (a) DELPH-IN MRS Bi-Lexical Dependencies (DM) and (b) Prague Semantic Dependencies (PSD). 1 1 Note, however, that the parsing problem for these frameworks is harder in the current shared task than in the ealier</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DELPH-IN MRS Bi-Lexical Dependencies</head><p>The DM bi-lexical dependencies <ref type="bibr" target="#b37">(Ivanova et al., 2012)</ref> originally derive from the underspecified logical forms computed by the English Resource Grammar <ref type="bibr" target="#b29">(Flickinger et al., 2017;</ref><ref type="bibr" target="#b17">Copestake et al., 2005)</ref>. These logical forms are not in and of themselves semantic graphs (in the sense of §2 above) and are often refered to as English Resource Semantics (ERS; <ref type="bibr" target="#b7">Bender et al., 2015)</ref>. The underlying grammar is rooted in the general linguistic theory of Head-Driven Phrase Structure Grammar (HPSG; <ref type="bibr" target="#b72">Pollard and Sag, 1994)</ref>. <ref type="bibr" target="#b37">Ivanova et al. (2012)</ref> propose a two-stage conversion from ERS into bi-lexical semantic dependency graphs, where ERS logical forms are first recast as Elementary Dependency Structures (EDS; <ref type="bibr" target="#b67">Oepen and Lønning, 2006</ref>; see below) and then further simplified into pure bi-lexical semantic dependencies, dubbed DELPH-IN MRS Bi-Lexical Dependencies (or DM). As a Flavor (0) framework, graph nodes in DM are restricted to surface tokens. But DM graphs are neither lexically fully covering nor rooted trees, i.e. some tokens do not contribute to the graph, and for some nodes there are multiple incoming edges. In the example DM graph in Figure <ref type="figure">1</ref>, technique semantically depends on the determiner (the quantificational locus), the modifier similar, and the predicate apply. Conversely, the predicative copula, infinitival to, and the vacu-SDP 2014 and 2015 tasks, because gold-standard tokenization, lemmas, and parts of speech are not available as part of the parser input data. Also, some minor lemmatization errors have been corrected for both the DM and PSD graphs, in comparison to the original SDP releases.</p><p>ous preposition marking the deep object of apply (in the top of Figure <ref type="figure">1</ref>) are analyzed as not having a semantic contribution of their own. The top node in the DM graph is the degree adverb almost, reflecting the underlying logical form, where almost has operator-like status scoping over the full proposition.</p><p>In DM, edge labels predominantly indicate semantic argument positions (ARG1, ARG2, . . . ) into the relation corresponding to their source node, but there are some more specialized edge labels too, like BV (bound variable) as a reflection of quantification in the underlying logic, conj and others for coordinate structures, and mwe to structurally tie together multi-token predicates. Node labels are tripartite, combining the lemmatized surface form with a part of speech (pos) and a frameworkspecific frame identifier. Together, these encode grammaticalized word sense distinctions, such as those between the nominal vs. verbal usages of crop or the distinct valency frames for three-place apply . . . to (e.g. paint, to the wall) vs. binary apply for (e.g. promotion).</p><p>Prague Semantic Dependencies Another instance of simplification from richer syntacticosemantic representations into Flavor (0) bi-lexical semantic dependencies is the reduction of tectogrammatical trees (or t-trees) from the linguistic school of Functional Generative Description (FGD; <ref type="bibr" target="#b76">Sgall et al., 1986;</ref><ref type="bibr" target="#b31">Hajič et al., 2012)</ref> into what are called Prague Semantic Dependencies (or PSD).  sketch the nature of this conversion, which essentially collapses empty (or generated, in FGD terminology) t-tree nodes with corresponding surface nodes and forward-projects incoming dependencies onto all members of paratactic constructions, e.g. the appositive and coordinate structures in the bottom of Figure <ref type="figure">1</ref>.</p><p>The PSD graph for our running example has many of the same dependency edges as the DM one (albeit using a different labeling scheme and inverse directionality in a few cases), but it analyzes the predicative copula as semantically contentful and does not treat almost as 'scoping' over the entire graph. The ADDR.m(ember) argument relation to the apply predicate has been recursively propagated to both elements of the apposition and to all members of the coordinate structure. Accordingly, edge labels in PSD are not in general functional, in the sense of allowing multiple outgoing edges from one node with the same label.</p><p>In FGD, role labels (called functors) ACT(or), PAT(ient), ADDR(essee), ORIG(in), and EFF(ect) indicate 'participant' positions in an underlying valency frame and, thus, correspond more closely to the numbered argument positions in other frameworks than their names might suggest. <ref type="bibr">2</ref> The PSD annotations are grounded in a machine-readable valency lexicon <ref type="bibr" target="#b88">(Urešová et al., 2016)</ref>, and the frame values on verbal nodes in Figure <ref type="figure">1</ref> indicate specific verbal senses in the lexicon.</p><p>Elementary Dependency Structures Elementary Dependency Structures (EDS; <ref type="bibr" target="#b67">Oepen and Lønning, 2006)</ref> encode English Resource Semantics in a variable-free semantic dependency graphnot limited to bi-lexical dependencies-where graph nodes correspond to logical predications and edges to labeled argument positions. The EDS conversion from underspecified logical forms to directed graphs discards partial information on semantic scope from the full ERS, which makes these graphs abstractly-if not linguistically-similar to Abstract Meaning Representation (see below).</p><p>Nodes in EDS are in principle independent of surface lexical units, but for each node there is an explicit, many-to-many anchoring onto sub-strings of the underlying sentence. Thus, EDS instantiates Flavor (1) in our hierarchy of different formal types of semantic graphs. Breaking free of the Flavor (0) one-to-one correspondence between graph nodes and surface lexical units enables EDS to more adequately represent, among other things, lexical decomposition (e.g. of comparatives), sublexical or construction semantics, and covert (e.g. elided) meaning contributions. All nodes in the example EDS in the top of Figure <ref type="figure">2</ref> make explicit their anchoring onto sub-strings of the underlying input, for example span 2 : 9 for similar.</p><p>In the EDS analysis for the running example, nodes representing covert quantifiers (e.g. on bare nominals, labeled udef q 3 ), the two-place such+as p relation, as well as the implicit conj(unction) relation (which reflects recursive decomposition of the coordinate structure  <ref type="bibr" target="#b84">(Sulem et al., 2015)</ref>. It has also been successfully used for improving text simplification <ref type="bibr" target="#b86">(Sulem et al., 2018b)</ref>, as well as to the evaluation of a number of text-to-text generation tasks <ref type="bibr" target="#b8">(Birch et al., 2016;</ref><ref type="bibr" target="#b85">Sulem et al., 2018a;</ref><ref type="bibr" target="#b16">Choshen and Abend, 2018)</ref>. The basic unit of annotation is the scene, denoting a situation mentioned in the sentence, typically involving a predicate, participants, and potentially modifiers. Linguistically, UCCA adopts a notion of semantic constituency that transcends pure dependency graphs, in the sense of introducing separate, unlabeled nodes, called units. One or more labels are assigned to each edge. Formally, UCCA has a Type (1) flavor, where leaf (or terminal) nodes of the graph are anchored to possibly discontinuous sequences of surface sub-strings, while interior (or 'phrasal') graph nodes are formally unanchored.</p><p>The UCCA graph for the running example (see the bottom of Figure <ref type="figure">2</ref>) includes a single scene, whose main relation is the Process (P) evoked by apply. It also contains a secondary relation labeled Adverbial (D), almost impossible, which is broken down into its Center (C) and Elaborator (E); as well as two complex arguments, labeled as Participants (A). Unlike the other frameworks in the task, the UCCA foundational layer integrates all surface tokens into the graph, possibly as the targets of semantically bleached Function (F) and Punctuation (U) edges. UCCA graphs need not be rooted trees: Argument sharing across units will give rise to reentrant nodes much like in the other frameworks. For example, technique in Figure <ref type="figure">2</ref> is both a Participant in the scene evoked by similar and a Center in the parent unit. UCCA in principle also supports implicit (unexpressed) units which do not correspond to any tokens, but these are currently excluded from parsing evaluation and, thus, suppressed in the UCCA graphs distributed in the context of the shared task.</p><p>Abstract Meaning Representation Finally, the shared task includes Abstract Meaning Representation (AMR; <ref type="bibr" target="#b4">Banarescu et al., 2013)</ref>, which in the MRP hierarchy of different formal types of semantic graphs (see §2 above) is simply unanchored, i.e. represents Flavor (2). The AMR framework is independent of particular approaches to derivation and compositionality and, accordingly, does not make explicit how elements of the graph correspond to the surface utterance. Although most AMR parsing research presupposes a pre-processing step that 'aligns' graph nodes with (possibly discontinuous) sets of tokens in the underlying input, this anchor-ing is not part of the meaning representation proper.</p><p>At the same time, AMR frequently invokes lexical decomposition and normalization towards verbal senses, such that AMR graphs often appear to 'abstract' furthest from the surface signal. Since the first general release of an AMR graph bank in 2014, the framework has provided a popular target for data-driven meaning representation parsing and has been the subject of two consecutive tasks at SemEval 2016 and 2017 <ref type="bibr" target="#b52">(May, 2016;</ref><ref type="bibr" target="#b53">May and Priyadarshi, 2017)</ref>.</p><p>The AMR example graph in Figure <ref type="figure" target="#fig_0">3</ref> has a topology broadly comparable to EDS, with some notable differences. Similar to the UCCA example graph (and unlike EDS), the AMR representation of the coordinate structure is flat. Although most lemmas are linked to derivationally related forms in the sense lexicon, this is not universal, as seen by the nodes corresponding to similar and such as, which are labeled as resemble-01 and exemplify-01, respectively. These sense distinctions (primarily for verbal predicates) are grounded in the inventory of predicates from the PropBank lexicon <ref type="bibr" target="#b41">(Kingsbury and Palmer, 2002;</ref><ref type="bibr" target="#b36">Hovy et al., 2006)</ref>.</p><p>Role labels in AMR encode semantic argument positions, with the particular roles defined according to each PropBank sense, though the counting in AMR is zero-based such that the ARG1 and ARG2 roles in Figure <ref type="figure" target="#fig_0">3</ref> often correspond to ARG2 and ARG3, respectively, in the EDS of Figure <ref type="figure">2</ref>. Prop-Bank distinguishes such numbered arguments from non-core roles labeled from a general semantic inventory, such as frequency, duration, or domain.</p><p>Figure <ref type="figure" target="#fig_0">3</ref> also shows the use of inverted edges in AMR, for example ARG1-of and mod. These serve to allow annotators (and in principle also parsing systems) to view the graph as a tree-like structure (with occasional reentrancies) but are formally merely considered notational variants. Therefore, the MRP rendering of the AMR example graph also provides an unambiguous indication of the underlying, normalized graph: Edges with a label component shown in parentheses are to be reversed in normalization, e.g. representing an actual ARG0 edge from resemble-01 to technique or a domain edge from other to crop.</p><p>Given the non-compositionality of AMR annotation, AMR allows the introduction of semantic concepts which have no explicit lexicalization in the text, for example the et-cetera element in the coordinate structure in Figure <ref type="figure" target="#fig_0">3</ref>  in the other frameworks (except UCCA), some surface tokens are analyzed as semantically vacuous.</p><p>For example, parallel to the PSD graph in Figure <ref type="figure">1</ref>, there is no meaning contribution annotated for the determiner a (let alone for covert determiners in bare nominals, as are made explicit as quantificational nodes in EDS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task Setup</head><p>The following paragraphs summarize the 'logistics' of the MRP 2019 shared task, including data and software provided to participants, the schedule, and rules of participation.</p><p>Training and Evaluation Data Table <ref type="table" target="#tab_3">1</ref> summarizes the primary training and evaluation data provided to task participants. The DM and PSD data sets are annotations over the exact same selection of texts, which for the eariler SemEval tasks have been aligned at the sentence and token levels. As DM was originally derived from EDS, the EDS graphs also cover the same texts. The training data for these frameworks draws from a homogeneous source, WSJ Sections 00-20 from the PTB. As a common point of reference, a sample of 100 WSJ sentences annotated in all five frameworks is available for public download from the task web site (see §9 below).</p><p>UCCA training annotations are over web reviews from the English Web Treebank (LDC 2012T13), and from English Wikipedia articles on celebrities. While in principle UCCA structures are not confined to a single sentence (about 0.18 percent of edges cross sentence boundaries), in the MRP context passages are split to individual sentences, discarding inter-relations between them, to create a standard setting across the frameworks.</p><p>AMR annotations are drawn from a wide variety of texts, with the majority of sentences coming from on-line discussion forums. The training corpus also contains newswire, folktales, fiction, and Wikipedia articles.</p><p>Table <ref type="table" target="#tab_5">2</ref> provides a quantitative side-by-side comparison of the training data, using some of the graph-theoretic properties discussed by <ref type="bibr" target="#b45">Kuhlmann and Oepen (2016)</ref>; see §2 for semi-formal definitions (the row indices in Table <ref type="table" target="#tab_5">2</ref> correspond to the numbering used by <ref type="bibr" target="#b45">Kuhlmann and Oepen, 2016)</ref>. The table indicates clear differences among the frameworks. The underlying input strings for AMR (where text selection is more varied), for example, are shorter; and EDS and UCCA have many more nodes per token, on average, than the other frameworks-reflecting lexical decomposition and 'phrasal' grouping, respectively, as evident in Figure 2. In some respects, the PSD and UCCA graphs are more tree-like than graphs in the other frameworks, for example in their proportions of actual rooted trees, the frequencies of reentrant nodes, and the lower percentages of multi-rooted structures. At the same time, PSD exhibits comparatively high average and maximal treewidth. Finally, the properties applicable to the ordered bi-lexical frameworks only are largely comparable, though PSD edges on average span over larger distances; propagation of dependencies into paratactic structures observed in Figure <ref type="figure">1</ref> may well contribute substantially to this quantitative difference.</p><p>Evaluation data for the five frameworks (also summarized in Table <ref type="table" target="#tab_3">1</ref>) draws on many of the same domains and genres, with two major additions: For DM, PSD, and EDS (where the training data is homogeneously comprised of newspaper texts), a little more than half of the evaluation data are taken from 'out-of-domain' texts, viz. a balanced sample of documents from the Brown Corpus (Francis and <ref type="bibr" target="#b30">Kučera, 1982)</ref>. Additionally, a fresh random selection of 100 sentences from the novel The Little Prince (by Antoine de Saint-Exupéry) was manually annotated with gold-standard semantic graphs   <ref type="bibr" target="#b45">Kuhlmann and Oepen (2016)</ref>. Here, % g and % n indicate percentages of all graphs and nodes, respectively, in each framework; AMR −1 refers to the normalized form of the graphs, with inverted edges reversed, as discussed in § 3. in all five frameworks. <ref type="bibr">4</ref> This subset of the evaluation data is available for download from the task site.</p><p>Because some of the semantic graph banks involved in the shared task had originally been released by the Linguistic Data Consortium (LDC), the training data was made available to task participants by the LDC under no-cost evaluation licenses. Upon completion of the competition, all task data (including system submissions and evaluation results) are being prepared for general release through the LDC, while those subsets that are copyright-free will also become available for direct, open-source download.</p><p>Additional Resources For reasons of comparability and fairness, the shared task constrained which additional data or pre-trained models (e.g. corpora, word embeddings, lexica, or other annotations) can be legitimately used besides the resources distributed by the task organizers. The overall goal was that all participants should in principle be able to use the same range of data. However, to keep such constraints to the minimum required, a 'white-list' of legitimate resources was compiled from nominations by participants (with a cut-off date six weeks before the end of the evalua-tion period). 5 Thus, the task design reflects what is at times called a closed track, where participants are constrained in which additional data and pretrained models can be used in system development.</p><p>At a technical level, training (and evaluation) data were distributed in two formats, (a) as sequences of 'raw' sentence strings and (b) in pretokenized, part-of-speech-tagged, lemmatized, and syntactically parsed form. For the latter, premiumquality English morpho-syntactic analyses were provided to participants, described in more detail below. These parser outputs are referred to as the MRP 2019 morpho-syntactic companion trees. Additional companion data available to participants includes automatically generated reference anchorings (commonly called 'alignments' in AMR parsing) for the AMR graphs in the training data, obtained from the JAMR and ISI tools of <ref type="bibr" target="#b27">Flanigan et al. (2016)</ref> and <ref type="bibr" target="#b74">Pourdamghani et al. (2014)</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Companion Dependency Trees</head><p>The optional morpho-syntactic trees were generated from the combination of a rule-based PTB-style tokenizer and a high-accuracy dependency parser trained on the union of (the majority of) available English syntactic treebanks. Notably, we applied an updated version of the converter by <ref type="bibr" target="#b75">Schuster and Manning (2016)</ref> to the PTB annotations of the Brown Corpus (Francis and <ref type="bibr" target="#b30">Kučera, 1982)</ref> and of the WSJ <ref type="formula">9</ref>Corpus, as well as to the PTB-style annotations of the GENIA Corpus <ref type="bibr" target="#b87">(Tateisi et al., 2005)</ref>. This conversion targets Universal Dependencies (UD; <ref type="bibr" target="#b54">McDonald et al., 2013;</ref><ref type="bibr" target="#b62">Nivre, 2015)</ref> version 2.x, so that the resulting gold-standard annotations could be concatenated with the UD English Web Treebank <ref type="bibr" target="#b77">(Silveira et al., 2014)</ref>, for a total of 2.2 million tokens annotated with lemmas, Universal and PTBstyle parts of speech, and UD labeled dependency trees.</p><p>We then trained the currently best-performing UDPipe architecture <ref type="bibr" target="#b81">(Straka, 2018;</ref>, which implements a joint part-of-speech tagger, lemmatizer, and dependency parser employing contextualized BERT embeddings. To avoid overlap of morpho-syntactic training data with the texts underlying the semantic graphs of the shared task, we performed five-fold jack-knifing on the WSJ and EWT corpora. For compatibility with the majority of the training data, the 'raw' input strings for the MRP semantic graphs were tokenized using the PTB-style REPP rules of <ref type="bibr" target="#b23">Dridan and Oepen (2012)</ref> and input to UDPipe in pre-tokenized form. Whether as merely a source of state-of-the-art PTBstyle tokenization, or as a vantage point for approaches to meaning representation parsing that start from explicit syntactic structure, the optional morpho-syntactic companion data offers community value in its own right.</p><p>Graph Interchange Format Besides differences in anchoring, the frameworks also vary in how they label nodes and edges, and to what degree they allow multiple edges between two nodes, multiple outgoing edges of the same label, or multiple instances of the same property on a node. Node labels for Flavor (0) graphs typically are lemmas, optionally combined with a (morpho-syntactic) part of speech and a (syntactico-semantic) frame (or sense) identifier. Node labels for the other graph flavors tend to be more abstract, i.e. are interpreted as concept or relation identifiers (where for the vast majority, of course, there also is a systematic relationship to lemmas, lexical categories, and (sub-)senses). Graph nodes in UCCA are formally unlabeled, and anchoring is used to relate leaf nodes of these graphs to input sub-strings. Conversely, edge labels in all cases come from a fixed and relatively small inventory of (semantic) argument names, though there is stark variation in label granularity, ranging between about a dozen in UCCA and around 90 or 100 in PSD and AMR, respectively; see Table <ref type="table" target="#tab_5">2</ref>. The shared task has, for the first time, repackaged the five graph banks into a uniform and normalized abstract representation with a common serialization format.</p><p>The common interchange format for semantic graphs implements the abstract model of <ref type="bibr" target="#b45">Kuhlmann and Oepen (2016)</ref> as a JSON-based serialization for graphs across frameworks. This format describes general directed graphs, with structured node and edge labels, and optional anchoring and ordering of nodes. JSON is easily manipulated in all programming languages and offers parser developers the option of 'in situ' augmentation of the graph representations from the task with system-specific additional information, e.g. by adding private properties to the JSON objects. The MRP interchange format is based on the JSON Lines format, where a stream of objects is serialized with line breaks as the separator character.</p><p>Each MRP graph is represented as a JSON object with top-level properties tops, nodes, and edges, reflecting the definitions in §2 above. Additionally, an input property on all graphs presents the 'raw' surface string corresponding to this graph; thus, parser inputs for the task are effectively assumed to be sentence-segmented but not pre-tokenized. Additional information about each graph is provided as properties id (a string), flavor (an integer in the range 0-2), framework (a string), version (a decimal number), and time (a string, encoding when the graph was serialized).</p><p>The nodes and edges values on graphs each are list-valued, but the order among list elements is only meaningful for the nodes of Flavor (0) graphs. Node objects have an obligatory id property (an integer) and optional properties called label, properties and values, as well as anchors. The label (a string) has a distinguished status in evaluation; the properties and values are both list-valued, such that elements between the lists correspond by position. Together, the two lists present a framework-specific, non-recursive attribute-value matrix (where duplicate properties are in principle allowed). The anchors list, if present, contains pairs of from-to sub-string indices into the input string of the graph. Finally, the edge objects in the top-level edges list all have two integer-valued properties: source and target, which encode the start and end nodes, respectively, to which the edge is incident. All edges in the MRP collection further have a (stringvalued) label property, although formally this is considered optional. Parallel to graph nodes, edges can carry framework-specific attributes and values lists; in MRP 2019, only the UCCA framework makes use of edge attributes, viz. a boolean remote flag (corresponding to dashed edges in the bottom of Figure <ref type="figure">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rules of Participation</head><p>The shared task was first announced in early March 2019, the initial release of the unified training data became available in mid-April, and the evaluation period ran between July 8 and 25, 2019; during this period, teams obtained the unannotated input strings for the evaluation data and had available a little more than two weeks to prepare and submit parser outputs. Submission of semantic graphs for evaluation was through the online CodaLab infrastructure, which proved a suboptimal choice-in part due to limited transparency and customization options of the service, in part because technical problems on the CodaLab site caused the entire infrastructure to be unavailable for five days during the MRP evaluation period.</p><p>Teams were allowed to make repeated submissions, but only the most recent successful upload to CodaLab within the evaluation period was considered for the official, primary ranking of submissions. Task participants were encouraged to process all inputs using the same general parsing system, but-owing to inevitable fuzziness about what constitutes 'one' parser-this constraint was not formally enforced. Unlike in recent years of other CoNLL shared tasks, processing of the evaluation data was not tied to a uniform virtualization platform (such as TIRA; <ref type="bibr" target="#b73">Potthast et al., 2014)</ref>, because GPU computing resources are a prerequisite to modern, neural parsing architectures but are not currently available on such platforms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>For each of the individual frameworks, there are established ways of evaluating the quality of parser outputs in terms of graph similarity to goldstandard target representations called EDM (Dridan and Oepen, 2011), SMATCH , SDP , and UCCA . There is broad similarity between the framework-specific evaluation metrics used to date, but also some subtle differences. Meaning representation parsing is commonly evaluated in terms of a graph similarity F 1 score at  the level of individual node-edge-node and nodeproperty-value triples. Variations in extant metrics relate to among others, how node correspondences across two graphs are established, whether edge labels can optionally be ignored in triple comparison, and how top nodes (and other node properties, including anchoring) are evaluated.</p><p>Background In a nutshell, semantic graphs in all frameworks can be broken down into 'atomic' component pieces, i.e. tuples capturing (a) top nodes, (b) node labels, (c) node properties, (d) node anchoring, (e) labeled edges, and (f) edge attributes. <ref type="bibr">6</ref> Not all tuple types apply to all frameworks, however, as is summarized in Table <ref type="table" target="#tab_7">3</ref>.</p><p>To evaluate any of these tuple types, a correspondence relation must be established between nodes (and edges) from the gold-standard vs. the system graphs. This relation presupposes a notion of node (and edge) identities, which is where the various flavors and frameworks differ. In bi-lexical (semantic) dependencies-e.g. DM and PSD, our Flavor (0)the nodes are surface lexical units (tokens); their identities are uniquely determined as the character range of the corresponding sub-strings (rather than by token indices, which would not be robust to tokenization mis-matches). In the Flavor (1) graphs (EDS and UCCA), multiple distinct nodes can have overlapping or even identical anchors; in EDS, for example, the semantics of an adverb like today is decomposed into four nodes, all anchored to the same substring:</p><formula xml:id="formula_0">implicit q x : time n(x) ∧ today a 1(x) ∧ temp loc(e, x) .</formula><p>The standard EDS and UCCA evaluation metrics determine node identities through anchors (and transitively the union of child anchors, in the case of UCCA) and allow many-to-many correspondences across the gold-standard and system graphs . Finally, as a Flavor (2) framework, nodes in AMR graphs are unanchored. Thus, node-to-node correspondences need to be established (as one-toone equivalence classes of node identifiers), to maximize the set of shared tuples between each pair of graphs. Abstractly, this is an instance of the NP-hard maximum common edge subgraph isomorphism problem (where node-local tuples can be modeled as 'pseudo-edges' with globally unique target nodes). The standard SMATCH scorer for AMR approximates a solution through a hill-climbing search for high-scoring correspondences, with a fixed number of random restarts .</p><p>Unified Evaluation For the shared task, we have implemented a generalization of existing, framework-specific metrics, along the lines above. Our goal is for the unified MRP metric to (a) be applicable across different flavors of semantic graphs, (b) enable labeled and unlabeled variants, as much as possible, (c) not require corresponding node anchoring, but (d) minimize the impact of nondeterministic approximations, and (e) take advantage of anchoring information when available. The official MRP metric for the task is the average F 1 score across frameworks over all tuple types.</p><p>The basic principle is that all information presented in the MRP graph representations is scored with equal weight, i.e. all applicable tuple types for each framework. There is no special status (or 'primacy') to anchoring in this scheme: Unlike the original SDP, EDM, and UCCA metrics, the MRP scorer searches for a correspondence relation between the gold-standard and system graphs that maximizes tuple overlap. Thus, the MRP approach is abstractly similar to SMATCH, but using a search algorithm that considers the full range of different tuple types and finds an exact solution in the majority of cases. <ref type="bibr">7</ref> Anchoring (for all frameworks but AMR) in this scheme is treated on a par with node labels and properties, labeled edges, and edge attributes. Likewise, the pos and frame (or sense) node properties in DM and PSD are scored with equal weight as the node labels (which are lemmas for the bi-lexical semantic graphs), given that the three properties jointly determine the semantic predicate.</p><p>For AMR evaluation, there is an exception to the above principle that all information in MRP graphs be scored equally: The MRP encodings of AMR graphs preserve the tree-like topology used in AMR annotations, using 'inverted' edges with labels like ARG0-of (see §3 above). To make explicit which AMR edges actually are inverted, the MRP encoding in JSON provides an additional normal property, which is present only an inverted edges and provides the effective 'base' label (e.g. ARG0). AMR graphs are standardly evaluated in normalized form, i.e. with inverted edges restored to their 'base' directionality and label.</p><p>Software Support MRP scoring is implemented in the open-source mtool software (the Swiss Army Knife of Meaning Representation), which is hosted in a public Microsoft GitHub repository to stimulate community engagement. 8 mtool implements a refinement of the maximum common edge subgraph (MCES) algorithm by <ref type="bibr" target="#b56">McGregor (1982)</ref>, initializing and scheduling candidate node-to-node correspondences based on pre-computed per-node rewards and upper bounds on adjacent edge correspondences. <ref type="bibr">9</ref> In addition to the cross-framework MRP metric, the tool also provides reference implementations of the SDP, EDM, SMATCH, and UCCA metrics, in the case of SDP and UCCA generalized to support character-based anchoring (rather than using token indices).</p><p>Value comparison in MRP evaluation is robust to 'uninteresting' variation, i.e. different encodings of essentially the same information. Specifically, literal values will always be compared as caseinsensitive strings, such that for example 42 (an integer) and "42" (a string) are considered equivalent, as are "Pierre" and "pierre"; this applies to node and edge labels, node properties, and edge attributes. Anchor values are normalized for comparison into sets of non-whitespace character positions. For example, assuming the underlying 8 See https://github.com/cfmrp/mtool for access to the software and available documentation. <ref type="bibr">9</ref> For the ordered DM and PSD graphs, an optimal initialization regarding node-local information can be efficiently computed, using an adaptation of the dynamic programming algorithm for minimum-edit-distance problems. For these graphs, scheduling of variant correspondences is further constrained to search for local variations first, i.e. alternate node-node pairings are considered in increasing node distance relative to the initial candidate correspondences.  not considered for the primary ranking because they used training data beyond the white-listed resources (indicated by the symbol "∦"), arrived after the closing deadline (" §"), or were prepared by the task co-organizers as points of reference (" †"). The secondary ranking (see § 6) considers all submissions by genuine task participants (excluding co-organizers), i.e. both the middle and bottom blocks (but not the 'reference' systems from the top block).</p><p>input string contains whitespace at character position 6, the following are considered equivalent: { 0 : 13 } and { 0 : 6 , 7 : 13 }. Furthermore, character positions corresponding to basic punctuation marks in the left or right periphery of a normalized anchor are discarded for comparison:</p><p>. ? ! : ; , " " " ' ' ' ( ) [ ] { }</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Submissions and Results</head><p>The task received submissions from sixteen teams, plus another two 'reference' submissions prepared by the task co-organizers <ref type="bibr" target="#b35">(Hershcovich and Arviv, 2019;</ref><ref type="bibr" target="#b64">Oepen and Flickinger, 2019)</ref>. These reference points are not considered in the overall ranking. Non-reference submissions are further subdivided into 'official' and 'unofficial' ones, where the latter are characterized by either arriving after the closing deadline of the evaluation period or using training data beyond the official resources provided (and white-listed) for the task; see §4 above.</p><p>Table <ref type="table" target="#tab_9">4</ref> provides an inventory of participating teams, where the top block corresponds to reference submissions from the co-organizers, and the bottom block shows unofficial submissions by task participants. In two cases, participants discovered serialization or other technical issues in their submissions shortly after the closing date and provided corrected parser outputs (ÚFAL MRPipe andÚFAL-Oslo). The two submissions from the Peking team are considered unofficial because they incorporate EDS-specific training data beyond the white-listed resources for the shared task (see §4 above). 10 And, finally, the Anonymous and CUHK submissions only became available a few days after the closing date of the evaluation period.</p><p>It is evident in Table <ref type="table" target="#tab_9">4</ref> that some submissions are partial, in the sense of not providing parser outputs for all target frameworks. Albeit not the ultimate goal of the cross-framework shared task design, such partiality was explicitly allowed to lower the technical barrier to entry and make it possible to include framework-specific parsers in the comparison. Seven (of thirteen) of the official submissions, as well as the two TUPA baselines, provide semantic graphs for all five frameworks. Three highly par-tial submissions declined the invitation to submit a system description for publication in the shared task proceedings (and one team asked to remain anonymous), such that only limited information is available about these parsers, and they will not be considered in further detail in §7.</p><p>Finally, based on input by task participants, Table 4 also provides an indication of which submissions employed multi-task learning (MTL) and a high-level characterization of the overall parsing approach. The distinction between transition-, factorization-, and composition-based architectures follows  and is discussed in more detail in §7 below. In some submissions there can of course be elements of more than one of these high-level architecture types. Also, not all of the teams who indicate the use of multi-task learning actually apply it across different semantic graph frameworks, but in some cases rather to multiple sub-tasks within the parsing architecture for a single framework. <ref type="bibr">11</ref> The main task results are summarized in Table <ref type="table" target="#tab_15">6</ref>, showing average MRP scores across frameworks, broken down by the different component pieces (see §5 above). These cross-framework averages can only be meaningfully compared for parsers that support all five frameworks, indicated with italics in the table. The top-three submissions achieve performance levels in the mid-80s F 1 range, followed by a competitive middle field of complete submissions that perform comparably to the TUPA baselines and well above. Despite fundamental architectural differences, there are emergent patterns in the average performance levels for different graph elements. Except for the binary top property, node-local information (fine-grained labels and properties) tend to be harder to predict than labeled edges. Edge attributes are only present in UCCA, encoding a binary distinction between primary and remote edges, which none of the parsers appear to predict successfully.</p><p>The correlation between the primary ranking of the official submissions (by overall average MRP F 1 ) and per-framework ranks is indicated in Table 5. The top-performing HIT-SCIR submission performs best on only one of the five frameworks (UCCA), but achieves uniformly strong results <ref type="bibr">11</ref> In the case of the SUDA-Alibaba submission, multi-task learning is only applied for the two bi-lexical frameworks; and for the Hitachi team it was only enabled in follow-up work after completion of the official evaluation period, as discussed in the system description by <ref type="bibr" target="#b44">Koreeda et al. (2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>DM PSD EDS UCCA AMR HIT-SCIR 2 : 2 4 : 3 2 : 3 1 : 1 2 : 2 SJTU-NICT 1 : 3 3 : 1 3 : 2 3 : 3 3 : 4 SUDA-Alibaba 7 : 7 8 : 8 1 : 1 2 : 2 5 : 5 Saarland 4 : 6 1 : 6 4 : 5 6 : 6 6 : 6 Hitachi 8 : 4 2 : 4 6 : 6 5 : 5 8 : 8 UFAL MRPipe 9 : 10 9 : 10 7 : 7 4 : 4 4 : 3 ShanghaiTech 3 : 1 6 : 2 5 : 4 10 : 10 7 : 7 Amazon 6 : 9 5 : 9 10 : 10 10 : 10 1 : 1 JBNU 5 : 5 7 : 5 10 : 10 7 : 8 11 : 11 SJTU 11 : 11 11 : 12 8 : 8 9 : 9 9 : 9 UFAL-Oslo 10 : 8 10 : 7 9 : 9 10 : 10 11 : 11 HKUST 12 : 12 12 : 11 10 : 10 8 : 7 11 : 11 Bocharov 13 : 13 13 : 13 10 : 10 10 : 10 10 : 10 across the board; the picture is similar for the second-ranked SJTU-NICT submission (which has the best performance on DM). For the other topperforming submissions, there is more variation across frameworks: SUDA-Alibaba is strongest on the Flavor (1) EDS and UCCA graphs, and Saarland and Hitachi rank first and second, respectively, on the PSD graphs, but are not among the top-three ranks for the other frameworks.</p><p>As indicated, Table <ref type="table" target="#tab_10">5</ref> shows the primary ranking, and unofficial submissions are not included. The complete summary of quantitative results from the task (see §9 below) also provides a secondary ranking, considering all submissions (but not reference points) and excluding those entries that are superseded by others from the same team, viz. the earlier submissions fromÚFAL MRPipe andÚFAL-Oslo and the EDS-only composition-based entry from Peking. In terms of secondary ranks, the unofficiaĺ UFAL MRPipe entry (correcting a minor bug in the original submission) would come in third overall (outranking SUDA-Alibaba), and the factorizationbased Peking submission would take an overall seventh rank (outranking ShanghaiTech, and notably showing overall best performance for the EDS framework). Remaining secondary ranks are eleventh, thirteenth, and sixtenth, forÚFAL-Oslo, CUHK, and Anonymous, respectively.           <ref type="bibr">.16 .16 .163 .19 .18 .185 .19 .19 .188 .19 .19 .187 .18 .18 .179 ---.18 .18 .184 .17 .17 .174 .18 .18 .181 .16 .18 .166 .19 .19 .190 .18 .18 .178 ---.18 .19 .183</ref>  and 'local' divergences in the rankings obtained from the different scoring approaches: In total, there are four instances of pairs of teams swapping ranks when comparing MRP vs. frameworkspecific results (the absolute per-framework scores in Table <ref type="table">7</ref> suggest that such 'fluctuation' primarily reflects minor differences in performance). For DM and PSD, on the other hand, Table <ref type="table" target="#tab_10">5</ref> reveals greater differences between the two ranks indicated in each cell: ShanghaiTech, for example, ranks much higher in the framework-specific SDP metric than in the official MRP ranks. These divergences likely reflect the more limited scope of the SDP approach to scoring, which essentially only considers labeled edges (and top nodes, as a pseudo-edge) but ignores node labels, properties, and anchors (which all used to be provided as part of the parser inputs in the original SDP parsing tasks; see §3 above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ShanghaiTech</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Peking</head><p>Finally, Tables <ref type="table">7 and 8</ref> complement the breakdown of official results from the shared task with two per-framework views, using the official MRP metric and earlier framework-specific metrics, respectively. On both views, there are stark differences in overall parser accuracy across frameworks-ranging from the low-70s to mid-90s F 1 ranges-with mostly decreasing performance when moving from the bi-lexical Flavor (0) graphs to the unanchored Flavor (2) ones. Given the crossframework MRP metric, these results become comparable for the first time (within the same parsing system at least, and assuming optimistically that it has been engineered and tuned at comparable effort levels for all frameworks). As such, it is tempting to interpret these differences as indicative of framework-specific parsing difficulty.</p><p>However, the volume, uniformity, and quality of available training data (and its similarity to evaluation data, in each framework) inevitably also must factor into such comparison; for example, goldstandard UCCA annotations count at less than one fifth the tokens of the other frameworks. Breaking down results further, viz. into component-wise per-framework scores (available through the task web site; see §9), suggests that scoring the more technical anchoring information at equal weight as the genuinely linguistic node and edge properties contributes to higher average MRP accuracies, in particular for the bi-lexical frameworks where anchors essentially encode tokenization. Ultimately, to put these differences into perspective more, con-trastive, phenomena-oriented studies would likely be called for, as for example the comparison of parsing accuracies for EDS vs. AMR by <ref type="bibr" target="#b48">Lin and Xue (2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Overview of Approaches</head><p>The participating systems in the shared task have approached this multi-meaning representation task in a variety of ways, which we characterize into three broad families of approaches: transition-, factorization-, or composition-based architectures.</p><p>Transition-Based Architectures In these parsing system, the meaning representation graph is generated via a series of actions, in a process that is very similar to dependency tree parsing, with the difference being that the actions for graph parsing need to allow reentrancies, as well as (possibly) non-token nodes, labels, properties, and attributes. At any given point in the parsing process, a parser state, which typically consists of a stack that holds already processed elements in the input and a buffer for yet-to-be processed elements, needs to be maintained. Which action to take next is predicted by a classifier using a representation of the parser state as input. When this parsing procedure is complete, the sequence of parsing actions will be used to deterministically reconstitute the meaning representation graph.</p><p>This basic method allows variations in various aspects of the parsing process. First of all, the set of actions can vary from system to system. Apart from the standard actions used in syntactic dependency parsing such as SHIFT, LEFTARC, RIGHTARC, and REDUCE <ref type="bibr" target="#b61">(Nivre, 2003;</ref><ref type="bibr" target="#b94">Yamada and Matsumoto, 2003)</ref>, transition systems in meaning representation parsing also include actions to create reentrant edges, such as LEFTREMOTE and RIGHTREMOTE from the pre-task version of TUPA <ref type="bibr" target="#b32">(Hershcovich et al., 2017)</ref>. It may also include actions to create abstract concepts that do not correspond to a word token in the input sentence, such as the NODE action from TUPA, and actions that allow the transition to skip a word token in the input when it does not have semantic content, such as the PASS action from HIT-SCIR. The transition set may also include actions that label the nodes or edges, such as LA-BEL in the version of TUPA used in the shared task. CUHK developed a transition-based parser with a general transition system suited for all five frameworks, by including a variable-arity RESOLVE action.  <ref type="bibr">.47 .67 .555 .44 .63 .518 .83 .79 .810 .20 .45 .276 .42 .48 .447 .50 .70 .586 .52 .68 .589 .83 .79 .814 .31 .57 .401 .43 .51 .470 TUPA multi .31 .69 .427 .45 .63 .526 .74 .74 .740 .17 .38 .236 .29 .41 .338 .28 .68 .395 .47 .65 .545 .74 .76 .748 .34 .52 .410 .45 .42</ref>    <ref type="table">7</ref>: Per-framework results using the official MRP metric. For each framework we report precision (P), recall (R), and F 1 score (F). Entries are split and sorted into the same three blocks as in Tables <ref type="table" target="#tab_9">4 and 6</ref>, and again the two rows per submission correspond to the full evaluation data and the Little Prince subset.  <ref type="bibr">.90 .91 .906 .80 .80 .796 .80 .78 .794 .34 .31 .324 .70 .63 .661 .91 .93 .919 .79 .80 .798 .87 .85 .860 .52 .49 .505 .73 .71 .722 Hitachi .91 .93 .919 .80 .82 .808 .78 .78 .783 .39 .37 .381 .46 .40 .425 .92 .94 .927 .80 .82 .807 .73 .79 .757 .47 .44 .454 .45 .45 .453 UFAL MRPipe .80 .70 .745 .69 .52 .594 .73 .49 .587 .42 .38 .396 .77 .67 .716 .81 .72 .759 .68 .45 .539 .67 .48 .560 .48 .42 .445 .74 .67</ref>   <ref type="bibr">[87]</ref><ref type="bibr">[88]</ref><ref type="bibr">[89]</ref><ref type="bibr">[90]</ref><ref type="bibr">[91]</ref><ref type="bibr">[92]</ref><ref type="bibr">[93]</ref>    <ref type="table">8</ref>: Results using the framework-specific (labeled) metrics: SDP (for DM and PSD), EDM (for EDS), UCCA, and SMTACH (for AMR); see § 5 above. For each framework (and its metric) we report precision (P), recall (R), and F 1 score (F). Entries are split and sorted into the same three blocks as in Tables <ref type="table" target="#tab_9">4 and 6</ref>, and again the two rows per submission correspond to the full evaluation data and the Little Prince subset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Saarland</head><p>Second, the classifier used to predict the action for any given state can also vary a great deal. For example, the HIT-SCIR system aggregates information from the action history, the stack, the list, and the buffer with a stack LSTM and then predicts the action by taking a softmax over the output of the LSTM. The CUHK system uses a regular LSTM to aggregate information from the stack, the sequence of words before the current word token, and the sequence of words after the current token, and then predict the action with a softmax. The TUPA system uses a BiLSTM with an MLP and softmax layer, with the BiLSTM running over the sequence of input tokens.</p><p>Factorization-Based Architectures These parsing models for meaning representation also have their roots in syntactic dependency parsing (where they are often called graph-based; <ref type="bibr" target="#b55">McDonald and Pereira, 2006)</ref>. Given a set of nodes, the basic idea of the factorization-based approach is to find the graph that has the highest score among all possible graphs. In the case of dependency parsing, the goal is to find the Maximum Spanning Tree, and this has been extended to meaning representation parsing, where the goal is to find the Maximum Spanning Connected Subgraphs <ref type="bibr" target="#b28">(Flanigan et al., 2014)</ref>. To make the computation of the score of a graph practical, the typical strategy is to factorize the score of a graph into the sum of the scores of its subgraphs, and in the case of first-order factorization, into the sum of the scores of its nodes and edges. A popular choice for predicting the edge is to feed the output of an LSTM encoder to a biaffine classifier to predict if an edge exists between a pair of nodes as well as the label of the edge (SJTU-NICT, SUDA-Alibaba, Hitachi, and JBNU), with slight variations as to the input to the LSTM encoder. Due to the difference in anchoring between the nodes in the graph and the word tokens in the sentence, the way to identify nodes also differs from framework to framework.ÚFAL-Oslo used the factorization-based NeurboParser <ref type="bibr" target="#b69">(Peng et al., 2017)</ref> for DM and PSD, and for EDS they simply submitted graphs identical to the DM ones. They also used the factorization-based JAMR <ref type="bibr" target="#b28">(Flanigan et al., 2014</ref><ref type="bibr" target="#b27">(Flanigan et al., , 2016</ref> for AMR, and further adjusted JAMR to support UCCA graphs, by converting UCCA to the standard AMR serialization.</p><p>Composition-Based Architectures Finally, this approach to meaning representation parsing empha-sizes the principle of compositionality in meaning construction and assumes an explict inventory of operations that combine pieces of meaning into larger fragments. Typically grounded in some kind of formal derivation process, compositionbased architectures associate meaning fragments with lexical items (leaf nodes in the derivation) and apply a designated composition operation for each step in the derivation. What differentiates composition-based approaches from transitionbased or factorization-based ones is that the derivations are licensed by some form of 'grammar' (explicit or implicit), where illegitimate derivations can be ruled out by the structural constraints over the lexical items and the rules of derivation. The MRP shared task attracted two (and a half) composition-based systems, the Apply-Modify (AM) algebra based system from Saarland and the Peking parser based on Synchronous Hyperedge Replacement Grammar (SHRG) for EDS. 12 For composition-based approaches, the extraction of lexical items from a sentence is a crucial component of the system. In the case of the Saarland parser, the lexical items are produced by a BiLSTM-based supertagger, and the best derivation is selected in a tree dependency parsing process where the edge between a head and its argument or modifier is labeled with the derivation operation. In the case of the Peking system, the SHRG rules are extracted with a context-free parser, and the derivation is scored by a sum of the scores of its subgraphs.</p><p>Other Approaches The transition-, factorization-, and composition-based systems represent the main approaches in the shared task, but there are a few systems that stretch the dividing lines of this this categorization. When parsing the UCCA framework, a number of systems-e.g. SJTU-NICT, SUDA-Alibaba, and Amazon-adopt an approach where 'remote' (reentrancy) edges are first removed to create constituent tree structures to train standard constituent tree parsers using neural network-based models, and then in a postprocessing stage, the remote edges are added back with a separate classifier, following .</p><p>The MRPipe system could be said to define its own category. It differs from transition-based systems in that it does not use the typical actions used in transition-based systems and it also does not maintain a typical parser state. It also differs from factorization-based systems in that it builds the meaning representation iteratively, while in a factorization-based systems all possible graphs are (conceptually) enumerated at once and the focus is on finding the graph with the highest score.</p><p>Anchoring One difference among the five meaning representation frameworks covered in the shared task is the correspondence relation between the concepts (graph nodes) and word tokens in the sentence (see §2). In Flavors (0) and (1) (DM, PSD, EDS, and UCCA), this alignment is explicit, while in Flavor (2) AMRs there is no explicit anchoring. How to tackle anchoring in the parsing system has a significant impact on parser performance. Some of the participating systems follow early approaches in AMR parsing and use a separate 'alignment' model to provide hard anchorings and then proceed with the rest of the parsing process (e.g. the HIT-SCIR system) assuming the alignments are already in place. Other submissions use a soft alignment component that is trained jointly with other components of their systems. For example, the Amazon and the SUDA-Alibaba parsers jointly model anchoring, node detection, and edge detection, adopting the approach of <ref type="bibr" target="#b50">Lyu and Titov (2018)</ref>, while the SJTU-NICT system uses a sequence-to-sequence model with a pointer-generator network to predict the concepts in AMR, following <ref type="bibr" target="#b95">Zhang et al. (2019a)</ref>. That sequence-to-sequence model is trained jointly with other components of their system.</p><p>Cross-Framework Architecture Design One question that the co-organizers would like to help answer through the shared task is to what degree the same general architecture can be used to effectively parse all five meaning representation frameworks. The answer to this question is tentatively in the affirmative. The HIT-SCIR and TUPA systems use a transition-based system to parse all five meaning representations, with the caveat that the transitions for the five meaning representations vary in the actions that are used. The CUHK parser, on the other hand, uses a uniform transition set for all frameworks. The Saarland system uses the same AM algebra composition system to parse all five meaning representations, but has to do a considerable amount of pre-processing to convert the meaning representations into well-formed terms of the AM algrebra (accordingly, some of the pre-processing effects need to be undone in post-processing). The MRPipe system adopts an approach in which the meaning representation graph is built up iteratively with two operations, ADDNODES and ADDEDGES, and applies this model successfully to all five meaning representations. Other participating systems adopt the strategy of using the model that they consider to be the most appropriate for a particular flavor of meaning representation. For example, the SJTU-NICT submission uses a factorization-based model for DM, PSD, and EDS parsing, but uses a constituent tree parsing approach for UCCA, as it is not obvious how a factorization-based model would be extended to also handle UCCA parsing. The Amazon system uses a factorization-based model for DM, PSD, and AMR while adopting a constituent tree parsing approach for UCCA and EDS. The SUDA-Alibaba system also adopts a constituent tree parsing approach to UCCA, similar to .</p><p>Benefits of Multi-Task Learning Another research question the shared task seeks to advance is whether and how multi-task learning (MTL) helps with multi-framework meaning representation parsing. The term, in fact, seems to be applied somewhat variably in the system descriptions. In one sense, it is equated with traditional joint learning, where different components of the SUDA-Alibaba system are trained jointly by combining their objectives. The sense of the term that was intended by the organizers is whether pooling the training data for all five frameworks in a multi-task learning framework can improve the parser performance of one particular framework. A number of participating systems attempted MTL in the latter sense, and the results are mixed and not definitive. The MTL version of the TUPA system performs much worse than its single-task version, but this might be attributed to inadequate training strategies and incomplete tuning. The Hitachi systems (in a postcompetition experiment) show MTL results that are slightly better than single framework results, but the difference is probably not statistically significant.</p><p>parsers also diverge in terms of their assumptions regarding the syntax-semantics interface, some parsing raw text directly to meaning representation graphs, and some producing the graphs from or in parallel with syntactic derivations.</p><p>While some meaning representations have parsers for languages other than English <ref type="bibr" target="#b89">Wang et al., 2018;</ref><ref type="bibr" target="#b18">Damonte and Cohen, 2018;</ref>, we limit the discussion here to the state of the art in English meaning representation parsing, as has been the focus of the current shared task. DM and PSD were both among the representations targeted in two SemEval shared tasks on Semantic Dependency Parsing , where the winning system <ref type="bibr" target="#b40">(Kanerva et al., 2015)</ref> utilized SVM-based sequence labeling. The runner-up <ref type="bibr" target="#b25">(Du et al., 2014</ref><ref type="bibr" target="#b26">(Du et al., , 2015</ref> used an ensemble based on factorization-based weighted tree approximation. More recently, <ref type="bibr" target="#b69">Peng et al. (2017</ref><ref type="bibr" target="#b70">Peng et al. ( , 2018a</ref> improved upon previous approaches by using a neural factorization-based multi-task system, sharing parameters between representations and applying joint inference. <ref type="bibr" target="#b79">Stanovsky and Dagan (2018)</ref> linearized the bi-lexical graphs and modeled the parsing task as a sequence-to-sequence problem. They also used multi-task learning, adapting multilingual machine translation algorithms to 'translate' between text and meaning representations, outperforming the previous best results on PSD. Lindemann et al. (2019) trained a composition-based parser on DM, PAS, PSD, AMR and EDS, using the Apply-Modify algebra, on which the Saarland submission to the shared task is based. They employed multi-task training with all tackled semantic frameworks and UD, establishing the state of the art on all graph banks but AMR 2017.</p><p>AMR has been a challenging target representation for parsing, due to the fact that AMRs are Flavor (2), unanchored graphs. AMR parsing was pioneered by <ref type="bibr" target="#b28">Flanigan et al. (2014)</ref>, who performed alignment as a preprocessing step during training. They developed their own rule-based alignment method, complemented by <ref type="bibr" target="#b74">Pourdamghani et al. (2014)</ref>, who adapted methods from machine translation. Some transition-based AMR parsers also perform rule-based alignment <ref type="bibr" target="#b19">(Damonte et al., 2017;</ref><ref type="bibr" target="#b18">Damonte and Cohen, 2018;</ref><ref type="bibr" target="#b3">Ballesteros and Al-Onaizan, 2017;</ref><ref type="bibr" target="#b59">Naseem et al., 2019)</ref>, while others derive AMRs from syntactic dependencies by applying transitions <ref type="bibr" target="#b92">(Wang et al., 2015;</ref><ref type="bibr" target="#b91">Wang and Xue, 2017)</ref>. The latter approach reached the best performance <ref type="bibr" target="#b90">(Wang et al., 2016;</ref><ref type="bibr" target="#b60">Nguyen and Nguyen, 2017)</ref> in two SemEval shared tasks on AMR parsing <ref type="bibr" target="#b52">(May, 2016;</ref><ref type="bibr" target="#b53">May and Priyadarshi, 2017)</ref>, where in the former it performed as well as a novel character-level neural translation based AMR parser <ref type="bibr" target="#b5">(Barzdins and Gosko, 2016)</ref>. Compositionbased AMR parsers include <ref type="bibr" target="#b1">Artzi et al. (2015)</ref>, who combined CCG grammar induction with AMR parsing. Sequence-to-sequence attention-based approaches <ref type="bibr" target="#b43">(Konstas et al., 2017;</ref><ref type="bibr" target="#b63">van Noord and Bos, 2017)</ref> use techniques from machine translation to directly generate (linearized) graphs from text. <ref type="bibr" target="#b50">Lyu and Titov (2018)</ref> parsed AMR using a joint probabilistic model with latent alignments, avoiding cascading errors due to alignment inaccuracies and outperforming previous approaches. The factorization-based parser by <ref type="bibr">Zhang et al. (2019a,b)</ref> uses an attention-based architecture, but derives target graphs directly instead of a linearization, also treating alignment as a latent variable with a copy mechanism. Their parser additionally supports UCCA and SDP, and establishes the stateof-the-art in AMR parsing, though without using multi-task training across frameworks.</p><p>UCCA parsing was first tackled by <ref type="bibr" target="#b32">Hershcovich et al. (2017)</ref>, who used a neural transition-based parser. <ref type="bibr" target="#b33">Hershcovich et al. (2018)</ref> further showed that multi-task learning with AMR, DM, and UD as auxiliary tasks improves UCCA parsing performance. UCCA also recently featured in a SemEval shared task , where the composition-based best system  outperformed the transition-based baseline by treating the task as constituency tree parsing with the recovery of remote edges as a postprocessing task. EDS, being a result of automatic conversion from English Resource Semantics <ref type="bibr" target="#b7">(Bender et al., 2015)</ref>, can be derived by any ERG parser (e.g. <ref type="bibr" target="#b11">Callmeier, 2002;</ref><ref type="bibr" target="#b68">Packard, 2012)</ref>. <ref type="bibr" target="#b9">Buys and Blunsom (2017)</ref> were the first to build a purely datadriven EDS parser, combining graph linearization with a custom transition system. <ref type="bibr" target="#b14">Chen et al. (2018)</ref> established the state of the art on data-driven EDS parsing, using a neural SHRG-based, ERG-guided parser. Their comparison on in-domain WSJ evaluation data showed parsing accuracies on par or in excess of the full, grammar-based ACE parser of <ref type="bibr" target="#b68">Packard (2012)</ref>.</p><p>While some shared task submissions are based on existing systems that have been specifically im-proved, direct comparison to previously published results is impossible: Our definition of the SDP task, for example, is different from ; prior EDS work has mostly tested on WSJ only; the UCCA annotations have been revised and extended; we are using a new, forthcoming version of AMRbank; and gold-standard tokenization is not provided for any of the frameworks. Also, even some of our framework-specific metrics are not exactly what was used previously: We have made SDP and UCCA character-based (for increased robustness to tokenization mismatches), and we un-invert edges more thoroughly in AMR graphs before calling SMATCH for scoring. However, overall performance levels and general trends observed in §6 appear consistent with recent developments in the field: By and large, the transition-, factorization-, and composition-based approaches all can yield competitive parsers, where crossframework multi-task learning sometimes helps but only slightly so. While general methods for meaning representation graph parsing are clearly beneficial, there is yet progress to be made (so far) in sharing information between parsers for different frameworks and making better use of their overlap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Reflections and Outlook</head><p>The MRP 2019 shared task was a first step in a new direction, aiming to more closely (inter)relate the representations and parsing approaches across a diverse range of semantic graph frameworks. Despite new uniformity in packaging and evaluation, cumulative overall complexity and inherent technical and linguistic diversity of the frameworks deemed participation in the competition a demanding challenge. The problem attracted broad interest: Some 140 individuals have subscribed to the shared task mailing list, and 38 teams obtained the training data package from the LDC (of these, sixteen submitted parser outputs for evaluation). In a post-evaluation questionnaire and through informal communication, several prospective participants have indicated that they had started to work towards a system submission but in the end simply ran out of time for the official evaluation period.</p><p>Possibly related to the high technological barrier to participation is the comparatively low proportion of submissions that successfully utilize multi-task learning (across frameworks). Even though some of the participating teams have previously applied multi-task learning for semantic graph parsing, it appears some may have shied away from increased training times and tuning effort and instead had to focus their work on developing strong end-toend parsers for individual frameworks. As task co-organizers, we remain committed to enabling continued research along these lines, and we will ultimately make all training and evaluation data generally available. In the interim, however, we are delighted (and a little frightened) to confirm that CoNLL has invited us to orchestrate a follow-up shared task on Cross-Framework Meaning Representation Parsing in 2020.</p><p>Deciding on the task parameters for MRP 2020 will be a balancing act between keeping overall complexity manageable, in particular for 'newcomer' participants, and pushing further in the direction of learning from complementary knowledge sources. Above all, the mid-to long-term goals of the cross-framework meaning representation initiative are to advance our understanding of degrees of complementarity among the various frameworks. Current plans foresee inclusion of one additional framework, viz. a graph-based encoding of the Discourse Representation Structures of <ref type="bibr" target="#b6">Basile et al. (2012)</ref>. Further, we plan on refining and extending the available training data (in particular for UCCA) and will put greater focus on the systematic exploration of variant evaluation perspectives, for example scoring at the level of larger sub-graphs in the spirit of the 'complete predications' metric of , or 'semantic n-grams' along the lines of the SemBleu proposal by <ref type="bibr" target="#b78">Song and Gildea (2019)</ref>. Aiming for increased linguistic diversity, it will of course also be tempting to seek to include meaning representations for additional languages. For each of the frameworks involved (six in total for MRP 2020), gold-standard annotations are in principle available for at least one language besides English, but in most cases these would be different languages for each framework. Thus, it remains yet to be decided how best to balance cross-linguistic and multi-task perspectives on the MRP problem.</p><p>All technical information regarding the MRP 2019 shared task, including system submissions, detailed official results, and links to supporting resources and software are available from the task web site at: http://mrp.nlpl.eu Many colleagues have assisted in designing the task and preparing its data and software resources. Emily M. Bender and Dan Flickinger provided a critical review of (a sample of) the DM and EDS graphs. Sebastian Schuster made available a prerelease of the converter from PTB-style constituent trees to (basic) UD 2.x dependency graphs. Dotan Dvir has coordinated the team of UCCA annotators, always ensuring that the corpora were ready in time. Andrey Kutuzov helped with the preparation of morpho-syntactic companion trees for the evaluation data.</p><p>The task design and implementation has benefited from input by the Steering Committee of the ACL Special Interest Group on Natural Language Learning, notably Xavier Carreras and Julia Hockenmaier, as well as by the CoNLL 2019 Programme Chairs, Mohit Bansal and Aline Villavicencio.</p><p>We are grateful to the Nordic e-Infrastructure Collaboration for their support to the Nordic Language Processing Laboratory (NLPL), which has provided technical infrastructure for the MRP 2019 task. Also, we thankfully acknowledge the assistance of the Linguistic Data Consortium in distributing the training data for the task to participants at no cost to anyone.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Abstract Meaning Representation (AMR) for the running example A similar technique is almost impossible to apply to other crops, such as cotton, soybeans and rice.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>. Conversely, like</figDesc><table><row><cell></cell><cell></cell><cell>DM</cell><cell>PSD</cell><cell>EDS</cell><cell>UCCA</cell><cell>AMR</cell></row><row><cell></cell><cell>Flavor</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>TRAIN</cell><cell>Text Type Sentences Tokens</cell><cell>newspaper 35,656 802,717</cell><cell>newspaper 35,656 802,717</cell><cell>newspaper 35,656 802,717</cell><cell>mixed 6,572 138,268</cell><cell>mixed 56,240 1,000,217</cell></row><row><cell>TEST</cell><cell>Text Type Sentences Tokens</cell><cell>mixed 3,359 64,853</cell><cell>mixed 3,359 64,853</cell><cell>mixed 3,359 64,853</cell><cell>mixed 1,131 21,647</cell><cell>mixed 1,998 39,520</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Quantitative summary of gold-standard training and evaluation data for the five frameworks.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Contrastive graph statistics for the MRP 2019 training data using a subset of the properties defined by</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Different tuple types per framework.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Overview of participating teams. The top and bottom blocks represent 'unofficial' submissions, which are</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Per-framework rankings of the official sub-</cell></row><row><cell>missions, contrasting the cross-framework MRP metric</cell></row><row><cell>(first in each cell) and framework-specific evaluation</cell></row><row><cell>(second). The order of entries reflects the primary rank-</cell></row><row><cell>ing by overall average MRP F 1 . Team names in italics</cell></row><row><cell>indicate submissions that support all five frameworks.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5</head><label>5</label><figDesc>also contrasts the ranking obtained from the official, cross-framework MRP metric in comparison to the pre-existing framework-specific metrics. For EDS, UCCA, and AMR there are only few</figDesc><table><row><cell>Tops</cell><cell></cell><cell>Labels</cell><cell></cell><cell cols="2">Properties</cell><cell cols="2">Anchors</cell><cell>Edges</cell><cell></cell><cell cols="2">Attributes</cell><cell>All</cell><cell></cell></row><row><cell>P R</cell><cell>F</cell><cell>P R</cell><cell>F</cell><cell>P R</cell><cell>F</cell><cell>P R</cell><cell>F</cell><cell>P R</cell><cell>F</cell><cell>P R</cell><cell>F</cell><cell>P R</cell><cell>F</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>.08 .097 .85 .85 .848 SJTU-NICT .92 .91 .915 .73 .70 .712 .71 .67 .687 .78 .77 .776 .80 .75 .777 .13 .07 .094 .87 .83 .853 .94 .92 .931 .71 .70 .702 .50 .52 .505 .78 .77 .778 .79 .76 .773 .10 .05 .069 .85 .84 .842 SUDA-Alibaba .88 .84 .860 .69 .70 .695 .68 .68 .682 .77 .77 .771 .77 .76 .768 .11 .07 .082 .84 .84 .840 .90 .87 .884 .65 .67 .662 .60 .67 .636 .77 .78 .775 .77 .77 .770 .13 .05 .076 .82 .84 .832 Saarland .83 .92 .867 .72 .71 .713 .72 .56 .611 .76 .75 .751 .76 .74 .750 ---.83 .80 .819 .88 .93 .905 .72 .72 .723 .61 .58 .586 .77 .77 .771 .79 .77 .778 ---.85 .85 .849 Hitachi .89 .90 .893 .64 .64 .641 .56 .54 .519 .75 .75 .755 .70 .69 .696 .08 .03 .042 .77 .75 .760 .91 .92 .917 .62 .63 .624 .48 .43 .374 .75 .77 .760 .71 .70 .703 .10 .02 .034 .75 .77 .762 UFAL MRPipe .83 .71 .751 .71 .59 .640 .70 .50 .565 .76 .64 .695 .70 .56 .622 .10 .06 .079 .83 .69 .747 .85 .72 .758 .67 .55 .604 .68 .47 .539 .76 .63 .686 .69 .55 .608 .12 .05 .068 .80 .67 .729</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>.56 .473 CUHK .51 .50 .502 .34 .40 .365 .29 .35 .317 .55 .59 .568 .10 .10 .095 ---.36 .41 .378 .51 .51 .514 .30 .39 .340 .24 .35 .283 .52 .62 .565 .09 .09 .</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">087 --</cell><cell>-.33 .42 .365</cell></row><row><cell>Anonymous</cell><cell>.04 .03 .035 .08 .13 .101 --.04 .04 .038 .07 .11 .084 --</cell><cell>--</cell><cell>----</cell><cell>--</cell><cell>----</cell><cell>--</cell><cell>----</cell><cell>-.02 .03 .022 -.01 .03 .019</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 6 :</head><label>6</label><figDesc>Official results using the cross-framework MRP metric, broken down by 'atomic' component pieces. For each component we report precision (P), recall (R), and F 1 score (F). Entries are split into the same three blocks as in Table4: references (top), official submissions (middle), and unofficial submissions (bottom). For each system, the first row shows MRP scores on the full evaluation set, while the second shows results on the public 100-sentence subset sampled from The Little Prince. The official and unofficial submissions are sorted by overall average F 1 .</figDesc><table /><note>Team names in italics indicate submissions that support all five frameworks.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head></head><label></label><figDesc>.951 .90 .91 .905 .91 .90 .907 .83 .81 .817 .77 .69 .729  .95 .95 .950 .85 .90 .874 .89 .90 .898 .84 .82 .826 .72 .66  .690 SJTU-NICT .96 .95 .955 .91 .91 .912 .95 .86 .899 .80 .76 .778 .75 .69 .720 .95 .95 .949 .86 .91 .885 .94 .88 .912 .77 .74 .755 .72 .70 .706 SUDA-Alibaba .91 .93 .923 .85 .86 .856 .92 .92 .918 .81 .76 .784 .73 .70 .717 .89 .92 .907 .79 .87 .828 .92 .93 .925 .85 .80 .821 .67 .69 .679 Saarland .95 .95 .947 .91 .91 .913 .90 .88 .891 .71 .65 .675 .70 .63 .667 .94 .95 .948 .86 .91 .883 .93 .91 .920 .78 .74 .762 .74 .72 .731 Hitachi .91 .91 .910 .91 .92 .912 .84 .84 .837 .72 .68 .704 .47 .41 .439 .89 .90 .894 .86 .91 .884 .78 .84 .811 .78 .73 .750 .47 .47 .470 UFAL MRPipe .91 .79 .850 .87 .68 .763 .82 .57 .674 .76 .71 .732 .77 .67 .718 .91 .80 .854 .82 .60 .691 .77 .57 .651 .78 .71 .741 .74 .67 .707   .431 .48 .48 .476 .75 .41 .532 .31 .35 .327 .40 .37 .385  .35 .53 .419 .47 .51 .488 .74 .44 .553 .31 .40 .353 .46 .42 .441   95 .947 .90 .92 .910 .90 .89 .891 .76 .71 .732 .77 .67 .718  .93 .95 .943 .85 .91 .878 .89 .90 .896 .78 .71 .740 .74 .67 .707   .805 .48 .83 .609 .27 .35 .306 .23 .07 .112 .58 .27 .364  .68 .91 .778 .43 .83 .566 .26 .43 .326 .23 .14 .175 .54 .50 .519   CUHK  .63 .75 .687 .60 .71 .648 .31 .25 .276 .18 .22 .196 .06 .12 .081  .57 .73 .644 .51 .70 .590 .31 .32 .313 .22 .26 .235 .03 .08 .042    </figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.434</cell></row><row><cell cols="10">HIT-SCIR .95 .95 ShanghaiTech .95 .95 .949 .90 .89 .895 .86 .88 .869 .94 .94 .943 .83 .88 .852 .86 .89 .875</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="2">.61 .66 .636 .66 .67 .668</cell></row><row><cell>Amazon</cell><cell cols="6">.94 .93 .933 .90 .90 .900 .92 .92 .921 .85 .91 .879</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="2">.75 .71 .734 .71 .72 .711</cell></row><row><cell>JBNU</cell><cell cols="6">.94 .94 .940 .88 .88 .879 .92 .92 .924 .84 .88 .857</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="3">.53 .49 .507 .66 .62 .636</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell cols="10">SJTU .36 .53 UFAL-Oslo .72 .91 .805 .48 .83 .609 .27 .35 .306 .68 .91 .778 .43 .83 .566 .26 .43 .326</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>HKUST</cell><cell cols="6">.34 .41 .370 .28 .48 .353 .32 .42 .364 .26 .48 .334</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="3">.51 .50 .502 .61 .58 .592</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>Bocharov</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="2">.37 .29 .327 .28 .44 .342</cell></row><row><cell cols="13">UFAL MRPipe .94 .Peking .94 .94 .944 .90 .89 .893 .95 .94 .945 .78 .77 .772 .92 .93 .925 .83 .88 .853 .92 .93 .928 .82 .78 .803</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell cols="3">UFAL-Oslo .72 .91 Anonymous ----</cell><cell>--</cell><cell cols="3">.08 .16 .109 .07 .15 .095</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>Peking</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="3">.92 .92 .918 .90 .93 .914</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head></head><label></label><figDesc>.670 .51 .60 .552 .77 .71 .741 .28 .19 .224 .41 .47 .438  .66 .71 .690 .55 .63 .585 .77 .72 .744 .32 .25 .284 .42 .49 .451   TUPA multi  .51 .62 .562 .47 .53 .501 .68 .64 .656 .28 .19 .224 .28 .39 .328  .50 .63 .557 .52 .59 .553 .67 .65 .660 .32 .25 .284 .42 .40  .411 HIT-SCIR .93 .92 .925 .81 .81 .810 .87 .86 .866 .68 .66 .667 .77 .69 .725 .94 .94 .937 .79 .80 .794 .85 .86 .857 .66 .63 .644 .71 .65 .680 SJTU-NICT .93 .92 .924 .82 .81 .817 .93 .83 .877 .63 .59 .609 .75 .68 .714 .94 .93 .936 .81 .81 .810 .93 .87 .897 .63 .57 .597 .71 .69 .696 SUDA-Alibaba .89 .91 .898 .76 .76 .760 .90 .89 .893 .66 .62 .639 .73 .70 .713 .88 .91 .895 .75 .77 .759 .90 .91 .903 .69 .63 .662 .66 .69 .674</figDesc><table><row><cell></cell><cell></cell><cell>DM</cell><cell></cell><cell></cell><cell>PSD</cell><cell></cell><cell></cell><cell>EDS</cell><cell></cell><cell></cell><cell>UCCA</cell><cell></cell><cell></cell><cell>AMR</cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>ERG</cell><cell cols="3">.91 .91 .912 .93 .93 .929</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="3">.93 .92 .926 .94 .95 .944</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>TUPA single</cell><cell cols="2">.65 .69</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>.379 .49 .26 .340 .66 .33 .435 .05 .04 .045 .39 .36 .373  .45 .27 .335 .52 .28 .359 .64 .34 .449 .06 .05 .055 .43 .39 .411    </figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>.700</cell></row><row><cell>ShanghaiTech</cell><cell cols="9">.94 .92 .930 .83 .81 .816 .81 .82 .814 .95 .94 .945 .82 .82 .819 .81 .84 .825</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="2">.61 .66 .631 .65 .66 .659</cell></row><row><cell>Amazon</cell><cell cols="6">.87 .86 .866 .76 .72 .742 .87 .87 .869 .77 .78 .771</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="2">.75 .71 .730 .70 .71 .704</cell></row><row><cell>JBNU</cell><cell cols="6">.92 .90 .912 .80 .80 .800 .93 .92 .926 .82 .81 .815</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="3">.19 .17 .177 .34 .31 .325</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell cols="10">SJTU .51 .30 UFAL-Oslo .90 .86 .880 .81 .73 .769 .14 .21 .168 .90 .88 .888 .82 .77 .795 .15 .27 .192</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>HKUST</cell><cell cols="6">.33 .27 .297 .45 .36 .398 .33 .27 .299 .47 .36 .412</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="3">.21 .20 .203 .25 .24 .244</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>Bocharov</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell cols="2">.35 .28 .314 .26 .41 .321</cell></row><row><cell>UFAL MRPipe</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Accordingly, multiple instances of the same core participant role-as ADDR.m in Figure1-will only occur with propagation of dependencies into paratactic constructions.3  In the EDS example in the top of Figure2, all nodes corresponding to instances of bare 'nominal' meanings are bound by a covert quantificational predicate, including the group-forming implicit conj and and c nodes that represent the nested, binary-branching coordinate structure. This practice of uniform quantifier introduction in ERS is acknowledged as "particularly exuberant" bySteedman (2011, p. 21).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Annotations of the full novel have long served as a common reference point for AMR, and gold-standard DM and EDS graphs could be converted from the ERS inter-annotator agreement study by<ref type="bibr" target="#b7">Bender et al. (2015)</ref>. For PSD and UCCA, the 100-sentence subset used for MRP evaluation has been annotated specifically for the shared task.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">See http://svn.nlpl.eu/mrp/2019/public/ resources.txt for the full list of seventeen generally available third-party resources, including a broad range of large English corpora and distributed word representations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">In principle, one could further view unlabeled edges and their labels as two distinct pieces of information, but the task design shies away from such formal purity for both linguistic and practical reasons. First, it does not appear desirable to try and give credit for edges with incompatible labels (e.g. an ARG1 with an ARG3); and, second, it would make the search for node-to-node correspondences somewhat less tractable.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">The MRP scorer further avoids a few known implementation issues in SMATCH related to over-counting, incomplete normalization, and top nodes.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">In the case of the factorization-based Peking submission, the extra training data is limited to gold-standard tokenization from the original EDS annotations, which in hindsight could in principle have been white-listed.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">The unofficial submission of DM and EDS reference graphs obtained from parsing with the ERG also represents a composition-based approach.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">On the State of the ArtPrior to the shared task, various methods have been proposed for semantic graph parsing, including transition-, factorization-, and composition-based, as well as sequence-to-sequence systems. Existing</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments We acknowledge the support of the Czech Ministry of Education, Youth, and Sports, through project CZ.02.1.01/0.0/0.0/16 013/0001781 (EF16 013/0001781); Czech Ministry of Culture, project DG16P02R019, the support for the data and services used by the Research Infrastructure projects LM2015071 and LM2018101, also of the Czech Ministry of Education, Youth, and Sports, and the support of the Grant Agency of the Czech Republic, project No. GA17-07313S. The work on UCCA and TUPA was partially supported by the Israel Science Foundation (grant no. 929/17). We also acknowledge the support of the US National Science Foundation on the Uniform Meaning Representation project via Award No. 1763926. All views expressed in this paper are those of the authors and do not necessarily represent the view of the National Science Foundation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">UCCA. A semantics-based grammatical annotation scheme</title>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Computational Semantics</title>
				<meeting>the 10th International Conference on Computational Semantics<address><addrLine>Potsdam, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Broad-coverage CCG semantic parsing with AMR</title>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1198</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1699" to="1710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SJTU at MRP 2019: A transition-based multi-task parser for cross-framework meaning representation parsing</title>
		<author>
			<persName><forename type="first">Hongxiao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="86" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">AMR parsing using stack-LSTMs</title>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1130</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1269" to="1275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Abstract Meaning Representation for sembanking</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
				<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR parsing accuracy</title>
		<author>
			<persName><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didzis</forename><surname>Gosko</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S16-1176</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1143" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Developing a large semantically annotated corpus</title>
		<author>
			<persName><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kilian</forename><surname>Evang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noortje</forename><surname>Venhuizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation</title>
				<meeting>the 8th International Conference on Language Resources and Evaluation<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3196" to="3200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Layers of interpretation. On grammar and compositionality</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Woodley</forename><surname>Packard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Copestake</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Conference on Computational Semantics</title>
				<meeting>the 11th International Conference on Computational Semantics<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="239" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">HUME. Human UCCA-based evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, TX, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1264" to="1274" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Robust incremental neural semantic graph parsing</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="158" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Smatch. An evaluation metric for semantic feature structures</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 51th Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Preprocessing and encoding techniques in PET</title>
		<author>
			<persName><forename type="first">Ulrich</forename><surname>Callmeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Collaborative Language Engineering. A Case Study in Efficient Grammar-based Processing</title>
				<editor>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
			<persName><forename type="first">Daniel</forename><surname>Flickinger</surname></persName>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
			<persName><forename type="first">Hans</forename><surname>Uszkoreit</surname></persName>
		</editor>
		<meeting><address><addrLine>Stanford, CA</addrLine></address></meeting>
		<imprint>
			<publisher>CSLI Publications</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="127" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Amazon at MRP 2019: Parsing meaning representations with lexical and phrasal anchoring</title>
		<author>
			<persName><forename type="first">Jie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adel</forename><surname>Youssef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivek</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-03" />
			<biblScope unit="page" from="138" to="148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">HIT-SCIR at MRP 2019: A unified pipeline for meaning representation parsing via efficient training and effective encoding</title>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Longxu</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="76" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Accurate SHRG-based semantic parsing</title>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="408" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Peking at MRP 2019: Factorization-and compositionbased parsing for Elementary Dependency Structures</title>
		<author>
			<persName><forename type="first">Yufei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajie</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="166" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Referenceless measure of faithfulness for grammatical error correction</title>
		<author>
			<persName><forename type="first">Leshem</forename><surname>Choshen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter</title>
				<meeting>the 2015 Conference of the North American Chapter<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Minimal Recursion Semantics. An introduction</title>
		<author>
			<persName><forename type="first">Ann</forename><surname>Copestake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><forename type="middle">A</forename><surname>Sag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Research on Language and Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="281" to="332" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Crosslingual abstract meaning representation parsing</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1146" to="1155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An incremental parser for abstract meaning representation</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Meeting of the European Chapter</title>
				<meeting>the 15th Meeting of the European Chapter<address><addrLine>Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Valencia</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="536" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Basic Linguistic Theory</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><surname>Dixon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Saarland at MRP 2019: Compositional parsing across all graphbanks</title>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Donatelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meaghan</forename><surname>Fowlie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Groschwitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Lindemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Mina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pia</forename><surname>Weißenhorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="66" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Parser evaluation using elementary dependency matching</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Dridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Parsing Technologies</title>
				<meeting>the 12th International Conference on Parsing Technologies<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="225" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tokenization. Returning to a long solved problem. A survey, contrastive experiment, recommendations, and toolkit</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Dridan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 50th Meeting of the Association for Computational Linguistics<address><addrLine>Jeju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="378" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">ÚFAL-oslo at MRP 2019: Garage sale semantic parsing</title>
		<author>
			<persName><forename type="first">Kira</forename><surname>Droganova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrey</forename><surname>Kutuzov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikita</forename><surname>Mediankin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="158" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Peking: Profiling syntactic tree parsing techniques for semantic graph parsing</title>
		<author>
			<persName><forename type="first">Yantao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/S14-2080</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
				<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="459" to="464" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Peking: Building semantic dependency graphs with a hybrid parser</title>
		<author>
			<persName><forename type="first">Yantao</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="927" to="931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">CMU at SemEval-2016 task 8. Graph-based AMR parsing with infinite ramp loss</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S16-1186</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1202" to="1206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the Abstract Meaning Representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Meeting of the Association for Computational Linguistics</title>
				<meeting>the 52nd Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sustainable development and refinement of complex linguistic annotations at scale</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Linguistic Annotation</title>
				<editor>
			<persName><forename type="first">Nacy</forename><surname>Ide</surname></persName>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</editor>
		<meeting><address><addrLine>The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="353" to="377" />
		</imprint>
	</monogr>
	<note>Dordrecht</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Frequency Analysis of English Usage. Lexicon and Grammar</title>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry</forename><surname>Kučera</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<pubPlace>Houghton Mifflin; New York, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Announcing Prague Czech-English Dependency Treebank 2.0</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Hajičová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarmila</forename><surname>Panevová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Sgall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Fučíková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Mikulová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Pajas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Popelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiří</forename><surname>Semecký</surname></persName>
		</author>
		<author>
			<persName><surname>Janašindlerová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Janštěpánek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zdeňka</forename><surname>Toman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zdeněkžabokrtský</forename><surname>Urešová</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation</title>
				<meeting>the 8th International Conference on Language Resources and Evaluation<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3153" to="3160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A transition-based directed acyclic graph parser for UCCA</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1127" to="1138" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multitask parsing across semantic representations</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="373" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">SemEval-2019 task 1. Cross-lingual semantic parsing with UCCA</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zohar</forename><surname>Aizenbud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leshem</forename><surname>Choshen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elior</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2001</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">TUPA at MRP 2019: A multi-task baseline system</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ofir</forename><surname>Arviv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">OntoNotes. The 90% solution</title>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2006 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers</title>
				<meeting>Human Language Technologies: The 2006 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers<address><addrLine>New York City, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Who did what to whom? A contrastive study of syntacto-semantic dependencies</title>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilja</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Linguistic Annotation Workshop</title>
				<meeting>the 6th Linguistic Annotation Workshop<address><addrLine>Jeju, Republic of Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">at SemEval-2019 task 1: UCCA graph parsing as constituent tree parsing</title>
		<author>
			<persName><surname>Hlt</surname></persName>
		</author>
		<author>
			<persName><surname>Suda</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, MI, USA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="11" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Turku: Semantic dependency parsing as a sequence classification</title>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="965" to="969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">From Tree-Bank to PropBank</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Language Resources and Evaluation</title>
				<meeting>the 3rd International Conference on Language Resources and Evaluation<address><addrLine>Las Palmas, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="1989" to="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Graph-based meaning representations. Design and processing</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weiwei</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-4002</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Meeting of the Association for Computational Linguistics: Tutorial Abstracts</title>
				<meeting>the 57th Meeting of the Association for Computational Linguistics: Tutorial Abstracts<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neural AMR: Sequence-to-sequence models for parsing and generation</title>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1014</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Hitachi at MRP 2019: Unified encoder-to-biaffine network for cross-framework meaning representation parsing</title>
		<author>
			<persName><forename type="first">Yuta</forename><surname>Koreeda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaku</forename><surname>Morio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terufumi</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroaki</forename><surname>Ozaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kohsuke</forename><surname>Yanai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="114" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Towards a catalogue of linguistic graph banks</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="819" to="827" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">CUHK at MRP 2019: Transitionbased parser with cross-framework variable-arity resolve action</title>
		<author>
			<persName><forename type="first">Sunny</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chun</forename><forename type="middle">Hei</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwong</forename><surname>Sak Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="104" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">SJTU-NICT at MRP 2019: Multi-task learning for end-toend uniform semantic graph parsing</title>
		<author>
			<persName><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eiichiro</forename><surname>Sumita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Parsing meaning representations. Is easier always better?</title>
		<author>
			<persName><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-3304</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Workshop on Designing Meaning Representations</title>
				<meeting>the First International Workshop on Designing Meaning Representations<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Compositional semantic parsing across graphbanks</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Lindemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Groschwitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Koller</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1450</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4576" to="4585" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">AMR parsing as graph prediction with latent alignment</title>
		<author>
			<persName><forename type="first">Chunchuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1037</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="397" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English. The Penn Treebank</title>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">SemEval-2016 Task 8. Meaning representation parsing</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05" />
			<biblScope unit="page" from="1063" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Abstract Meaning Representation parsing and generation</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>May</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jay</forename><surname>Priyadarshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="536" to="545" />
		</imprint>
	</monogr>
	<note>SemEval-2017 Task 9</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Universal dependency annotation for multilingual parsing</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvonne</forename><surname>Quirmbach-Brundage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipanjan</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kuzman</forename><surname>Ganchev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Täckström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 51th Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="92" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Online learning of approximate dependency parsing algorithms</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Meeting of the European Chapter of the Association for Computational Linguistics</title>
				<meeting>the 11th Meeting of the European Chapter of the Association for Computational Linguistics<address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Backtrack search algorithms and the maximal common subgraph problem</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">J</forename><surname>Mcgregor</surname></persName>
		</author>
		<idno type="DOI">10.1002/spe.4380120103</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Software: Practice and Experience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="23" to="34" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">In-House. An ensemble of pre-existing offthe-shelf parsers</title>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
				<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Jbnu at MRP 2019: Multi-level biaffine attention for semantic dependency parsing</title>
		<author>
			<persName><forename type="first">Jinwoo</forename><surname>Seung-Hoon Na</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kwanghyeon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jong-Hun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young-Kil</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="95" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Rewarding Smatch: Transition-based AMR parsing with reinforcement learning</title>
		<author>
			<persName><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Wan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1451</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4586" to="4592" />
		</imprint>
	</monogr>
	<note>Radu Florian, Salim Roukos, and Miguel Ballesteros</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">UIT-DANGNT-CLNLP at SemEval-2017 task 9: Building scientific concept fixing patterns for improving CAMR</title>
		<author>
			<persName><forename type="first">Khoa</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dang</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S17-2156</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="909" to="913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An efficient algorithm for projective dependency parsing</title>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Parsing Technologies</title>
				<meeting>the 8th International Conference on Parsing Technologies<address><addrLine>Nancy, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="149" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Towards a universal grammar of natural language processing</title>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Intelligent Text Processing and Computational Linguistics</title>
				<meeting>the 16th International Conference on Intelligent Text Processing and Computational Linguistics<address><addrLine>Cairo, Egypt</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Dealing with co-reference in neural semantic parsing</title>
		<author>
			<persName><forename type="first">Rik</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Semantic Deep Learning (SemDeep-2)</title>
				<meeting>the 2nd Workshop on Semantic Deep Learning (SemDeep-2)<address><addrLine>Montpellier, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The ERG at MRP 2019: Radically compositional semantic dependencies</title>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="40" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Broad-coverage semantic dependency parsing</title>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-01" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="915" to="926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Broad-coverage semantic dependency parsing</title>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Flickinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angelina</forename><surname>Ivanova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
				<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="63" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Discriminant-based MRS banking</title>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">Tore</forename><surname>Lønning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Language Resources and Evaluation</title>
				<meeting>the 5th International Conference on Language Resources and Evaluation<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1250" to="1255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Choosing an evaluation metric for parser design</title>
		<author>
			<persName><forename type="first">Woodley</forename><surname>Packard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Human Language Technologies: The 2012 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
				<meeting>Human Language Technologies: The 2012 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="29" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Deep multitask learning for semantic dependency parsing</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 55th Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2037" to="2048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Backpropagating through structured argmax using a SPIGOT</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1173</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1863" to="1873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Learning joint semantic parsers from disjoint data</title>
		<author>
			<persName><forename type="first">Hao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1492" to="1502" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Head-Driven Phrase Structure Grammar</title>
		<author>
			<persName><forename type="first">Carl</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><forename type="middle">A</forename><surname>Sag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Studies in Contemporary Linguistics</title>
				<meeting><address><addrLine>Chicago, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The University of Chicago Press</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Improving the reproducibility of PAN&apos;s shared tasks. Plagiarism detection, author identification, and author profiling</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative</title>
				<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Aligning English strings with Abstract Meaning Representation graphs</title>
		<author>
			<persName><forename type="first">Nima</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1048</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="425" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Enhanced English Universal Dependencies. An improved representation for natural language understanding tasks</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation</title>
				<meeting>the 10th International Conference on Language Resources and Evaluation<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">The Meaning of the Sentence and Its Semantic and Pragmatic Aspects</title>
		<author>
			<persName><forename type="first">Petr</forename><surname>Sgall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Hajičová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarmila</forename><surname>Panevová</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>D. Reidel Publishing Company</publisher>
			<pubPlace>Dordrecht, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">A gold standard dependency corpus for English</title>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miriam</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Conference on Language Resources and Evaluation</title>
				<meeting>the 9th International Conference on Language Resources and Evaluation<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">SemBleu: A robust metric for AMR parsing evaluation</title>
		<author>
			<persName><forename type="first">Linfeng</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Gildea</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1446</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4547" to="4552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Semantics as a foreign language</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1263</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2412" to="2421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Taking Scope</title>
		<author>
			<persName><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">UDPipe 2.0 prototype at CoNLL 2018 UD shared task</title>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="197" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">ÚFAL MR-Pipe at MRP 2019: UDPipe goes semantic in the Meaning Representation Parsing shared task</title>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jana</forename><surname>Straková</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="127" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jana</forename><surname>Straková</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.07448</idno>
		<title level="m">Evaluating Contextualized Embeddings on 54 Languages in POS Tagging, Lemmatization and Dependency Parsing</title>
				<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Conceptual annotations preserve structure across translations. A French-English case study</title>
		<author>
			<persName><forename type="first">Elior</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Semantics-Driven Statistical Machine Translation</title>
				<meeting>the 1st Workshop on Semantics-Driven Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="11" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Semantic structural annotation for text simplification</title>
		<author>
			<persName><forename type="first">Elior</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Simple and effective text simplification using semantic and neural methods</title>
		<author>
			<persName><forename type="first">Elior</forename><surname>Sulem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Syntax annotation for the GENIA corpus</title>
		<author>
			<persName><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akane</forename><surname>Yakushiji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd International Joint Conference on Natural Language Processing</title>
				<meeting>the 2nd International Joint Conference on Natural Language Processing<address><addrLine>Jeju, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="220" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">CzEngVallex. A bilingual Czech-English valency lexicon</title>
		<author>
			<persName><forename type="first">Zdeňka</forename><surname>Urešová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Fučíková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janašindlerová</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="17" to="50" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Transition-based Chinese AMR parsing</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="247" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">CAMR at SemEval-2016 task 8: An extended transition-based AMR parser</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ji</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1173" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Getting the most out of AMR parsing</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1257" to="1268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">A transition-based algorithm for AMR parsing</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="366" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">ShanghaiTech at MRP 2019: Sequence-to-graph transduction with second-order edge inference for cross-framework meaning representation parsing</title>
		<author>
			<persName><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixia</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengyue</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kewei</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="55" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Statistical dependency analysis with support vector machines</title>
		<author>
			<persName><forename type="first">Hiroyasu</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Parsing Technologies</title>
				<meeting>the 8th International Conference on Parsing Technologies<address><addrLine>Nancy, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="195" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">AMR parsing as sequence-tograph transduction</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xutai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1009</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="80" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Broad-coverage semantic parsing as transduction</title>
		<author>
			<persName><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xutai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Sudaalibaba at MRP 2019: Graph-based models with BERT</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingrong</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning</title>
				<meeting>the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="149" to="157" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
