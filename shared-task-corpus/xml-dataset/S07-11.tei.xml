<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2007 Task 11: English Lexical Sample Task via English-Chinese Parallel Text</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hwee</forename><forename type="middle">Tou</forename><surname>Ng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<addrLine>3 Science Drive 2</addrLine>
									<postCode>117543</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Yee</forename><forename type="middle">Seng</forename><surname>Chan</surname></persName>
							<email>chanys@comp.nus.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<addrLine>3 Science Drive 2</addrLine>
									<postCode>117543</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2007 Task 11: English Lexical Sample Task via English-Chinese Parallel Text</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We made use of parallel texts to gather training and test examples for the English lexical sample task. Two tracks were organized for our task. The first track used examples gathered from an LDC corpus, while the second track used examples gathered from a Web corpus. In this paper, we describe the process of gathering examples from the parallel corpora, the differences with similar tasks in previous SENSEVAL evaluations, and present the results of participating systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As part of the SemEval-2007 evaluation exercise, we organized an English lexical sample task for word sense disambiguation (WSD), where the senseannotated examples were semi-automatically gathered from word-aligned English-Chinese parallel texts. Two tracks were organized for this task, each gathering data from a different corpus. In this paper, we describe our motivation for organizing the task, our task framework, and the results of participants.</p><p>Past research has shown that supervised learning is one of the most successful approaches to WSD. However, this approach involves the collection of a large text corpus in which each ambiguous word has been annotated with the correct sense to serve as training data. Due to the expensive annotation process, only a handful of manually sense-tagged corpora are available.</p><p>An effort to alleviate the training data bottleneck is the Open Mind Word Expert <ref type="bibr">(OMWE)</ref> project <ref type="bibr" target="#b1">(Chklovski and Mihalcea, 2002)</ref> to collect sense-tagged data from Internet users. Data gathered through the OMWE project were used in the SENSEVAL-3 English lexical sample task. In that task, WordNet-1.7.1 was used as the sense inventory for nouns and adjectives, while Wordsmyth 1 was used as the sense inventory for verbs.</p><p>Another source of potential training data is parallel texts. Our past research in <ref type="bibr" target="#b4">(Ng et al., 2003;</ref><ref type="bibr" target="#b0">Chan and Ng, 2005)</ref> has shown that examples gathered from parallel texts are useful for WSD. Briefly, after manually assigning appropriate Chinese translations to each sense of an English word, the English side of a word-aligned parallel text can then serve as the training data, as they are considered to have been disambiguated and "sense-tagged" by the appropriate Chinese translations.</p><p>Using the above approach, we gathered the training and test examples for our task from parallel texts. Note that our examples are collected without manually annotating each individual ambiguous word occurrence, allowing us to gather our examples in a much shorter time. This contrasts with the setting of the English lexical sample task in previous SENSE-VAL evaluations. In the English lexical sample task of SENSEVAL-2, the sense tagged data were created through manual annotation by trained lexicographers. In SENSEVAL-3, the data were gathered through manual sense annotation by Internet users.</p><p>In the next section, we describe in more detail the process of gathering examples from parallel texts and the two different parallel corpora we used. We then give a brief description of each of the partici-pating systems. In Section 4, we present the results obtained by the participants, before concluding in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Gathering Examples from Parallel Corpora</head><p>To gather examples from parallel corpora, we followed the approach in <ref type="bibr" target="#b4">(Ng et al., 2003)</ref>. Briefly, after ensuring the corpora were sentence-aligned, we tokenized the English texts and performed word segmentation on the Chinese texts <ref type="bibr" target="#b3">(Low et al., 2005)</ref>.</p><p>We then made use of the GIZA++ software <ref type="bibr" target="#b5">(Och and Ney, 2000)</ref> to perform word alignment on the parallel corpora. Then, we assigned some possible Chinese translations to each sense of an English word w. From the word alignment output of GIZA++, we selected those occurrences of w which were aligned to one of the Chinese translations chosen. The English side of these occurrences served as training data for w, as they were considered to have been disambiguated and "sense-tagged" by the appropriate Chinese translations. The English half of the parallel texts (each ambiguous English word and its 3sentence context) were used as the training and test material to set up our English lexical sample task. Note that in our approach, the sense distinction is decided by the different Chinese translations assigned to each sense of a word. This is thus similar to the multilingual lexical sample task in SENSEVAL-3 <ref type="bibr" target="#b2">(Chklovski et al., 2004)</ref>, except that our training and test examples are collected without manually annotating each individual ambiguous word occurrence. The average time needed to assign Chinese translations for one noun and one adjective is 20 minutes and 25 minutes respectively. This is a relatively short time, compared to the effort otherwise needed to manually sense annotate individual word occurrences. Also, once the Chinese translations are assigned, more examples can be automatically gathered as more parallel texts become available.</p><p>We note that frequently occurring words are usually highly polysemous and hard to disambiguate. To maximize the benefits of our work, we gathered training data from parallel texts for a set of most frequently occurring noun and adjective types in the Brown Corpus. Also, similar to the SENSEVAL-3 English lexical sample task, we used WordNet-1.7.1 as our sense inventory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">LDC Corpus</head><p>We have two tracks for this task, each track using a different corpus. The first corpus is the Chinese English News Magazine Parallel Text (LDC2005T10), which is an English-Chinese parallel corpus available from the Linguistic Data Consortium (LDC </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Web Corpus</head><p>Since not all interested participants may have access to the LDC corpus described in the previous subsection, the second track of this task makes use of English-Chinese documents gathered from the URL pairs given by the STRAND Bilingual Databases. 3 STRAND <ref type="bibr" target="#b6">(Resnik and Smith, 2003)</ref> is a system that acquires document pairs in parallel translation automatically from the Web. Using this corpus, we gathered examples for 40 English words (20 nouns and 20 adjectives).</p><p>The rows Web noun and Web adjective in Table <ref type="table">1</ref> show that we selected an average of 182.0 training and 91.3 test examples for each noun and these examples represent an average of 3.5 senses per noun. We note that the average number of senses per word for the Web corpus is slightly lower than that of the LDC corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Annotation Accuracy</head><p>To measure the annotation accuracy of examples gathered from the LDC corpus, we examined a random selection of 100 examples each from 5 nouns and 5 adjectives. From these 1,000 examples, we measured a sense annotation accuracy of 84.7%. These 10 words have an average of 8.6 senses per word in the WordNet-1.7.1 sense inventory. As described in <ref type="bibr" target="#b4">(Ng et al., 2003)</ref>, when several senses of an English word are translated by the same Chinese word, we can collapse these senses to obtain a coarser-grained, lumped sense inventory. If we do this and measure the sense annotation accuracy with respect to a coarser-grained, lumped sense inventory, these 10 words will have an average of 6.5 senses per word and an annotation accuracy of 94.7%.</p><p>For the Web corpus, we similarly examined a random selection of 100 examples each from 5 nouns and 5 adjectives. These 10 words have an average of 6.5 senses per word in WordNet-1.7.1 and the 1,000 examples have an average sense annotation accuracy of 85.0%. After sense collapsing, annotation accuracy is 95.3% with an average of 4.8 senses per word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training and Test Data from Different Documents</head><p>In our previous work <ref type="bibr" target="#b4">(Ng et al., 2003)</ref>, we conducted experiments on the nouns of SENSEVAL-2 English lexical sample task. We found that there were cases where the same document contributed both training and test examples and this inflated the WSD accuracy figures. To avoid this, during our preparation of the LDC and Web data, we made sure that a document contributed only either training or test examples, but not both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Participating Systems</head><p>Three teams participated in the Web corpus track of our task, with each team employing one system. There were no participants in the LDC corpus track, possibly due to the licensing issues involved. All participating systems employed supervised learning and only used the training examples provided by us.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CITYU-HIF</head><p>The CITYU-HIF team from the City University of Hong Kong trained a naive Bayes (NB) classifier for each target word to be disambiguated, using knowledge sources such as parts-of-speech (POS) of neighboring words and single words in the surrounding context. They also experimented with using different sets of features for each target word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">HIT-IR-WSD</head><p>The system submitted by the HIT-IR-WSD team from Harbin Institute of Technology used Support Vector Machines (SVM) with a linear kernel function as the learning algorithm. Knowledge sources used included POS of surrounding words, local collocations, single words in the surrounding context, and syntactic relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">PKU</head><p>The system submitted by the PKU team from Peking University used a combination of SVM and maximum entropy classifiers. Knowledge sources used included POS of surrounding words, local collocations, and single words in the surrounding context. Feature selection was done by ignoring word features with certain associated POS tags and by selecting the subset of features based on their entropy values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>As all participating systems gave only one answer for each test example, recall equals precision and we will only report micro-average recall on the Web corpus track in this section.   In Table <ref type="table" target="#tab_4">3</ref> and Table <ref type="table" target="#tab_6">4</ref>, we show the scores obtained by each system on each of the 20 nouns and 20 adjectives. For comparison purposes, we also show the corresponding MFS score of each word. Paired t-test on the results of the top two systems show no significant difference between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We organized an English lexical sample task using examples gathered from parallel texts. Unlike the English lexical task of previous SENSEVAL evaluations where each example is manually annotated, we  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>). From this parallel corpus, we gathered examples for 50 English words (25 nouns and 25 adjectives) using the method described above. From the gathered examples of each word, we randomly selected training and test examples, where the number of training examples is about twice the number of test examples. The rows LDC noun and LDC adjective in Table 1 give some statistics about the examples. For instance, each noun has an average of 197.6 training and 98.5 test examples and these examples represent an average of 5.2 senses per noun. 2 Participants taking part in this track need to have access to this LDC corpus in order to access the training and test material in this track.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>gives the overall results obtained by each of the systems when evaluated on all the test examples of the Web corpus. We note that all the participants obtained scores which exceed the baseline heuristic of tagging all test examples with the most</figDesc><table><row><cell>System ID</cell><cell>Contact author</cell><cell>Learning algorithm</cell><cell>Score</cell></row><row><cell cols="2">HIT-IR-WSD Yuhang Guo, &lt;astronaut@ir.hit.edu.cn&gt;</cell><cell>SVM</cell><cell>0.819</cell></row><row><cell>PKU</cell><cell>Peng Jin, &lt;jandp@pku.edu.cn&gt;</cell><cell cols="2">SVM and maximum entropy 0.815</cell></row><row><cell>CITYU-HIF</cell><cell>Oi Yee Kwong, &lt;rlolivia@cityu.edu.hk&gt;</cell><cell>NB</cell><cell>0.753</cell></row><row><cell>MFS</cell><cell>-</cell><cell cols="2">Most frequent sense baseline 0.689</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Overall micro-average scores of the participants and the most frequent sense (MFS) baseline.</figDesc><table><row><cell>Noun</cell><cell cols="4">MFS CITYU-HIF HIT-IR-WSD PKU</cell></row><row><cell>age</cell><cell>0.486</cell><cell>0.643</cell><cell>0.743</cell><cell>0.700</cell></row><row><cell>area</cell><cell>0.480</cell><cell>0.693</cell><cell>0.773</cell><cell>0.773</cell></row><row><cell>body</cell><cell>0.872</cell><cell>0.897</cell><cell>0.910</cell><cell>0.923</cell></row><row><cell>change</cell><cell>0.411</cell><cell>0.400</cell><cell>0.578</cell><cell>0.611</cell></row><row><cell>director</cell><cell>0.580</cell><cell>0.890</cell><cell>0.960</cell><cell>0.960</cell></row><row><cell>experience</cell><cell>0.830</cell><cell>0.830</cell><cell>0.880</cell><cell>0.840</cell></row><row><cell>future</cell><cell>0.889</cell><cell>0.889</cell><cell>0.990</cell><cell>0.990</cell></row><row><cell>interest</cell><cell>0.308</cell><cell>0.165</cell><cell>0.813</cell><cell>0.780</cell></row><row><cell>issue</cell><cell>0.651</cell><cell>0.711</cell><cell>0.892</cell><cell>0.855</cell></row><row><cell>life</cell><cell>0.820</cell><cell>0.830</cell><cell>0.860</cell><cell>0.740</cell></row><row><cell>material</cell><cell>0.719</cell><cell>0.719</cell><cell>0.781</cell><cell>0.641</cell></row><row><cell>need</cell><cell>0.907</cell><cell>0.907</cell><cell>0.918</cell><cell>0.918</cell></row><row><cell cols="2">performance 0.410</cell><cell>0.570</cell><cell>0.690</cell><cell>0.700</cell></row><row><cell>program</cell><cell>0.590</cell><cell>0.590</cell><cell>0.730</cell><cell>0.690</cell></row><row><cell>report</cell><cell>0.870</cell><cell>0.840</cell><cell>0.880</cell><cell>0.870</cell></row><row><cell>system</cell><cell>0.510</cell><cell>0.700</cell><cell>0.610</cell><cell>0.730</cell></row><row><cell>time</cell><cell>0.455</cell><cell>0.673</cell><cell>0.733</cell><cell>0.693</cell></row><row><cell>today</cell><cell>0.800</cell><cell>0.750</cell><cell>0.800</cell><cell>0.780</cell></row><row><cell>water</cell><cell>0.882</cell><cell>0.921</cell><cell>0.868</cell><cell>0.895</cell></row><row><cell>work</cell><cell>0.644</cell><cell>0.743</cell><cell>0.842</cell><cell>0.891</cell></row><row><cell>Micro-avg</cell><cell>0.656</cell><cell>0.719</cell><cell>0.813</cell><cell>0.802</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Micro-average scores of the most frequent sense baseline and the various participants on each noun.frequent sense (MFS) in the training data. This suggests that the Chinese translations assigned to senses of the ambiguous words are appropriate and provide sense distinctions which are clear enough for effective classifiers to be learned.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Micro-average scores of the most frequent sense baseline and the various participants on each adjective.only need to assign appropriate Chinese translations to each sense of a word. Once this is done, we automatically gather training and test examples from the parallel texts. All the participating systems of our task obtain results that are significantly better than the most frequent sense baseline.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://www.wordsmyth.net</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Only senses present in the examples are counted. 3 http://www.umiacs.umd.edu/∼resnik/strand</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>Yee Seng Chan is supported by a Singapore Millennium Foundation Scholarship (ref no. SMF-2004(ref no. SMF- -1076.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Scaling up word sense disambiguation via parallel texts</title>
		<author>
			<persName><forename type="first">Yee</forename><surname>Seng Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AAAI05</title>
				<meeting>AAAI05<address><addrLine>Pittsburgh, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1037" to="1042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Building a sense tagged corpus with Open Mind Word Expert</title>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Chklovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions</title>
				<meeting>ACL02 Workshop on Word Sense Disambiguation: Recent Successes and Future Directions<address><addrLine>Philadelphia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="116" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The SENSEVAL-3 multilingual English-Hindi lexical sample task</title>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Chklovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amruta</forename><surname>Purandare</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SENSEVAL-3</title>
				<meeting>SENSEVAL-3<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="5" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A maximum entropy approach to Chinese word segmentation</title>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">Kiat</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenyuan</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth SIGHAN Workshop on Chinese Language Processing</title>
				<meeting>the Fourth SIGHAN Workshop on Chinese Language Processing<address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="161" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploiting parallel texts for word sense disambiguation: An empirical study</title>
		<author>
			<persName><forename type="first">Bin</forename><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yee Seng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL03</title>
				<meeting>ACL03<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="455" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improved statistical alignment models</title>
		<author>
			<persName><forename type="first">Josef</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeedings of ACL00</title>
				<meeting>eeedings of ACL00<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="440" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The web as a parallel corpus</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="380" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
