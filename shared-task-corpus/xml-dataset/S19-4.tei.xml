<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2019 Task 4: Hyperpartisan News Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Maria</forename><surname>Mestre</surname></persName>
							<email>mariarmestre@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Factmata Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rishabh</forename><surname>Shukla</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Factmata Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Emmanuel</forename><surname>Vincent</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Factmata Ltd</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Payam</forename><surname>Adineh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Corney</surname></persName>
							<email>dpacorney@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<email>martin.potthast@uni-leipzig.de</email>
							<affiliation key="aff2">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<address>
									<addrLine>1 0.822 0.871 0.755 0.809 8 0.643 0.616 0.762 0.681 Vernon Fenwick Srivastava et al. 2 0.820 0.815 0.828 0.821 Sally Smedley Hanawa et al. 3 0.809 0.823 0.787 0.805 11 0.625 0.640 0.571 0.603 Tom Jumbo Grumbo Yeh et al. 4 0.806 0.858 0.732 0.790 13 0.619 0.592 0.762 0.667 Dick Preston Isbister and Johansson 5 0.803 0.793 0.818 0.806 27 0.514 0.520 0.352 0.420 Borat Sagdiyev Palić et al. 6 0.791 0.883 0.672 0.763 19 0.592 0.644 0.412 0.502 Morbo Isbister and Johansson 7 0.790 0.772 0.822 0.796 16 0.601 0.587 0.679 0.630 Howard Beale Mutlu et al. 8 0.783 0.837 0.704 0.765 9 0.641 0.606 0.806 0.692 Ned Leeds Stevanoski and Gievska 9 0.775 0.865 0.653 0.744 22 0.573 0.546 0.857 0.667 Clint Buchanan Drissi et al. 10 0.771 0.832 0.678 0.747 Yeon Zi Lee et al. 11 0.758 0.744 0.787 0.765 5 0.663 0.635 0.766 0.694 Tony Vincenzo Staykovski 12 0.750 0.764 0.723 0.743 Paparazzo Nguyen et al. 13 0.747 0.754 0.732 0.743 24 0.530 0.530 0.541 0.535 Steve Martin Joo and Hwang 14 0.745 0.853 0.592 0.699 18 0.597 0.625 0.483 0.545 Eddie BrockSajatović et al. 15 0.744 0.782 0.675 0.725 10 0.631 0.681 0.491 0.571 Ankh Morpork Times Almendros et al. 16 0.742 0.811 0.631 0.710 21 0.588 0.646 0.389 0.486 Spider Jerusalem Alabdulkarim and Alhindi 17 0.742 0.814 0.627 0.709 Carl Kolchak Chen et al. 18 0.739 0.729 0.761 0.745 Doris Martin Agerri 19 0.737 0.754 0.704 0.728 Pistachon Saleh et al. 20 0.729 0.724 0.742 0.733 15 0.608 0.638 0.499 0.560 Joseph Rouletabille Moreno et al. 21 0.725 0.788 0.615 0.691 2 0.680 0.640 0.827 0.721 Fernando Pessa Cruz et al. 22 0.717 0.806 0.570 0.668 17 0.600 0.585 0.681 0.630 Pioquinto Manterola Sengupta and Pedersen 23 0.704 0.741 0.627 0.679 Miles Clarkson Zhang et al. 24 0.683 0.745 0.557 0.638 6 0.652 0.612 0.832 0.705 Xenophilius Lovegood Zehe et al. 25 0.675 0.619 0.914 0.738 4 0.663 0.632 0.781 0.699 Orwellian Times Knauth 26 0.672 0.654 0.729 0.690 23 0.537 0.530 0.658 0.587 Tintin Bestgen 27 0.656 0.642 0.707 0.673 1 0.706 0.742 0.632 0.683 D X Beaumont Amason et al. 28 0.653 0.597 0.939 0.730 Jack Ryder Shaprin et al. 29 0.646 0.646 0.646 0.646 7 0.645 0.600 0.869 0.710 Kermit the Frog Anthonio and Kloppenburg 30 0.621 0.582 0.860 0.694 20 0.589 0.575 0.681 0.623 Billy Batson Kreutz et al. 31 0.615 0.568 0.962 0.714 Peter Brinkmann Färber et al. 32 0.602 0.560 0.955 0.706 28 0.497 0.496 0.344 0.406 Anson Bryson Stiff and Medero 33 0.592 0.720 0.303 0.426 Sarah Jane Smith Chakravartula et al. 34 0.591 0.554 0.933 0.695 14 0.612 0.586 0.765 0.664 Kit Kittredge Cramerus and Scheffler 35 0.578 0.547 0.908 0.683 Brenda Starr Papadopoulou et al. 36 0.575 0.542 0.971 0.696 3 0.664 0.627 0.807 0.706 Harry Friberg Afsarmanesh et al. 37 0.565 0.537 0.949 0.686 Robin Scherbatsky Marx and Akut 38 0.551 0.542 0.662 0.596 25 0.524 0.822 0.062 0.116 Clark Kent Gupta et al. 39 0.548 0.683 0.178 0.283 26 0.519 0.565 0.170 0.261 Murphy Brown Sen and Jiang 40 0.529 0.518 0.822 0.635 12 0.623 0.615 0.659 0.636 Peter Parker Ning et al. 41 0.503 0.502 0.771 0.608 John King Bansal et al</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2019 Task 4: Hyperpartisan News Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.5281/zenodo.1489920</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hyperpartisan news is news that takes an extreme left-wing or right-wing standpoint. If one is able to reliably compute this meta information, news articles may be automatically tagged, this way encouraging or discouraging readers to consume the text. It is an open question how successfully hyperpartisan news detection can be automated, and the goal of this SemEval task was to shed light on the state of the art. We developed new resources for this purpose, including a manually labeled dataset with 1,273 articles, and a second dataset with 754,000 articles, labeled via distant supervision. The interest of the research community in our task exceeded all our expectations: The datasets were downloaded about 1,000 times, 322 teams registered, of which 184 configured a virtual machine on our shared task cloud service TIRA, of which in turn 42 teams submitted a valid run. The best team achieved an accuracy of 0.822 on a balanced sample (yes : no hyperpartisan) drawn from the manually tagged corpus; an ensemble of the submitted systems increased the accuracy by 0.048. Submission By-article dataset By-publisher dataset Team name Authors Code Rank Acc. Prec. Recall F1 Rank Acc. Prec. Recall F1 Bertha von Suttner Jiang et al.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Yellow journalism has established itself in social media, nowadays often linked to phenomena like clickbait, fake news, and hyperpartisan news. Clickbait has been its first "success story" <ref type="bibr" target="#b40">(Potthast et al., 2016)</ref>: When the viral spreading of pieces of information was first observed in social networks, some investigated how to manufacture such events for profit. Unlike for "natural" viral content, however, readers had to be directed to a web page containing the to-be-spread information alongside paid-for advertising, so that only teasers and not the information itself could be shared. Then, to maximize their virality, data-driven optimization revealed that teaser messages which induce curios-ity, or any other kind of strong emotion, spread best. The many forms of such teasers that have emerged since are collectively called clickbait. New publishing houses arose around viral content, which brought clickbait into the mainstream. Traditional news publishers, struggling for their share of the attention market that is a social network, adopted clickbait into their toolbox, too, despite its violation of journalistic codes of ethics.</p><p>The content spread using clickbait used to be mostly harmless trivia-entertainment and distraction to some, spam to others-, but in the wake of the 2016 United States presidential election, "fake news" came to widespread public attention. While certainly not a new phenomenon in yellow journalism, its viral success on social media was a surprise to many. Part of this success was then attributed to so-called hyperpartisan news publishers <ref type="bibr" target="#b7">(Bhatt et al., 2018)</ref>, which report strongly in favor of one political position and in fierce disagreement with its opponents. Clinging to hyperpartisanship often entails stretching the truth, if not breaking it with fake news, whose highly emotional content makes them spread exceptionally fast, like clickbait.</p><p>Given the hype surrounding fake news, activists, industry, and research are now paying a lot of attention to mitigating the problem, such as trying to check facts in news items. Clickbait and hyperpartisan news, however, have been less studied. In previous work, we sought to help close this gap from both ends: for clickbait detection <ref type="bibr" target="#b40">(Potthast et al., 2016)</ref>, part of our group created a large-scale evaluation dataset <ref type="bibr" target="#b37">(Potthast et al., 2018b)</ref> and set up an ongoing competition for the best detection approach <ref type="bibr" target="#b36">(Potthast et al., 2018a)</ref>. For hyperpartisan news detection <ref type="bibr" target="#b39">(Potthast et al., 2018c)</ref>, we teamed up to follow a similar approach that led to the Hyperpartisan News Detection task at SemEval-2019. This paper reports on the results of this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>We define hyperpartisan news detection as follows:</p><p>Given the text and markup of an online news article, decide whether the article is hyperpartisan or not.</p><p>Hyperpartisan articles mimic the form of regular news articles, but are one-sided in the sense that opposing views are either ignored or fiercely attacked. We deliberately disregard the distinction between left and right, since previous work has found that, in hyperpartisan form, both are more similar to each other in terms of style than either are to the mainstream <ref type="bibr" target="#b39">(Potthast et al., 2018c)</ref>. The challenge of this task is to unveil the mimicking and to detect the hyperpartisan language, which may be distinguishable from regular news at the levels of style, syntax, semantics, and pragmatics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>Our focus is on news articles published online, and we provide two datasets with this task. One has 1,273 articles, each labeled manually, while the second, larger dataset of 754,000 articles is labeled in a semi-automated manner via distant supervision at the publisher level. These datasets are further split into public and private sets. We released the public set for the model training, tuning, and evaluation, 1 while the unreleased private set is used to enable blind, cloud-based evaluation.</p><p>As online news articles are published mainly in the HTML format, both datasets use a unified HTML-like format (see Figure <ref type="figure" target="#fig_0">1</ref>). We restricted the markup for the article content to paragraphs (&lt;p&gt;), links (&lt;a&gt;), and quotes (&lt;q&gt;). We distinguished internal links to the other pages of the same domain, from which we removed the href-attribute value to avoid classifiers fitting to them; and links to external domains, for which we kept the attribute. An XML schema that exactly specifies the format is distributed along the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset Annotated By Article</head><p>We gathered a crowdsourced dataset of 1,273 articles, each labeled manually by 3 annotators <ref type="bibr" target="#b46">(Vincent and Mestre, 2018)</ref>. These articles were published by active hyperpartisan and mainstream websites and were all assured to contain political news. Annotators were asked to rate each article's bias on the following 5-point Likert scale:</p><p>1. No hyperpartisan content 2. Mostly unbiased, non-hyperpartisan content 3. Not Sure 4. Fair amount of hyperpartisan content 5. Extreme hyperpartisan content We removed all articles from the dataset with low agreement score and the aggregated rating of "not sure" (see Vincent and Mestre for more details). We then binarized the labels to hyperpartisan (average rating of 4 or 5) and not (average rating of 1 or 2). The final by-article set achieved an inter-annotator agreement of 0.5 Krippendorff's alpha. Of the remaining 1,273 articles, 645 were published as a training dataset, whereas the other 628 (50% hyperpartisan and 50% not) were kept private for the evaluation. To ensure that classifiers could not profit from overfitting to publisher style, we made sure there was no overlap between the publishers of the articles between these two sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dataset Annotated By Publisher</head><p>To allow for methods that require huge amounts of training data, we compiled a dataset of 754,000 articles, each labeled as per the bias of their respective publisher. To create this dataset, we cross-checked two publicly available news publisher bias lists compiled by media professionals from BuzzFeed news 2 and Media Bias Fact Check. <ref type="bibr">3</ref> The former was created by BuzzFeed journalists as a basis for a news article, whereas the latter is Media Bias Fact Check's main product. While both lists contain several hundred news publishers, they disagree only for nine, which we removed from our dataset.</p><p>We then crawled, archived, and post-processed the articles available on the publishers' web sites and Facebook feeds. We archived all articles using a specialized tool <ref type="bibr" target="#b25">(Kiesel et al., 2018)</ref> that removes pop-overs and similar things preventing the article content from being loaded. After filtering out publishers that did not mainly publish political articles or had no political section to which we could restrict our crawl, we were left with 383 publishers. For each of the publishers' web sites we wrote a content-wrapper to extract the article content and relevant meta data from the HTML DOM. We then removed all articles that were too short to contain news, 4 that are not written in English, &lt;article id="0182515" published-at="2007-01-22" title="They're crumbling"&gt; &lt;p&gt;What a pleasant surprise to see Jacques Leslie, a journalist and real expert on dams, with a long &lt;a href="http://www.nytimes.com/2007/01/22/opinion/22leslie.2.html ?ex=1327122000&amp;amp;amp;en=42caf99f05e4cba8&amp;amp;amp;ei=5090&amp;amp;amp;partner= rssuserland&amp;amp;amp;emc=rss" type="external"&gt;op-ed&lt;/a&gt; on the hallowed pages of the New York Times. Leslie, author of &lt;a href="" type="internal"&gt;Deep Water: The Epic Struggle Over Dams, Displaced People and the Environment&lt;/a&gt;, highlights the threat posed by poorly maintained and increasingly failing dams around the country:&lt;/p&gt; &lt;p&gt;Unlike, say, waterways and sanitation plants, a majority of dams -56 percent of those inventoried -are privately owned, which is one reason dams are among the country's most dangerous structures. Many private owners can't afford to repair aging dams; some owners go so far as to resist paying by tying up official repair demands in court or campaigning to weaken state dam safety laws.&lt;/p&gt; &lt;p&gt;Kinda makes you want to find out what is upstream.&lt;/p&gt; &lt;/article&gt; or that contain obvious encoding errors. The final dataset consisted of 754,000 articles, split into a public training set (600,000 articles), a public validation set (150,000 articles) and a non-public test set (4,000 articles). Like for the by-article dataset, we ensured that there is no overlap of publishers between the sets. Each set consists of 50% articles from non-hyperpartisan publishers and 50% articles from hyperpartisan publishers, the latter again being 50% from left-wing and 50% from right-wing publishers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Fairness and Reproducibility</head><p>In this shared task, we asked participants to submit their software instead of just its run output. The submissions were executed at our site on the test data, enabling us to keep the test data entirely secret. This has two important advantages over traditional shared task setups: first, software submission gives rise to blind evaluation; and second, it maximizes the replicability and the reproducibility of each participant's approach. To facilitate software submission and to render it feasible in terms of work overhead and flexibility for both participants and organizers, we employ the TIRA Integrated Research Architecture <ref type="bibr" target="#b38">(Potthast et al., 2019)</ref>.</p><p>A shortcoming of traditional shared task setups is that typically the test data are shared with participants, albeit without ground truth. Although participants in shared tasks generally exercise integrity and do not analyze the test data other than running their software on it, we have experienced cases to the contrary. Such problems particularly arise in shared tasks where the stakes are higher than usual; when monetary incentives are offered or winning results in high visibility. A partial workaround is to share the test data only very close to the final submission deadline, minimizing analysis oppor-tunities. But if sharing the test data is impossible for reasons of sensibility and proprietariness, or because the ground truth can be easily reverseengineered, a traditional shared task cannot be held.</p><p>Another shortcoming of traditional shared tasks (and many computer science publications in general) is their lack of reproducibility. Although sharing the software underlying experiments as well as the trained models is easy, and although it would greatly aid reproducibility, this is still rare. Typically, all that remains after a shared task are the papers and datasets published. Given that shared tasks often establish a benchmark for the task in question, acting normative for future evaluations, this outcome is far from optimal and comparably wasteful. All of the above can be significantly improved upon by asking participants not to submit their software's run output, but the software itself. However, this entails a significant work overhead for organizers, especially for larger tasks.</p><p>In order to mitigate the work overhead, we employ TIRA. In a nutshell, TIRA implements evaluation as a service in the form of a cloud-based evaluation platform. Participants deploy their software into virtual machines hosted at TIRA's cloud, and then remotely control the machines and the software within, executing it on the test data. The test data are available only within the cloud, and made accessible on demand so that participants cannot access it directly. At execution time, the virtual machine is disconnected from the internet, copied, and only the copy gets access to the test data. Once the automatically executed software terminates, its run output is saved and the virtual machine copy is destroyed so as to prevent data leaks. This way, all submitted pieces of software can be archived in working condition, and be re-evaluated at a later time, even on new datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Participating Systems</head><p>This task attracted a very diverse and interesting set of solutions from the participating teams. The teams employed very different sets of features, a wide variety of classifiers, and also employed the large by-publisher dataset in different ways. Around half of the submissions used hand-crafted features. In the following, we give an overview of the submitted approaches. For a more readable and condensed form, we only use the team names here, which were chosen from fictional journalistic characters or entities (see Table <ref type="table">1</ref> for references).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Features</head><p>The teams that participated in this task employed a variety of features, including standard word ngrams (also unigrams, i.e., bag-of-words), word embeddings, stylometric features, HTML features like the target of hyperlinks, and a meta data feature in the form of the publication date.</p><p>N-Grams Most teams that used hand-crafted features also included word n-grams: Pioquinto Manterola and Tintin used them as their only features. Character and part-of-speech n-grams were, for example, used by Paparazzo.</p><p>Word embeddings Many teams integrated word embeddings into their approach. Frequently used were Word2Vec, fastText, and GloVe. Noticeably, Tom Jumbo Grumbo relied exclusively on them. Bertha von Suttner relied on ELMo embeddings <ref type="bibr" target="#b35">(Peters et al., 2018)</ref>, which have the advantage of modeling polysemy. Where the aforementioned word embeddings all rely on neural networks, Doris Martin employed a document representation based on word clusters as part of their approach.</p><p>BERT <ref type="bibr" target="#b13">(Devlin et al., 2018)</ref>, which jointly conditions on both left and right context in all layers, is a rather new technique that was used by several teams. Peter Parker directly applied a freely available pre-trained BERT model to the task, whereas Howard Beale and Clint Buchanan trained their own BERT models on the by-publisher dataset and then performed fine-tuning on the by-article dataset. Despite the fine-tuning, Howard Beale reported overfitting issues for this strategy. Going one step further, Jack Ryder and Yeon Zi integrated BERT in their neural network architectures.</p><p>Stylometry Many teams used stylometric features including punctuation and article structure (Steve Martin, Spider Jerusalem, Fernando Pessa, Ned Leeds, Carl Kolchak, Orwellian Times), readability scores (Ned Leeds, Pistachon, Steve Martin, Orwellian Times, D X Beaumont), or psycholinguistic lexicons (Ned Leeds, Spider Jerusalem, Steve Martin, Pistachon). Borat Sagdiyev employed a self-compiled list of trigger words that contains mostly profanities. They noticed that such words are used more often in hyperpartisan articles.</p><p>Emotionality Several teams used sentiment and emotion features, either based on libraries (Borat Sagdiyev, Steve Martin, Carl Kolchak) or lexicons (Spider Jerusalem, D X Beaumont). Notably, Kermit the Frog uses sentiment detection only. Vernon Fenwick and D X Beaumont used subjectivity and polarity metrics as features.</p><p>Named entities Borat Sagdiyev used named entity types as features. In preliminary tests only the type of "nationalities or religious and political groups" was found to be predictive.</p><p>Quotations A few teams treated quotations separately. Whereas Spider Jerusalem and Borat Sagdiyev created separate features from quotations, the Ankh Morpork Times filtered them out for not necessarily representing the views of the author.</p><p>Hyperlinks Only few teams considered hyperlinks. Both Borat Sagdiyev and Steve Martin used external lists of partisan web pages to count how often an article links to partisan and non-partisan pages. They assume that articles tend to link other articles on the same side of the political spectrum.</p><p>Publication date Based on the conjecture that months around American elections could see more hyperpartisan activity, Borat Sagdiyev used the publication month and year as separate features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Classifiers</head><p>While many different classifiers were used overall, neural networks were the most frequent, which mirrors the current trend in text classification.</p><p>The most popular type of neural networks among the participants were convolutional ones (CNNs), which employ convolving filters over neighboring words. Many teams cited the architecture by <ref type="bibr" target="#b26">Kim (2014)</ref>. Xenophilius Lovegood added a second layer to their CNN in order to encode more information about the articles, using both available and custom-learned embeddings. While Pioquinto Manterola experimented with a CNN, it suffered from overfitting and was thus not used for the final submission. Peter Brinkmann built a submission using available embeddings. Brenda Starr combined a CNN with a sentence-level bidirectional recurrent neural network and an attention mechanism to a complex architecture. A similar approach was employed by the Ankh Morpork Times. An ensemble of three CNN-based models was used by Bertha von Suttner. Steve Martin used a character bigram CNN as part of their approach.</p><p>Next to CNNs, long short term memory networks (LSTM) were employed by Kit Kittredge and Miles Clarkson. The latter extended the network with an attention model. Moreover, Joseph Rouletabille used the hierarchical attention network of <ref type="bibr" target="#b47">Yang et al. (2016)</ref>.</p><p>Besides neural networks, a wide variety of classifiers were used. A few teams opted for SVMs (e.g., the Orwellian Times), others for random forests (e.g., Fernando Pessa), linear models (e.g., Pistachon), the Naive Bayes model (e.g., Carl Kolchak), XGBOOST (Clark Kent), Maxent (Doris Martin), and rule-based models (Harry Friberg). Morbo used ULMFit <ref type="bibr" target="#b20">(Howard and Ruder, 2018)</ref> to adapt a language model pre-trained on Wikipedia articles to the articles and classes of this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Usage of the By-publisher Dataset</head><p>The submitted systems can also be distinguished by whether and how they used the large, distantly-supervised by-publisher dataset. Though much larger than the by-article set, its labels are noisy, whereas the opposite holds for the by-article dataset. One of the key challenges faced by many teams was how to train a powerful expressive model on the smaller dataset without overfitting. Most teams made use of the larger dataset in some form or another. A challenge faced by some of the teams was that the test split of the by-article dataset was balanced between classes, whereas the corresponding training dataset was not.</p><p>Several systems trained the whole or part of their system on the by-publisher dataset. Some extracted features like n-grams (e.g., Sally Smedley), word clusters (Doris Martin), or neural network word embeddings (e.g., Clint Buchanan). Others used the larger dataset to perform hyperparameter search (e.g., Miles Clarkson). Many teams trained their models using the by-publisher dataset only (Pistachon, Joseph Rouletabille, Xenophilius Lovegood, Peter Brinkmann, and Kit Kittredge).</p><p>To reduce the noise in the distantly-supervised data, some teams used only a subset of it. Yeon Zi, Borat Sagdiyev and the Anhk Morpork Times fitted a model on the by-article dataset and ran it on the by-publisher one: the articles of the by-publisher dataset that were misclassified by this model, were presumed to be noisy and filtered out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>A total of 42 teams completed the task, representing more than twenty countries between them, including India, China, the USA, Japan, Vietnam, and many European countries. Table <ref type="table">1</ref> shows the accuracy, precision, recall, and F 1 score for each team, sorted by accuracy. This task used accuracy as the main metric to represent a filtering scenario. The accuracy scores ranged from 0.462 up to 0.822.</p><p>The results show a range of trade-offs between precision and recall and the resulting F 1 scores. The highest F 1 was 0.821 with a precision of 0.815 and a recall of 0.828; the highest precision was 0.883 with a recall of 0.672 (F 1 : 0.763); and the highest recall was 0.971 with a relatively low precision of 0.542 (F 1 : 0.696).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Methods Used by the Top Teams</head><p>While the winning team, Bertha von Suttner, used deep learning (sentence-level embeddings and a convolutional neural network) the second-placed team, Vernon Fenwick, took a different approach and combined sentence embeddings with more domain-specific features and a linear model. Out of the top five teams, only two used "pure" deep learning models of neural networks without any domain-specific, hand-crafted features, showing no single method has a clear advantage over others.</p><p>Bertha von Suttner used a model based on ELMo embeddings <ref type="bibr" target="#b35">(Peters et al., 2018)</ref> and trained on the by-article dataset. After minimal preprocessing, a pre-trained ELMo was applied onto each token of each sentence, and then averaged, to obtain average sentence embeddings. The sentence embeddings were later passed through a CNN, batch-normalized, followed by a dense layer and a sigmoid function to obtain the final probabilities. The final model was an ensemble of the 3 best-performing models of a 10-fold crossvalidation. The authors tried to include the bypublisher dataset, but found in their preliminary tests no approach to profit from the large data.</p><p>Table <ref type="table">1</ref>: For each team and dataset, the performance of the submission that reached the highest accuracy is shown. If a team published their code, the links to the respective repository. We forked all repositories for archival. <ref type="bibr">6</ref> The second and third best teams used linear models as their main predictor and embeddings as features, training on the by-article dataset only. Vernon Fenwick extracted sentence embeddings with the Universal Sentence Encoder (USE) <ref type="bibr" target="#b8">(Cer et al., 2018)</ref>, while Sally Smedley used BERT to generate contextual embeddings. Both teams also employed hand-crafted, domain-specific features. Vernon Fenwick extracted article-level and sentencelevel polarity, bias, and subjectivity, among others, while Sally Smedley used the by-publisher dataset to extract key discriminative phrases, which they later looked up in the training data.</p><p>6 https://github.com/hyperpartisan-news-challenge</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Overall Insights</head><p>The results reveal several insights into the suitability of different features and approaches for the task of hyperpartisan news detection.</p><p>Word-embeddings have been reported to be a very efficient feature by many teams. Tom Jumbo Grumbo achieved an accuracy of 0.806 with GloVe embeddings and a classifier trained on the by-article dataset. The application of a pretrained BERT model by Peter Parker performed very poorly (acc. 0.503). However, the same BERT embeddings were used for great effect by Sally Smedley, using techniques like word-dropout and informative phrase identification (acc. 0.809).</p><p>Also standard word n-grams were found to be suitable for the task, though not as strong as embeddings. While n-grams where used in several well-performing approaches, Pioquinto Manterola reached an accuracy of 0.704 with unigrams alone.</p><p>Several teams reported an increase in accuracy through sentiment or similar features (e.g., Borat Sagdiyev). Kermit the Frog used sentiment detection alone to reach an accuracy of 0.621.</p><p>Besides textual features, a few teams also analyzed HTML and article meta-features. Borat Sagdiyev performed a detailed analysis in this regard, which helped them to achieve the highest precision of all teams. For example, they found that both the publication date and the number of links to known hyperpartisan pages could each improve the overall accuracy by about 0.01 to 0.02.</p><p>Of the top teams, only Sally Smedley used the by-publisher dataset, and only to select n-grams. Based on the reports of several teams, the utilization of this dataset thus seems more difficult than we expected. We conjecture that this is due to the mis-classification of what should be the most informative articles: non-hyperpartisan articles from mainly hyperpartisan publishers, and hyperpartisan articles from non-hyperpartisan publishers. These articles are especially suited to distinguish features that identify hyperpartisanship from features that identify publisher style. While we assumed that the advantages of big data would outweigh this drawback, the results suggest that it might be more worthwhile to put effort in larger datasets where each article is annotated separately. Still, some teams managed to use the by-publisher dataset as a large dataset of in-domain texts. For example, Clint Buchanan reported that pre-training embeddings on the by-publisher dataset increased the accuracy of their system on the by-article dataset.</p><p>Moreover, the ranking of teams for the two test datasets is quite different. Bertha von Suttner, who ranked first for by-article, reached only rank eight for the by-publisher dataset. Conversely, Tintin, who optimized for by-publisher, ranked first there but only 27th for the by-article dataset. This discrepancy highlights the unexpected large differences between the datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Meta-Classification Task</head><p>Inspired by successes of meta classifiers in past SemEval tasks (e.g., <ref type="bibr" target="#b18">Hagen et al. (2015)</ref>), we enabled and encouraged participants to devise meta  classifiers that learn from the classifications of the submitted approaches. For this meta-classification task, we split the test datasets further into new training (66%) and test sets (33%). We again made sure that there are an equal amount of non-hyperpartisan and hyperpartisan articles, as well as an equal share of left-wing and right-wing articles within the hyperpartisan sets. Furthermore, we again assured that no publisher had articles in both the training and the test sets. An instance in these datasets corresponds to the classifications (hyperpartisan or not) of the best-performing software of each team (42 classifications for the by-article dataset and 30 for the by-publisher one) of one article from the original test data.</p><p>We provide two simple classification systems for baselines, majority voting and an out-of-the-box decision tree, which both outperform the best single submitted software and which were both outperformed by the meta-classifiers submitted. Majority voting refers to a system that outputs the classification (hyperpartisan or not) that the most base classifiers selected. As it does not learn a decision boundary, it is-strictly speaking-not a meta classifier. For the decision tree, we used the J48 implementation of WEKA <ref type="bibr" target="#b16">(Frank et al., 2016)</ref>. We tested two variants: standard settings (J48-M2) and restricting leaf nodes to contain at least 10 articles (J48-M10) to force a simpler decision tree. Simpler trees often generalize better to unseen data.</p><p>Figure <ref type="figure" target="#fig_1">2</ref> shows the J48-M10 tree for the byarticle dataset. For every leaf of the tree, more than 75% of the corresponding training articles are from the same class. This shows that even with as few as 5 decision nodes, the training set  could be fitted reasonably well. The meta classifier was thus able to use the submitted systems as predictive and distinct features, which shows that some submitted systems performed well on some articles where other systems did not and vice versa. Even more, the 5 systems employed by the meta-classifier are all within the top 10 systems of the task, which shows that there is considerable variation even among the top performers. This is reasonable, given the variety of approaches used.</p><p>In addition to our approaches, two teams submitted their own classifiers in the short time span they had. Fernando Pessa used a random forest classifier trained on the single predictions as well as the average vote. Spider Jerusalem used a weighted majority voting algorithm, where they weighted each single prediction by the precision of the respective classifier on the training set.</p><p>Table <ref type="table" target="#tab_2">2</ref> shows the performance of the approaches on the meta learning test dataset. Note that the best single system, Bertha von Suttner, reaches an increased accuracy of 0.851 on the meta learning test set. This is due to variations in the small dataset. Still, all ensemble approaches reach a higher accuracy. The majority voting approach reaches an accuracy of 0.885, and thus outperforms the J48 classifiers. This is somewhat surprising, but shows that there is a lot to gain by integrating also the systems that performed less well-team Fernando Pessa came to a similar insight in their paper <ref type="bibr" target="#b12">(Cruz et al., 2019)</ref>. The approaches of the two participants performed very similar, despite their methodological differences, and outperformed the majority vote. They managed to achieve an accuracy 0.048 points above Bertha von Suttner and therefore a considerable increase in performance.</p><p>We also repeated the experiments for the bypublisher dataset, but could not produce decisive results there, yet. We assume that this is due to most teams focusing on the other dataset and both datasets being more different than expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This paper reports on the setup, participation, results, and insights gained from the first task in hyperpartisan news detection, hosted as Task 4 at SemEval-2019. We detailed the construction of both a manually annotated dataset of 1,273 articles as well as a large dataset of 754,000 articles, compiled using distant supervision. Moreover, it provides a systematic overview of the 34 papers submitted by the participants, insights gathered from single teams, by comparing their approaches, and by an ad-hoc meta classification.</p><p>Through the use of TIRA <ref type="bibr" target="#b38">(Potthast et al., 2019)</ref>, we were able to establish a blind evaluation setup, so that future approaches can be compared on same grounds. For this, we continue to accept new approaches in ongoing submissions. <ref type="bibr">7</ref> Moreover, through the use of TIRA we can directly evaluate the submitted approaches on new datasets for hyperpartisan news detection, provided they are formatted like the datasets presented here.</p><p>Very promising results were achieved during the task, with accuracy values above 80% on a balanced test set-and even up to 90% using meta classification on all submissions. Like in many other NLP tasks, word embeddings could be used to great effect, but hand-crafted features also performed well. The differences between the two employed datasets were larger than anticipated, which suggests a focus on by-article annotations in the future. A larger dataset of this kind will probably assist in improving the accuracy of future models even beyond the already very good level.</p><p>It thus seems that hyperpartisan news detection is already sufficiently developed to take the next step and demand human-understandable explanations from the approaches. The most obvious use cases of hyperpartisan news detectors are for filtering articles, which always requires a careful handling to avoid unwarranted censorship. Especially in the current political climate, it therefore seems necessary that hyperpartisanship detectors not only reach a high accuracy, but also reveal their reasoning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of a non-hyperpartisan article in our dataset. An archived version of the original article is available at https://web.archive.org/web/20121006194050/https://grist.org/article/remember-the-dams/.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Meta-classification decision tree J48-M10 learned on the predictions of the submitted systems (hyperpartisan: yes or no; by-article dataset). The numbers show the training class-distribution at the leafs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Accuracy, precision, recall, and F 1 -measure for the by-article meta learning test dataset.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://doi.org/10.5281/zenodo.1489920</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/BuzzFeedNews/ 2017-08-partisan-sites-and-facebook-pages 3 https://mediabiasfactcheck.com 4 Based on manual inspection of a hundred short articles, we set the threshold to 40 words.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">https://webis.de/events/semeval-19/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Our thanks go out to all participating teams; your contributions made this task a success. We hope we have been able to do your work justice, and are looking forward to doing so in the future. Our special thanks go out to the SemEval organizers for providing perfect organizational support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Team Harry Friberg at SemEval-2019 Task 4: Identifying Hyperpartisan News through Editorially Defined Metatopics</title>
		<author>
			<persName><forename type="first">Nazanin</forename><surname>Afsarmanesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jussi</forename><surname>Karlgren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Sumbler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Viereckel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Doris Martin at SemEval-2019 Task 4: Hyperpartisan News Detection with Generic Semi-supervised Featuresl</title>
		<author>
			<persName><forename type="first">Rodrigo</forename><surname>Agerri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spider-Jerusalem at SemEval-2019 Task 4: Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">Amal</forename><surname>Alabdulkarim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tariq</forename><surname>Alhindi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cardiff University at SemEval-2019 Task 4: Linguistic Features for Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">Carla</forename><surname>Perez Almendros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Espinosa Anke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Schockaert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Harvey Mudd College at SemEval-2019 Task 4: The D.X. Beaumont Hyperpartisan News Detector</title>
		<author>
			<persName><forename type="first">Evan</forename><surname>Amason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jake</forename><surname>Palanker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Clare</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Medero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Team Kermit-the-frog at SemEval-2019 Task 4: Bias Detection Through Sentiment Analysis and Simple Linguistic Features</title>
		<author>
			<persName><forename type="first">Talita</forename><surname>Anthonio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lennart</forename><surname>Kloppenburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tintin at SemEval-2019 Task 4: Detecting Hyperpartisan News Article with only Simple Tokens</title>
		<author>
			<persName><forename type="first">Yves</forename><surname>Bestgen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Illuminating the ecosystem of partisan websites</title>
		<author>
			<persName><forename type="first">Shweta</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sagar</forename><surname>Joglekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shehar</forename><surname>Bano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nishanth</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on World Wide Web Companion, WWW &apos;18 Companion. International World Wide Web Conferences Steering Committee</title>
				<meeting>the 27th International Conference on World Wide Web Companion, WWW &apos;18 Companion. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Sheng Yi Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rhomni</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName><surname>St</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mario</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steve</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName><surname>Yuan</surname></persName>
		</author>
		<editor>Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Universal Sentence Encoder</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fermi at SemEval-2019 Task 4: The sarah-jane-smith Hyperpartisan News Detector</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Chakravartula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vijayasaradhi</forename><surname>Indurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bakhtiyar</forename><surname>Syed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Harvey Mudd College at SemEval-2019 Task 4: The Carl Kolchak Hyperpartisan News Detector</title>
		<author>
			<persName><forename type="first">Celena</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Celine</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Dwyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Medero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Team Kit Kittredge at SemEval-2019 Task 4</title>
		<author>
			<persName><forename type="first">Rebekah</forename><surname>Cramerus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatjana</forename><surname>Scheffler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Team Fernando-Pessa at SemEval-2019 Task 4: Back to Basics in Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">André</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gil</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Sousa-Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><forename type="middle">Lopes</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Harvey Mudd College at SemEval-2019 Task 4: The Clint Buchanan Hyperpartisan News Detector</title>
		<author>
			<persName><forename type="first">Mehdi</forename><surname>Drissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><forename type="middle">Sandoval</forename><surname>Segura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vivaswat</forename><surname>Ojha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Medero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Team Peter Brinkmann at SemEval-2019 Task 4: Detecting Biased News Articles Using Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Färber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agon</forename><surname>Qurdina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lule</forename><surname>Ahmedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining: Practical Machine Learning Tools and Techniques</title>
		<title level="s">chapter The WEKA Workbench</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>4th edition</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Clark Kent at SemEval-2019 Task 4: Stylometric Insights into Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">Viresh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><surname>Baani Leen Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramneek</forename><surname>Jolly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanmoy</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Webis: An Ensemble for Twitter Sentiment Detection</title>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Büchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Workshop on Semantic Evaluation</title>
				<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="582" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Sally Smedley Hyperpartisan News Detector at SemEval-2019 Task 4</title>
		<author>
			<persName><forename type="first">Kazuaki</forename><surname>Hanawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shota</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroki</forename><surname>Ouchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Universal Language Model Fine-tuning for Text Classification</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno>abs/1801.06146</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Tim</forename><surname>Isbister</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fredrik</forename><surname>Johansson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">and Morbo at SemEval-2019 Task 4: Transfer Learning for Hyperpartisan News Detection</title>
		<author>
			<persName><surname>Dick-Preston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Team Bertha von Suttner at SemEval-2019 Task 4: Hyperpartisan News Detection using ELMo Sentence Representation Convolutional Network</title>
		<author>
			<persName><forename type="first">Ye</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johann</forename><surname>Petrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingyi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalina</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Maynard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Steve Martin at SemEval-2019 Task 4: Ensemble Learning Model for Detecting Hyperpartisan News</title>
		<author>
			<persName><forename type="first">Youngjun</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Inchon</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reproducible Web Corpora: Interactive Archiving with Automatic Quality Assessment</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Kneist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Alshomary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.1145/3239574</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Data and Information Quality (JDIQ)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks for Sentence Classification</title>
		<author>
			<persName><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/d14-1181</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Orwellian-times at SemEval-2019 Task 4: A Stylistic and Content-based Classifier</title>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Knauth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Team yeon-zi at SemEval-2019 Task 4: Hyperpartisan News Detection by De-noising Weakly-labeled Data</title>
		<author>
			<persName><forename type="first">Nayeon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zihan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascale</forename><surname>Fung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rouletabille at SemEval-2019 Task 4: Neural Network Baseline for Identification of Hyperpartisan Publishers</title>
		<author>
			<persName><forename type="first">Jose</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoann</forename><surname>Pitarch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gilles</forename><surname>Hubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Team Howard Beale at SemEval-2019 Task 4: Hyperpartisan News Detection with BERT</title>
		<author>
			<persName><forename type="first">Osman</forename><surname>Mutlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erenay</forename><surname>Ozan Arkan Can</surname></persName>
		</author>
		<author>
			<persName><surname>Dayanik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">NLP@UIT at SemEval-2019 Task 4: The Paparazzo Hyperpartisan News Detector</title>
		<author>
			<persName><forename type="first">Duc-Vu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thin</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ngan</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Team Peter-Parker at SemEval-2019 Task 4: BERT-Based Method in Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanzhen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruichao</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">TakeLab at SemEval-2019 Task 4: Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">Niko</forename><surname>Palić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juraj</forename><surname>Vladika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominik</forename><surname>Cubelić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Lovrencic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Brenda Starr at SemEval-2019 Task 4: Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">Olga</forename><surname>Papadopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgos</forename><surname>Kordopatis-Zilos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markos</forename><surname>Zampoglou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Symeon Papadopoulos, and Yiannis Kompatsiaris</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep Contextualized Word Representations</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-1202</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The Clickbait Challenge 2017: Towards a Regression Model for Clickbait Strength</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<idno>abs/1812.10847</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Crowdsourcing a Large Corpus of Clickbait on Twitter</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristof</forename><surname>Komlossy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matti</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erika Patricia Garces</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">27th International Conference on Computational Linguistics (COLING 2018)</title>
				<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1498" to="1507" />
		</imprint>
	</monogr>
	<note>The COLING 2018 Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">TIRA Integrated Research Architecture</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matti</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
				<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A Stylometric Inquiry into Hyperpartisan and Fake News</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Reinartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">56th Annual Meeting of the Association for Computational Linguistics (ACL 2018)</title>
				<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="231" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Clickbait Detection</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Köpsel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-30671-1_72</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Information Retrieval. 38th European Conference on IR Research</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">9626</biblScope>
			<biblScope unit="page" from="810" to="817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Team QCRI-MIT at SemEval-2019 Task 4: Propaganda Analysis Meets Hyperpartisan News Detection</title>
		<author>
			<persName><forename type="first">Abdelrhman</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramy</forename><surname>Baly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitra</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Duluth at SemEval-2019 Task 4: The Pioquinto Manterola Hyperpartisan News Detector</title>
		<author>
			<persName><forename type="first">Saptarshi</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Team Jack Ryder at SemEval-2019 Task 4: Using BERT Representations for Detecting Hyperpartisan News</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Shaprin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Vernon-fenwick at SemEval-2019 Task 4: Hyperpartisan News Detection using Lexical and Semantic Features</title>
		<author>
			<persName><forename type="first">Vertika</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ankita</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divya</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sudeep</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Rohit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeon Hyang</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Team Ned Leeds at SemEval-2019 Task 4: Exploring Language Indicators of Hyperpartisan Reporting</title>
		<author>
			<persName><forename type="first">Bozhidar</forename><surname>Stevanoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonja</forename><surname>Gievska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Crowdsourced Measure of News Articles Bias: Assessing Contributors&apos; Reliability</title>
		<author>
			<persName><forename type="first">Emmanuel</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Mestre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Subjectivity, Ambiguity and Disagreement (SAD) in Crowdsourcing</title>
				<meeting>the 1st Workshop on Subjectivity, Ambiguity and Disagreement (SAD) in Crowdsourcing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Hierarchical Attention Networks for Document Classification</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1480" to="1489" />
		</imprint>
	</monogr>
	<note>NAACL HLT 2016</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Tom Jumbo-Grumbo at SemEval-2019 Task 4: Hyperpartisan News Detection with GloVe vectors and SVM</title>
		<author>
			<persName><forename type="first">Chia-Lun</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Babak</forename><surname>Loni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Schuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Team Xenophilius Lovegood at SemEval-2019 Task 4: Hyperpartisanship Classification using Convolutional Neural Networks</title>
		<author>
			<persName><forename type="first">Albin</forename><surname>Zehe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lena</forename><surname>Hettinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Ernst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Hotho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">UBC-NLP at SemEval-2019 Task 4: Hyperpartisan News Detection With Attention-Based Bi-LSTMs</title>
		<author>
			<persName><forename type="first">Chiyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arun</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Abdul-Mageed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 13th International Workshop on Semantic Evaluation</title>
				<meeting>The 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
