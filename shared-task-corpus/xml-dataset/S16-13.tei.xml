<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2016 Task 13: Taxonomy Extraction Evaluation (TExEval-2)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Georgeta</forename><surname>Bordea</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Insight Centre for Data Analytics</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Els</forename><surname>Lefever</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">LT3, Language and Translation Technology Team</orgName>
								<orgName type="institution">Ghent University</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Buitelaar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Insight Centre for Data Analytics</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<addrLine>June 16-17</addrLine>
									<postCode>2016</postCode>
									<settlement>San Diego</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2016 Task 13: Taxonomy Extraction Evaluation (TExEval-2)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the second edition of the shared task on Taxonomy Extraction Evaluation organised as part of SemEval 2016. This task aims to extract hypernym-hyponym relations between a given list of domain-specific terms and then to construct a domain taxonomy based on them. TExEval-2 introduced a multilingual setting for this task, covering four different languages including English, Dutch, Italian and French from domains as diverse as environment, food and science. A total of 62 runs submitted by 5 different teams were evaluated using structural measures, by comparison with gold standard taxonomies and by manual quality assessment of novel relations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Taxonomies are useful tools for content organisation, navigation, and retrieval, providing valuable input for semantically intensive tasks such as question answering <ref type="bibr" target="#b3">(Harabagiu et al., 2003)</ref> and textual entailment <ref type="bibr" target="#b1">(Geffet and Dagan, 2005)</ref>. In general, a hierarchical relation is any asymmetrical relation that indicates subordination between two terms, but in this task we focus on hyponym-hypernym relations. Taxonomy learning from text is a challenging task that can be divided in several subtasks, including term extraction, hypernym identification and taxonomy construction. Existing approaches for hypernym identification from text rely on lexico-syntactic patterns <ref type="bibr" target="#b4">(Hearst, 1992;</ref><ref type="bibr" target="#b7">Lefever et al., 2014)</ref>, cooccurrence information <ref type="bibr" target="#b2">(Grefenstette, 2015)</ref>, substring inclusion, or exploit semantic relations provided in textual definitions <ref type="bibr" target="#b19">(Velardi et al., 2013)</ref>. This stage usually produces a large number of noisy, inconsistent relations, which assign multiple parents to a node and contain cycles. Hence, the third stage of taxonomy learning, taxonomy construction, focuses on the overall structure of the resulting graph and aims to organise terms in a hierarchical structure, more specifically a directed acyclic graph <ref type="bibr" target="#b19">(Velardi et al., 2013;</ref><ref type="bibr" target="#b6">Kozareva and Hovy, 2010)</ref>.</p><p>More recently, the hypernym identification subtask has attracted an increased interest from the distributional semantics community <ref type="bibr" target="#b16">(Santus et al., 2014;</ref><ref type="bibr" target="#b14">Rei and Briscoe, 2014;</ref><ref type="bibr" target="#b15">Roller et al., 2014;</ref><ref type="bibr" target="#b22">Yu et al., 2015)</ref>, as part of a wider effort to distinguish between different semantic relations which exist between distributional similar words <ref type="bibr" target="#b21">(Weeds et al., 2014;</ref><ref type="bibr" target="#b8">Levy et al., 2015)</ref>. Although this is a promising direction of research, that addresses some of the limitations of pattern-based approaches, including low coverage of domain-specific terms, most participants in this shared task opted for traditional approaches for hypernym identification, with the exception of one system <ref type="bibr" target="#b13">(Pocostales, 2016)</ref>.</p><p>TexEval-2 is mainly concerned with automatically extracting hierarchical relations from text and subsequent taxonomy construction, therefore we make the assumption that a list of terms is readily available. This simplifies evaluation by providing a common ground for all the systems, but participants are allowed to add additional nodes, i.e. terms, in the hierarchy as they consider appropriate. To avoid the need for term extraction, terms are extracted from existing taxonomies, providing participants with a domain lexicon that has to be organised in a hierarchical structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Description</head><p>The first TExEval shared task <ref type="bibr">(Bordea et al., 2015)</ref>, organised as part of SemEval 2015, introduced a monolingual dataset that covers terms and hierarchical relations from four domains that were not previously considered for this task. Performance was evaluated across domains, considering common sense knowledge as well as technical domains gathered from WordNet and other well known taxonomies. The second TExEval shared task aimed to extend this experimental setting to a multilingual setting, covering English, French, Italian and Dutch. A main challenge faced by the participants in the first TExEval was that no corpus was provided by the task organisers. We address this issue by providing participants with instructions for downloading and preparing a Wikipedia-based corpus. Depending on the selected approach, a system may or may not require large amounts of text to extract relations between terms, therefore participants are allowed to extend this corpus as they consider appropriate. The task is structured in several subtasks, including monolingual subtasks for hypernym identification and taxonomy construction in English, as well as two corresponding multilingual subtasks that cover Dutch, French and Italian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Creation</head><p>We selected three target domains (i.e. Environment, Food and Science) with three root concepts (i.e. "environment", "food" and "science", respectively). Then, for each domain we considered different sources for gathering gold standard taxonomies, including a multilingual thesaurus, Eurovoc 1 , a large lexical database of English, WordNet, and a general purpose resource, the Wikipedia Bitaxonomy <ref type="bibr">(Flati et al., 2014)</ref>. We also considered other domainspecific resources including "The Google product taxonomy" 2 for Food, and the "Taxonomy of Fields and their Subfields" 3 for Science.</p><p>English taxonomies The English gold standard taxonomies are collected from each of the sources described above as follows. Gold standards are gathered from WordNet by selecting concepts and relationships in the hypernym-hyponym hierarchy rooted on the corresponding root concept for each domain. Relations extracted from Wikipedia are combined together with relations extracted from domain-specific resources, to obtain high-coverage domain-specific taxonomies. Hierarchical relations from Eurovoc were used integrally without any modification, but currently Eurovoc covers only the Environment and Science domains. It is worth nothing that the English gold standard taxonomies gathered from WordNet and from combined resources were also used as test data in the previous edition of this shared task <ref type="bibr">(Bordea et al., 2015)</ref>.</p><p>Multilingual taxonomies For the three other languages, the collected English gold standards were manually translated by six linguists (two computational linguists and four master students of the Ghent University Translation, Communication and Interpreting department). In a first step, the English term lists were translated in Excel by one annotator per language. The first annotator was allowed to mark entries that needed to be revised by a second annotator. In addition, the annotators could make remarks in an additional column. Some of the English terms could not be properly translated in the specific domain (e.g. "center" in the food domain) and were left out. In a second step, the translated term lists were used to automatically replace the English terms in the gold standard taxonomies with their corresponding translation.</p><p>The translation of English gold standards revealed a number of issues. First of all, some of the translations were near-synonyms in the other language, which eventually lead to cycles in the taxonomy. Examples in Italian are for instance "cibo" (English: food) and "vitto" (English: fare) which are in Italian almost synonymous, whereas their English counterparts have a more distinctive meaning. Another problematic example are the Italian words "condimento" (English: seasoning, sauce, dressing) and "salsa" (English: dressing, sauce), which can be hypernyms of each other, depending on the exact meaning of the word. The translated taxonomies also revealed errors in the original English taxonomy, such as for instance "conserve" is a kind of "confiture", which is incorrect.  Table <ref type="table" target="#tab_1">1</ref> shows the resulting number of vertices |V | and edges |E| of the produced gold standard taxonomies for each considered domain, source and language. We also report structural information about the number of intermediate nodes (#i.i), the number of connected components (#c.c.) and the number of cycles. Test data for this task consists of six lists of domain-specific terms for each language that were provided to participants as a shared basis to construct the taxonomies. The initial English taxonomies provide connections from the root node to all the other nodes, as they form one connected component. As some of the terms did not have a correspondent in all the other languages, some of the translated taxonomies have several components. This is specifically the case for the food domain that is highly dependent on the language and that shows the largest variation in number of nodes. For example, 127 terms from the Combined English taxonomy for Food could not be translated into Dutch and 279 terms could not be translated into Italian. Additionally, four cycles are erroneously introduced for the WordNet Italian taxonomy for Food, including "cibo"-"vitto"-"cibo" and "piatto principale"-"piatto"-"piatto principale". Slight differences exist between the Eurovoc taxonomies constructed for different languages as well, and these taxonomies underwent a thorough review process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Approach</head><p>The construction of taxonomies is a challenging task even for humans but evaluating a taxonomy is not a trivial task either. In this shared task, taxonomies are evaluated through comparison with gold standard relations collected from WordNet and other well known, freely available taxonomies. This is complemented by a manual evaluation of relations that are not covered by the gold standard and through quantitative and qualitative structural analysis of the resulting graph. The evaluation methodology is sim-  ilar to the approach introduced in the first edition of TExEval, with the main difference that we also report separate overall rankings of the participant systems for each of the subtasks.</p><p>Let S = (V S , E S ) be an output taxonomy produced by a system for a given domain, where V S includes the set of domain concepts initially provided by the task organizers and E S is the set of taxonomy edges extracted by the system. To broadly analyze the quality of the produced set of hypernymy relationships E S , these results are benchmarked against the string-based baseline described in Section 4.1, using the following evaluation approaches: i) analyse the graph structure and check if the produced taxonomy is a Directed Acyclic Graph (DAG); ii) compare the edges E S , against the set of relations from each type of gold standard; iii) manually validate a sample of novel relationships produced by the system that are not contained in the gold standard.</p><p>The final ranking of the systems takes into consideration these three types of evaluation by aggregating the achieved ranks using a voting scheme. First, the output taxonomies are ranked on the basis of the average performance obtained for each evaluated aspect and for each domain. The resulting ranks are simply summed up, favoring systems at the top of the ranked list and penalizing systems at the lower end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline</head><p>Simple string-based approaches that exploit term compositionality as a main property to hierarchically relate terms are known to be highly effective <ref type="bibr">(Bordea et al., 2015)</ref>. In this task, we implement the following baseline approach for hypernym extraction and taxonomy construction that is used to benchmark the evaluated systems. The baseline accounts for relations between compound terms such as (science, network science) and is implemented as follows:</p><formula xml:id="formula_0">B = (V B , E B )<label>(1)</label></formula><p>where E B = {(a, b)| b starts with a or ends with a and |b| &gt; |a|}. In this equation a is a term and b is a compound term that includes a as a substring. This baseline approach takes as input only a list of terms and does not require any external corpora or other structured information. It is worth noting that the same approach was applied in the multilingual setting, without any language-specific modification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Structural Analysis</head><p>In this task, the structural evaluation quantifies the size of a taxonomy under investigation in terms of nodes and edges, evaluating whether the overall graph generated by hypernym-hyponym relations provides connections between the root of the taxonomy and all the other nodes. This is an important property of taxonomies that are used for search because it ensures that all the nodes are findable when exploring the taxonomy from the root. Another structural property of taxonomies is the absence of cycles, which are inconsistent with the semantics of hierarchical relations. Additionally, we highlight the number of nodes located on higher lev-els of a taxonomy, called intermediate nodes. Finding these nodes is more important than connecting a large number of leaves, as they generate taxonomies with a deeper and richer structure.</p><p>Based on these considerations, structural evaluation is performed by computing the cardinality of |V S | and |E S |. We use an algorithm that finds all the elementary circuits of a simple directed graph <ref type="bibr" target="#b5">(Johnson, 1975)</ref> to establish if the taxonomy S contains simple directed cycles (self loop excluded). We then use an approach based on the Tarjan algorithm <ref type="bibr" target="#b18">(Tarjan, 1972)</ref> to calculate the number of connected components in S. Finally, we compute the number of intermediate nodes as the number of nodes |V S | − |L S | where L S is the set of leaf nodes in S, where a leaf node is defined as a node with the outdegree zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Gold Standard Comparison</head><p>While initial gold standard datasets for evaluating taxonomy extraction were mainly based on relations extracted from WordNet <ref type="bibr" target="#b6">(Kozareva and Hovy, 2010)</ref>, more recent work <ref type="bibr" target="#b19">(Velardi et al., 2013)</ref> focuses on specialized domains such as artificial intelligence. The dataset introduced in this shared task brings together gold standards collected from Word-Net together with gold standards extracted from domain-specific taxonomies and from Wikipedia, a collaborative resource.</p><p>Given a gold standard taxonomy G = (V G , E G ), the comparison between a target taxonomy and a gold standard taxonomy is quantified using the following measures:</p><formula xml:id="formula_1">• Edge precision: P = |E S ∩ E G |/|E S | • Edge recall: R = |E S ∩ E G |/|E G | • F-score: F = 2(P * R)/(P + R)</formula><p>Additionally, we consider the Cumulative Fowlkes&amp;Mallows (Cumulative F&amp;M) measure <ref type="bibr" target="#b19">(Velardi et al., 2013)</ref>, denoted as B S,G , and defined as a value between 0.0 and 1.0 which measures level by level how well a target taxonomy S clusters similar nodes compared to a gold standard taxonomy G. B S,G is calculated as follows: let k be the maximum depth of both S and G, and H ij a cut of the hierarchy, where i ∈ {0, ..., k} is the cut level and j ∈ {G, S} selects the clustering of interest.</p><p>Then, for each cut i, the two hierarchies can be seen as two flat clusterings C iS and C iG of the n concepts. When i = 0 the cut is a single cluster incorporating all the objects, and when i = k we obtain n singleton clusters. Now let: n 11 be the number of object pairs that are in the same cluster in both C iS and C iG ; n 00 be the number of object pairs that are in different clusters in both C iS and C iG ; n 10 be the number of object pairs that are in the same cluster in C iS but not in C iG ; n 01 be the number of object pairs that are in the same cluster in C iG but not in C iS .</p><p>The generalized Fowlkes&amp;Mallows measure of cluster similarity for the cut i (i ∈ {0, ..., k}), as reformulated in <ref type="bibr" target="#b20">(Wagner and Wagner, 2007)</ref>, is defined as:</p><formula xml:id="formula_2">B i S,G = n i 11 (n i 11 + n i 10 ) • (n i 11 + n i 01 )</formula><p>.</p><p>(</p><formula xml:id="formula_3">)<label>2</label></formula><p>And the Cumulative Fowlkes&amp;Mallows Measure:</p><formula xml:id="formula_4">B S,G = k−1 i=0 i+1 k B i S,G k−1 i=0 i+1 k = k−1 i=0 i+1 k B i S,G k+1 2 . (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Manual Evaluation</head><p>Even the most complete and up to date taxonomy can be extended with additional nodes and relations, therefore it is possible for systems to identify correct relations that are not covered by the gold standard.</p><p>A problem faced by gold standard evaluation is that these relations are considered incorrect when relying on a direct comparison with the gold standard taxonomy. This is why we additionally evaluate by hand a subset of new relations proposed by each system to estimate the number of relations in E S that do not belong to E G . Due to limited resources, we extract only a random sample of novel relations from each submission and manually annotate them to compute precision P as: |correctISA|/|sample|. At most 100 relations were evaluated by one annotator for each system, domain, and language for a total of 6200 term pairs. Two different annotators were tasked to evaluate submissions for the monolingual subtask (English) and for the multilingual subtask (Dutch, French, Italian). The annotators were provided with a list of term pairs organized by domain and were asked if the relation was a correct ISA relation, if the relation and the terms were domain specific, and if the relation was too generic. Overall, a relation is considered correct only if it is considered a correct hypernymhyponym relation, if it is relevant for the given domain and not over-generic. Take for example the following edges from the food domain: (linguine, pasta) and (lemon, food). Both edges are correct ISA relations and are domain specific, but the second edge is over-generic because lemons can be categorized more precisely as fruits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Participants and Results</head><p>A total of five teams participated in the shared task, but only two systems participated in the multilingual subtasks. Two of the systems that participated in the monolingual subtask alone did not submit runs for the food domain, which has the largest number of nodes. Overall, 62 system runs were submitted by the five teams, 36 for the multilingual subtasks and 26 for the monolingual subtasks. Next, we provide a short description of each approach starting with the two systems that participated in the multilingual subtasks.</p><p>JUNLP The JUNLP system makes use of an external linguistic resource for hypernym identification <ref type="bibr" target="#b9">(Maitra and Das, 2016)</ref>. This resource is the BabelNet semantic network that connects concepts and named entities in a very large network of semantic relations, called Babel synsets <ref type="bibr" target="#b11">(Navigli and Ponzetto, 2010)</ref>. To make sure that no relations that were used to construct the gold standards are considered, only relations that mention Wikipedia as a source were selected, discarding relations from all the other sources. Additionally, the system makes use of two string inclusion heuristics. The first heuristic checks if any of the terms provided by the organisers is included as a substring in another term. The second heuristic considers terms that have a considerable overlap, for instance Chocolate Pudding and Vanilla Pudding although their hypernym (i.e., Pudding) is not mentioned in the list of terms. A limitation of this approach is that stopwords are also considered as hypernyms, but this can be easily avoided by using a stopword list.</p><p>TAXI The methods for hypernym identification used in the TAXonomy Induction system (TAXI) rely on two sources of evidence: substring matching   and Hearst-like patterns <ref type="bibr" target="#b12">(Panchenko et al., 2016)</ref>.</p><p>The Hearst patterns for all languages are extracted from Wikipedia and from focused crawls with seed pages that are Wikipedia pages. In addition, for English, several additional corpora are used including GigaWord, ukWaC, a news corpus and the CommonCrawl. For French, Italian and Dutch the method is completely unsupervised and relies on KNN approach. For English, an SVM classifier is trained on the trial data. For all languages the features are the same: substrings and ISA relations extracted with lexico-syntactic patterns. No databases or linguistic resources beyond trial data and raw text corpora mentioned above are used. For the taxonomy construction subtasks, the system makes use of an unsupervised graph pruning approach based on the Tarjan algorithm, connecting the resulting disconnected components to the root of the graph. NUIG-UNLP The system implements a semisupervised method that finds hypernym candidates for the provided noun phrases by representing them as distributional vectors. Roughly, this method assumes that hypernyms may be induced by adding a vector offset <ref type="bibr" target="#b10">(Mikolov et al., 2013;</ref><ref type="bibr" target="#b14">Rei and Briscoe, 2014)</ref> to the corresponding hyponym representation generated by GloVe over a Wikipedia dump. The vector offset is obtained as the average offset between 200 pairs of hyponym-hypernym in the same vector space selected from trial data.</p><p>USAAR This system introduces hypernym endocentricity as a useful property for hypernym identification <ref type="bibr" target="#b17">(Tan, 2016)</ref>. Often multi-word hyponyms are endocentric constructions which contains a word that fulfills the same function as one part of its word. E.g. an "apple pie" is essentially a "pie". The number of multi-words terms that are endocentric in English is investigated and whether this endocentric property can be used to generate entity links to connect terms in the Wikipedia list of list.</p><p>QASSIT A semi-supervised methodology is used for the acquisition of lexical taxonomies based on genetic algorithms <ref type="bibr">(Cleuziou and Moreno, 2016)</ref>. It is based on the theory of pretopology that offers a powerful formalism to model semantic relations and transforms a list of terms into a structured term space by combining different discriminant criteria.</p><p>In particular, rare but accurate pieces of knowledge are used to parameterize the different criteria defining the pretopological term space. Then, a structuring algorithm is used to transform the pretopological space into a lexical taxonomy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Monolingual Subtasks (English)</head><p>Table <ref type="table" target="#tab_3">2</ref> presents the results of the structural analysis for English, giving an overview of the structural measures presented in Section 4.2 for each of the submitted runs. The taxonomies constructed by the TAXI and QASSIT systems are the only taxonomies that provide a path from the root to all the other nodes, as the corresponding graphs have a single connected component. All the other submissions have more than ten disconnected components. The string-based baseline is also producing several disconnected components. The TAXI and USAAR systems are the only systems that produce directed acyclic graphs across all the domains. The QAS-SIT system generates two cycles in the case of the combined taxonomy for Science. Overall, only the TAXI system consistently produces well-structured taxonomies across domains. The systems that output taxonomies with a large number of nodes, edges and intermediate nodes (e.g., JUNLP and NUIG-UNLP) tend to do so at the cost of introducing cycles in the graph.</p><p>In Table <ref type="table" target="#tab_5">3</ref> we summarize the results of the comparison with gold standards in terms of Fscore and the Cumulative F&amp;M measure. The string-based baseline is relatively strong compared to the other systems in terms of Fscore, providing the best results for all the domains with the exception of the food domain. A reason why the baseline is weaker in this domain is that a much larger number of food terms are single-word terms that are not compositional, but in absolute terms the results are still comparative with the results of the best system coming second on the overall ranking. In terms of the Cumulative F&amp;M measure that quantifies structural similarity with the gold standards, the QASSIT system takes the lead for all the domains where a taxonomy was submitted. In the case of the Food domain, it is the TAXI system that achieves the best results for the Combined gold standard and the USAAR system for the WordNet gold standard. The string-based baseline captures only a small part of the structure of the gold standard, as shown by the poor results for the Cumulative F&amp;M measure.</p><p>The results of the manual evaluation of a sample of novel relations is presented in Table <ref type="table" target="#tab_6">4</ref>. It is worth noting that not all the systems had at least one hundred novel relations to analyse, therefore in some cases a smaller number of relations was manually evaluated. The USAAR submissions introduce the largest number of correct novel relations, with precision higher than 70% for Food taxonomies and the Science taxonomy gathered from Combined sources. The TAXI system comes second for all the domains with the exception of the Science taxonomy gathered from Eurovoc, where the QASSIT system achieves the best results.</p><p>The final ranking of the systems is produced by using a voting approach based on the averaged scores of selected measures that cover the main properties of a well-formed taxonomy. For this shared task all the properties are considered to be equally important, but a weighted approach could also be considered depending on the intended purpose of a taxonomy. These properties include (1) cyclicity, measured in terms of the number of submissions that have cycles; (2) structural similarity with gold standard taxonomies, measured with Cumulative F&amp;M measure; (3) categorization, measured in number of intermediate nodes #i.i. that can be interpreted as taxonomical categories; (4) connectivity, measured in number of connected components #c.c.; (5) overlap of edges with the gold standard taxonomy, measured by Fscore; (6) number of covered domains; (7) precision of novel relations from manual evaluation of sample relations. Table <ref type="table">5</ref> presents the averaged results for each of these measures across domains.</p><p>Take for example the best ranked system TAXI, where none of the submitted taxonomies had any cycles, which resulted in an overall score of 0 for cyclicity and a rank 1 in the overall ranking, as this is a desirable feature for a taxonomy. In the case of the structure property, measured by averaging the Cumulative F&amp;M measure over all the submitted taxonomies, the TAXI system achieved the second highest score. This score is below the score achieved by the QASSIT system for the same feature, which brings the TAXI system on the second position in the final ranking for the structure property. Cyclicity  and connectivity are the only two properties where low scores are preferable, while for the structure, categorisation, gold standard Fscore, domains, and manual precision higher values are preferred.</p><p>The averaged scores shown in Table <ref type="table">5</ref> are directly used to obtain the final ranking of the system for the monolingual subtasks presented in Table <ref type="table">6</ref>. The scores used to generate the rankings for the Hypernym Identification (HI) subtask are mainly the last three properties, namely the Fscore with the gold standard, the number of domains, and the precision from manual evaluation. All the seven taxonomical properties described above are used for ranking systems for the Taxonomy Construction (TC) subtask. The TAXI system achieves the best results based on most of these measures, coming third only for the categorization property. This brings the system to the first place both for the Hypernym Identification and the Taxonomy Construction subtasks, in the monolingual setting. There is a tie with the USAAR system, but only for the Hypernym Identification subtask. The second placed system is the QASSIT system, that is ranked on the top three positions for most of the properties with the exception of the categorization property, where it is ranked on the second last place. This is due to the fact that the QASSIT system produces a relatively flat structure, with a smaller number of intermediate nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multilingual Subtasks (Dutch, French,</head><p>Italian)</p><p>The results for the multilingual subtasks cover a much smaller number of systems, as only two out of the five participants submitted multilingual taxonomies. The same properties are used for the final rankings of the systems as in the previous section, as can be seen in Table <ref type="table" target="#tab_10">7</ref>. This table shows the average scores of the two systems and of the string-based baseline across domains. Both systems submitted runs for all the domains, therefore in the multilingual subtask the number of domains was not used for ranking the systems.   termediate nodes. Again, the string-based baseline achieves the best Fscore results in comparison with the gold standards. The TAXI system achieves the best results for English, with a 12.5% decrease in Fscore for Dutch and French and a 9.4% decrease for Italian. JUNLP performance is more stable across languages, with only a 5% drop in Fscore for Dutch and Italian compared to English, and the same Fscore for French.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>This paper provides an overview of the SemEval 2016 task on Taxonomy Extraction, that introduced a multilingual dataset for evaluating hypernym extraction and taxonomy construction. The constructed dataset covers three domains including Environment, Food, and Science. The task attracted 62 submissions from five teams that were automatically evaluated against gold standards collected from WordNet, Eurovoc, Wikipedia and other domain-specific resources. We also reported the results of an extensive structural analysis of the submitted taxonomies and a manual evaluation of a sample of edges that are not covered by the gold standards.</p><p>The best results were obtained by an approach based on Hearst patterns that makes use of a large web-based corpus including Wikipedia. All the systems could benefit from addressing the taxonomy construction subtask, by paying attention to the overall structure of the taxonomy not just the task of extracting pairs of terms. Compared to the previous edition of TExEval, there are two systems that submitted proper taxonomies compared to just one system last year. In this edition, it is also worthy of mention the introduction of methods that make use of purely distributional approaches. These approaches leave a lot of place for improvement, achieving a competitive recall but lagging behind pattern-based approaches in terms of precision.</p><p>A possible improvement of this shared task is to analyse system performance in relation to word polysemy. This could be measured by example based on Wikipedia disambiguation pages or on the number of WordNet senses. It is reasonable to assume that hypernym/hyponym pairs between polysemous words are more difficult to connect without using disambiguation methods to identify the appropriate sense for a domain.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Structural  </figDesc><table><row><cell>measures of gold standard taxonomies, including number of vertices (|V |), edges (|E|), interme-diate nodes (#i.i), connected components (#c.c.) and cycles.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Structural analysis of the submitted taxonomies and the string-based baseline for the monolingual setting</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Gold standard comparison using Fscore and Cumulative F&amp;M measure for the monolingual setting, where B stands for the string-based baseline</figDesc><table><row><cell>Domain</cell><cell>Source</cell><cell cols="5">JUNLP TAXI NUIG-UNLP USAAR QASSIT</cell></row><row><cell cols="2">Environment Eurovoc Food Combined Food WordNet Science Combined Science Eurovoc Science WordNet</cell><cell>0.02 0.2 0.18 0.06 0.02 0.06</cell><cell>0.11 0.36 0.32 0.14 0.02 0.22</cell><cell>0.08 --0.09 0.04 0.05</cell><cell>0.22 0.73 0.81 0.71 0.0 0.47</cell><cell>0.07 --0.07 0.05 0.22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Manual evaluation of 100 (at most) randomly selected novel relations based on precision for English</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :Table 6 :</head><label>56</label><figDesc>Average scores achieved by the systems for the monolingual subtasks. Overall ranking of the systems for the monolingual subtasks on Taxonomy Construction (TC) and Hypernym Indentification (HI).</figDesc><table><row><cell>Subtask</cell><cell>Measure</cell><cell cols="5">JUNLP TAXI NUIG-UNLP USAAR QASSIT</cell></row><row><cell cols="2">TC TC &amp; HI GS Fscore Cyclicity Structure (F&amp;M) Categorisation (#i.i.) Connectivity (#c.c.) Domains Manual Precision</cell><cell>3 3 1 3 4 1 4</cell><cell>1 2 3 1 1 1 2</cell><cell>4 4 2 2 5 2 5</cell><cell>1 5 4 4 2 1 1</cell><cell>2 1 5 1 3 2 3</cell></row><row><cell>TC HI</cell><cell>Ranking</cell><cell>4 3</cell><cell>1 1</cell><cell>5 4</cell><cell>3 1</cell><cell>2 2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>presents the final</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Average scores of the systems for the multilingual subtasks.</figDesc><table><row><cell>Subtask</cell><cell>Measure</cell><cell cols="2">JUNLP TAXI</cell></row><row><cell cols="2">TC TC &amp; HI GS Fscore Cyclicity Structure (F&amp;M) Categorisation (#i.i.) Connectivity (#c.c.) Manual Precision</cell><cell>1 2 1 2 2 2</cell><cell>1 1 2 1 1 1</cell></row><row><cell>TC HI</cell><cell>Ranking</cell><cell>2 2</cell><cell>1 1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Overall ranking of the systems for the multilingual subtasks on Taxonomy Construction (TC) and Hypernym Indentification (HI).</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Eurovoc: http://eurovoc.europa.eu/drupal/ 2 http://www.google.com/basepages/ producttype/taxonomy.en-US.txt 3 http://sites.nationalacademies.org/PGA/ Resdoc/PGA_044522</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Association for Computational Linguistics</title>
	</analytic>
	<monogr>
		<title level="m">-955</title>
				<meeting><address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The distributional inclusion hypotheses and lexical entailment</title>
		<author>
			<persName><forename type="first">Maayan</forename><surname>Geffet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05</title>
				<meeting>the 43rd Annual Meeting on Association for Computational Linguistics, ACL &apos;05<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">INRIASAC: Simple hypernym extraction methods</title>
		<author>
			<persName><forename type="first">Gregory</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Workshop on Semantic Evaluation</title>
				<meeting>the Ninth International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Open-domain textual question answering techniques</title>
		<author>
			<persName><forename type="first">Sanda</forename><forename type="middle">M</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Maiorano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="231" to="267" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic acquisition of hyponyms from large text corpora</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th conference on Computational linguistics</title>
				<meeting>the 14th conference on Computational linguistics</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="539" to="545" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding all the elementary circuits of a directed graph</title>
		<author>
			<persName><forename type="first">B</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="84" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A semisupervised method to learn and construct taxonomies using the web</title>
		<author>
			<persName><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10</title>
				<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;10<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1110" to="1118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">HypoTerm: Detection of hypernym relations between domain-specific terms in Dutch and English</title>
		<author>
			<persName><forename type="first">Els</forename><surname>Lefever</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Van De Kauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronique</forename><surname>Hoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Terminology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="250" to="278" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Do supervised distributional methods really learn lexical inference relations</title>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Remus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Israel</forename><surname>Ramat-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
				<meeting>NAACL<address><addrLine>Denver, CO</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">JUNLP at SemEval-2016 Task 13: A language independent approach for hypernym identification</title>
		<author>
			<persName><forename type="first">Promita</forename><surname>Maitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Linguistic regularities in continuous space word representations</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yih</forename><surname>Wen-Tau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">HLT-NAACL</title>
				<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="746" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Babelnet: Building a very large multilingual semantic network</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 48th annual meeting of the association for computational linguistics</title>
				<meeting>the 48th annual meeting of the association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="216" to="225" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">TAXI at SemEval-2016 Task13: a taxonomy induction method based on lexico-syntactic patterns, substrings and focused crawling</title>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Faralli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugen</forename><surname>Ruppert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steffen</forename><surname>Remus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hubert</forename><surname>Naets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cedrick</forename><surname>Fairon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">NUIG-UNLP at SemEval-2016 Task 13: A simple word embedding-based approach for taxonomy extraction</title>
		<author>
			<persName><forename type="first">Joel</forename><surname>Pocostales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Looking for hyponyms in vector space</title>
		<author>
			<persName><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CoNLL</title>
				<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="68" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Inclusive yet selective: Supervised distributional hypernymy detection</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gemma</forename><surname>Boleda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
				<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1025" to="1036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Chasing hypernyms in vector spaces with entropy</title>
		<author>
			<persName><forename type="first">Enrico</forename><surname>Santus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Lenci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Schulte Im Walde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
				<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="38" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">USAAR at SemEval-2016 Task 13: Hyponym endocentricity</title>
		<author>
			<persName><forename type="first">Liling</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Depth-first search and linear graph algorithms</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Tarjan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Computing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="146" to="160" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">OntoLearn Reloaded: A Graph-Based Algorithm for Taxonomy Induction</title>
		<author>
			<persName><forename type="first">Paola</forename><surname>Velardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefano</forename><surname>Faralli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="665" to="707" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Comparing clusterings an overview</title>
		<author>
			<persName><forename type="first">Silke</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorothea</forename><surname>Wagner</surname></persName>
		</author>
		<idno>2006-04</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>Faculty of Informatics, Universität Karlsruhe (TH</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to distinguish hypernyms and co-hyponyms</title>
		<author>
			<persName><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daoud</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Reffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Weir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
				<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2249" to="2259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning term embeddings for hypernymy identification</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haixun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuemin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI&apos;15</title>
				<meeting>the 24th International Conference on Artificial Intelligence, IJCAI&apos;15</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1390" to="1397" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
