<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Framework and Results for the Spanish SENSEVAL</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">German</forename><surname>Rig Au</surname></persName>
							<email>g.rigau@lsi.upc.es</email>
						</author>
						<author>
							<persName><forename type="first">Mariona</forename><surname>Taule</surname></persName>
							<email>rntaule@lingua.filub.es</email>
						</author>
						<author>
							<persName><forename type="first">Ana</forename><surname>Fernandez</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">TALP Research Center</orgName>
								<orgName type="institution" key="instit2">Universitat Politecnica de Catalunya</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<addrLine>CLiC, Universitat Autonoma de</addrLine>
									<settlement>Barcelona</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">GPLN, Universidad Nacional de Educaci6n a Distancia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Framework and Results for the Spanish SENSEVAL</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the structure, organisation and results of the SENSEVAL exercise for Spanish. We present several design decisions we taked for the exercise, we describe the creation of the goldstandard data and finally, we present the results of the evaluation. Twelve systems from five different universities were evaluated. Final scores ranged from 0.56 to 0.65.</p><p>1 The noun "arte" was not included in the exercise because it was provided to the competitors during the trial phase. 2  The working corpus of the HERMES project CICYT TIC2000-0335-C03-02.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe the structure, organisation and results of the Spanish exercise included within the framework of SENSEVAL-2.</p><p>Although we closely follow the general architecture of the evaluation of SENSEVAL-2, the final setting of the Spanish exercise involved a number of choices detailed in section 2. In the following sections we describe the data, the manual tagging process (including the inter-tagger agreement figures), the participant systems and the accuracy results (including some baselines for comparison purposes).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Design Decisions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task Selection</head><p>For Spanish SENSEVAL, the lexical-sample variant for the task was chosen. The main reasons for this decision are the following:</p><p>• During the same tagging session, it is easier and quicker to concentrate only on one word at a time. That is, tagging multiple instances of the same word.</p><p>• The all-words task requires access to a full dictionary. To our knowledge, there are no full Spanish dictionaries available (with low or no cost). Instead, the lexical-sample task required only as many dictionary entries as words in the sample task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="41">2.2 Word Selection</head><p>The task for Spanish is a "lexical sample" for 39 words 1 (17 nouns, 13 verbs, and 9 adjectives). See table 1 for the complete list of all words selected for the Spanish lexical sample task. The words can belong only to one of the syntactic categories. The fourteen words selected to be translation-equivalents to English has been:</p><p>• Nouns: arte (=art), autoridad (= authority), canal ( = channel), circuito ( = circuit), and naturaleza ( = nature).</p><p>• Verbs: conducir (=drive), tratar (=treat), and usar (=use).</p><p>• Adjectives: ciego (=blind), local(= local), natural (= natural), simple (= simple), verde (= green), and vital(= vital).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Corpus Selection</head><p>The corpus was collected from two different sources: "El Peri6dico" 2 (a Spanish newspaper) and LexEsp 3 (a balanced corpus of 5.5 million words). The length of corpus samples is the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Selection of Dictionary</head><p>The lexicon provided was created specifically for the task and it consists of a definition for each sense linked to the Spanish version of EuroWordNet and, thus, to the English WordNet 1.5. The syntactic category and, sometimes, examples and synonyms are also provided. The connections to EuroWord-Net have been provided in order to have a common language independent conceptual structure. Neither proper nouns nor multiwords has been considered. We have also provided the complete mapping between WordNet 1.5 and 1.6 versions 4 • Each dictionary entry have been constructed consulting the cor-pus and multiple Spanish dictionaries (including the Spanish WordNet).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Annotation procedure</head><p>The Spanish SENSEVAL annotation procedure was divided into three consecutive phases.</p><p>• Corpus and dictionary creation • Annotation</p><p>• Referee process All these processes have been possible thanks to the effort of volunteers from three NLP groups from Universitat Politecnica de Catalunya 5 (UPC), Universitat de Barcelona 6 (UB) and Universidad Nacional de Educaci6n a Distancia 7 (UNED).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Corpus and Dictionary Creation</head><p>The most important and crucial task was carried out by the UB team of linguists, headed by Mariana Taule. They were responsible for the selection of the words, the creation of the dictionary entries and the selection of the corpus instances. First, this team selected the polysemous words for the task consulting several dictionaries including the Spanish WordNet and a quick inspection to the Spanish corpus. For the words selected, the dictionary entries were created simultaneously with the annotation of all occurrences of the word. This allowed the modification of the dictionary entries (i.e. adapting the dictionary to the corpus) during the annotation and the elimination of unclear corpus instances (i.e. adapting the corpus to the dictionary).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Annotation</head><p>Once the Spanish SENSEVAL dictionary and the annotated corpus were created, all the data was delivered to the UPC and UNED teams, removing all the sense tags from the corpus. Having the Spanish SENSEVAL dictionary provided by the UB team as the unique semantic reference for annotation both teams performed in parallel and simultaneously a new annotation of the whole corpus. Both teams where allowed to provide comments/problems on the each of the corpus instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.3">Referee Control</head><p>Finally, in order to provide a coherent annotation, a unique referee from the UPC team collate both annotated corpus tagged by the UPC and the UNED teams. This referee was not integrated in the UPC team in the previous annotating phase. The referee was in fact providing a new annotation for each instance when occurring a disagreement between the sense tags provided by the UPC and UNED teams.</p><p>3 The Spanish data 3.1 Spanish Dictionary The Spanish lexical sample is a selection of higl medium and low polysemy frequent nouns, verbs an adjectives. The dictionary has 5.10 senses per wor and the polysemy degree ranges from 2 to 13. Noun has 3.94 ranging from 2 to 10, verbs 7.23 from 4 t 13 and adjectives 4.22 from 2 to 9 (see table 1 fo further details).</p><p>The lexical entries of the dictionary have the fol lowing form: </p><formula xml:id="formula_0">&lt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Spanish Corpus</head><p>We adopted, when possible, the guidelines propose1 by the SENSEVAL organisers <ref type="bibr" target="#b1">(Edmonds, 2000)</ref>. Fo each word selected having n senses we provided a least 75 + 15n instances. For the adjective popular ; larger set of instances has been provided to test per formance improvement when increasing the numbe of examples. These data has been then ramdoml: divided in a ratio of 2:1 between training and tes set.</p><p>The corpus was structured following the standan SENSEVAL XML format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Major problems during annotation</head><p>In this section we discuss the most frequent and reg ular types of disagreement between annotators.</p><p>In particular, the dictionary proved to be not suf ficiently representative of the selected words to b1 annotated. Although the dictionary was built fo the task, out of 48% of the problems during the sec and phase of the annotation where due to the lacl of the appropriate sense in the corresponding dictionary entry. This portion includes 5% of metaphorical uses not explicitly described into the dictionary entry. Furthermore, 51% of the problems reported by the annotators were concentrated only on five words <ref type="bibr">(pasaje, canal, bomba, usar, and saltar)</ref>.</p><p>Selecting only one sentence as a context during annotation was the other main problem. Around 26% of the problems where attributed to insufficient context to determine the appropriate sense.</p><p>Other sources of minor problems included different Part-of-Speech from the one selected for the word to be annotated, and sentences with multiple meanings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Inter-tagger agreement</head><p>In general, disagreement between annotators (and sometimes the use of multiple tags) must be interpreted as misleading problems in the definition of the dictionary entries. The inter-tagger agreement between UPC and UNED teams was 0.64% and the Kappa measure 0.44%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Systems</head><p>Twelve systems from five teams participated in the Spanish task.</p><p>• Universidad de Alicante (UA) combined a Knowledge-based method and a supervised method. The first uses WordNet and the second a Maximum Entropy model.</p><p>• John Hopkins University (JHU) presented a metalearner of six diverse supervised learning subsystems integrated via classifier. The subsystems included decision lists, transformationbased error-driven learning, cosine-based vector models, decision stumps and feature-enhanced naive Bayes systems.</p><p>• Stanford University (SU) presented a metalearner mainly using Naive Bayes methods, but also including vector space, n-gram, and KNN classifiers.</p><p>• University of Maryland (UMD) used a marginbased algorithm to the task: Support Vector Machine.</p><p>• University of Manitoba (d6-lO,dX-Z) presented different combinations of classical Machine Learning algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">The Results</head><p>Table <ref type="table" target="#tab_2">1</ref> presents the results in detail for all systems and all words. The best scores for each word are highlighted in boldface. The best average score is obtained by the JHU system. This system is the best in 12 out of the 39 words and is also the best for nouns and verbs but not for adjectives. The SU system gets the highest score for adjectives.</p><p>The associated agreement and kappa measures for each system are shown in Table <ref type="table" target="#tab_3">2</ref>. Again JHU system scores higher in both agreement and Kappa measures. This indicates that the results from the JHU system are closer to the corpus than the rest of participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Further Work</head><p>Obviously, an in deep study of the strengths and weaknesses of each system with respect to the results of the evaluation must be carried out, including also further analysis comparing the UPC and UNED annotations against each system.</p><p>Following the ideas described in <ref type="bibr" target="#b2">(Escudero et al., 2000)</ref> we are considering also to add a cross-domain aspect to the evaluation in future SENSEVAL editions, allowing the training on one domain and the evaluation on the other, and vice-versa.</p><p>In order to provide a common platform for evaluating different WSD algorithms we are planning to process the Spanish corpus tagged with POS using MACO <ref type="bibr" target="#b0">(Carmona et al., 1998)</ref> and RELAX <ref type="bibr" target="#b3">(Padro, 1998)</ref>.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Evaluation of Spanish words. p stands for Part-of-Speech; e for the total number of examples (including train and test sets); s for the number of senses; MF for the Most Frequent Sense Classifier and the rest are the system acronyms. words UA su JHU UMD d6 d7 d8 d9 dlO dX dY dZ</figDesc><table><row><cell cols="2">Agreement 0.51 0.63</cell><cell>0.65</cell><cell>0.61</cell><cell>0.55 0.57 0.59 0.53 0.59 0.55</cell><cell>0.51</cell><cell>0.57</cell></row><row><cell>Kappa</cell><cell>0.20 0.34</cell><cell>0.47</cell><cell>0.20</cell><cell cols="3">0.13 0.19 0.23 0.06 0.24 0.15 -0.03 0.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Agreement and Kappa measures</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">http://www.lsi.upc.es/.-vnlp 6 http://www.ub.es/ling/labing.htm 7 http://rayuela.ieec.uned.es/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>The Spanish SENSEVAL has been possible thanks to the effort of volunteers from three NLP groups from UPC, UB, and UNED universities.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An Environment for Morphosyntactic Processing of Unrestricted Spanish Text</title>
		<author>
			<persName><forename type="first">J</forename><surname>Carmona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cervell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Marti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Padro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Placer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Turmo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First International Conference on Language Resources and Evaluation</title>
				<meeting>the First International Conference on Language Resources and Evaluation<address><addrLine>LREC, Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Designing a task for SENSEVAL-2. Draft, Sharp Laboratories, Oxford</title>
		<author>
			<persName><forename type="first">P</forename><surname>Edmonds</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Comparison between Supervised Learning Algorithms for Word Sense Disambiguation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Escudero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Marquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Computational Natural Language Learning Workshop</title>
				<meeting>the 4th Computational Natural Language Learning Workshop<address><addrLine>CoNLL, Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Portugal</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A Hybrid Environment for Syntax-Semantic Tagging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Padro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>LSI). Technical University of Catalonia (UPC</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Phd. Thesis, Software Department</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
