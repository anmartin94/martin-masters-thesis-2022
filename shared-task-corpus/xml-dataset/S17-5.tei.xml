<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Keith</forename><surname>Cortis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Mathematics</orgName>
								<orgName type="institution">University of Passau</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">André</forename><surname>Freitas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Mathematics</orgName>
								<orgName type="institution">University of Passau</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tobias</forename><surname>Daudert</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Insight Centre for Data Analytics</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manuela</forename><surname>Hürlimann</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Insight Centre for Data Analytics</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Manel</forename><surname>Zarrouk</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Insight Centre for Data Analytics</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Siegfried</forename><surname>Handschuh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Mathematics</orgName>
								<orgName type="institution">University of Passau</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Brian</forename><surname>Davis</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Insight Centre for Data Analytics</orgName>
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2017 Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper discusses the "Fine-Grained Sentiment Analysis on Financial Microblogs and News" task as part of SemEval-2017, specifically under the "Detecting sentiment, humour, and truth" theme. This task contains two tracks, where the first one concerns Microblog messages and the second one covers News Statements and Headlines. The main goal behind both tracks was to predict the sentiment score for each of the mentioned companies/stocks. The sentiment scores for each text instance adopted floating point values in the range of -1 (very negative/bearish) to 1 (very positive/bullish), with 0 designating neutral sentiment. This task attracted a total of 32 participants, with 25 participating in Track 1 and 29 in Track 2.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Overview</head><p>Our task is focused on Sentiment Analysis in the domain of financial microblogs and news. Domainspecific Sentiment Analysis has received much attention within the NLP community, motivated by the highly domain-dependent language used to express sentiment <ref type="bibr" target="#b19">(Liu, 2012)</ref>. Domain-specificity impacts all levels of analysis. On the lexical level, which is crucial in sentiment analysis, <ref type="bibr" target="#b19">Liu (2012)</ref> notes that positive words in one domain can be negative in another, and vice versa. For instance, <ref type="bibr" target="#b20">Loughran and McDonald (2011a)</ref> show that many words which are considered negative in generalpurpose polarity lexicon have a neutral meaning in the financial domain (e.g. "liability"). This makes it difficult to transport sentiment classifiers across domains and underlines the need for domain-specific tools.</p><p>The financial domain is a high-impact use case for Sentiment Analysis because it has been shown that sentiments and opinions can affect market dynamics <ref type="bibr" target="#b10">(Goonatilake and Herath, 2007;</ref><ref type="bibr" target="#b4">de Kauter et al., 2015)</ref>. Sentiments are in some cases derived from news which discuss macroeconomic factors, company-specific, or political information as all of these can be market-relevant <ref type="bibr" target="#b44">(Sinha, 2014)</ref>. Good news tends to lift markets and increase optimism <ref type="bibr" target="#b4">(de Kauter et al., 2015;</ref><ref type="bibr" target="#b42">Schuster, 2003)</ref>. Evidence has been found that both quantitative measures (e.g. the quantity of news, market fluctuation) and qualitative indicators, (e.g. linguistic style and tone) affect investors' behaviour <ref type="bibr" target="#b48">(Tetlock et al., 2008;</ref><ref type="bibr" target="#b20">Loughran and McDonald, 2011a;</ref><ref type="bibr" target="#b47">Takala et al., 2014)</ref>. <ref type="bibr" target="#b0">(Bollen et al., 2011)</ref> showed that changes in public mood reflect value shifts in the Dow Jones Industrial Index three to four days later.</p><p>Given the link between sentiment and market dynamics, the analysis of public sentiment becomes a powerful method to predict the market reaction. However, the accuracy of machine learning-based sentiment analysis approaches rarely exceeds seventy percent <ref type="bibr" target="#b47">(Takala et al., 2014;</ref><ref type="bibr" target="#b6">Eagle Alpha, 2016)</ref>. Research effort is required to overcome and address complex linguistic issues, such as sarcasm, irony and poorly-structured and/or colloquial language <ref type="bibr" target="#b6">(Eagle Alpha, 2016)</ref>. In addition, text that is short in length (such as microblog messages) can be quite opinionated, dense in information, dependent on the modelling of economic context and challenging to parse, due to the different vocabularies used <ref type="bibr" target="#b44">(Sinha, 2014)</ref>. Our task is motivated by the interest of this field and the great potential for improvement. It aims at assessing the overall market sentiment as well as sentiment about specific stocks and thus to make use of their predictive power.</p><p>More specifically, the aim of organising this task and creating this test collection was to achieve the following goals:</p><p>1. Developing state-of-the-art on classification methods for sentiment analysis in the domain of financial short texts.</p><p>2. Incentivising the creation of new lexical resources for the financial domain.</p><p>3. Understanding how state-of-the-art sentiment analysis performs on a domain-specific / highly technical corpus.</p><p>4. Improving the understanding of linguistic phenomena and the creation of semantic models for the financial domain.</p><p>The domain of finance has unique linguistic and semantic features, whose interpretation depends on the formulation of semantic models which reflect the economic and mathematical tools used by the experts to assess financial information. Moreover, the accurate interpretation of financial text requires the orchestration of large volumes of common sense and domain-specific financial/economic knowledge. Additionally, as much of the financial discourse is mediated by terms which demand precise definitions, many times associated with the quantification of economic phenomena, the semantic interpretation processes in the financial domain require fine-grained semantic interpretation approaches.</p><p>From a linguistic standpoint, topics of interest in this task include (but are not limited to):</p><p>• Low-level linguistic analysis tools for the financial domain (e.g. tokenization, part-ofspeech tagging, parsing)</p><p>• Sentiment classification on financial texts;</p><p>• Understanding of linguistic phenomena associated with financial tweets;</p><p>• New semantic models for finance;</p><p>• Construction and application of distributional semantic models on finance;</p><p>• Sentiment compositionality;</p><p>• Machine learning approaches for sentiment classification;</p><p>• Lexical resources for the financial domain;</p><p>2 Data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tracks</head><p>The test collection consists of two tracks:</p><p>1. Microblog Messages derived from two sources:</p><p>(a) StockTwits Messages: Consists of microblog messages focusing on stock market events and assessments from investors and traders, exchanged via the Stock-Twits microblogging platform 1 . Typical stocktwits consist of references to company stock symbols (so-called cashtags -a stock symbol preceded by "$", e.g. "$AAPL" for the company Apple Inc.), a short supporting text or references to a link or pictures (typically containing charts showing stock values analysis).</p><p>(b) Twitter Messages: Some stock market discussion also takes place on the Twitter platform 2 . In order to extend and diversify our data sources, we extract Twitter posts containing company stock symbols (cashtags).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">News Statements &amp; Headlines</head><p>Sentences have been taken from news headlines as well as news text. The textual content was crawled from different sources on the Internet, such as Yahoo Finance 3 . The Enterprise identification for this track was based on company names and abbreviations, as cashtags are not typically used in news statements and headlines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Corpus Creation</head><p>The corpus of statements was created by conducting random sampling and an initial filtering process over a pool of StockTwits messages, tweets and RSS News feeds. While the random sampling ensured an unbiased set of statements, the filtering mechanism aimed at removing messages from the set microblog messages which are spam. The filtering mechanism was based on a manual curation of the set of microblog users which are classified as spammers. The goal of data sampling is to come up with a most representative and manageable amount of data for manual annotation. The first step in our case is to ap-ply a stratified random sampling by objects δ per the smallest time unit level θ we determine (in our case it is stock's messages per day) to ensure that all different objects are adequately represented in the sample with respect to their distribution in the population. Then, the random samples of a timeunit level θ i are pooled into a time-unit level θ i+1 and randomly sampled.</p><p>The purpose of re-sampling at different time-unit levels is to make the resulted random sample more random, more balanced and more representative of the entire time-span of our data. A general negative sentiment in a certain sub-sample will be counterbalanced by the other sub-samples.</p><p>StockTwits data have been provided by Stock-Twits in a batch export and refer to the period from October 2011 to June 2015. The original pool before sampling contains 27 million StockTwits, from which 1847 messages were sampled. Twitter data was collected between March 11th and 18th 2016 using the official Streaming APIs. Sampling was also applied to this data and resulted in a sample of 1591 messages.</p><p>The News Statements and Headlines have been collected from a pool of 20.000 RSS feeds in the period between August and November 2015 (e.g. AP News, Reuters, Handelsblatt, Bloomberg and Forbes). A final set of about 1780 News Statements and Headlines has been produced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Annotation</head><p>To create the Gold Standard, the final sample has been annotated by 3 independent financial expert annotators using a Web platform developed for that purpose and according to the annotations guidelines we defined. A fourth domain expert consolidated the ratings to create the final data set. The total time the experts spend on annotating and consolidating the data set is 120 hours (30 hours per expert). The costs of annotation and consolidation have been covered by <ref type="bibr">ICT-15-2014 Grant: 645425 (SSIX project)</ref>.</p><p>Each statement (instance) is annotated with the following information:</p><p>• Cashtag (subtask1) / Company (subtask2):</p><p>A stock company symbol (for microblogs) or reference to a company (for news/headlines) to which a sentiment score is assigned.</p><p>• Sentiment Score: A sentiment between -1 (very negative/bearish) and 1 (very positive/bullish), with 0 representing neutral/no sentiment is assigned to each cashtag or company. The sentiment is assigned from the point of view of an investor and the sentiment annotation is carried out by domain experts. Textual data containing information implying a positive prospective trend for a company or stock, the markets, or the economy, in general, constitutes a positive sentiment, whereas information revealing negative trends constitutes a negative sentiment since it may impact companies, markets or the economy negatively.</p><p>• Span (subtask 1): extract of a text string in which sentiment is expressed.</p><p>• Message (subtask 1) / Title (subtask2): Text string in which sentiment is expressed.</p><p>• Source (subtask 1): Either "twitter" or "stocktwits" dependent on the origin of the text message.</p><p>Examples of annotated microblog messages and news headlines are provided in Section 2.6 below.</p><p>The quality of the annotations was assessed following a similar methodology as proposed in <ref type="bibr" target="#b47">Takala et al. (2014)</ref>, where inter-annotator agreements measures for continuous data is calculated for the sentiment classifications. Spearman's Rank Correlation on sentiment scores was calculated for each pair of annotators, then averaged across annotator pairs. This yielded the following results: 0.54 for news headlines (three annotators, three pairs) and 0.69 for microblogs (four annotators, six pairs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Gold Standard</head><p>After annotating and consolidating the data, the gold standard for subtask 1 consists of 2510 Twitter and StockTwit messages. The gold standard for subtask 2 contains 1647 Headlines and News Statements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Task Formulation</head><p>Participating systems needed to fulfil the following task: given a text instance (microblog message in Track 1, news statement or headline in Track 2; cp. Section 2.1), predicting the sentiment score for each of the companies/stocks mentioned. Sentiment values needed to be floating point values within the range of -1 (very negative/bearish) to 1 (very positive/bullish), with 0 designating neutral sentiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Examples</head><p>Below we present annotated example statements, two for microblogs and one for news. Please note that sentiment score agreement as per Section 2.3 is not given as annotations for these examples were provided by a single expert. Also, the string covered by the 'span' is given for ease of reading. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Microblogs</head><formula xml:id="formula_0">• Cashtag -$SPY -$QQQ -$TQQQ -$SQQQ • Span -$SPY:</formula><p>* (0, 41) -"Awaiting These Sell Signals on the $SPY" * (From the blog post) -"this bearish rising wedge for the next sell signal in the SPY" * (From the blog post) -Chart shows a bearish rising wedge -$QQQ, $TQQQ: * The message and blog make reference to shorting the SPY, but as but indexes are strongly correlated so some of the sentiment for SPY could be transferred to these ETFs.</p><p>-$SQQQ: * The message and blog make reference to shorting the SPY, but as indexes are strongly correlated so some of the sentiment for SPY could be transferred to this ETF but inverted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>News Statements &amp; Headlines</head><p>First Solar, Vivint Solar Lead Short Interest Trend</p><p>• Sentiment Score:</p><p>-First Solar: -0.7 -Vivint Solar: -0.7</p><formula xml:id="formula_1">• Company -First Solar -Vivint Solar</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Assessment Infrastructure &amp; Baselines</head><p>Two classification baselines were provided:</p><p>• Random selection: Consists of a random number generated within the sentiment range.</p><p>• SentiWordNet-based average and maximum functions: Consist of the maximum and averaging of all the sentiment words using a simple SentiWordNet-based lookup.</p><p>For the Microblogs test set, SentiWordNet lexicon-based look-up (average) achieved an average score of 0.3021, while the same look-up method using the max/min score achieved 0.2428. The random baseline achieved 0.0148.</p><p>For the Financial Headlines test set, a SentiWord-Net lexicon-based look-up classifier, which averages all the sentiment scores of individual lemmatised words, achieved a score of 0.290, while the same look-up method using a max/min score achieved 0.2184. The random baseline achieved 0.1064.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Pilot Task</head><p>A pilot dataset consisting of financial social data was collected from two on-line social networking services, specifically Twitter and StockTwits, as part of a pilot study carried out within the SSIX: Social Sentiment analysis financial IndeXes 4 project as part of the European Horizon 2020 Research and Innovation programme <ref type="bibr" target="#b3">(Davis et al., 2016)</ref>. A domain expert experienced in trading annotated 100 tweets and 100 StockTwits messages selected randomly. He annotated the messages for sentiment following the guideline of assuming the point of view of an investor in the given stock(s) (see Section 2.3 above).</p><p>The results from the pilot study provided valuable insights with regards to the distribution of sentiment and the need for improved filtering (Figures <ref type="figure" target="#fig_1">3 and 2</ref>). These insights proved to be valuable when building the data set for this task, enabling us to provide a higher-quality data collection.</p><p>The results (Figure <ref type="figure" target="#fig_0">1</ref>) showed a relatively even distribution of positive and negative sentiment, with slight differences between the StockTwits and Twitter sources as regards the intensity of the sentiment .  The pilot study also pointed to the need to improve the filtering phase as 25% -36% of Twitter and StockTwits messages, respectively, have been deemed irrelevant (i.e. spam and/or not providing any relevant financial sentiment) by the annotator (figure <ref type="figure" target="#fig_1">3 and 2</ref>). As a consequence, filtering rules have been added to the filtering phase and the data for the gold standard proposed in this task under-went additionally manual post-filtering by a domain expert prior to sentiment annotation. This is ensuring that only relevant messages are included in the data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>The Evaluation of the participating systems was based on cosine similarity, in a spirit similar to <ref type="bibr" target="#b9">Ghosh et al. (2015)</ref>. As the sentiment scores to be predicted by systems lie on a continuous scale between -1 and 1 (cp. Section 2.5), cosine enables us to compare the proximity between gold standard and predicted results (conceptualized as vectors), while not requiring exact correspondence between the gold and predicted score for a given instance. An instance is a message or headline which can include several entities (companies or cashtags). Cosine similarity is calculated according to equation ( <ref type="formula">1</ref>), where G is the vector of gold standard scores and P is the vector of corresponding scores predicted by the system:</p><formula xml:id="formula_2">cosine(G, P ) = n i=1 G i × P i n i=1 G 2 i × n i=1 P 2 i (1)</formula><p>In order to reward systems which attempt to answer all problems in the gold standard, the final score is obtained by weighting the cosine similarity from (1) with the ratio of answered problems (scored instances), given in (2) in line with <ref type="bibr" target="#b9">Ghosh et al. (2015)</ref>.</p><formula xml:id="formula_3">cos weight = |P | |G| (2)</formula><p>The equation for the final score is the product of the cosine similarity (1) and the weight (2), given in (3).</p><p>f inal score = cos weight × cosine(G, P ) (3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Participants</head><p>Task 5 attracted a total of 32 participants: 25 teams participated in Track 1 and 29 in Track 2, of which 22 teams addressed both tracks. The analysis and results for each track are discussed in more detail in the sub-sections below. Given that 19 out of the 32 participants submitted a paper with their approach and findings, we opted to include the system analysis and ranking of results of only the submitted participants.</p><p>Analysis of the systems consisted of the following criteria: pre-processing methods, techniques used, external sources, data sets and/or lexica used, tools utilised, why the adopted approach was chosen and if it is (i) multilingual/cross-lingual and/or (ii) domain dependent/independent, any issues encountered and how they were tackled and potentially solved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Track 1 -Microblog Messages</head><p>Figure <ref type="figure" target="#fig_2">4</ref> shows the results of the 25 participants in Track 1. Results of all participants were ranked (first column) according to the evaluation metric (last column) described in the Section 4 -Evaluation. The second column specifies the team's/participant's name. Please note that the analysis of systems discussed in this sub-section includes only the participants highlighted in yellow since only these submitted a paper with their approach and findings. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Pre-processing</head><p>In terms of pre-processing, all 14 participants adopted some methods in order to clean the microblog messages before further processing. The most common methods used were: removal of special characters and/or punctuations, removal of URLs and user mentions ('@username') and/or substitution of certain expressions by specific words (e.g., replace 'full urls' with 'url' and 'company names' with 'company'), stop word removal, tokenisation, lemmatisation and lowercase conversion. Some participants also performed Named Entity Recognition (NER), emoticon removal, Part-of-Speech (POS) tagging, stemming and URL resolution, besides other specific tasks, such as concatenation of spans to form a unified string <ref type="bibr" target="#b29">(Nasim, 2017)</ref>. NLTK 5 was the tool mostly used <ref type="bibr" target="#b43">(Seyeditabari et al., 2017;</ref><ref type="bibr" target="#b5">Deborah et al., 2017;</ref><ref type="bibr" target="#b17">Kumar et al., 2017;</ref><ref type="bibr" target="#b46">Symeonidis et al., 2017;</ref><ref type="bibr" target="#b13">Jiang et al., 2017)</ref> for pre-processing tasks, such as lemmatisation, stemming and lowercase conversion. It is clear that most techniques were of a Hybrid nature with the Machine Learning and Lexiconbased approach being the most popular choice, followed by Machine Learning-based approaches. Authors of some systems experimented with multiple approaches to find the one that fared best in the competition. In fact, <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref> implemented two-hybrid techniques (as noted above), where the Hybrid (DL, Lex) approach produced their best result for this track. On the other hand, <ref type="bibr" target="#b17">Kumar et al. (2017)</ref> implemented two Hybrid (ML, Lex) systems, one adopting Support Vector Machine and Logistic Regression and the other adopting SVR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Techniques</head><p>The Hybrid (ML, Lex) technique by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> ranked first for this track, whereas the Hybrid (DL, Lex) technique by <ref type="bibr" target="#b8">Ghosal et al. (2017)</ref> ranked second. The system placing third <ref type="bibr" target="#b5">(Deborah et al., 2017)</ref> adopted a ML technique.</p><p>The Machine Learning-based techniques made use of the following algorithms:</p><p>• Artificial Neural Network (ANN) -adopted by The most common ML techniques used overall -by 4 participants-were RF, SVM and SVR. The SVR was part of the ensemble regression model used by the system that ranked first for this track <ref type="bibr" target="#b13">(Jiang et al., 2017)</ref>. The RF classifier was ultimately used by <ref type="bibr" target="#b43">Seyeditabari et al. (2017)</ref>, since it is the best performer in terms of tweets classification. Regarding the ANN computational approach, both <ref type="bibr" target="#b18">Li (2017)</ref> and <ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref>  • Bidirectional Gated Recurrent Unit (Bi-GRU) -adopted by <ref type="bibr" target="#b15">Kar et al. (2017)</ref> The MLP based ensemble model in <ref type="bibr" target="#b8">Ghosal et al. (2017)</ref> that combines the CNN and LSTM Deep Learning algorithms ranked second in this track. In <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref>, their best submission for this track was provided by the RNN (as opposed to SVR).</p><p>Lexicon-based methods made use of the following known sentiment lexica: • AFINN 14 -adopted by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Corpus of Business News <ref type="bibr" target="#b32">(Pivovarova et al., 2013</ref>) -adopted by <ref type="bibr" target="#b31">Pivovarova et al. (2017)</ref> The following three lexica listed are the ones mostly used overall: (i) the Loughran and McDonald Sentiment Word (rank 2), (ii) Opinion Lexicon (rank 1, 2) and (iii) MPQA Subjectivity Lexicon (rank 1, 2). An interesting observation is that the systems that ranked first <ref type="bibr" target="#b13">(Jiang et al., 2017)</ref> and second <ref type="bibr" target="#b8">(Ghosal et al., 2017)</ref> in this track utilised all three lexicons (ranked system using the particular lexicon represented next to each name), whereby lexica (ii) and (iii) were used by both. <ref type="bibr" target="#b43">Seyeditabari et al. (2017)</ref> extended Loughran and McDonald's word list of positive and negative words with 10,000 financial reports containing a summary of the company's performances in order to add features to the training dataset In <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref>, the authors, besides using the sentiment lexica identified above, also built and used a custom Financial Sentiment Lexicon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Track 2 -News Statements and Headlines</head><p>Figure <ref type="figure" target="#fig_7">6</ref> shows the results of the 29 participants in Track 2. Results of all participants were ranked (first column) according to the evaluation metric (last column) described in Section 4 -Evaluation. The second column specifies the team/participant name. Please note that the analysis of systems discussed in this sub-section includes only the participants highlighted in yellow, which are the participants who submitted a paper with their approach and findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Pre-processing</head><p>In terms of pre-processing -same as for Track 1 -all 17 participants adopted some methods in order to clean the news statements and headlines before further processing. The most common methods used were: removal of numbers, special characters and/or punctuations, removal of URLs and user mentions and/or substitution of certain expressions with tags (e.g. replace 'company name' with 13 http://www.wjh.harvard.edu/˜inquirer/ 14 http://www2.imm.dtu.dk/pubdb/views/ publication_details.php?id=6010 ' company ' and 'numbers' with ' number '), stop word removal, tokenisation, lemmatisation, lowercase conversion and NER on certain entities (e.g., Organisation and Person). Some participants also performed dependency parsing, POS tagging, stemming and URL resolution, besides other specific tasks, such as filtering out all named entities and keeping only "general" tokens given that they are generally the ones carrying the sentiment <ref type="bibr" target="#b37">(Rotim et al., 2017)</ref>. Same as track 1, NLTK was the tool mostly used <ref type="bibr" target="#b8">(Ghosal et al., 2017;</ref><ref type="bibr" target="#b5">Deborah et al., 2017;</ref><ref type="bibr" target="#b17">Kumar et al., 2017;</ref><ref type="bibr" target="#b46">Symeonidis et al., 2017;</ref><ref type="bibr" target="#b13">Jiang et al., 2017)</ref> for pre-processing, whereas Stanford CoreNLP 15 was used for performing NER, sentence breaking and parsing. <ref type="bibr" target="#b29">(Nasim, 2017;</ref><ref type="bibr" target="#b37">Rotim et al., 2017;</ref><ref type="bibr" target="#b41">Schouten et al., 2017;</ref><ref type="bibr" target="#b2">Chen et al., 2017;</ref><ref type="bibr" target="#b13">Jiang et al., 2017)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Techniques</head><p>Figure <ref type="figure" target="#fig_10">7</ref> shows all the techniques used by each system of the 17 participants. Each system has been analysed and categorised under one of the following techniques: Hybrid, Machine Learning (ML), Deep Learning (DL), Lexicon (Lex) and Ontology (Ont).</p><p>Similar to track 1, the Machine Learning and a Machine Learning/Lexicon-based Hybrid approach were the ones mostly used (six participants). However, the techniques were more balanced in this track, with six participants adopting a Machine Learning-based approach. It is worth noting that one of the systems used a Machine Learning and Ontology-based Hybrid approach, which technique is unique in both tracks. In this system, <ref type="bibr" target="#b41">Schouten et al. (2017)</ref> used the SVR algorithm with ontology features (including features derived from ontology reasoning), which ontology was self-designed by the authors. Multiple techniques were used by some authors in order to find the best one to use in this competition within their system. <ref type="bibr" target="#b27">Moore and Rayson (2017)</ref> experimented with an ML and DL algorithm respectively, with the latter performing better. On the other hand, <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref> implemented two-hybrid techniques, where the Hybrid (DL, Lex) approach produced their best result for this track , same as for track 1.</p><p>The systems that ranked first <ref type="bibr" target="#b24">(Mansar et al., 2017)</ref> and second <ref type="bibr" target="#b15">(Kar et al., 2017</ref>) both adopted a Hybrid (DL, Lex) technique, whereas an ML technique was used by the system in rank three.</p><p>The Machine Learning-based techniques made use of the following algorithms:</p><p>• Artificial Neural Network (ANN) -adopted by <ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref> • Random Forests -adopted by Symeonidis et al. • Linear Regression (LiR) -adopted by <ref type="bibr" target="#b14">John and Vechtomova (2017)</ref>; <ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref> • Logistic Regression (LoR) -adopted by <ref type="bibr" target="#b17">Kumar et al. (2017)</ref> • Multi-Kernel Gaussian Process (MKGP)adopted by <ref type="bibr" target="#b5">Deborah et al. (2017)</ref> • XGBoost Regressor (XGB) -adopted by <ref type="bibr" target="#b29">Nasim (2017)</ref>; <ref type="bibr" target="#b14">John and Vechtomova (2017)</ref>; <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Boosted Decision Tree Regression (BDTR)adopted by <ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref> • AdaBoost Regressor (ABR) -adopted by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Bagging Regressor (BR) -adopted by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Gradient Boosting Regressor (GBR) -adopted by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Least Absolute Shrinkage and Selection Operator (LASSO) -adopted by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> As can be seen above, the most common ML technique used within the systems was SVR by 9 participants. This was used by the system that ranked third for this track <ref type="bibr" target="#b37">(Rotim et al., 2017)</ref>.</p><p>The Deep Learning-based techniques made use of the following algorithms: • Bidirectional Gated Recurrent Unit (Bi-GRU) -adopted by <ref type="bibr" target="#b15">Kar et al. (2017)</ref> The CNN algorithm was the most popular amongst all Deep Learning-based techniques, with both systems ranking first <ref type="bibr" target="#b24">(Mansar et al., 2017)</ref> and second <ref type="bibr" target="#b15">(Kar et al., 2017)</ref> using it.</p><p>Lexicon-based methods made use of the following known sentiment lexica: • IMDB -adopted by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • AFINN -adopted by <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • DepecheMood Affective Lexicon <ref type="bibr" target="#b45">(Staiano and Guerini, 2014</ref>) -adopted by <ref type="bibr" target="#b24">Mansar et al. (2017)</ref> • Amazon Product Reviews 16 -adopted by John and Vechtomova (2017)</p><p>• Financial Phrasebank <ref type="bibr" target="#b22">(Malo et al., 2014a</ref>)adopted by <ref type="bibr" target="#b14">John and Vechtomova (2017)</ref> • Corpus of Business News -adopted by <ref type="bibr" target="#b31">Pivovarova et al. (2017)</ref> In total, four lexica listed above are the ones mostly used (all by 4 participants each): (i) the Loughran and McDonald Sentiment Word, (ii) Sen-tiWordNet, (iii) Opinion Lexicon and (iv) Harvard's General Inquirer Lexicon. Unlike the case in track 1, none of the participants ranked first till third used one of these four lexica. Some authors constructed their own lexica from external sources, such as Moore and Rayson (2017) (rank four) who manually downloaded 189,206 financial articles which contain 161,877,425 tokens from Factiva 17 (articles come from sources such as Financial Times that relate to United States companies only).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Tools used in both tracks</head><p>Several tools were used within the participants' systems, with the following (Figure <ref type="figure">8</ref>) being the most popular:</p><p>Scikit-learn is a Machine Learning kit (in Python) that offers simple efficient tools (e.g., classification and regression algorithms) for data mining and data analysis. This is the tool mostly used by the participants of our task (42% in total) to compute their results. Similarly, Weka -a collection of machine learning algorithms for data mining tasks-was used by 2 participants. The Keras Deep Learning library was used by 2 participants, whereas TensorFlowan open source software library for numerical computation using data flow graph-was also used by 3 participants (work in <ref type="bibr" target="#b31">Pivovarova et al. (2017)</ref> built their implementation on top of it).</p><p>GloVe, an unsupervised learning algorithm for obtaining vector representations of words, was used by 6 participants for word embeddings. Word2vec -an efficient implementation of the continuous bagof-words and skip-gram architectures for computing vector representations of words-was also used for the same purpose by 4 participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">General assessment of the task</head><p>The approaches proposed by the participating systems explored a combination of machine learning methods using lexical features, sentiment lexical resources (both generic and specific to finance) and pre-trained word embedding models. Novel features specific to the task included the creation of a domain-specific ontology <ref type="bibr" target="#b41">(Schouten et al., 2017)</ref>, a stocktwits-based embedding model and distance supervision model <ref type="bibr" target="#b18">(Li, 2017)</ref> and domain-specific lexica <ref type="bibr" target="#b27">(Moore and Rayson, 2017)</ref>. Moreover, due to the emphasis of the task on the sentiment classification on a continuous scale, many approaches targeted regression-based models.</p><p>With the exception of <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref>, few approaches explicitly tackled the problem of compositionality <ref type="bibr" target="#b39">(Sales et al., 2016)</ref>, valency shifting <ref type="bibr" target="#b22">(Malo et al., 2014a)</ref>, and clausal disembedding <ref type="bibr" target="#b30">(Niklaus et al., 2016)</ref>, a fact that is reflected by the lack of submissions which explored syntactic features.</p><p>With regard to language transportability, most approaches have a medium level of transportability, being dependent on the translation of the sentiment lexica, but not depending on syntactic parser.</p><p>Important specific aspects proposed by the task remained unexplored or poorly explored, including:</p><p>(i) the use of quantitative background knowledge (e.g. stock price, financial report data), (ii) the use of the annotated text spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Alternative Evaluation Metric</head><p>Based on the evaluation metric as stated in Section 4, another evaluation metric has been developed during the competition. The intention to propose a modified way of evaluation was based on the fact that the cosine similarity ( <ref type="formula">1</ref>) is treating all predicted scores with the same weight. This approach is not exploiting all information given in the data set, in specific it is not taking the link between entities and instances into consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">First Modification</head><p>Therefore, we proposed an approach which is using multiple vectors (one per instance) instead of only two. These instance vectors are containing one score per corresponding entity. Cosine similarity scores are calculated for each instance and added up to then divide the sum of all similarity scores by the number of submitted instance predictions in order to retrieve an average cosine similarity score.</p><p>While considering this modified evaluation metric a drawback, dividing the predictions on one hand into a regression problem but on the other hand into a classification problem, was noticed. The cosine similarity (1) for vectors with a length of 1 is resulting in either +1 or -1. However, the cosine similarity for vectors with a length greater than 1 is resulting in a floating point value. Thus, another modification of the initial evaluation formula has been conducted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Second Modification</head><p>The second modification of the initial evaluation metric is also using one vector per instance containing one score per corresponding entity. Those instance vectors are populated into either a gold standard (GS) or predicted system (PS) vector. As both vectors are populated according to matching instances and entities, both vectors should be the same length. In contrast to the first modification (6.1), the second modification is using two different methods of evaluating the given scores dependent on the length of a vector. For each instance vector in GS/PS which has a length of 1, the absolute distance between both scores ( <ref type="formula">4</ref>) is added to the total similarity score (6). s similarity(G, P ) = 1 − |G 0 − P 0 | (4) Tool System scikit-learn 18 <ref type="bibr" target="#b29">Nasim (2017)</ref>, <ref type="bibr" target="#b27">Moore and Rayson (2017)</ref>, <ref type="bibr" target="#b14">John and Vechtomova (2017)</ref>, <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref>, <ref type="bibr" target="#b17">Kumar et al. (2017)</ref>, <ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref>, <ref type="bibr" target="#b15">Kar et al. (2017)</ref>, <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> word2vec <ref type="bibr">19</ref> Li (2017), <ref type="bibr" target="#b8">Ghosal et al. (2017)</ref>, <ref type="bibr" target="#b17">Kumar et al. (2017)</ref>, <ref type="bibr" target="#b38">Saleiro et al. (2017</ref><ref type="bibr">) Weka 20 Seyeditabari et al. (2017</ref>, <ref type="bibr" target="#b51">Zini et al. (2017)</ref> GloVe 21 <ref type="bibr" target="#b43">Seyeditabari et al. (2017)</ref>, <ref type="bibr" target="#b24">Mansar et al. (2017)</ref>, <ref type="bibr" target="#b37">Rotim et al. (2017)</ref>, <ref type="bibr" target="#b31">Pivovarova et al. (2017)</ref>, <ref type="bibr" target="#b8">Ghosal et al. (2017)</ref>, <ref type="bibr">Kumar et al. (</ref> <ref type="formula">2017</ref>) LIBSVM <ref type="bibr">22</ref> Rotim et al. (2017) LIBLINEAR <ref type="bibr">23</ref>  <ref type="bibr" target="#b37">Rotim et al. (2017)</ref>, <ref type="bibr" target="#b13">Jiang et al. (2017)</ref> Keras <ref type="bibr">24</ref> Moore and Rayson (2017), <ref type="bibr" target="#b8">Ghosal et al. (2017)</ref> XGBoost <ref type="bibr">25</ref> John and Vechtomova (2017), Jiang et al. ( <ref type="formula">2017</ref>) gensim <ref type="bibr">26</ref> John and Vechtomova (2017), <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref> TensorFlow <ref type="bibr">27</ref> John and Vechtomova (2017), <ref type="bibr" target="#b31">Pivovarova et al. (2017)</ref>, <ref type="bibr" target="#b1">Cabanski et al. (2017)</ref> Figure <ref type="figure">8</ref>: Tools used by systems in both tracks</p><p>For each instance vector with a length greater than 1, the cosine similarity is "length times" added to the total similarity score (5). </p><p>Once the similarity scores are calculated for each instance vector and added to the total similarity, the final score is calculated by dividing the total similarity score by the number of predicted entities to then multiply the quotient with a weight which consists of the quotient of all predicted entities divided by all possible entity predictions (7). In contrast to the cosine weight as stated in (2), this weight is calculated on an entity level.</p><p>f inal score(GS, P S)</p><formula xml:id="formula_5">= |P S| i=1 |P S i | |GS| i=1 |GS i | × total similarity(GS, P S) |P S| i=1 |P S i | (7)</formula><p>Similarity scores produced using this alternative evaluation metric can be found in the appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Pros and Cons</head><p>On one hand, the evaluation metric as stated in 6.2 differentiating between vectors according to their lengths avoids the regression/classification problem as described in 6.1. In addition, it is considering the link between instances and entities in the final score.</p><p>On the other hand, one disadvantage of this is approach is the linearity / non-linearity of the two sub-methods used ((4), ( <ref type="formula">5</ref>)). One could argue that both sub-methods are not equally impacting the total score. Balancing would be one approach to reducing discrepancy but also be subjectively influenced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Related Initiatives</head><p>A number of projects have addressed questions pertaining to Sentiment Analysis and Finance. The FIRST (2010-2013) FP7 European project 28 provides sentiment extraction and analysis of market participants from social media networks in near real-time, for detecting and predicting financial market events, such as insights about financial market movements and financial market abuse. The developed tool consists of a decision support model based on Web sentiment as found within textual data extracted from Twitter or blogs, for the financial domain.</p><p>The TrendMiner (2011-2014) FP7 European project 29 , presents an innovative and portable opensource real-time method for cross-lingual mining and summarisation of large-scale social media streams, such as weblogs, Twitter, Facebook, etc. One high profile case study was a financial decision support (with analysts, traders, regulators and economists).</p><p>StockWatcher <ref type="bibr" target="#b25">(Micu et al., 2008)</ref> provides a customised, aggregated view of news categorised by different topics, where it performs sentiment analysis -positive, negative or neutral effect -on particular news messages about a particular company. This tool enables the extraction of relevant news items from RSS feeds concerning the NASDAQ-100 listed companies. The sentiment of the news messages directly affects a company's respective stock price.</p><p>Mirowski et al. <ref type="bibr" target="#b26">(Mirowski et al., 2010)</ref> present an algorithm for topic modelling, text classification and retrieval from time-stamped documents. This algorithm has been applied to predict the stock market volatility using financial news from Bloomberg. The volatility considered is estimated from daily stock prices of a particular company.</p><p>Several data sets have been created which are relevant in the context of our current endeavour. (Sanders, 2011) provide the Sanders Twitter Sentiment corpus, consisting of 5513 tweets about four topics/companies (Apple, Google, Microsoft, Twitter). One annotator manually assigned a positive, negative, neutral or irrelevant annotation to each tweet, depending on the sentiment expressed towards the given topic (company). This can refer to any aspect of the company, e.g. the service at the Apple store or the features of the iPhone in the case of Apple Inc. The current proposal will instead focus on a much larger range of companies and evaluate them specifically with respect to their stock market value. Furthermore, sentiment scoring will be more fine-grained as it will consist of floating-point numbers in the range of -1 (very negative/bearish) and 1 (very positive/bullish), with 0 representing neutral sentiment. <ref type="bibr" target="#b23">(Malo et al., 2014b)</ref> present the Financial Phrase Bank, a resource containing around 5000 sentences from English-language news about companies listed on the Helsinki stock exchange. Annotations at the level of syntactic phrases assigned one of three sentiment classes (positive, negative, neutral), based on the expected influence on the stock price. Each phrase was scored by between five and eight annotators. In our proposed task, the sentiment was also assigned with a view to the stock price or market development. However, our annotation is more fine-grained, ranging on a scale from -1 to 1. Furthermore, we annotate at the target (stock or company entity) rather than the phrase-level.</p><p>Over the years, many shared tasks in SemEval have focused on Sentiment Analysis, exploring var-ious angles within the field. A series of tasks have concentrated on Sentiment Analysis in Twitter <ref type="bibr" target="#b28">(Nakov et al., 2013;</ref><ref type="bibr" target="#b35">Rosenthal et al., 2014;</ref><ref type="bibr" target="#b36">Rosenthal and Stoyanov, 2015)</ref>. They have covered tasks such as Polarity Disambiguation, documentand topic-level Polarity Classification, and topicbased Sentiment Aggregation. These tasks targeted open domains, with topics being determined using Named Entity Recognition (e.g. celebrities, places, sports clubs). The sentiment was assigned on two-point (positive, negative), three-point (positive, negative, neutral) or five-point (strongly positive, weakly positive, neutral, weakly negative, strongly negative) scales. In contrast, our proposed task aims to detect fine-grained sentiment, a scoring company-and stock-level sentiment on a floating point scale between -1 and 1. Furthermore, the data in our proposed task focuses only on the financial domain and its particular semantic challenges.</p><p>Aspect-based Sentiment Analysis has also emerged in recent editions of SemEval <ref type="bibr" target="#b34">(Pontiki et al., 2014</ref><ref type="bibr" target="#b33">(Pontiki et al., , 2015</ref>. Depending on the subtask, entities and their aspects are provided to the participants or need to be identified. Sentiment for entity-aspect pairs is scored according to four categories: positive, negative, neutral and conflict. In terms of data, while the 2014 task focused on isolated sentences from customer reviews, the 2015 edition dealt with full reviews. Again, our proposed task differs in the assignment of fine-grained sentiment, in the short nature of the text instances and in terms of the domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions and Future Work</head><p>We presented a new task on fine-grained sentiment analysis for the financial domain, where a sentiment in range (-1, 1) is assigned to entities. In our two subtasks, we focussed on two distinct data sources: financial microblogs (Twitter and Stock-Twits), where the target entities are company stock symbols ("cashtags"), and financial news headlines, where sentiment needs to be assigned to companies.</p><p>Deep Learning (word embeddings) and more traditional Machine Learning techniques account for the majority of contributions. Many participants made use of sentiment lexica, both finance-specific (e.g. the word lists from <ref type="bibr" target="#b21">(Loughran and McDonald, 2011b)</ref>) and general domain (e.g. <ref type="bibr" target="#b11">(Hu and Liu, 2004;</ref><ref type="bibr" target="#b49">Wilson et al., 2009)</ref>), as well as custom lexica created in the context of this task. A review of the results obtained by participants shows that three of the systems that performed best (top three in each track) adopted a Hybrid (Deep Learning, Lexicon) technique, while the other three used a Machine Learning-based approach.</p><p>For a future edition of this task, we will focus on enhancing the evaluation metric in the light of the discussion in Section 6. It would be interesting to add subtasks with different sources, perhaps broadening the scope to include longer texts, such as full news articles from financial newspapers, or Facebook posts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Pilot results on sentiment distribution for StockTwits and Twitter</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3</head><label>3</label><figDesc>Figure 3Pilot results on percentage of sentiment-containing and irrelevant messages on StockTwits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Track 1 Results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>All the techniques used by each system of the 14 participants are shown in Figure 5. Each system was analysed and in-turn categorised under one of the following techniques: Hybrid, Machine Learning (ML), Deep Learning (DL) and Lexicon-based (Lex).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>5</head><label></label><figDesc>http://www.nltk.org/<ref type="bibr" target="#b18">Li (2017)</ref>;<ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref>;<ref type="bibr" target="#b38">Saleiro et al. (2017)</ref> • Random Forests -adopted by<ref type="bibr" target="#b43">Seyeditabari et al. (2017)</ref>;<ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref>;<ref type="bibr" target="#b13">Jiang et al. (2017)</ref>;<ref type="bibr" target="#b38">Saleiro et al. (2017)</ref> • Support Vector Machine (SVM) -adopted by<ref type="bibr" target="#b43">Seyeditabari et al. (2017)</ref>; Cabanski et al. (2017); Kumar et al. (2017); Saleiro et al. (2017) • Support Vector Regression (SVR) -adopted by Zini et al. (2017); Kumar et al. (2017); Chen et al. (2017); Jiang et al. (2017) • Linear Regression (LiR) -adopted by Symeonidis et al. (2017) • Logistic Regression (LoR) -adopted by Seyeditabari et al. (2017); Kumar et al. (2017) • Naive Bayes (NB) -adopted by Seyeditabari et al. (2017) • Multi-Kernel Gaussian Process (MKGP)adopted by Deborah et al. (2017) • XGBoost Regressor (XGB) -adopted by Nasim (2017); Jiang et al. (2017)• Boosted Decision Tree Regression (BDTR)adopted by<ref type="bibr" target="#b46">Symeonidis et al. (2017)</ref> • AdaBoost Regressor (ABR) -adopted by<ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Bagging Regressor (BR) -adopted by<ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Gradient Boosting Regressor (GBR) -adopted by<ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • Least Absolute Shrinkage and Selection Operator (LASSO) -adopted by<ref type="bibr" target="#b13">Jiang et al. (2017)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :•</head><label>5</label><figDesc>Figure 5: Techniques used by systems in Track 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>•</head><label></label><figDesc>Loughran and McDonald Sentiment Word  Lists (Loughran and McDonald, 2011b)adopted by<ref type="bibr" target="#b29">Nasim (2017)</ref>;<ref type="bibr" target="#b43">Seyeditabari et al. (2017)</ref>;<ref type="bibr" target="#b38">Saleiro et al. (2017)</ref>;<ref type="bibr" target="#b8">Ghosal et al. (2017)</ref> • Stock Market Lexicon 6 -adopted by<ref type="bibr" target="#b29">Nasim (2017)</ref> • SentiWordNet 7 -adopted by<ref type="bibr" target="#b1">Cabanski et al. (2017)</ref>;<ref type="bibr" target="#b2">Chen et al. (2017)</ref>;<ref type="bibr" target="#b13">Jiang et al. (2017)</ref> • SenticNet 4 8 -adopted by<ref type="bibr" target="#b2">Chen et al. (2017)</ref>;<ref type="bibr" target="#b15">Kar et al. (2017)</ref> • VADER (Hutto and Gilbert, 2014) -adopted by<ref type="bibr" target="#b1">Cabanski et al. (2017)</ref> • Opinion Lexicon<ref type="bibr" target="#b11">(Hu and Liu, 2004)</ref> -adopted by Cabanski et al. (2017); Kumar et al. (2017); Jiang et al. (2017); Ghosal et al. (2017) • MPQA Subjectivity Lexicon (Wilson et al., 2009) -adopted by Kumar et al. (2017); Jiang et al. (2017); Saleiro et al. (2017); Ghosal et al. (2017) • NRC Hashtag Sentiment Lexicon (Kiritchenko et al., 2014) -adopted by Cabanski et al. (2017); Kumar et al. (2017); Jiang et al. (2017); Ghosal et al. (2017) • NRC Hashtag Emotion Lexicon (Kiritchenko et al., 2014) -adopted by Chen et al. (2017) • NRC Hashtag Affirmative Context Sentiment Lexicon (Kiritchenko et al., 2014) -adopted by Chen et al. (2017); Ghosal et al. (2017) • NRC Hashtag Negated Context Sentiment Lexicon (Kiritchenko et al., 2014) -adopted by Chen et al. (2017) • NRC Word-Emotion Association Lexicon / NRC Emotion Lexicon (Kiritchenko et al., 2014) -adopted by (Chen et al., 2017) • Emoticon Lexicon / Sentiment140 Lexicon 9 -adopted by Chen et al. (2017); Jiang et al. (2017); Ghosal et al. (2017) • Sentiment140 Affirmative Context Lexicon (Kiritchenko et al., 2014) -adopted by Ghosal et al. (2017); Chen et al. (2017) • Yelp Restaurant Sentiment Lexicon 10adopted by Chen et al. (2017)• Amazon Laptop Sentiment Lexicon 11adopted by<ref type="bibr" target="#b2">Chen et al. (2017)</ref> • Macquarie Semantic Orientation Lexicon 12adopted by<ref type="bibr" target="#b2">Chen et al. (2017)</ref> • Harvard's General Inquirer Lexicon 13adopted by<ref type="bibr" target="#b13">Jiang et al. (2017)</ref>;<ref type="bibr" target="#b8">Ghosal et al. (2017)</ref> • IMDB (Zhu et al., 2013) -adopted by<ref type="bibr" target="#b13">Jiang et al. (2017)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Track 2 Results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(2017); Jiang et al. (2017); Saleiro et al. (2017) • Support Vector Machine (SVM) -adopted by Kumar et al. (2017); Saleiro et al. (2017) • Support Vector Regression (SVR) -adopted by Rotim et al. (2017); Schouten et al. (2017); Moore and Rayson (2017); John and Vechtomova (2017); Zini et al. (2017); Cabanski et al. (2017); Kumar et al. (2017); Chen et al. (2017); Jiang et al. (2017)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>•</head><label></label><figDesc>Convolution Neural Network (CNN) -adopted by Mansar et al. (2017); Pivovarova et al. (2017); Ghosal et al. (2017); Kar et al. (2017) • Recurrent Neural Network (RNN) : Long Short-Term Memory (LSTM) -adopted by Ghosal et al. (2017); Cabanski et al. (2017)• RNN : Bidirectional Long Short-Term Memory (BLSTM) -adopted by<ref type="bibr" target="#b27">Moore and Rayson (2017)</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>•Figure 7 :</head><label>7</label><figDesc>Figure 7: Techniques used by systems in Track 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>m similarity(G, P ) = |P | × cosine(G, P ) (5) total similarity(GS, P S) = |P S| i=1 |P S i | = 1 s similarity(GS i , P S i ) |P S i | &gt; 1 m similarity(GS i , P S i )</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://stocktwits.com/ 2 https://twitter.com 3 http://finance.yahoo.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://ssix-project.eu/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://github.com/nunomroliveira/ stock_market_lexicon 7 http://sentiwordnet.isti.cnr.it/ 8 http://sentic.net/senticnet-4.pdf</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">http://stanfordnlp.github.io/CoreNLP/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16">http://jmcauley.ucsd.edu/data/amazon/ 17 https://global.factiva.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="28">http://project-first.eu/ 29 http://www.trendminer-project.eu/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Horizon 2020 ICT Program Project SSIX: Social Sentiment analysis financial IndeXes, has received funding from the European Union's Horizon 2020 Research and Innovation Program ICT 2014 -Information and Communications Technologies under grant agreement No. 645425.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Twitter mood predicts the stock market</title>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bollen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Hhu at semeval-2017 task 5: Fine-grained sentiment analysis on financial data using machine learning methods</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Cabanski</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Nlg301 at semeval-2017 task 5: Fine-grained sentiment analysis on financial microblogs and news</title>
		<author>
			<persName><forename type="first">Chung-Chi</forename><surname>Chen</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Social sentiment indices powered by x-scores</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Big Data, Small Data, Linked Data and Open Data</title>
				<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fine-grained analysis of explicit and implicit sentiment in financial news articles</title>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Van De Kauter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="4999" to="5010" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ssn mlrg1 at semeval-2017 task 5: Fine-grained sentiment analysis using multiple kernel gaussian process regression model</title>
		<author>
			<persName><forename type="first">Angel</forename><surname>Deborah</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Sentiment analysis in the financial domain. does it work?</title>
		<author>
			<persName><forename type="first">Alpha</forename><surname>Eagle</surname></persName>
		</author>
		<ptr target="https://medium" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">com/eagle-alpha/sentiment-analysisin-the-financial-domain-does-itwork-36fa974ea3cb#.o793xdr9h</title>
		<imprint>
			<date type="published" when="2016-03" />
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Iitp at semeval-2017 task 5: An ensemble of deep learning and feature based models for financial sentiment analysis</title>
		<author>
			<persName><forename type="first">Deepanway</forename><surname>Ghosal</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 11: Sentiment analysis of figurative language in twitter</title>
		<author>
			<persName><forename type="first">Aniruddha</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="470" to="478" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The volatility of the stock market and news</title>
		<author>
			<persName><forename type="first">Rohitha</forename><surname>Goonatilake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susantha</forename><surname>Herath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Research Journal of Finance and Economics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName><forename type="first">Minqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
				<meeting>the tenth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Vader: A parsimonious rule-based model for sentiment analysis of social media text</title>
		<author>
			<persName><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Hutto</surname></persName>
		</author>
		<author>
			<persName><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International AAAI Conference on Weblogs and Social Media</title>
				<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ecnu at semeval-2017 task 5: An ensemble of regression algorithms with effective features for fine-grained sentiment analysis in financial domain</title>
		<author>
			<persName><forename type="first">Mengxiao</forename><surname>Jiang</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Uw-finsent at semeval-2017 task 5: Fine-grained sentiment analysis on financial microblogs and news</title>
		<author>
			<persName><forename type="first">Vineet</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ritual-uh at semeval-2017 task 5: Sentiment analysis on financial data using neural networks</title>
		<author>
			<persName><forename type="first">Sudipta</forename><surname>Kar</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sentiment analysis of short informal texts</title>
		<author>
			<persName><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="723" to="762" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Iitpb at semeval-2017 task 5: Sentiment prediction in financial text</title>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">funsentiment at semeval-2017 task 5: Fine-grained sentiment analysis on financial microblogs using different word embeddings and target contexts</title>
		<author>
			<persName><forename type="first">Quanzhi</forename><surname>Li</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sentiment analysis and opinion mining</title>
		<author>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis lectures on human language technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="167" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">when is a liability not a liability? textual analysis, dictionaries, and 10-ks</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Loughran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">When is a liability not a liability? textual analysis, dictionaries, and 10-ks</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Loughran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="65" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Good debt or bad debt: Detecting semantic orientations in economic texts</title>
		<author>
			<persName><forename type="first">Pekka</forename><surname>Malo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="782" to="796" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Good debt or bad debt: Detecting semantic orientations in economic texts</title>
		<author>
			<persName><forename type="first">Pekka</forename><surname>Malo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="782" to="796" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fortia-fbk at semeval-2017 task 5:bullish or bearish? inferring sentiment towards brands from financial news headlines</title>
		<author>
			<persName><forename type="first">Youness</forename><surname>Mansar</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Financial news analysis using a semantic web approach</title>
		<author>
			<persName><forename type="first">Alex</forename><surname>Micu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dynamic auto-encoders for semantic indexing</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Mirowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS 2010 Workshop on Deep Learning</title>
				<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Lancaster a at semeval-2017 task 5: Evaluation metrics matter: predicting sentiment from financial news headlines</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Rayson</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Semeval-2013 task 2: Sentiment analysis in twitter</title>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Iba-sys at semeval-2017 task 5: Fine-grained sentiment analysis on financial microblogs and news</title>
		<author>
			<persName><forename type="first">Zarmeen</forename><surname>Nasim</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A sentence simplification system for improving relation extraction</title>
		<author>
			<persName><forename type="first">Christina</forename><surname>Niklaus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">26th International Conference on Computational Linguistics</title>
				<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hcs at semeval-2017 task 5: Polarity detection in business news using convolutional neural networks</title>
		<author>
			<persName><forename type="first">Lidia</forename><surname>Pivovarova</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Event representation across genres</title>
		<author>
			<persName><forename type="first">Lidia</forename><surname>Pivovarova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL HLT</title>
				<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2013</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 12: Aspect based sentiment analysis</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="486" to="495" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName><forename type="first">Maria</forename><surname>Pontiki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th international workshop on semantic evaluation</title>
				<meeting>the 8th international workshop on semantic evaluation<address><addrLine>Se-mEval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="27" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semeval-2014 task 9: Sentiment analysis in twitter</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
				<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Se-mEval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="73" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<title level="m">Semeval-2015 task 10: Sentiment analysis in twitter. Proceedings of SemEval-2015</title>
				<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Takelab at semeval-2017 task 5: Linear aggregation of word embeddings for fine-grained sentiment analysis of financial news</title>
		<author>
			<persName><forename type="first">Leon</forename><surname>Rotim</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Feup at semeval-2017 task 5: Predicting sentiment polarity and intensity with financial word embeddings</title>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Saleiro</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A compositionaldistributional semantic model for searching complex entity categories</title>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">Efson</forename><surname>Sales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th Joint Conference on Lexical and Computational Semantics (*SEM)</title>
				<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Niek</surname></persName>
		</author>
		<author>
			<persName><surname>Sanders</surname></persName>
		</author>
		<ptr target="http://www.sananalytics.com/lab/twitter-sentiment" />
		<title level="m">Sanders-twitter sentiment corpus</title>
				<imprint>
			<date type="published" when="2011-03-30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Commit at semeval-2017 task 5: Ontology-based method for sentiment analysis of financial headlines</title>
		<author>
			<persName><forename type="first">Kim</forename><surname>Schouten</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Meta-communication and market dynamics. reflexive interactions of financial markets and the mass media</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Schuster</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Sentiheros at semeval-2017 task 5: An application of sentiment analysis on financial tweets</title>
		<author>
			<persName><forename type="first">Armin</forename><surname>Seyeditabari</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">using-big-data-in-finance-exampleof-sentiment-extraction-from-newsarticles-20140326</title>
		<author>
			<persName><forename type="first">Nitish</forename><surname>Sinha</surname></persName>
		</author>
		<ptr target="http://www.federalreserve.gov/econresdata/notes/feds-notes/2014/" />
	</analytic>
	<monogr>
		<title level="j">html. Accessed</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2014-03" />
		</imprint>
	</monogr>
	<note>Using big data in finance: Example of sentiment-extraction from news articles</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Depechemood: A lexicon for emotion analysis from crowd-annotated news</title>
		<author>
			<persName><forename type="first">Jacopo</forename><surname>Staiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Guerini</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1405.1605</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Duth at semeval-2017 task 5: Sentiment predictability in financial microblogging and news articles</title>
		<author>
			<persName><forename type="first">Symeon</forename><surname>Symeonidis</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Gold-standard for topicspecific sentiment analysis of economic texts</title>
		<author>
			<persName><forename type="first">Pyry</forename><surname>Takala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC. Citeseer</title>
				<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="2152" to="2157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">More than words: Quantifying language to measure firms&apos; fundamentals</title>
		<author>
			<persName><surname>Paul C Tetlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Finance</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1437" to="1467" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Recognizing contextual polarity: An exploration of features for phraselevel sentiment analysis</title>
		<author>
			<persName><forename type="first">Theresa</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="399" to="433" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Ecnucs: A surface information based system description of sentiment analysis in twitter in the semeval-2013 (task 2). Atlanta, Georgia</title>
		<author>
			<persName><surname>Tian Tian Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">408</biblScope>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Inf-ufrgs at semeval-2017 task 5: A supervised identification of sentiment score in tweets and headlines</title>
		<author>
			<persName><forename type="first">Tiago</forename><surname>Zini</surname></persName>
		</author>
		<ptr target="http://alt.qcri.org/semeval2017/" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A Supplemental Material Similarity scores calculated using the evaluation metric as proposed in Section 6</title>
		<ptr target="http://alt.qcri.org/semeval2017/task5/data/uploads/results/subtask1-microblogs-siscosim.pdfhttp://alt.qcri.org/semeval2017" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
