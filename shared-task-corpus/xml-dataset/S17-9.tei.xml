<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2017 Task 9: Abstract Meaning Representation Parsing and Generation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jonathan</forename><surname>May</surname></persName>
							<email>jonmay@isi.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Institute Computer Science Department</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jay</forename><surname>Priyadarshi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences Institute Computer Science Department</orgName>
								<orgName type="institution">University of Southern California</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2017 Task 9: Abstract Meaning Representation Parsing and Generation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this report we summarize the results of the 2017 AMR SemEval shared task. The task consisted of two separate yet related subtasks. In the parsing subtask, participants were asked to produce Abstract Meaning Representation (AMR) <ref type="bibr" target="#b0">(Banarescu et al., 2013)</ref> graphs for a set of English sentences in the biomedical domain. In the generation subtask, participants were asked to generate English sentences given AMR graphs in the news/forum domain. A total of five sites participated in the parsing subtask, and four participated in the generation subtask. Along with a description of the task and the participants' systems, we show various score ablations and some sample outputs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Abstract Meaning Representation (AMR) is a compact, readable, whole-sentence semantic annotation <ref type="bibr" target="#b0">(Banarescu et al., 2013)</ref>. It includes entity identification and typing, PropBank semantic roles <ref type="bibr" target="#b12">(Kingsbury and Palmer, 2002)</ref>, individual entities playing multiple roles, as well as treatments of modality, negation, etc. AMR abstracts in numerous ways, e.g., by assigning the same conceptual structure to fear (v), fear (n), and afraid (adj). Figure <ref type="figure">1</ref> gives an example.</p><p>In 2016 an AMR parsing shared task was held at SemEval <ref type="bibr" target="#b15">(May, 2016)</ref>. Task participants demonstrated several new directions in AMR parsing technology and also validated the strong performance of existing parsers. We sought, in 2017, to focus AMR parsing performance on the biomedical domain, for which a not insignificant but still relatively small training corpus had been produced. While sentences from this domain are quite The soldier was not afraid of dying. The soldier was not afraid to die. The soldier did not fear death.</p><p>Figure <ref type="figure">1</ref>: An Abstract Meaning Representation (AMR) with several English renderings. Example borrowed from <ref type="bibr" target="#b19">Pust et al. (2015)</ref>.</p><p>formal compared to some of those evaluated in last year's task, they are also very complex, and have many terms unique to the domain. An example is shown in Figure <ref type="figure">2</ref>. We continue to use Smatch  as a metric for AMR parsing, but we perform additional ablative analysis using the approach proposed by <ref type="bibr" target="#b5">Damonte et al. (2016)</ref>. Along with parsing into AMR, it is important to encourage improvements in automatic generation of natural language (NL) text from AMR. Humans favor communication in NL. An AI that is able to parse text into AMR at a quality level indistinguishable from humans may be said to understand NL, but without the ability to render its own semantic representations into NL no human will ever be able to appreciate this.</p><p>The advent of several systems that generate English text from AMR input <ref type="bibr" target="#b8">(Flanigan et al., 2016b;</ref><ref type="bibr" target="#b18">Pourdamghani et al., 2016)</ref> inspired us to conduct a generation-based shared task from AMRs in the news/discussion forum domain. For the generation subtask, we solicited human judgments of sentence quality. We followed the precedent established by the Workshop in Machine Translation <ref type="bibr" target="#b2">(Bojar et al., 2016)</ref> and used the Appraise solicitation system <ref type="bibr" target="#b6">(Federmann, 2012)</ref>, lightly mod-Interestingly, serpinE2 mRNA and protein were also markedly enhanced in human CRC cells exhibiting mutation in &lt;i&gt;KRAS &lt;/i&gt;and &lt;i&gt;BRAF&lt;/i&gt;.</p><p>(e / enhance-01 :li 2 :ARG1 (a3 / and :op1 (n6 / nucleic-acid :name (n / name :op1 "mRNA") :ARG0-of (e2 / encode-01 :ARG1 p)) :op2 (p / protein :name (n2 / name :op1 "serpinE2"))) :manner (m / marked) :mod (a2 / also) :location (c / cell :ARG0-of (e3 / exhibit-01 :ARG1 (m2 / mutate-01 :ARG1 (a4 / and :op1 (g / gene :name (n4 / name :op1 "KRAS")) :op2 (g2 / gene :name (n5 / name :op1 "BRAF"))))) :mod (h / human) :mod (d / disease :name (n3 / name :op1 "CRC"))) :manner (i / interesting))</p><p>Figure <ref type="figure">2</ref>: One of the simpler biomedical domain sentences and its AMR. Note the italics markers in the original sentence are preserved, as they are semantically important to the sentence's understanding.</p><p>ified, to gather human rankings, then TrueSkill <ref type="bibr" target="#b21">(Sakaguchi et al., 2014)</ref> to elicit an overall system ranking.</p><p>Since the same training data and tools are available to both subtasks (though, in the case of the generation subtask, the utility of the Bio-AMR corpus is unclear), we will describe all the resources for both subtasks in Sections 2 and 3 but then will handle descriptions and ablations for the parsing and generation subtasks separately, in, respectively, Sections 4 and 5. Readers interested in only one of these subtasks should not feel compelled to read the other section. We will reconvene in Section 6 to conclude and discuss hardware, as we continue the tradition established last year in the awarding of trophies to the declared winners of each subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>LDC released a new corpus of AMRs (LDC2016E25), created as part of the DARPA DEFT program, in March of 2016. The new corpus, which was annotated by teams at SDL, LDC, and the University of Colorado, and su-pervised by Ulf Hermjakob at USC/ISI, is an extension of previous releases (LDC2015E86, LDC2014E41 and LDC2014T12). It contains 39,260 sentences (subsuming, in turn, the 19,572 AMRs from LDC2015E86, the 18,779 AMRs from LDC2014E41, and the 13,051 AMRs from LDC2014T12), partitioned into training, development, and test splits, from a variety of news and discussion forum sources. Participants in the generation task only were provided with AMRs for an additional 1,293 sentences for evaluation; the original sentences were also provided, as needed, to human evaluators during the human evaluation phase of the generation subtask (see Section 5.2). These sentences and their corresponding AMRs were sequestered and never released as data before the evaluation phase.</p><p>We also made available the Bio-AMR corpus version 0.8, which consists of 6,452 AMR annotations of sentences from cancer-related PubMed articles, covering 3 full papers 1 as well as the result sections of 46 additional PubMed papers. The corpus also includes about 1000 sentences each from the BEL BioCreative training corpus and the Chicago Corpus. The Bio-AMR corpus was partitioned into training, development, and test splits. An additional 500 sentences and their AMRs were sequestered until the evaluation phase, at which point the sentences were provided to parsing task participants only. Table <ref type="table" target="#tab_1">1</ref> summarizes the available data, including the split sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Other Resources</head><p>We made the following resources available to participants:</p><p>• The tokenizer (from Ulf Hermjakob) used to produce the tokenized sentences in the training corpus. 2</p><p>• The AMR specification, used by annotators in producing the AMRs. 3</p><p>• The JAMR <ref type="bibr" target="#b9">(Flanigan et al., 2014)</ref>   Figure <ref type="figure">3</ref>: The Appraise interface, adapted for AMR generation evaluation.</p><p>• The JAMR <ref type="bibr" target="#b8">(Flanigan et al., 2016b</ref>) generation system, as a strong generation baseline.</p><p>• An unsupervised AMR-to-English aligner <ref type="bibr" target="#b17">(Pourdamghani et al., 2014)</ref>. 6</p><p>• The same Smatch  scoring script used in the evaluation. 7</p><p>• A Python AMR manipulation library, from Nathan Schneider. 8</p><p>4 Parsing Sub-Task</p><p>In the parsing sub-task, participants were given 500 previously sequestered Bio-AMRs and were 6 http://isi.edu/˜damghani/papers/ Aligner.zip 7 https://github.com/snowblink14/ smatch 8 https://github.com/nschneid/ amr-hackathon asked to produce AMR graphs. Main results and ablative results are shown in Table <ref type="table" target="#tab_3">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Systems</head><p>Five teams participated in the task, a noticeable decline from last year's task, which saw eleven full participants. One team submitted two systems for a total of six distinct systems. Two teams were repeats from last year: CMU and RIGOTRIO (previously RIGA). Below are brief descriptions of each of the various systems, based on summaries provided by the system authors. Readers are encouraged to consult individual system description papers or relevant conference paper descriptions for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">The Meaning Factory (van Noord and Bos, 2017)</head><p>This team submitted two parsers. TMF-1 is a character-level sequence-to-sequence deep learn-  ing model 9 similar to that of <ref type="bibr" target="#b1">Barzdins and Gosko (2016)</ref>, but with a number of pre-and postprocessing changes to improve results. TMF-2 is an ensemble of CAMR <ref type="bibr" target="#b25">(Wang et al., 2015b</ref>) models trained on different data sets and the seq-to-seq model to find the best CAMR parse. <ref type="bibr" target="#b16">(Nguyen and Nguyen, 2017)</ref> This team implemented two wrapper layers for CAMR <ref type="bibr" target="#b24">(Wang et al., 2015a)</ref>. The first layer standardizes and adds additional information to input sentences to eliminate the weakness of the dependency parser observed when parsing scientific quotations, figures, formulas, etc. The second layer wraps the output data of CAMR. It is based on a prebuilt list of (biology term-AMR structure) pairs to fix the output data of CAMR. This makes CAMR deal with unknown scientific concepts better. <ref type="bibr" target="#b3">(Buys and Blunsom, 2017)</ref> This is a neural encoder-decoder AMR parser modeling the alignment between graph nodes and sentence tokens explicitly with a pointer mechanism. Candidate lemmas are predicted as a preprocessing step so that the lemmas of lexical node labels are factored out of the graph linearization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">UIT-DANGNT-CLNLP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Oxford</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">CMU</head><p>This was the same JAMR parsing system used in last year's evaluation <ref type="bibr" target="#b7">(Flanigan et al., 2016a)</ref>. The participants declined to submit a new system description paper. 4.1.5 RIGOTRIO <ref type="bibr" target="#b11">(Gruzitis et al., 2017)</ref> This team extended their CAMR-based AMR parser from last year's shared task <ref type="bibr" target="#b1">(Barzdins and Gosko, 2016)</ref> with a gazetteer for recognizing as named entities the biomedical compounds frequently mentioned in the biomedical texts. The gazetteer was populated from the provided biomedical AMR training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Quantitative Ablation</head><p>We made use of the analysis scripts produced by <ref type="bibr" target="#b5">Damonte et al. (2016)</ref> to conduct a more finegrained ablation of scores. As noted in that work, Smatch provides full-sentence analysis but some aspects of an AMR are more difficult to parse correctly than others. The ablation study considers only (or excludes) an aspect of the AMR and then calculates Smatch (or F1, when no heuristic matching is needed) with that limitation in place. Ablation scores are shown in Table <ref type="table" target="#tab_3">2</ref>. The ablations are: 10</p><p>• Unlabeled: All argument labels (e.g. ARG0, location) are replaced with a single common label</p><p>• No WSD: Propbank frames indicating different senses (such as die-01 vs die-02) are conflated</p><p>• NER: Only named entities are scored; that is, in both reference and hypothesis AMR, only nodes with an incoming arc labeled name are considered.</p><p>• Wiki: Only wikifications are scored; this is achieved in a manner similar to NER but with the incoming arc labeled wiki.</p><p>• Negation: Only concepts with an outgoing polarity arc are considered. In practice this arc is only used to indicate negation.</p><p>• Concepts: Only concepts, not relations, are scored.</p><p>• Reentrancies: Only concepts with two or more incoming relations are scored. Reentrancies occur when a concept has several mentions in a sentence, or where an 'inverted' relation (one that ends in -of) occurs, implying inverse dependency. In practice the latter is much more often the cause of a re-entrancy.</p><p>• Semantic Role Labeling (SRL): only relations corresponding to roles in PropBank, i.e. those named ARG0 and the like, are scored.</p><p>The ablation results show that superior performance in Smatch correlates with superior performance in the Unlabeled, No-WSD, NER, and Concepts performance. Additionally, Figure <ref type="figure" target="#fig_2">4</ref>, which plots each ablation score against Smatch and induces a linear regression, shows that six of the eight ablation sub-metrics are well correlated with Smatch; only wikification and negation are not. Wikification is generally handled as a separate process on top of overall AMR parsing; this may explain that discrepancy. We have no great explanation for negation's weak correlation but note that it is generally considered a difficult task in semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Discussion</head><p>It is interesting to note that the top-scoring system was, as in last year's shared task, based on CAMR <ref type="bibr" target="#b25">(Wang et al., 2015b)</ref>. It is also interesting to note that, in the Oxford team's submission, once again, a pure neural system is nearly as good as the CAMR system, despite having rather little data to train on. The Oxford system appears to be quite different from last year's neural submission <ref type="bibr" target="#b10">(Foland and Martin, 2016)</ref> but nevertheless is a strong competitor. Finally, the top-scoring system, that of UIT-DANGNT-CLNLP, got a 0.61 Smatch, while last year's top scoring systems <ref type="bibr" target="#b1">(Barzdins and Gosko, 2016;</ref><ref type="bibr" target="#b26">Wang et al., 2016</ref>) scored a 0.62, practically the same score. This, despite the fact that the evaluation corpora were quite different. One might expect the biomedical corpus to be easier to parse than the news/forum corpus, since its sentences are rather formal, and do not use slang or incorrect syntax. On the other hand, the sentences in the biomedical corpus are on average longer than those in the news/forum corpus (on average 25 words in bio vs. 14.5 in news/forum) and the biomedical corpus contains many unknown words, corresponding to domain terminology not in general use (1-count words are 9% of tokens in bio training, vs. 7.2% in news/forum). The news/forum corpus has, in its forum content, colloquialisms and writing variants that are very difficult to automatically analyze. Perhaps the relatively 'easy' and 'hard' parts of each corpus canceled each other out, yielding corpora that were about the same level of difficulty to parse. Nevertheless, it is somewhat concerning that AMR parsing quality appears to have stalled, as parsing performance remains in the low 0.60 range.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Generation Sub-Task</head><p>As AMR provides full-sentence semantics, it may be a suitable formalism for semantics-to-text generation. This subtask explored the suitability of that hypothesis. Given that AMRs do not capture non-semantic surface phenomena nor some essential properties of realized text such as tense, we incorporated human judgments into our evaluation, since automatic metrics against a single reference were practically guaranteed to be inadequate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Systems</head><p>Four teams participated in the task. We also included a submission from <ref type="bibr" target="#b18">Pourdamghani et al. (2016)</ref> run by the organizer, though a priori declared that submission to be non-competitive due to a conflict of interest. Below we provide short summaries of each team's approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">CMU</head><p>This was the JAMR generation system described in <ref type="bibr" target="#b8">(Flanigan et al., 2016b)</ref>. The participants declined to submit a system description paper. <ref type="bibr" target="#b14">(Lampouras and Vlachos, 2017)</ref> This team's method is based on inverting previous work on transition-based parsers, and casts NLG from AMR as a sequence of actions (e.g., insert/remove/rename edges and nodes) that progressively transform the AMR graph into a syntactic parse tree. It achieves this by employing a sequence of four classifiers, each focusing on a subset of the transition actions, and finally realizing the syntactic parse tree into the final sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Sheffield</head><p>5.1.3 RIGOTRIO <ref type="bibr" target="#b11">(Gruzitis et al., 2017)</ref> For generation, this team's approach was to write transformation rules for converting AMR into Grammatical Framework <ref type="bibr" target="#b20">(Ranta, 2004)</ref> abstract syntax from which semantically correct English text can be rendered automatically. In reality the approach worked for 10% of AMRs. For the submission the remaining 90% AMRs were converted to text using the JAMR <ref type="bibr" target="#b9">(Flanigan et al., 2014)</ref> tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">FORGe (Simon Mille and Wanner, 2017)</head><p>UPF-TALN's generation pipeline comprises a series of rule-based graph-transducers, for the syn-tacticization of the input graphs (converted to CoNLL format) and the resolution of morphological agreements, and an off-the-shelf statistical linearization component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.5">ISI</head><p>This was an internal, non-trophy-eligible submission based on the work of <ref type="bibr" target="#b18">Pourdamghani et al. (2016)</ref>. It views generation as phrase based machine translation and learns a linearization of AMR such that the result can be used in an offthe-shelf Moses <ref type="bibr" target="#b13">(Koehn et al., 2007)</ref> PBMT implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Manual Evaluation</head><p>We used Appraise <ref type="bibr" target="#b6">(Federmann, 2012)</ref>, an opensource system for manual evaluation of machine translation, to conduct a human evaluation of generation quality. The system asks human judges to rank randomly selected systems' translations of sentences from the test corpus. This in turn yields pairwise preference information that can be used to effect an overall system ranking.</p><p>For the purposes of this task we needed to adapt the Appraise system to admit nested representations of AMRs, and to be compatible with our IT infrastructure. A screen shot is shown in Figure <ref type="figure">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Scoring</head><p>We provided BLEU as a potentially helpful automatic metric but consider several metrics induced over pairwise comparisons induced by manual evaluation to be the "true" evaluation metric for the purposes of trophy-awarding:</p><p>• Win+tie percentage: This is simply the percentage "wins" (better pairwise comparisons) plus "ties" (equal comparisons) of the total number of its pairwise comparisons. This metric was largely used to induce rankings from human judgments through WMT 2011.</p><p>• Win percentage: This is a "harsher" version of Win+tie; the percentage is wins wins+ties+losses .</p><p>Essentially, ties are judged as losses. This was used in WMT 2011 and 2012.</p><p>• TrueSkill <ref type="bibr" target="#b21">(Sakaguchi et al., 2014)</ref>. This is an adaptation of a metric developed for player rankings in ongoing competitions such as on Microsoft Xbox Live. The metric maintains estimates of player (i.e., generation system)   ability as Gaussian distributions and rewards events (i.e., pairwise rankings of outputs) that are unexpected, such as a poorly ranked player outperforming a highly-ranked player, more than expected events.</p><p>We note that the three metrics derived from human pairwise rankings agree with the relative ordering of the submitted systems' abilities on the evaluation data, while the BLEU metric does not. It is not terribly surprising the BLEU does not correlate with human judgment; it was designed for a very different task.</p><p>Since the participants in this task were also judges in the human evaluation, we were somewhat concerned that implicit bias might lead to a skewing of the results, even though system identification was not available during evaluation. We thus removed all judgments that involved selfscoring and recalculated results. The results, shown in Table <ref type="table" target="#tab_6">4</ref>, show little difference from the main results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Qualitative Analysis</head><p>The generation task was quite challenging, as generation from AMR is still a nascent field. Table <ref type="table" target="#tab_7">5</ref> shows an example of a single AMR and the content generated by each system for it, along with the number of wins, ties, and losses per system by the human evaluations (note: not all segments were scored for all systems, and not all systems received the same number of comparisons). Some systematic errors, such as incorporating label text into the generation, could lead to improvements, as could a stronger language model; generated output is often disfluent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Both biomedical AMR parsing and generation from AMRs appear to be challenging tasks; perhaps too challenging, as the number of participants in either subtask was significantly lower than the participation rate from a year ago. However, we observed that AMR parsing quality on the seemingly more difficult biomedical domain was no worse than that observed on the news/forum domain. In fact, the same fundamental technology that dominated in last year's evaluation once again reigned supreme. A concern that Smatch was too coarse a metric to evaluate AMRs was not borne out, as scores in an ablation study tracked well with the overall Smatch score. We are pleased to award the parsing trophy to the UIT-DANGNT-CLNLP team, which added domain-specific modification to the strong CAMR <ref type="bibr" target="#b25">(Wang et al., 2015b)</ref> parsing platform.</p><p>On the generation side, it seems that there is still a long way to go to reach fluency. We note that BLEU, which is often used as a generation metric, is woefully inadequate compared to human evaluation. We hope the analysis presented here will lead to better generation systems in the future. It was clear from the human evaluations, however, that the RIGOTRIO team prevailed and will receive the generation trophy. Source Text W T L Reference following the 1992-1995 war bosnia remains ethnically divided and violence during major football matches occasionally occurs here. RIGOTRIO following the 1992 1995 war, bosnia has remained an ethnic divide, and the major football matches occasionally violence in here.</p><p>1 2 1</p><p>CMU following the 1992 1995 war , bosnia remains divided in ethnic and the occasional football match in major violence in here 2 0 0</p><p>FORGe Bosnia and Herzegovina remains under about ethnic the Bosnia and Herzegovina divide and here at a majored match a violence. 0 0 4 ISI following war between 1992 and 1995 , the country :wiki bosnia and herzegovina bosnia remain divided on ethnic and violence in football match by major here from time to time 3 0 1 Sheffield Remain Bosnia ethnic divid following war 920000 950000 major match footbal occasional here violency 0 2 0 </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>9</head><label></label><figDesc>https://www.tensorflow.org/ tutorials/seq2seq/</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Relationship between each of the eight quantitative ablation studies from Damonte et al. (2016) and Smatch; six of the eight metrics are well-correlated with Smatch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>d3 / date-entity :year 1992) :op2 (d4 / date-entity :year 1995)))))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>A summary of data used in this task; split sizes indicate the number of AMRs per sub-corpus.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Main parsing results: For Smatch, a mean of ten runs with ten restarts per run is shown; standard deviation was about 0.0003 per system. For the remaining ablations, a single run was used.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="3">: Main generation results: The three</cell></row><row><cell cols="3">manually-derived metrics agree on the systems'</cell></row><row><cell cols="2">relative rankings.</cell><cell></cell></row><row><cell cols="3">Win Win+Tie Trueskill</cell></row><row><cell>RIGOTRIO 53.00</cell><cell>79.98</cell><cell>1.03</cell></row><row><cell>CMU 50.02</cell><cell>71.91</cell><cell>0.819</cell></row><row><cell>FORGe 44.49</cell><cell>58.57</cell><cell>0.458</cell></row><row><cell>ISI 26.40</cell><cell>38.60</cell><cell>-1.172</cell></row><row><cell>Sheffield 9.46</cell><cell>22.84</cell><cell>-2.132</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Human judgments of generation results</cell></row><row><cell>after self-judgments are removed: The results are</cell></row><row><cell>fundamentally the same</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Examples of an AMR from the Generation subtask and each system's generation for it (W = # wins, T = # ties, L = # losses in human evaluation).</figDesc><table><row><cell>the SemEval organizers: Steven Bethard, Marine</cell></row><row><cell>Carpuat, Marianna Apidianaki, Saif Mohammad,</cell></row><row><cell>Daniel Cer, and David Jurgens. We also gratefully</cell></row><row><cell>acknowledge the participating teams' efforts. This</cell></row><row><cell>work was sponsored by DARPA DEFT (FA8750-</cell></row><row><cell>13-2-0045).</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/jflanigan/jamr 5 https://github.com/c-amr/camr</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">see<ref type="bibr" target="#b5">Damonte et al. (2016)</ref> for more details</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We were overjoyed to be offered volunteer human judgments by Nathan Schneider and his class at Georgetown: Austin Blodgett, Emma Manning, Harry Eldridge, Joe Garman, Lucia Donatelli, Sean MacAvaney, Max Kim, Nicholas Chapman, Mohammad Ali Yekataie, and Yushi Zhao. Thanks to Marco Damonte and Shay Cohen for reaching out regarding Smatch ablations and providing scoring code. The human evaluations would not have been possible without the use of the Appraise system, which was shared by Christian Federmann and Matt Post. Many thanks to the AMR creation team: Kira Griffitt, Ulf Hermjakob, Kevin Knight, and Martha Palmer. Thanks also to</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Abstract Meaning Representation for sembanking</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W13-2322" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse. Association for Computational Linguistics</title>
				<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse. Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR parsing accuracy</title>
		<author>
			<persName><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didzis</forename><surname>Gosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Findings of the 2016 conference on machine translation</title>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rajen</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><forename type="middle">Jimeno</forename><surname>Yepes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurelie</forename><surname>Neveol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariana</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raphael</forename><surname>Rubino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carolina</forename><surname>Scarton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Turchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W/W16/W16-2301" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
				<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="131" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Oxford at SemEval-2017 task 9: Neural AMR parsing with pointeraugmented attention</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P13-2131" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">An incremental parser for abstract meaning representation</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giorgio</forename><surname>Satta</surname></persName>
		</author>
		<idno>abs/1608.06111</idno>
		<ptr target="http://arxiv.org/abs/1608.06111" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Appraise: An open-source toolkit for manual evaluation of machine translation output</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Prague Bulletin of Mathematical Linguistics</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="25" to="35" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CMU at SemEval-2016 task 8: Graph-based AMR parsing with infinite ramp loss</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Generation from abstract meaning representation using tree transducers</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N16-1087" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
				<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="731" to="739" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the Abstract Meaning Representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P14-1134" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CU-NLP at SemEval-2016 task 8: AMR parsing using LSTM-based recurrent neural networks</title>
		<author>
			<persName><forename type="first">William</forename><surname>Foland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">RIGOTRIO at SemEval-2017 task 9: Combining machine learning and grammar engineering for AMR parsing and generation</title>
		<author>
			<persName><forename type="first">Normunds</forename><surname>Gruzitis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didzis</forename><surname>Gosko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">From Treebank to Propbank</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation</title>
				<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P07-2045" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions. Association for Computational Linguistics</title>
				<meeting>the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume the Demo and Poster Sessions. Association for Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sheffield at SemEval-2017 task 9: Transition-based language generation from AMR</title>
		<author>
			<persName><forename type="first">Gerasimos</forename><surname>Lampouras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 8: Meaning representation parsing</title>
		<ptr target="http://www.aclweb.org/anthology/S16-1166" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016). Association for Computational Linguistics</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016). Association for Computational Linguistics<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05" />
			<biblScope unit="page" from="1063" to="1073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">UIT-DANGNT-CLNLP at SemEval-2017 task 9: Building scientific concept fixing patterns for improving CAMR</title>
		<author>
			<persName><forename type="first">Khoa</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dang</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Aligning English strings with Abstract Meaning Representation graphs</title>
		<author>
			<persName><forename type="first">Nima</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1048" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="425" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generating English from Abstract Meaning Representations</title>
		<author>
			<persName><forename type="first">Nima</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Natural Language Generation conference</title>
				<meeting>the 9th International Natural Language Generation conference<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Parsing English into Abstract Meaning Representation using syntaxbased machine translation</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/D15-1136" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="1143" to="1154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Grammatical framework</title>
		<author>
			<persName><forename type="first">Aarne</forename><surname>Ranta</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0956796803004738</idno>
		<ptr target="https://doi.org/10.1017/S0956796803004738" />
	</analytic>
	<monogr>
		<title level="j">Journal of Functional Programming</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">145189</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficient elicitation of annotations for human evaluation of machine translation</title>
		<author>
			<persName><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W14-3301" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth Workshop on Statistical Machine Translation. Association for Computational Linguistics</title>
				<meeting>the Ninth Workshop on Statistical Machine Translation. Association for Computational Linguistics<address><addrLine>Baltimore, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">FORGe at SemEval-2017 task 9: Deep sentence generation based on a sequence of graph transducers</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Burga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Mille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leo</forename><surname>Wanner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The meaning factory at SemEval-2017 task 9: Producing AMRs with neural semantic parsing</title>
		<author>
			<persName><forename type="first">Rik</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
				<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Boosting transition-based AMR parsing with refined actions and auxiliary analyzers</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-2141" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
				<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="857" to="862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A transition-based algorithm for AMR parsing</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/N15-1040" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="366" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">CAMR at SemEval-2016 task 8: An extended transition-based AMR parser</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
