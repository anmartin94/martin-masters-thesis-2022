<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2013 Task 5: Evaluating Phrasal Semantics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Ioannis</forename><surname>Korkontzelos</surname></persName>
							<email>ioannis.korkontzelos@man.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="laboratory">National Centre for Text Mining</orgName>
								<orgName type="institution">University of Manchester</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">CompSci Dept</orgName>
								<orgName type="institution" key="instit1">UKP Lab</orgName>
								<orgName type="institution" key="instit2">Technische Universität</orgName>
								<address>
									<settlement>Darmstadt</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Fabio</forename><forename type="middle">Massimo</forename><surname>Zanzotto</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Enterprise Engineering</orgName>
								<orgName type="institution">University of Rome &quot;Tor Vergata&quot;</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">FG Language Technology</orgName>
								<orgName type="department" key="dep2">CompSci Dept. Technische</orgName>
								<orgName type="institution">Universität Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2013 Task 5: Evaluating Phrasal Semantics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the SemEval-2013 Task 5: "Evaluating Phrasal Semantics". Its first subtask is about computing the semantic similarity of words and compositional phrases of minimal length. The second one addresses deciding the compositionality of phrases in a given context. The paper discusses the importance and background of these subtasks and their structure. In succession, it introduces the systems that participated and discusses evaluation results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Numerous past tasks have focused on leveraging the meaning of word types or words in context. Examples of the former are noun categorization and the TOEFL test, examples of the latter are word sense disambiguation, metonymy resolution, and lexical substitution. As these tasks have enjoyed a lot success, a natural progression is the pursuit of models that can perform similar tasks taking into account multiword expressions and complex compositional structure. In this paper, we present two subtasks designed to evaluate such phrasal models: a. Semantic similarity of words and compositional phrases b. Evaluating the compositionality of phrases in context For example, the first subtask addresses computing how similar the word "valuation" is to the compositional sequence "price assessment", while the second subtask addresses deciding whether the phrase "piece of cake" is used literally or figuratively in the sentence "Labour was a piece of cake!". The aim of these subtasks is two-fold. Firstly, considering that there is a spread interest lately in phrasal semantics in its various guises, they provide an opportunity to draw together approaches to numerous related problems under a common evaluation set. It is intended that after the competition, the evaluation setting and the datasets will comprise an on-going benchmark for the evaluation of these phrasal models.</p><p>Secondly, the subtasks attempt to bridge the gap between established lexical semantics and fullblown linguistic inference. Thus, we anticipate that they will stimulate an increased interest around the general issue of phrasal semantics. We use the notion of phrasal semantics here as opposed to lexical compounds or compositional semantics. Bridging the gap between lexical semantics and linguistic inference could provoke novel approaches to certain established tasks, such as lexical entailment and paraphrase identification. In addition, it could ul-timately lead to improvements in a wide range of applications in natural language processing, such as document retrieval, clustering and classification, question answering, query expansion, synonym extraction, relation extraction, automatic translation, or textual advertisement matching in search engines, all of which depend on phrasal semantics.</p><p>The remainder of this paper is structured as follows: Section 2 presents details about the data sources and the variety of sources applicable to the task. Section 3 discusses the first subtask, which is about semantic similarity of words and compositional phrases. In subsection 3.1 the subtask is described in detail together with some information about its background. Subsection 3.2 discusses the data creation process and subsection 3.3 discusses the participating systems and their results. Section 4 introduces the second subtask, which is about evaluating the compositionality of phrases in context. Subsection 4.1 explains the data creation process for this subtask. In subsection 4.2 the evaluation statistics of participating systems are presented. Section 5 is a discussion about the conclusions of the entire task. Finally, in section 6 we summarize this presentation and discuss briefly our vision about challenges in distributional semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Sources &amp; Methodology</head><p>Data instances of both subtasks are drawn from the large-scale, freely available WaCky corpora <ref type="bibr" target="#b1">(Baroni et al., 2009)</ref>. The resource contains corpora in 4 languages: English, French, German and Italian. The English corpus, ukWaC, consists of 2 billion words and was constructed by crawling to the .uk domain of the web and using medium-frequency words from the BNC as seeds. The corpus is part-of-speech (PoS) tagged and lemmatized using the TreeTagger <ref type="bibr" target="#b11">(Schmid, 1994)</ref>. The French corpus, frWaC, contains 1.6 billion word corpus and was constructed by web-crawling the .fr domain and using mediumfrequency words from the Le Monde Diplomatique corpus and basic French vocabulary lists as seeds. The corpus was PoS tagged and lemmatized with the TreeTagger. The French corpus, deWaC, consists of 1.7 billion word corpus and was constructed by crawling the .de domain and using mediumfrequency words from the SudDeutsche Zeitung cor-pus and basic German vocabulary lists as seeds. The corpus was PoS tagged and lemmatized with the TreeTagger. The Italian corpus, itWaC, is a 2 billion word corpus constructed from the .it domain of the web using medium-frequency words from the Repubblica corpus and basic Italian vocabulary lists as seeds. The corpus was PoS tagged with the Tree-Tagger, and lemmatized using the Morph-it! lexicon <ref type="bibr" target="#b17">(Zanchetta and Baroni, 2005)</ref>. Several versions of the WaCky corpora, with various extra annotations or modifications are also available <ref type="bibr">1</ref> .</p><p>We ensured that data instances occur frequently enough in the WaCky corpora, so that participating systems could gather statistics for building distributional vectors or other uses. As the evaluation data only contains very small annotated samples from freely available web documents, and the original source is provided, we could provide them without violating copyrights.</p><p>The size of the WaCky corpora is suitable for training reliable distributional models. Sentences are already lemmatized and part-of-speech tagged. Participating approaches making use of distributional methods, part-of-speech tags or lemmas, were strongly encouraged to use these corpora and their shared preprocessing, to ensure the highest possible comparability of results. Additionally, this had the potential to considerably reduce the workload of participants. For the first subtask, data were provided in English, German and Italian and for the second subtask in English and German.</p><p>The range of methods applicable to both subtasks was deliberately not limited to any specific branch of methods, such as distributional or vector models of semantic compositionality. We believe that the subtasks can be tackled from different directions and we expect a great deal of the scientific benefit to lie in the comparison of very different approaches, as well as how these approaches can be combined. An exception to this rule is the fact that participants in the first subtask were not allowed to use directly definitions extracted from dictionaries or lexicons. Since the subtask is considered fundamental and its data were created from online knowledge resources, systems using the same tools to address it would be of limited use. However, participants were allowed to use other information residing in dictionaries, such as Wordnet synsets or synset relations.</p><p>Participating systems were allowed to attempt one or both subtasks, in one or all of the languages supported. However, it was expected that systems performing well at the first basic subtask would provide a good starting point for dealing with the second subtask, which is considered harder. Moreover, language-independent models were of special interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Subtask 5a: Semantic Similarity of Words and Compositional Phrases</head><p>The aim of this subtask is to evaluate the component of a semantic model that computes the similarity between word sequences of different length.</p><p>Participating systems are asked to estimate the semantic similarity of a word and a short sequence of two words. For example, they should be able to figure out that contact and close interaction are similar whereas megalomania and great madness are not. This subtask addresses a core problem, since satisfactory performance in computing the similarity of full sentences depends on similarity computations on shorter sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background and Description</head><p>This subtask is based on the assumption that we first need a basic set of functions to compose the meaning of two words, in order to construct more complex models that compositionally determine the meaning of sentences, as a second step. For compositional distributional semantics, the need for these basic functions is discussed in <ref type="bibr" target="#b8">Mitchell and Lapata (2008)</ref>. Since then, many models have been proposed for addressing the task <ref type="bibr" target="#b9">(Mitchell and Lapata, 2010;</ref><ref type="bibr" target="#b0">Baroni and Zamparelli, 2010;</ref><ref type="bibr" target="#b6">Guevara, 2010)</ref>, but still comparative analysis is in general based on comparing sequences that consist of two words.</p><p>As in <ref type="bibr" target="#b18">Zanzotto et al. (2010)</ref>, this subtask proposes to compare the similarity of a 2-word sequence and a single word. This is important as it is the basic step to analyse models that can compare any word sequences of different length.</p><p>The development and testing set for this subtask were built based on the idea described in Zanzotto et al. <ref type="bibr">(2010)</ref>. Dictionaries were used as sources of contact/[kon-takt] 1. the act or state of touching; a touching or meeting, as of two things or people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">close interaction</head><p>3. an acquaintance, colleague, or relative through whom a person can gain access to information, favors, influential people, and the like. Figure <ref type="figure" target="#fig_0">1</ref> presents the definition of the word contact, from which the pair (contact, close interaction) can be extracted. Such equivalences extracted from dictionaries can be seen as natural and unbiased data instances. This idea opens numerous opportunities:</p><p>• Since definitions in dictionaries are syntactically rich, we are able to create examples for different syntactic relations.</p><p>• We have the opportunity to extract positive examples for languages for which dictionaries with sufficient entries are available.</p><p>Negative examples were generated by matching words under definition with randomly chosen defining sequences. In the following subsection, we provide details about the application of this idea to build the development and testing set for subtask 5a.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Creation</head><p>Data for this subtask were provided in English, German and Italian. Pairs of words under definitions and defining sequences were extracted from the English, German and Italian part of Wiktionary, respectively. In particular, for each language, all Wiktionary entries were downloaded and part-of-speech tagged using the Genia tagger <ref type="bibr" target="#b13">(Tsuruoka et al., 2005</ref>  were kept, only. For the purpose of extracting word and sequence pairs for this subtask, we consider as noun phrases, sequences that consist of adjectives or noun and end with a noun. In cases where the extracted noun phrase was longer than two words, the right-most two sequences were kept, since in most cases noun phrases are governed by their rightmost component. Subsequently, we discarded instances whose words occur too infrequently in the WaCky corpora <ref type="bibr" target="#b1">(Baroni et al., 2009)</ref> of each language. WaCky corpora are available freely and are large enough for participating systems to extract distributional statistics. Taking the numbers of extracted instances into account, we set the frequency thresholds at 10 occurrences for English and 5 for German and Italian. Data instances extracted following this process were then checked by a computational linguist. Candidate pairs in which the definition sequence was not judged to be a precise and adequate definition of the word under definition were discarded. These cases were very limited and mostly account for shortcomings of the very simple pattern used for extraction. For example, the pair (standard, transmission vehicle) coming from the definition of "standard" as "A manual transmission vehicle" was discarded. Similarly in German, the pair (Fremde (Eng. stranger), weibliche Person (Eng. female person)) was discarded. "Fremde", which is of female grammatical genre, was defined as "weibliche Person, die man nicht kennt (Eng. female person, one does not know)". In Italian, the pair (paese (Eng. land, country, region), grande estensione (Eng. large tract)) was discarded, since the original definition was "grande estensione di terreno abitato e generalmente coltivato (Eng. large tract of land inhabited and cultivated in general)".</p><p>The final data sets were divided into training and held-out testing sets, according to a 60% and 40% ratio, respectively. The first three rows of table 1 present the numbers of the train and test sets for the three languages chosen. It was identified that a fair percentage of the German instances (approximately 27%) refer to the definitions of first names or family names. This is probably a flaw of the German part of Wiktionary. In addition, the pattern used for extraction happens to apply to the definitions of names. Name instances were discarded from the German data set to produce the data set described in the last row of table 1.</p><p>The training set was released approximately 3 months earlier than the test data. Instances in both set ware annotated as positive or negative. Test set annotations were not released to the participants, but were used for evaluation, only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>Participating systems were evaluated on their ability to predict correctly whether the components of each test instance, i.e. word-sequence pair, are semantically similar or distinct. Participants were allowed to use or ignore the training data, i.e. the systems could be supervised or unsupervised. Unsupervised systems were allowed to use the training data for development and parameter tuning. Since this is a core task, participating systems were not be able to use dictionaries or other prefabricated lists. Instead, they were allowed to use distributional similarity models, selectional preferences, measures of semantic similarity etc.</p><p>Participating system responses were scored in terms of standard information retrieval measures: accuracy (A), precision (P), recall (R) and F 1 score <ref type="bibr" target="#b10">(Radev et al., 2003)</ref>. Systems were encouraged to submit at most 3 solutions for each language, but submissions for fewer languages were accepted.</p><p>Five research teams participated. Ten system runs were submitted for English, one for German (on data set: German -no names) and one for Italian. Table <ref type="table" target="#tab_3">2</ref> illustrates the results of the evaluation process. The teams of (HsH) <ref type="bibr" target="#b16">(Wartena, 2013)</ref>  these approaches performed better than some supervised ones for this experiment. Below, we summarise the properties of participating systems.</p><p>(HsH) <ref type="bibr" target="#b16">(Wartena, 2013)</ref> used distributed similarity and especially random indexing to compute similarities between words and possible definitions, under the hypothesis that a word and its definition are distributionally more similar than a word and an arbitrary definition. Considering all open-class words, context vectors over the entire WaCky corpus were computed for the word under definition, the defining sequence, its component words separately, the addition and multiplication of the vectors of the component words and a general context vector. Then, various similarity measures were computed on the vectors, including an innovative length-normalised version of Jensen-Shannon divergence. The similarity values are used to train a Support Vector Machine (SVM) classifier <ref type="bibr" target="#b3">(Cortes and Vapnik, 1995)</ref>.</p><p>The first approach (run 1) of CLaC <ref type="bibr" target="#b12">(Siblini and Kosseim, 2013</ref>) is based on a weighted semantic network to measure semantic relatedness between the word and the components of the phrase. A PART classifier is used to generate a partial decision trained on the semantic relatedness information of the labelled training set. The second approach uses a supervised distributional method based on words frequently occurring in the Web1TB corpus to calculate relatedness. A JRip classifier is used to gen-erate rules trained on the semantic relatedness information of the training set. This approach was used in conjunction with the first one as a backup method (run 2). In addition, features generated by both approaches were used to train the JRIP classifier collectively (run 3).</p><p>The first approach of MELODI (Van de Cruys et al., 2013), called lvw, uses a dependency-based vector space model computed over the ukWaC corpus, in combination with Latent Vector Weighting ( <ref type="bibr" target="#b14">Van de Cruys et al., 2011)</ref>. The system computes the similarity between the first noun and the head noun of the second phrase, which was weighted according to the semantics of the modifier. The second approach, called dm, used a dependency-based vector space model, but, unlike the first approach, disregarded the modifier in the defining sequence. Since both systems are unsupervised, the training data was used to train a similarity threshold parameter, only.</p><p>UMCC DLSI-(EPS) <ref type="bibr">(Dávila et al., 2013)</ref> locates the synsets of words in data instances and computes the semantic distances between each synset of the word under definition and each synsets of the defining sequence words. In succession, a classifier is trained using features based on distance and Word-Net relations.</p><p>The first attempt of ITNLP (run 1) consisted of an SVM classifier trained on semantic similarity computations between the word under definition and the defining sequence in each instance. Their second attempt also uses an SVM, however trained on WordNet-based similarities. The third attempt of ITNLP is a combination of the previous two; it combines their features to train an SVM classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Subtask 5b: Semantic Compositionality in Context</head><p>An interesting sub-problem of semantic compositionality is to decide whether a target phrase is used in its literal or figurative meaning in a given context. For example "big picture" might be used literally as in Click here for a bigger picture or figuratively as in To solve this problem, you have to look at the bigger picture. Another example is "old school" which can also be used literally or figuratively: He will go down in history as one of the old school, a true gentlemen. vs. During the 1970's the hall of the old school was converted into the library.</p><p>Being able to detect whether a phrase is used literally or figuratively is e.g. especially important for information retrieval, where figuratively used words should be treated separately to avoid false positives. For example, the example sentence He will go down in history as one of the old school, a true gentlemen. should probably not be retrieved for the query "school". Rather, the insights generated from subtask 5a could be utilized to retrieve sentences using a similar phrase such as "gentleman-like behavior". The task may also be of interest to the related research fields of metaphor detection and idiom identification.</p><p>There were no restrictions regarding the array of methods, and the kind of resources that could be employed for this task. In particular, participants were allowed to make use of pre-fabricated lists of phrases annotated with their probability of being used figuratively from publicly available sources, or to produce these lists from corpora. Assessing how well the phrase suits its context might be tackled using e.g. measures of semantic relatedness as well as distributional models learned from the underlying corpus.</p><p>Participants of this subtask were provided with real usage examples of target phrases. For each usage example, the task is to make a binary decision whether the target phrase is used literally or figu-ratively in this context. Systems were tested in two different disciplines: a known phrases task where all target phrases in the test set were contained in the training, and an unknown phrases setting, where all target phrases in the test set were unseen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Creation</head><p>The first step in creating the corpus was to compile a list of phrases that can be used either literally or metaphorically. Thus, we created an initial list of several thousand English idioms from Wiktionary by listing all entries under the category ENGLISH ID-IOMS using the JWKTL Wiktionary API <ref type="bibr" target="#b19">(Zesch et al., 2008)</ref>. We manually filtered the list removing most idioms that are very unlikely to be ever used literally (anymore), e.g. to knock on heaven's door. For each of the resulting list of phrases, we extracted usage contexts from the ukWaC corpus <ref type="bibr" target="#b1">(Baroni et al., 2009)</ref>. Each usage context contains 5 sentences, where the sentence with the target phrase appears in a randomized position. Due to segmentation errors, some usage contexts actually might contain less than 5 sentences, but we manually filtered all usage contexts where the remaining context was insufficient. This was done in the final cleaning step where we also manually removed (near) duplicates, obvious spam, encoding problems etc.</p><p>The target phrases in context were annotated for figurative, literal, both or impossible to tell usage, using the CrowdFlower 2 crowdsourcing annotation platform. We used about 8% of items as "gold" items for quality assurance, and had each example annotated by three crowdworkers. The task was comparably easy for crowdworkers, who reached 90%-94% pairwise agreement, and 95% success on the gold items. About 5% of items with low agreement and marked as impossible were removed. Table 3 summarizes the quantitative characteristics of all datasets resulting from this process. We took care in sampling the data as to keep similar distributions across the training, development and testing parts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>Training and development datasets were made available in advance, test data was provided during the evaluation period without labels. System perfor-    mance was measured in accuracy. Since all participants provided classifications for all test items, the accuracy score is equivalent to precision/recall/F1. Participants were allowed to enter up to three different runs for evaluation. We also provide baseline accuracy scores, which are obtained by always assigning the most frequent class (figurative). Table <ref type="table" target="#tab_6">4</ref> provides the evaluation results for the known phrases task, while Table <ref type="table" target="#tab_7">5</ref> ranks participants for the unseen phrases task. As expected, the unseen phrases setting is much harder than the known phrases setting, as for unseen phrases it is not possible to learn lexicalised contextual clues. In both settings, the winning entries were able to beat the MFC baseline. While performance in the known phrases setting is close to 80% and thus acceptable, the general task of recognizing the literal or figurative use of unseen phrases remains very challenging, with only a small improvement over the baseline. We refer to the system descriptions for more details on the techniques used for this subtask: UNAL <ref type="bibr" target="#b7">(Jimenez et al., 2013)</ref>, IIRG <ref type="bibr" target="#b2">(Byrne et al., 2013)</ref> and CLaC <ref type="bibr" target="#b12">(Siblini and Kosseim, 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Task Conclusions</head><p>In this section, we further discuss the findings and conclusion of the evaluation challenge in the task of "Phrasal Semantics".</p><p>Looking at the results of both subtasks, one observes that the maximum performance achieved is higher for the first than the second subtask. For this comparison to be fair, trivial baselines should be taken into account. A system randomly assigning an output value would be on average 50% correct in the first subtask, since the numbers of positive and negative instances in the testing set are equal. Similarly, a system assigning the most frequent class, i.e. the figurative use of any phrase, would be 50.3% and 61.6% accurate in the second subtask for seen and unseen test instances, respectively. It should also be noted that the testing instances in the first subtask are unseen in the respective training set. As a result, in terms of baselines, the second subtask on unseen data (Table <ref type="table" target="#tab_7">5</ref>) should be considered easier than the first subtask (Table <ref type="table" target="#tab_3">2</ref>). However, the best performing systems achieved much higher accuracy in the first than in the second subtask. This contradiction confirms our conception that the first subtask is less complex than the second.</p><p>In the first subtask, it is evident that no method performs much better or much worse than the others.</p><p>Although the participating systems have employed a wide variety of approaches and tools, the difference between the best and worst accuracy achieved is relatively limited, in particular approximately 14%. Even more interestingly, unsupervised approaches performed better than some supervised ones. This observation suggests that no "golden recipe" has been identified so far for this task. Thus, probably different processing tools take advantage of different sources of information. It is a matter of future research to identify these sources and the corresponding tools, and then develop hybrid methods of improved performance.</p><p>In the second subtask, the results of evaluation on known phrases are much higher than on unseen phrases. This was expected, as for unseen phrases it is not possible to learn lexicalised contextual clues. Thus, the second subtask has succeeded in identifying the complexity threshold up to which the current state-of-the-art can address the computational problem. Further than this threshold, i.e. for unseen phrases, current systems have not yet succeeded in addressing it. In conclusion, the difficulty in evaluating the compositionality of previously unseen phrases in context highlights the overall complexity of the second subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary and Future Work</head><p>In this paper we have presented the 5 th task of Se-mEval 2013, "Evaluating Phrasal Semantics", which consists of two subtasks: (1) semantic similarity of words and compositional phrases, and (2) compositionality of phrases in context. The former subtask, which focussed on the first step of composing the meaning of phrases of any length, is less complex than the latter subtask, which considers the effect of context to the semantics of a phrase. The paper presents details about the background and importance of these subtasks, the data creation process, the systems that took part in the evaluation and their results.</p><p>In the future, we expect evaluation challenges on phrasal semantics to progress towards two directions: (a) the synthesis of semantics of sequences longer than two words, and (b) aiming to improve the performance of systems that determine the compositionality of previously unseen phrases in con-text. The evaluation results of the first task suggest that state-of-the-art systems can compose the semantics of two word sequences with a promising level of success. However, this task should be seen as the first step towards composing the semantics of sentence-long sequences. As far as subtask 5b is concerned, the accuracy achieved by the participating systems on unseen testing data was low, only slightly better than the most frequent class baseline, which assigns the figurative use to all test phrases. Thus, the subtask cannot be considered well addressed by the state-of-the-art and further progress should be sought.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The definition of contact in a sample dictionary</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Quantitative characteristics of the datasets</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Task 5a: Evaluation results. A, P, R, rej. and F 1 stand for accuracy, precision, recall, rejection and F 1 score, respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Quantitative characteristics of the datasets</figDesc><table><row><cell>Rank System</cell><cell cols="2">Run Accuracy</cell></row><row><cell>1 IIRG</cell><cell>3</cell><cell>.779</cell></row><row><cell>2 UNAL</cell><cell>2</cell><cell>.754</cell></row><row><cell>3 UNAL</cell><cell>1</cell><cell>.722</cell></row><row><cell>5 IIRG</cell><cell>1</cell><cell>.530</cell></row><row><cell>4 Baseline MFC</cell><cell>-</cell><cell>.503</cell></row><row><cell>6 IIRG</cell><cell>2</cell><cell>.502</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="3">: Task 5b: Evaluation results for the known</cell></row><row><cell>phrases setting</cell><cell></cell><cell></cell></row><row><cell>Rank System</cell><cell cols="2">Run Accuracy</cell></row><row><cell>1 UNAL</cell><cell>1</cell><cell>.668</cell></row><row><cell>2 UNAL</cell><cell>2</cell><cell>.645</cell></row><row><cell>3 Baseline MFC</cell><cell>-</cell><cell>.616</cell></row><row><cell>4 CLaC</cell><cell>1</cell><cell>.550</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Task 5b: Evaluation results for the unseen</cell></row><row><cell>phrases setting</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">WaCky website: wacky.sslmit.unibo.it</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2"> www.crowdflower.com   </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The work relevant to subtask 5a described in this paper is funded by the European Community's Seventh Framework Program (FP7/2007<ref type="bibr" target="#b16">-2013</ref> under grant agreement no. 318736 (OSSMETER).</p><p>We would like to thank Tristan Miller for helping with the subtleties of English idiomatic expressions, and Eugenie Giesbrecht for support in the organization of subtask 5b. This work has been supported by the Volkswagen Foundation as part of the Lichtenberg-Professorship Program under grant No. I/82806, and by the Hessian research excellence program Landes-Offensive zur Entwicklung Wissenschaftlich-ökonomischer Exzellenz (LOEWE) as part of the research center Digital Humanities.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2010 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1183" to="1193" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The WaCky wide web: a collection of very large linguistically processed webcrawled corpora. Language Resources and Evaluation</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="209" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">IIRG: A naive approach to evaluating phrasal semantics</title>
		<author>
			<persName><forename type="first">Lorna</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Fenlon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Dunnion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation</title>
				<meeting>the 6th International Workshop on Semantic Evaluation<address><addrLine>Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Supportvector networks</title>
		<author>
			<persName><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Héctor</forename><surname>Dávila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><forename type="middle">Fernández</forename><surname>Orquín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Chávez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoan</forename><surname>Gutiérrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armando</forename><surname>Collazo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>José</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">UMCC DLSI-(EPS): Paraphrases detection based on semantic distance</title>
		<author>
			<persName><forename type="first">Andrés</forename><surname>Abreu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Montoyo</surname></persName>
		</author>
		<author>
			<persName><surname>Muñoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation</title>
				<meeting>the 6th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A regression model of adjective-noun compositionality in distributional semantics</title>
		<author>
			<persName><forename type="first">Emiliano</forename><surname>Guevara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 Workshop on GEometrical Models of Natural Language Semantics</title>
				<meeting>the 2010 Workshop on GEometrical Models of Natural Language Semantics<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="33" to="37" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">UNAL: Discriminating between literal and figurative phrasal usage using distributional statistics and POS tags</title>
		<author>
			<persName><forename type="first">Sergio</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Becerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation</title>
				<meeting>the 6th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vector-based models of semantic composition</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
				<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="236" to="244" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Composition in distributional models of semantics</title>
		<author>
			<persName><forename type="first">Jeff</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1388" to="1429" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Evaluation challenges in large-scale document summarization</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simone</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horacio</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wai</forename><surname>Saggion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hong</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arda</forename><forename type="middle">Ç</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danyu</forename><surname>Elebi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elliott</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Drabek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
				<meeting>the 41st Annual Meeting on Association for Computational Linguistics<address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="375" to="382" />
		</imprint>
	</monogr>
	<note>ACL &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Probabilistic Part-of-Speech tagging using decision trees</title>
		<author>
			<persName><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on New Methods in Language Processing</title>
				<meeting>the International Conference on New Methods in Language Processing<address><addrLine>Manchester, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CLaC: Semantic relatedness of words and phrases</title>
		<author>
			<persName><forename type="first">Reda</forename><surname>Siblini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leila</forename><surname>Kosseim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation</title>
				<meeting>the 6th International Workshop on Semantic Evaluation<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Developing a robust Partof-Speech tagger for biomedical text</title>
		<author>
			<persName><forename type="first">Yoshimasa</forename><surname>Tsuruoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuka</forename><surname>Tateishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mcnaught</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun'ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Informatics</title>
				<editor>
			<persName><forename type="first">Panayiotis</forename><surname>Bozanis</surname></persName>
			<persName><forename type="first">Elias</forename><forename type="middle">N</forename><surname>Houstis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">3746</biblScope>
			<biblScope unit="page" from="382" to="392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Latent vector weighting for word meaning in context</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Van De Cruys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Poibeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11</title>
				<meeting>the Conference on Empirical Methods in Natural Language Processing, EMNLP &apos;11<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1012" to="1022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MELODI: Semantic similarity of words and compositional phrases using latent vector weighting</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Van De Cruys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stergos</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philippe</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation</title>
				<meeting>the 6th International Workshop on Semantic Evaluation<address><addrLine>Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">HsH: Estimating semantic similarity of words and short phrases with frequency normalized distance measures</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Wartena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Workshop on Semantic Evaluation (Se-mEval 2012)</title>
				<meeting>the 6th International Workshop on Semantic Evaluation (Se-mEval 2012)<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Morph-it!: A free corpus-based morphological resource for the italian language</title>
		<author>
			<persName><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Corpus Linguistics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Estimating linear models for compositional distributional semantics</title>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Massimo Zanzotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ioannis</forename><surname>Korkontzelos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francesca</forename><surname>Fallucchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics (COLING)</title>
				<meeting>the 23rd International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Extracting lexical semantic knowledge from Wikipedia and Wiktionary</title>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christof</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Language Resources and Evaluation (LREC)</title>
				<meeting>the Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
