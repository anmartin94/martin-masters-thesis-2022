<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Findings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Manuel</forename><surname>Mager</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Arturo</forename><surname>Oncevay</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Abteen</forename><surname>Ebrahimi</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Ortega</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Annette</forename><surname>Rios</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ximena</forename><surname>Gutierrez-Vasques</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Luis</forename><surname>Chiruzzo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Gustavo</forename><forename type="middle">A</forename><surname>Giménez-Lugo</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ricardo</forename><surname>Ramos</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Universidad Tecnológica de Tlaxcala Universidad Nacional Autónoma de México ♣ Universidade Tecnológica Federal do Paraná ♦ University of Colorado Boulder ♥ University of Edinburgh</orgName>
								<orgName type="institution" key="instit2">University of Stuttgart ψ University of Zurich</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ivan</forename><surname>Vladimir</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Meza</forename><surname>Ruiz</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rolando</forename><surname>Coto-Solano</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Alexis</forename><surname>Palmer</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Elisabeth</forename><surname>Mager</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Graham</forename><surname>Neubig</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Ngoc</forename><surname>Thang Vu</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Katharina</forename><surname>Kann</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University Dartmouth College ∇ Facebook AI Research Ω New York University Universidad de la República</orgName>
								<address>
									<country key="UY">Uruguay</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Findings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the results of the 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas. The shared task featured two independent tracks, and participants submitted machine translation systems for up to 10 indigenous languages. Overall, 8 teams participated with a total of 214 submissions. We provided training sets consisting of data collected from various sources, as well as manually translated sentences for the development and test sets. An official baseline trained on this data was also provided. Team submissions featured a variety of architectures, including both statistical and neural models, and for the majority of languages, many teams were able to considerably improve over the baseline. The best performing systems achieved 12.97 ChrF higher than baseline, when averaged across languages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Many of the world's languages, including languages native to the Americas, receive worryingly little attention from NLP researchers. According to Glottolog <ref type="bibr" target="#b43">(Nordhoff and Hammarström, 2012)</ref>, 86 language families and 95 language isolates can be found in the Americas, and many of them are labeled as endangered. From an NLP perspective, the development of language technologies has the potential to help language communities and activists in the documentation, promotion and revitalization of their languages <ref type="bibr" target="#b36">(Mager et al., 2018b;</ref><ref type="bibr" target="#b19">Galla, 2016)</ref>. There have been recent initiatives to promote research on languages of the Americas <ref type="bibr" target="#b15">(Fernández et al., 2013;</ref><ref type="bibr" target="#b8">Coler and Homola, 2014;</ref><ref type="bibr" target="#b21">Gutierrez-Vasques, 2015;</ref><ref type="bibr" target="#b37">Mager and Meza, 2018;</ref><ref type="bibr" target="#b44">Ortega et al., 2020;</ref><ref type="bibr" target="#b58">Zhang et al., 2020;</ref><ref type="bibr">Schwartz et al., 2020;</ref><ref type="bibr">Barrault et al., 2020)</ref>. * *The first three authors contributed equally.</p><p>The AmericasNLP 2021 Shared Task on Open Machine Translation (OMT) aimed at moving research on indigenous and endangered languages more into the focus of the NLP community. As the official shared task training sets, we provided a collection of publicly available parallel corpora ( §3). Additionally, all participants were allowed to use other existing datasets or create their own resources for training in order to improve their systems. Each language pair used in the shared task consisted of an indigenous language and a high-resource language (Spanish). The languages belong to a diverse set of language families: Aymaran, Arawak, Chibchan, Tupi-Guarani, Uto-Aztecan, Oto-Manguean, Quechuan, and Panoan. The ten language pairs included in the shared task are: Quechua-Spanish, Wixarika-Spanish, Shipibo-Konibo-Spanish, Asháninka-Spanish, Raramuri-Spanish, Nahuatl-Spanish, Otomí-Spanish, Aymara-Spanish, Guarani-Spanish, and Bribri-Spanish. For development and testing, we used parallel sentences belonging to a new natural language inference dataset for the 10 indigenous languages featured in our shared task, which is a manual translation of the Spanish version of the multilingual XNLI dataset <ref type="bibr" target="#b9">(Conneau et al., 2018)</ref>. For a complete description of this dataset we refer the reader to <ref type="bibr">Ebrahimi et al. (2021)</ref>.</p><p>Together with the data, we also provided: a simple baseline based on the small transformer architecture <ref type="bibr" target="#b56">(Vaswani et al., 2017)</ref> proposed together with the FLORES dataset <ref type="bibr" target="#b23">(Guzmán et al., 2019)</ref>; and a description of challenges and particular characteristics for all provided resources 1 . We established two tracks: one where training models on the development set after hyperparameter tuning is allowed (Track 1), and one where models cannot be trained directly on the development set (Track 2).</p><p>Machine translation for indigenous languages often presents unique challenges. As many indigenous languages do not have a strong written tradition, orthographic rules are not well defined or standardized, and even if they are regulated, often times native speakers do not follow them or create their own adapted versions. Simply normalizing the data is generally not a viable option, as even the definition of what constitutes a morpheme or a orthographic word is frequently ill defined. Furthermore, the huge dialectal variability among those languages, even from one village to the other, adds additional complexity to the task. We describe the particular challenges for each language in Section §3.</p><p>Eight teams participated in the AmericasNLP 2021 Shared Task on OMT. Most teams submitted systems in both tracks and for all 10 language pairs, yielding a total of 214 submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Open Machine Translation</head><p>Given the limited availability of resources and the important dialectal, orthographic and domain challenges, we designed our task as an unrestrained machine translation shared task: we called it open machine translation to emphasize that participants were free to use any resources they could find. Possible resources could, for instance, include existing or newly created parallel data, dictionaries, tools, or pretrained models.</p><p>We invited submissions to two different tracks: Systems in Track 1 were allowed to use the development set as part of the training data, since this is a common practice in the machine translation community. Systems in Track 2 were not allowed to be trained directly on the development set, mimicking a more realistic low-resource setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Primary Evaluation</head><p>In order to be able to evaluate a large number of systems on all 10 languages, we used automatic metrics for our primary evaluation. Our main metric, which determined the official ranking of systems, was ChrF <ref type="bibr" target="#b49">(Popović, 2015)</ref>. We made this choice due to certain properties of our languages, such as word boundaries not being standardized for all languages and many languages being polysynthetic, resulting in a small number of words per sentence. We further reported BLEU scores <ref type="bibr" target="#b46">(Papineni et al., 2002)</ref> for all systems and languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Supplementary Evaluation</head><p>To gain additional insight into the strengths and weaknesses of the top-performing submissions, we further performed a supplementary manual evaluation for two language pairs and a limited number of systems, using a subset of the test set.</p><p>We asked our annotators to provide ratings of system outputs using separate 5-point scales for adequacy and fluency. The annotation was performed by the translator who created the test datasets. The expert received the source sentence in Spanish, the reference in the indigenous language, and an anonymized system output. In addition to the baseline, we considered the 3 highest ranked systems according to our main metric, and randomly selected 100 sentences for each language. The following were the descriptions of the ratings as provided to the expert annotator in Spanish (translated into English here for convenience):</p><p>Adequacy The output sentence expresses the meaning of the reference.</p><p>1. Extremely bad: The original meaning is not contained at all. 2. Bad: Some words or phrases allow to guess the content. 3. Neutral. 4. Sufficiently good: The original meaning is understandable, but some parts are unclear or incorrect. 5. Excellent: The meaning of the output is the same as that of the reference.</p><p>Fluency The output sentence is easily readable and looks like a human-produced text.</p><p>1. Extremely bad: The output text does not belong to the target language. 2. Bad: The output sentence is hardly readable. 3. Neutral. 4. Sufficiently good: The output seems like a human-produced text in the target language, but contains weird mistakes. 5. Excellent: The output seems like a humanproduced text in the target language, and is readable without issues.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Languages and Datasets</head><p>In this section, we will present the languages and datasets featured in our shared task. Figure <ref type="figure" target="#fig_0">1</ref> additionally provides an overview of the languages, their linguistic families, and the number of parallel sentences with Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Development and Test Sets</head><p>For system development and testing, we leveraged individual pairs of parallel sentences from Amer-icasNLI <ref type="bibr">(Ebrahimi et al., 2021)</ref>. This dataset is a translation of the Spanish version of XNLI <ref type="bibr" target="#b9">(Conneau et al., 2018)</ref> into our 10 indigenous languages. It was not publicly available until after the conclusion of the competition, avoiding an accidental inclusion of the test set into the training data by the participants. For more information regarding the creation of the dataset, we refer the reader to <ref type="bibr">(Ebrahimi et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Data</head><p>We collected publicly available datasets in all 10 languages and provided them to the shared task participants as a starting point. We will now introduce the languages and the training datasets, explaining similarities and differences between training sets on the one hand and development and test sets on the other.</p><p>Spanish-Wixarika Wixarika (also known as Huichol) with ISO code hch is spoken in Mexico and belongs to the Yuto-Aztecan linguistic family.</p><p>The training, development and test sets all belong to the same dialectal variation, Wixarika of Zoquipan, and use the same orthography. However, word boundaries are not always marked according to the same criteria in development/test and train.</p><p>The training data <ref type="bibr" target="#b35">(Mager et al., 2018a</ref>) is a translation of the fairy tales of Hans Christian Andersen and contains word acquisitions and code-switching.</p><p>Spanish-Nahuatl Nahuatl is a Yuto-Aztecan language spoken in Mexico and El Salvador, with a wide dialectal variation (around 30 variants). For each main dialect a specific ISO 639-3 code is available. <ref type="bibr">2</ref> There is a lack of consensus regarding the orthographic standard. This is very noticeable in the training data: the train corpus <ref type="bibr" target="#b22">(Gutierrez-Vasques et al., 2016)</ref> has dialectal, domain, orthographic and diachronic variation (Nahuatl side). However, the majority of entries are closer to a Classical Nahuatl orthographic "standard". The development and test datasets were translated to modern Nahuatl. In particular, the translations belong to Nahuatl Central/Nahuatl de la Huasteca (Hidalgo y San Luis Potosí) dialects. In order to be closer to the training corpus, an orthographic normalization was applied. A simple rule based approach was used, which was based on the most predictable orthographic changes between modern varieties and Classical Nahuatl.</p><p>Spanish-Guarani Guarani is mostly spoken in Paraguay, Bolivia, Argentina and Brazil. It belongs to the Tupian language family (ISO gnw, gun, gug, gui, grn, nhd). The training corpus for Guarani <ref type="bibr" target="#b6">(Chiruzzo et al., 2020)</ref> was collected from web sources (blogs and news articles) that contained a mix of dialects, from pure Guarani to more mixed Jopara which combines Guarani with Spanish neologisms. The development and test corpora, on the other hand, are in standard Paraguayan Guarani. Spanish-Bribri Bribri is a Chibchan language spoken in southern Costa Rica (ISO code bzd).</p><p>The training set for Bribri was extracted from six sources <ref type="bibr" target="#b14">(Feldman and Coto-Solano, 2020;</ref><ref type="bibr" target="#b38">Margery, 2005;</ref><ref type="bibr" target="#b27">Jara Murillo, 2018a;</ref><ref type="bibr" target="#b10">Constenla et al., 2004;</ref><ref type="bibr" target="#b29">Jara Murillo and García Segura, 2013;</ref><ref type="bibr" target="#b28">Jara Murillo, 2018b;</ref><ref type="bibr" target="#b17">Flores Solórzano, 2017)</ref>, including a dictionary, a grammar, two language learning textbooks, one storybook and the transcribed sentences from one spoken corpus. The sentences belong to three major dialects: Amubri, Coroma and Salitre.</p><p>There are numerous sources of variation in the Bribri data <ref type="bibr" target="#b14">(Feldman and Coto-Solano, 2020</ref>): 1) There are several different orthographies, which use different diacritics for the same words. 2) The Unicode encoding of visually similar diacritics differs among authors. 3) There is phonetic and lexical variation across dialects. 4) There is considerable idiosyncratic variation between writers, including variation in word boundaries (e.g. ikíe vrs i kie "it is called"). In order to build a standardized training set, an intermediate orthography was used to make these different forms comparable and learning easier. All of the training sentences are comparable in domain; they come from either traditional stories or language learning examples. Because of the nature of the texts, there is very little code-switching into Spanish. This is different from regular Bribri conversation, which would contain more borrowings from Spanish and more codeswitching. The development and test sentences were translated by a speaker of the Amubri dialect and transformed into the intermediate orthography.</p><p>Spanish-Rarámuri Rarámuri is a Uto-Aztecan language, spoken in northern Mexico (ISO: tac, twr, tar, tcu, thh). Training data for Rarámuri consists of a set of extracted phrases from the Rarámuri dictionary <ref type="bibr" target="#b5">Brambila (1976)</ref>. However, we could not find any description of the dialectal variation to which these examples belong. The development and test set are translations from Spanish into the highlands Rarámuri variant (tar), and may differ from the training set. As with many polysynthetic languages, challenges can arise when the boundaries of a morpheme and a word are not clear and have no consensus. Native speakers, even with a standard orthography and from the same dialectal variation, may define words in a different standards to define word boundaries.</p><p>Spanish-Quechua Quechua is a family of languages spoken in Argentina, Bolivia, Colombia, Ecuador, Peru, and Chile with many ISO codes for its language (quh, cqu, qvn, qvc, qur, quy, quk, qvo, qve, and quf). The development and test sets are translated into the standard version of Southern Quechua, specifically the Quechua Chanka (Ayacucho, code: quy) variety. This variety is spoken in different regions of Peru, and it can be understood in different areas of other countries, such as Bolivia or Argentina. This is the variant used on Wikipedia Quechua pages, and by Microsoft in its translations of software into Quechua. Southern Quechua includes different Quechua variants, such as Quechua Cuzco (quz) and Quechua Ayacucho (quy). Training datasets are provided for both variants. These datasets were created from JW300 <ref type="bibr" target="#b0">(Agić and Vulić, 2019)</ref>, which consists of Jehovah's Witness texts, sentences extracted from the official dictionary of the Minister of Education (MINEDU), and miscellaneous dictionary entries and samples which have been collected and reviewed by Huarcaya Taquiri (2020).</p><p>Spanish-Aymara Aymara is a Aymaran language spoken in Bolivia, Peru, and Chile (ISO codes aym, ayr, ayc). The development and test sets are translated into the Central Aymara variant (ayr), specifically Aymara La Paz jilata, the largest variant. This is similar to the variant of the available training set, which is obtained from Global Voices <ref type="bibr" target="#b50">(Prokopidis et al., 2016)</ref> (and published in OPUS <ref type="bibr" target="#b55">(Tiedemann, 2012)</ref>), a news portal translated by volunteers. However, the text may have potentially different writing styles that are not necessarily edited.</p><p>Spanish--Shipibo-Konibo Shipibo-Konibo is a Panoan language spoken in Perú (ISO shp and kaq). The training sets for Shipibo-Konibo have been obtained from different sources and translators: Sources include translations of a sample from the Tatoeba dataset (Gómez <ref type="bibr" target="#b20">Montoya et al., 2019)</ref>, translated sentences from books for bilingual education <ref type="bibr" target="#b18">(Galarreta et al., 2017)</ref>, and dictionary entries and examples <ref type="bibr">(Loriot et al., 1993)</ref>. Translated text was created by a bilingual teacher, and follows the most recent guidelines of the Minister of Education in Peru, however, the third source is an extraction of parallel sentences from an old dictionary. The development and test sets were created following the official convention as in the translated training sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spanish-Asháninka</head><p>Asháninka is an Arawakan language (ISO: cni) spoken in Peru and Brazil. Training data was created by collecting texts from different domains such as traditional stories, educational texts, and environmental laws for the Amazonian region <ref type="bibr" target="#b44">(Ortega et al., 2020;</ref><ref type="bibr" target="#b52">Romano, Rubén and Richer, Sebastián, 2008;</ref><ref type="bibr" target="#b41">Mihas, 2011)</ref>. The texts belong to domains such as: traditional stories, educational texts, environmental laws for the Amazonian region. Not all the texts are translated into Spanish, there is a small fraction of these that are translated into Portuguese because a dialect of pan-Ashaninka is also spoken in the state of Acre in Brazil. The texts come from different pan-Ashaninka dialects and have been normalized using the AshMorph <ref type="bibr" target="#b44">(Ortega et al., 2020)</ref>. There are many neologisms that are not spread to the speakers of different communities. The translator of the development and test sets only translated the words and concepts that are well known in the communities, whereas other terms are preserved in Spanish. Moreover, the development and test sets were created following the official writing convention proposed by the Peruvian Government and taught in bilingual schools.</p><p>Spanish--Otomí Otomí (also known as Hñähñu, Hñähño, Ñhato, Ñûhmû, depending on the region) is an Oto-Manguean language spoken in Mexico (ISO codes: ott, otn, otx, ote, otq, otz, otl, ots, otm). The training set 3 was collected from a set of different sources, which implies that the text contains more than one dialectal variation and orthographic standard, however, most texts belong to the Valle del Mezquital dialect (ote). This was specially challenging for the translation task, since the development and test sets are from the Ñûhmû de Ixtenco, Tlaxcala, variant (otz), which also has its own orthographic system. This variant is especially endangered as less than 100 elders still speak it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">External Data Used by Participants</head><p>In addition to the provided datasets, participants also used additional publicly available parallel data, monolingual corpora or newly collected data sets. The most common datasets were JW300 <ref type="bibr" target="#b0">(Agić and Vulić, 2019)</ref> and the Bible's New Testament <ref type="bibr" target="#b39">(Mayer and Cysouw, 2014;</ref><ref type="bibr" target="#b7">Christodouloupoulos and Steedman, 2015;</ref><ref type="bibr" target="#b40">McCarthy et al., 2020)</ref>. Besides those, GlobalVoices <ref type="bibr" target="#b50">(Prokopidis et al., 2016)</ref> and datasets available at OPUS <ref type="bibr" target="#b55">(Tiedemann, 2012)</ref> were added. New datasets were extracted from constitutions, dictionaries, and educational books. For monolingual text, Wikipedia was most commonly used, assuming one was available in a language.</p><p>3 Otomí online corpus: https://tsunkua.elotl.mx/about/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baseline and Submitted Systems</head><p>We will now describe our baseline as well as all submitted systems. An overview of all teams and the main ideas going into their submissions is shown in Table <ref type="table" target="#tab_3">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline</head><p>Our baseline system was a transformer-based sequence to sequence model <ref type="bibr" target="#b56">(Vaswani et al., 2017)</ref>. We employed the hyperparameters proposed by <ref type="bibr" target="#b23">Guzmán et al. (2019)</ref> for a low-resource scenario. We implemented the model using Fairseq . The implementation of the baseline can be found in the official shared task repository. 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">University of British Columbia</head><p>The team of the University of British Columbia (UBC-NLP; Billah-Nagoudi et al., 2021) participated for all ten language pairs and in both tracks. They used an encoder-decoder transformer model based on T5 <ref type="bibr" target="#b51">(Raffel et al., 2020)</ref>. This model was pretrained on a dataset consisting of 10 indigenous languages and Spanish, that was collected by the team from different sources such as the Bible and Wikipedia, totaling 1.17 GB of text. However, given that some of the languages have more available data than others, this dataset is unbalanced in favor of languages like Nahuatl, Guarani, and Quechua. The team also proposed a two-stage fine-tuning method: first fine-tuning on the entire dataset, and then only on the target languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Helsinki</head><p>The University of Helsinki (Helsinki; <ref type="bibr" target="#b57">Vázquez et al., 2021)</ref> participated for all ten language pairs in both tracks. This team did an extensive exploration of the existing datasets, and collected additional resources both from commonly used sources such as the Bible and Wikipedia, as well as other minor sources such as constitutions. Monolingual data was used to generate paired sentences through back-translation, and these parallel examples were added to the existing dataset. Then, a normalization process was done using existing tools, and the aligned data was further filtered. The quality of the data was also considered, and each dataset was assigned a weight depending on a noisiness estimation. The team used a transformer sequenceto-sequence model trained via two steps. For their main submission they first trained on data which  was 90% Spanish-English and 10% indigenous languages, and then changed the data proportion to 50% Spanish-English and 50% indigenous languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">CoAStaL</head><p>The team of the University of Copenhagen (CoAStaL) submitted systems for both tracks <ref type="bibr">(Bollmann et al., 2021)</ref>. They focused on additional data collection and tried to improve the results with low-resource techniques. The team discovered that it was even hard to generate correct words in the output and that phrase-based statistical machine translation (PB-SMT) systems work well when compared to the state-of-the-art neural models. Interestingly, the team introduced a baseline that mimicked the target language using a character-trigram distribution and length constraints without any knowledge of the source sentence. This random text generation achieved even better results than some of the other submitted systems. The team also reported failed experiments, where character-based neural machine translation (NMT), pretrained transformers, language model priors, and graph convolution encoders using UD annotations could not get any meaningful results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">REPUcs</head><p>The system of the Pontificia Universidad Católica del Perú (REPUcs; <ref type="bibr" target="#b42">Moreno, 2021)</ref> submitted to the the Spanish-Quechua language pair in both tracks. The team collected external data from 3 different sources and analyzed the domain disparity between this training data and the development set.</p><p>To solve the problem of domain mismatch, they decided to collect additional data that could be a better match for the target domain. The used data from a handbook (Iter and Ortiz-Cárdenas, 2019), a lexicon, 5 and poems on the web <ref type="bibr" target="#b12">(Duran, 2010)</ref>. <ref type="bibr">6</ref> Their model is a transformer encoder-decoder architecture with SentencePiece <ref type="bibr" target="#b32">(Kudo and Richardson, 2018)</ref> tokenization. Together with the existing parallel corpora, the new paired data was used for finetuning on top of a pretrained Spanish-English translation model. The team submitted two versions of their system: the first was only finetuned on JW300+ data, while the second one additionally leveraged the newly collected dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">UTokyo</head><p>The team of the University of Tokyo (UTokyo; <ref type="bibr" target="#b59">Zheng et al., 2021)</ref> submitted systems for all languages and both tracks. A multilingual pretrained encoder-decoder model (mBART;  was used, implemented with the Fairseq toolkit    <ref type="bibr" target="#b11">(Dror et al., 2018)</ref>.</p><p>ious high-resource languages, and then finetuned for each target language using the official provided data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">NRC-CNRC</head><p>The team of the National Research Council Canada (NRC-CNRC; <ref type="bibr" target="#b30">Knowles et al., 2021)</ref> submitted systems for the Spanish to Wixárika, Nahuatl, Rarámuri and Guarani language pairs for both tracks. Due to ethical considerations, the team decided not to use external data, and restricted themselves to the data provided for the shared task. All data was preprocessed with standard Moses tools <ref type="bibr" target="#b31">(Koehn et al., 2007)</ref>. The submitted systems were based on a Transformer model, and used BPE for tokenization.</p><p>The team experimented with multilingual models pretrained on either 3 or 4 languages, finding that the 4 language model achieved higher performance.</p><p>Additionally the team trained a Translation Memory <ref type="bibr" target="#b54">(Simard and Fujita, 2012)</ref> using half of the examples of the development set. Surprisingly, even given its small amount of training data, this system outperformed the team's Track 2 submission for Rarámuri.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Tamalli</head><p>The team Tamalli 7 <ref type="bibr" target="#b47">(Parida et al., 2021)</ref> participated in Track 1 for all 10 language pairs. The team used an IBM Model 2 for SMT, and a transformer model for NMT. The team's NMT models were trained in two settings: one-to-one, with one model being trained per target language, and one-to-many, where decoder weights were shared across languages and a language embedding layer was added to the decoder. They submitted 5 systems per language, which differed in their hyperparameter choices and training setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Track 1</head><p>The complete results for all systems submitted to Track 1 are shown in Table <ref type="table" target="#tab_5">3</ref>. Submission 2 of the Helsinki team achieved first place for all language pairs. Interestingly, for all language pairs, the Helsinki team also achieved the second best result with their Submission 1. Submission 3 was less successful, achieving third place on three pairs. The NRC-CNRC team achieved third place for Wixárika, Nahuatl, and Rarámuri, and fourth for Guarani.The lower automatic scores of their systems can also be partly due to the team not using additional datasets. The REPUcs system obtained the third best result for Quechua, the only language they participated in. CoAStaL's first system, a PB-SMT model, achieved third place for Bribri, Otomí, and Shipibo-Konibo, and fourth place for Ashaninka. This suggests that SMT is still competitive for low-resource languages. UTokyo and UBC-NLP were less successful than the other approaches. Finally, we attribute the bad performance of the anonymous submission to a possible bug. Since our baseline system was not trained on the development set, no specific baseline was available for this track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Track 2</head><p>All results for Track 2, including those of our baseline system, are shown in Table <ref type="table" target="#tab_9">5</ref>.</p><p>Most submissions outperformed the baseline by a large margin. As for Track 1, the best system was from the Helsinki team (submission 5), winning 9 out of 10 language pairs. REPUcs achieved the best score for Spanish-Quechua, the only language pair they submitted results for. Their pretraining on Spanish-English and the newly collected dataset proved to be successful.</p><p>Second places were more diverse for Track 2 than for Track 1. The NRC-CNRC team achieved second place for two languages (Wixarika and Guarani), UTokyo achieved second place for three languages (Aymara, Nahuatl and Otomí), and the Helsinki team came in second for Quechua. Tamalli only participated in Track 2, with 4 systems per language. Their most successful one was submission 1, a word-based SMT system. An interesting submission for this track was the CoAStaL submission 2, which created a random generated output that mimics the target language distribution. This system consistently outperformed the official baseline and even outperformed other approaches for most languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Supplementary Evaluation Results</head><p>As explained in §2, we also conducted a small human evaluation of system outputs based on adequacy and fluency on a 5-points scale, which was performed by a professional translator for two language-pairs: Spanish to Shipibo-Konibo and  Otomí. <ref type="bibr">8</ref> This evaluation was performed given the extremely low automatic evaluation scores, and the natural question about the usefulness of the outputs of MT systems at the current state-of-the-art.</p><p>While we selected two languages as a sample to get a better approximation to this question, further studies are needed to draw stronger conclusions.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows the adequacy and fluency scores annotated for Spanish-Shipibo-Konibo and Spanish-Otomí language-pairs. considering the baseline and the three highest ranked systems according to ChrF. For both languages, we observe that the adequacy scores are similar between all systems except for Helsinki, the best ranked submission given the automatic evaluation metric, which has more variance than the others. However, the average score is low, around 2, which means that only few words or phrases express the meaning of the reference.</p><p>Looking at fluency, there is less similarity between the Shipibo-Konibo and Otomí annotations. For Shipibo-Konibo, there is no clear difference between the systems in terms of their average scores. We note that Tamalli's system obtained the larger group with the relatively highest score. For Otomí, the three submitted systems are at least slightly better than the baseline on average, but only in 1 level of the scale. The scores for fluency are similar to adequacy in this case. Besides, according to the annotations, the output translations in Shipibo-Konibo were closer to human-produced texts than in Otomí.</p><p>We also show the relationship between ChrF and the adequacy and fluency scores in Figure <ref type="figure" target="#fig_1">2</ref>. However, there does not seem to be a correlation between the automatic metric and the manually assigned scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Analysis: NLI</head><p>One approach for zero-shot transfer learning of a sequence classification task is the translate-train approach, where a translation system is used to translate high-resource labeled training data into the target language. In the case of pretrained multilingual models, these machine translated examples are then used for finetuning. For our analysis, we used various shared task submissions to create different sets of translated training data. We then trained a natural language inference (NLI) model using this translated data, and used the downstream NLI performance as an extrinsic evaluation of translation quality.</p><p>Our experimental setup was identical to <ref type="bibr">Ebrahimi et al. (2021)</ref>. We focused only on submissions from Track 2, and analyzed the Helsinki-5 and the NRC-CNRC-1 system. We present results in Table <ref type="table" target="#tab_7">4</ref>. Performance from using the Helsinki system far outperforms the baseline on average, and using the NRC-CNRC system also improves over the baseline. For the four languages covered by all systems, we can see that the ranking of NLI performance matches that of the automatic ChrF evaluation. Between the Helsinki and Baseline systems, this ranking also holds for every other language except for Bribri, where the Baseline achieves around 3 percentage points higher accuracy. Overall, this evaluation both confirms the ranking created by the ChrF scores and provides strong evidence supporting the use of translationbased approaches for zero-shot tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Error Analysis</head><p>To extend the analysis in the previous sections, Tables 6 and 7 show output samples using the best ranked system (Helsinki-5) for Shipibo-Konibo and Otomí, respectively. In each table, we present the top-3 outputs ranked by ChrF and the top-3 ranked by Adequacy and Fluency.</p><p>For <ref type="bibr">Shipibo-Konibo, in</ref>    equacy annotation of the first sample is relatively low. We can also observe that many subwords are presented in both the reference and the system's output, but not entire words, which shows why BLEU may not be a useful metric to evaluate performance. However, the subwords are still located in different order, and concatenated with different morphemes, which impacts the fluency. Concerning the most adequate and fluent samples, we still observe a high presence of correct subwords in the output, and we can infer that the different order or concatenation of different morphemes did not affect the original meaning of the sentence.</p><p>For Otomí, in Table <ref type="table" target="#tab_12">7</ref>, the scenario was less positive, as the ChrF scores are lower than for Shipibo-Konibo, on average. This was echoed in the top-3 outputs, which are very short and contain words or phrases that are preserved in Spanish for the reference translation. Concerning the most adequate and fluent outputs, we observed a very low overlapping of subwords (less than in Shipibo-Konibo), which could only indicate that the outputs preserve part of the meaning of the source but they are expressed differently than the reference. Moreover, we noticed some inconsistencies in the punctuation, which impacts in the ChrF overall score.</p><p>In summary, there are some elements to explore further in the rest of the outputs: How many loanwords or how much code-switched text from Spanish is presented in the reference translation? Is there consistency in the punctuation, e.g., period at the end of a segment, between all the source and reference sentences?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper presents the results of the AmericasNLP 2021 Shared Task on OMT. We received 214 submissions of machine translation systems by 8 teams. All systems suffered from the minimal amount of data and the challenging orthographic, dialectal and domain mismatches of the training and test set. However, most teams achieved huge improvements over the official baseline. We found that text cleaning and normalization, as well as domain adaptation played large roles in the best performing systems. The best NMT systems were multilingual approaches with a limited size (over massive multilingual). Additionally, SMT models also performed well, outperforming larger pretrained submissions.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Adequacy and fluency distribution scores for Shipibo-Konibo and Otomí.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Relationship between ChrF scores and annotations for adequacy (left) and fluency (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The languages featured in the AmericasNLP 2021 Shared Task on OMT, their ISO codes, language families and dataset statistics. For the origins of the datasets, please refer to the text.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Participating team (Team) with system description paper, number of languages that system outputs were submitted for (Langs.), total number of submissions (Sub.), external data (Data), models (Models), if training was multilingual (Multilingual), and if pretraining was done (Pretrained). More details can be found in the text.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Results of Track 1 (development set used for training) for all systems and language pairs. The results are ranked by the official metric of the shared task: ChrF. One team decided to send a anonymous submission</figDesc><table /><note>(Anonym). Best results are shown in bold, and they are significantly better than the second place team (in each language-pair) according to the Wilcoxon signed-ranked test and Pitman's permutation test with p&lt;0.05</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Baseline 49.33 52.00 42.80 55.87 41.07 54.07 36.50 59.87 52.00 43.73 48.72 Helsinki-5 57.60 48.93 55.33 62.40 55.33 62.33 49.33 60.80 65.07 58.80</figDesc><table><row><cell>System</cell><cell>aym</cell><cell>bzd</cell><cell>cni</cell><cell>gn</cell><cell>hch</cell><cell>nah</cell><cell>oto</cell><cell>quy</cell><cell>shp</cell><cell>tar</cell><cell>Avg.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>57.59</cell></row><row><cell>NRC-CNRC-1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">57.20 50.40 58.94</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">53.47 55.00  *</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Results of the NLI analysis. * indicates that the average score is not directly comparable as the number of languages differs for the given system.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>, we observe that</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table /><note>Results of Track 2 (development set not used for training) for all systems and language pairs. The results are ranked by the official metric of the shared task: ChrF. Best results per language pair are shown in bold, and they are significantly better than the second place team (in each language-pair) according to the Wilcoxon signed-ranked test and Pitman's permutation test with p&lt;0.05<ref type="bibr" target="#b11">(Dror et al., 2018)</ref>.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Westiora serera ea kenai nokon shinanbo biti. C: 57.1 SRC: Hoy no he ido, así que no lo he visto.</figDesc><table><row><cell cols="2">Scores Sentences</cell></row><row><cell cols="2">C: 66.7 SRC: Un niño murió de los cinco.</cell></row><row><cell>A: 1</cell><cell>REF: Westiora bakera mawata iki pichika batiayax.</cell></row><row><cell>F: 4</cell><cell>OUT: Westiora bakera pichika mawata iki.</cell></row><row><cell cols="2">C: 60.9 SRC: Sé que no puedes oírme.</cell></row><row><cell>A: 4</cell><cell>REF: Eanra onanke min ea ninkati atipanyama.</cell></row><row><cell>F: 3</cell><cell>OUT: Minra ea ninkati atipanyamake.</cell></row><row><cell cols="2">C: 60.1 SRC: Necesito un minuto para recoger mis pensamientos.</cell></row><row><cell>A: 4</cell><cell>REF: Eara westiora minuto kenai nokon shinanbo biti kopi.</cell></row><row><cell cols="2">F: 3 OUT: A: 5 REF: Ramara ea kama iki, jakopira en oinama iki.</cell></row><row><cell>F: 5</cell><cell>OUT: Ramara ea kayamake, jaskarakopira en oinyamake</cell></row><row><cell cols="2">C: 53.6 SRC: El U2 tomó mucha película.</cell></row><row><cell>A: 5</cell><cell>REF: Nato U2ninra kikin icha película bike.</cell></row><row><cell>F: 5</cell><cell>OUT: U2ninra icha pelicula bike.</cell></row><row><cell cols="2">C: 48.3 SRC: No teníamos televisión.</cell></row><row><cell>A: 5</cell><cell>REF: Noara televisiónma ika iki.</cell></row><row><cell>F: 5</cell><cell>OUT: Televisiónmara noa iwanke.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6 :</head><label>6</label><figDesc>Translation outputs of the best system (Helsinki) for Shipibo-Konibo. Top-3 samples have the highest ChrF (C) scores, whereas the bottom-3 have the best adequacy (A) and fluency (F) values. Inbi bädi te ra nge'a bi nthati, bi ot'e ra guenda...</figDesc><table><row><cell cols="2">Scores Sentences</cell></row><row><cell cols="2">C: 49.6 SRC: Locust Hill oh claro, sí, genial</cell></row><row><cell>A: 1</cell><cell>REF: Locust Hill handa hâ</cell></row><row><cell>F: 4</cell><cell>OUT: Locust Hill ohbuho jä'i</cell></row><row><cell cols="2">C: 42.2 SRC: Kennedy habló con los pilotos.</cell></row><row><cell>A: 4</cell><cell>REF: Kennedy bi ñama nen ya pilotos.</cell></row><row><cell>F: 3</cell><cell>OUT: Kennedy bi ñäui ya pihnyo.</cell></row><row><cell cols="2">C: 32.2 SRC: ¿Te gustan los libros de Harry Potter o no?</cell></row><row><cell>A: 4</cell><cell>REF: ¿ di ho-y ya ynttothoma on Harry Potter a hin?</cell></row><row><cell>F: 3</cell><cell>OUT: ¿ Gi pefihu na rä libro ra Harry Potter o hina?</cell></row><row><cell cols="2">C: 13.1 SRC: Un niño murió de los cinco.</cell></row><row><cell>A: 5</cell><cell>REF: nā mehtzi bidû on ya qda</cell></row><row><cell>F: 5</cell><cell>OUT: N'a ra bätsi bi du ko ya kut'a.</cell></row><row><cell cols="2">C: 13.9 SRC: Él recibe ayuda con sus comidas y ropa.</cell></row><row><cell>A: 4</cell><cell>REF: na di hiâni mâhte nen ynu ynñuni xi áhxo</cell></row><row><cell>F: 4</cell><cell>OUT: Nu'a hä häni ko ya hñuni ne ya dutu.</cell></row><row><cell cols="2">C: 13.3 SRC: Ni siquiera entendió la ceremonia nupcial, ni siquiera</cell></row><row><cell></cell><cell>sabía que se había casado, en serio-</cell></row><row><cell>A: 4</cell><cell>REF: Hin bi ôccode na nînthadi, hin mipâca guê bin miqha</cell></row><row><cell></cell><cell>nthâdi,maqhuani ngu -a.</cell></row><row><cell>F: 4</cell><cell>OUT:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Translation outputs of the best system (Helsinki) for Otomí. Top-3 samples have the highest ChrF (C) scores, whereas the bottom-3 have the best adequacy (A) and fluency (F) values.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/AmericasNLP/americasnlp2021/ blob/main/data/information_datasets.pdf</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2"> nhn,  nch, ncx, naz, nln, nhe, ngu, azz, nhq,  nhk, nhx, nhp, ncl, nhm, nhy, ncj, nht,  nlv, ppl, nhz, npl, nhc, nhv, nhi, nhg,  nuz, nhw, nsu, xpo, nhn, nch, ncx, naz,  nln, nhe, ngu, azz, nhq, nhk, nhx, nhp,  ncl, nhm, nhy, ncj, nht, nlv, ppl, nhz,  npl, nhc, nhv, nhi, nhg, nuz, nhw, nsu,  and xpo.   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/AmericasNLP/americasnlp2021</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://www.inkatour.com/dico/ 6 https://lyricstranslate.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Participating universities: Idiap Research Institute, City University of New York, BITS-India, Universidad Autónoma Metropolitana-México, Ghent University, and Universidad Politécnica de Tulancingo-México</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">In the WMT campaigns, it is common to perform a crowdsourced evaluation with several annotators. However, we cannot follow that procedure given the low chance to find native speakers of indigenous languages as users in crowdsourcing platforms.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">(a) Shipibo-Konibo: Adequacy</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank translators of the test and development set, that made this shared task possible: Francisco Morales (Bribri), Feliciano Torres Ríos and Esau Zumaeta Rojas (Asháninka), Perla Alvarez Britez (Guarani), Silvino González de la Crúz (Wixarika), Giovany Martínez Sebastián, Pedro Kapoltitan, and José Antonio (Nahuatl), José Mateo Lino Cajero Velázquez (Otomí), Liz Chávez (Shipibo-Konibo), and María del Cármen Sotelo Holguín (Rarámuri). We also thank our sponsors for their financial support: Facebook AI Research, Microsoft Research, Google Research, the Institute of Computational Linguistics at the University of Zurich, the NAACL Emerging Regions Funding, Comunidad Elotl, and Snorkel AI. Additionally we want to thank all participants for their submissions and effort to advance NLP research for the indigenous languages of the Americas. Manuel Mager received financial support by DAAD Doctoral Research Grant for this work.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">JW300: A Wide-Coverage Parallel Corpus for Low-Resource Languages</title>
		<author>
			<persName><forename type="first">Željko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vulić</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1310</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3204" to="3210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><forename type="first">Loïc</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magdalena</forename><surname>Biesialska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvette</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthias</forename><surname>Huck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Joanis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Kocmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikola</forename><surname>Ljubešić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christof</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makoto</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshiaki</forename><surname>Nakazawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (WMT20). In Proceedings of the Fifth Conference on Machine Translation</title>
				<imprint>
			<biblScope unit="page" from="1" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">IndT5: A Text-to-Text Transformer for 10 Indigenous Languages</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AmericasNLP</title>
				<editor>
			<persName><forename type="first">Wei-Rui</forename><surname>El Moatez Billah-Nagoudi</surname></persName>
			<persName><forename type="first">Muhammad</forename><surname>Chen</surname></persName>
			<persName><forename type="first">Hasan</forename><surname>Abdul-Mageed</surname></persName>
			<persName><surname>Cavusoglu</surname></persName>
		</editor>
		<meeting>the AmericasNLP</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Miryam de Lhoneux, and Anders Søgaard. 2021. Moses and the characterbased random babbling baseline: CoAStaL at Amer-icasNLP 2021 shared task</title>
		<author>
			<persName><forename type="first">Marcel</forename><surname>Bollmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rahul</forename><surname>Aralikatte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Héctor</forename><surname>Murrieta-Bello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</title>
				<meeting>the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Diccionario rarámuricastellano (tarahumar)</title>
		<author>
			<persName><forename type="first">David</forename><surname>Brambila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
		</imprint>
	</monogr>
	<note>Obra Nacional de la buena Prensa</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Development of a Guarani -Spanish parallel corpus</title>
		<author>
			<persName><forename type="first">Luis</forename><surname>Chiruzzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Amarilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adolfo</forename><surname>Ríos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><forename type="middle">Giménez</forename><surname>Lugo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
				<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2629" to="2633" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A massively parallel corpus: the bible in 100 languages. Language resources and evaluation</title>
		<author>
			<persName><forename type="first">Christos</forename><surname>Christodouloupoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Steedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="375" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Rule-based machine translation for Aymara</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Coler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petr</forename><surname>Homola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page" from="67" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">XNLI: Evaluating cross-lingual sentence representations</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1269</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2475" to="2485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Adolfo</forename><surname>Constenla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feliciano</forename><surname>Elizondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Pereira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>Curso Básico de Bribri. Editorial de la Universidad de Costa Rica</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The hitchhiker&apos;s guide to testing statistical significance in natural language processing</title>
		<author>
			<persName><forename type="first">Rotem</forename><surname>Dror</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gili</forename><surname>Baumer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Segev</forename><surname>Shlomov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roi</forename><surname>Reichart</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1128</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1383" to="1392" />
		</imprint>
	</monogr>
	<note>Australia</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Lengua general de los incas</title>
		<author>
			<persName><forename type="first">Maximiliano</forename><surname>Duran</surname></persName>
		</author>
		<ptr target="http://quechua-ayacucho.org/es/index_es.php" />
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2021" to="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Abteen</forename><surname>Ebrahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Mager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arturo</forename><surname>Oncevay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luis</forename><surname>Chiruzzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ricardo</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Annette</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><forename type="middle">A</forename><surname>Giménez-Lugo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>Mager</surname></persName>
		</author>
		<title level="m">Ngoc Thang Vu, and Katharina Kann. 2021. AmericasNLI: Evaluating Zero-shot Natural Language Understanding of Pretrained Multilingual Models in Truly Low-resource Languages</title>
				<meeting><address><addrLine>Graham Neubig, Alexis Palmer, Rolando A. Coto Solano</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural machine translation models with back-translation for the extremely low-resource indigenous language Bribri</title>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rolando</forename><surname>Coto-Solano</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.coling-main.351</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
				<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3965" to="3976" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Design and implementation of an &quot;Web API&quot; for the automatic translation Colombia&apos;s language pairs: Spanish-Wayuunaiki case</title>
		<author>
			<persName><forename type="first">Ornela</forename><forename type="middle">Quintero</forename><surname>Dayana Iguarán Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jose</forename><surname>Gamboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar Elías Herrera</forename><surname>Molina Atencia</surname></persName>
		</author>
		<author>
			<persName><surname>Bedoya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communications and Computing (COLCOM)</title>
				<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Colombian Conference on</title>
		<imprint>
			<biblScope unit="page" from="1" to="9" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Corpus oral pandialectal de la lengua bribri</title>
		<author>
			<persName><surname>Sofía Flores Solórzano</surname></persName>
		</author>
		<ptr target="http://bribri.net" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Corpus creation and initial SMT experiments between Spanish and Shipibo-konibo</title>
		<author>
			<persName><forename type="first">Ana-Paula</forename><surname>Galarreta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrés</forename><surname>Melgar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arturo</forename><surname>Oncevay</surname></persName>
		</author>
		<idno type="DOI">10.26615/978-954-452-049-6_033</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
				<meeting>the International Conference Recent Advances in Natural Language Processing<address><addrLine>Varna, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="238" to="244" />
		</imprint>
	</monogr>
	<note>INCOMA Ltd</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Indigenous language revitalization, promotion, and education: Function of digital technology</title>
		<author>
			<persName><forename type="first">Candace</forename><surname>Kaleimamoowahinekapu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Galla</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Assisted Language Learning</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1137" to="1151" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A continuous improvement framework of machine translation for Shipibo-konibo</title>
		<author>
			<persName><forename type="first">Héctor Erasmo Gómez</forename><surname>Montoya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kervy Dante Rivas</forename><surname>Rojas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arturo</forename><surname>Oncevay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Technologies for MT of Low Resource Languages</title>
				<meeting>the 2nd Workshop on Technologies for MT of Low Resource Languages<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="17" to="23" />
		</imprint>
	</monogr>
	<note>European Association for Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bilingual lexicon extraction for a distant language pair using a small parallel corpus</title>
		<author>
			<persName><forename type="first">Ximena</forename><surname>Gutierrez-Vasques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="154" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Axolotl: a web accessible parallel corpus for Spanish-Nahuatl</title>
		<author>
			<persName><forename type="first">Ximena</forename><surname>Gutierrez-Vasques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerardo</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isaac</forename><surname>Hernandez Pompa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
				<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4210" to="4214" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The FLORES evaluation datasets for low-resource machine translation: Nepali-English and Sinhala-English</title>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng-Jen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1632</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
				<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6098" to="6111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Traducción automática neuronal para lengua nativa peruana. Bachelor&apos;s thesis</title>
		<author>
			<persName><forename type="first">Diego</forename><surname>Huarcaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taquiri</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
		<respStmt>
			<orgName>Universidad Peruana Unión</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">Cesar</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zenobio</forename><surname>Ortiz-Cárdenas</surname></persName>
		</author>
		<title level="m">Runasimita yachasun. Método de quechua</title>
				<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m">Francés de Estudios Andinos</title>
				<meeting><address><addrLine>Lima</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Gramática de la Lengua Bribri</title>
		<author>
			<persName><forename type="first">Carla</forename><surname>Victoria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jara</forename><surname>Murillo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>EDigital</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Carla</forename><surname>Victoria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jara</forename><surname>Murillo</surname></persName>
		</author>
		<title level="m">I Ttè Historias Bribris</title>
				<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Editorial de la Universidad de Costa Rica</orgName>
		</respStmt>
	</monogr>
	<note>second edition</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Se&apos; ttö&apos; bribri ie Hablemos en bribri</title>
		<author>
			<persName><forename type="first">Carla</forename><surname>Victoria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jara</forename><surname>Murillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alí García</forename><surname>Segura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>EDigital</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">NRC-CNRC Machine Translation Systems for the 2021 AmericasNLP Shared Task</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darlene</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Larkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</title>
				<meeting>the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th annual meeting of the association for computational linguistics companion volume proceedings of the demo and poster sessions</title>
				<meeting>the 45th annual meeting of the association for computational linguistics companion volume proceedings of the demo and poster sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</title>
		<author>
			<persName><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-2012</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multilingual Denoising Pre-training for Neural Machine Translation</title>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00343</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="726" to="742" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">James</forename><surname>Loriot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erwin</forename><surname>Lauriault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dwight</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peru</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Ministerio de Educación. 1993. Diccionario Shipibo-Castellano</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Probabilistic finite-state morphological segmenter for wixarika (huichol) language</title>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Mager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diónico</forename><surname>Carrillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Meza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent &amp; Fuzzy Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3081" to="3087" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Challenges of language technologies for the indigenous languages of the Americas</title>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Mager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximena</forename><surname>Gutierrez-Vasques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerardo</forename><surname>Sierra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Meza-Ruiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
				<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="55" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hacia la traducción automática de las lenguas indígenas de méxico</title>
		<author>
			<persName><forename type="first">Manuel</forename><surname>Mager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Meza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Digital Humanities Conference. The Association of Digital Humanities Organizations</title>
				<meeting>the 2018 Digital Humanities Conference. The Association of Digital Humanities Organizations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Diccionario Fraseológico Bribri-Español Español-Bribri, second edition</title>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Margery</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Editorial de la Universidad de Costa Rica</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Creating a massively parallel bible corpus</title>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cysouw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oceania</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">273</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The Johns Hopkins University Bible corpus: 1600+ tongues for typological exploration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Wicks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Winston</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Garrett</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
				<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2884" to="2892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Añaani katonkosatzi parenini</title>
		<author>
			<persName><forename type="first">Elena</forename><surname>Mihas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">El idioma del alto Perené. WI:Clarks Graphics</title>
				<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The REPU CS&apos; spanish-quechua submission to the AmericasNLP 2021 shared task on open machine translation</title>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</title>
				<meeting>the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Glottolog/Langdoc:Increasing the visibility of grey literature for low-density languages</title>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Nordhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harald</forename><surname>Hammarström</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
				<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3289" to="3294" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Overcoming resistance: The normalization of an Amazonian tribal language</title>
		<author>
			<persName><forename type="first">John</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Alexander</forename><surname>Castro-Mamani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime Rafael Montoya</forename><surname>Samame</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Technologies for MT of Low Resource Languages</title>
				<meeting>the 3rd Workshop on Technologies for MT of Low Resource Languages<address><addrLine>Suzhou, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">fairseq: A Fast, Extensible Toolkit for Sequence Modeling</title>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
				<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Bleu: a Method for Automatic Evaluation of Machine Translation</title>
		<author>
			<persName><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 40th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Philadelphia, Pennsylvania, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Yashvardhan Sharma, and Petr Motlicek. 2021. Open Machine Translation for Low Resource South American Languages (AmericasNLP 2021 Shared Task Contribution)</title>
		<author>
			<persName><forename type="first">Shantipriya</forename><surname>Parida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhadarshi</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amulya</forename><surname>Dash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esau</forename><surname>Villatoro-Tello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Seza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosa</forename><forename type="middle">M</forename><surname>Dogruöz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amadeo</forename><surname>Ortega-Mendoza</surname></persName>
		</author>
		<author>
			<persName><surname>Hernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AmericasNLP</title>
				<meeting>the AmericasNLP</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">chrF: character n-gram F-score for automatic MT evaluation</title>
		<author>
			<persName><forename type="first">Maja</forename><surname>Popović</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W15-3049</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Statistical Machine Translation</title>
				<meeting>the Tenth Workshop on Statistical Machine Translation<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="392" to="395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Parallel Global Voices: a Collection of Multilingual Corpora with Citizen Media Stories</title>
		<author>
			<persName><forename type="first">Prokopis</forename><surname>Prokopidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vassilis</forename><surname>Papavassiliou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stelios</forename><surname>Piperidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
				<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="900" to="905" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</title>
		<author>
			<persName><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Ñaantsipeta asháninkaki birakochaki</title>
		<author>
			<persName><forename type="first">Rubén</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastián</forename><surname>Richer</surname></persName>
		</author>
		<ptr target="www.lengamer.org/publicaciones/diccionarios/" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">Lane</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lori</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05477</idno>
		<title level="m">Neural polysynthetic language modelling</title>
				<meeting><address><addrLine>Emily Prud&apos;hommeaux, Hyunji Hayley Park, Kenneth Steimel, Rebecca Knowles</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>et al. 2020</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A poor man&apos;s translation memory using machine translation evaluation metrics</title>
		<author>
			<persName><forename type="first">Michel</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Atsushi</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Biennial Conference of the Association for Machine Translation in the Americas (AMTA)</title>
				<meeting>the 10th Biennial Conference of the Association for Machine Translation in the Americas (AMTA)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Parallel Data, Tools and Interfaces in OPUS</title>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
				<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">The Helsinki submission to the AmericasNLP shared task</title>
		<author>
			<persName><forename type="first">Raúl</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Scherrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sami</forename><surname>Virpioja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</title>
				<meeting>the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">ChrEn: Cherokee-English machine translation for endangered language revitalization</title>
		<author>
			<persName><forename type="first">Shiyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.43</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="577" to="595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Low-Resource Machine Translation Using Cross-Lingual Language Model Pretraining</title>
		<author>
			<persName><forename type="first">Francis</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Machel</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edison</forename><surname>Marrese-Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Matsuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</title>
				<meeting>the AmericasNLP 2021 Shared Task on Open Machine Translation for Indigenous Languages of the Americas, Online. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
