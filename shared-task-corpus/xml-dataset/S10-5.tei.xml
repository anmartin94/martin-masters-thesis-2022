<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2010 Task 5: Automatic Keyphrase Extraction from Scientific Articles</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Su</forename><forename type="middle">Nam</forename><surname>Kim</surname></persName>
							<email>sunamkim@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Dept of Computer Science and Software Engineering</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Olena</forename><surname>Medelyan</surname></persName>
							<email>medelyan@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Pingar LP</orgName>
								<address>
									<settlement>Auckland</settlement>
									<country key="NZ">New Zealand</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Dept of Computer Science and Software Engineering</orgName>
								<orgName type="institution">University of Melbourne</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2010 Task 5: Automatic Keyphrase Extraction from Scientific Articles</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes Task 5 of the Workshop on Semantic Evaluation 2010 (SemEval-2010). Systems are to automatically assign keyphrases or keywords to given scientific articles. The participating systems were evaluated by matching their extracted keyphrases against manually assigned ones. We present the overall ranking of the submitted systems and discuss our findings to suggest future directions for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Task Description</head><p>Keyphrases 1 are words that capture the main topics of a document. As they represent these key ideas, extracting high-quality keyphrases can benefit various natural language processing (NLP) applications such as summarization, information retrieval and question-answering. In summarization, keyphrases can be used as a form of semantic metadata <ref type="bibr" target="#b1">(Barzilay and Elhadad, 1997;</ref><ref type="bibr" target="#b7">Lawrie et al., 2001;</ref><ref type="bibr" target="#b2">D'Avanzo and Magnini, 2005)</ref>. In search engines, keyphrases can supplement full-text indexing and assist users in formulating queries.</p><p>Recently, a resurgence of interest in keyphrase extraction has led to the development of several new systems and techniques for the task (Frank et al.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>have showcased the potential benefits of keyphrase extraction to downstream NLP applications.</p><p>In light of these developments, we felt that this was an appropriate time to conduct a shared task for keyphrase extraction, to provide a standard assessment to benchmark current approaches. A second goal of the task was to contribute an additional public dataset to spur future research in the area.</p><p>Currently, there are several publicly available data sets. <ref type="bibr">2</ref> For example, <ref type="bibr" target="#b4">Hulth (2003)</ref> contributed 2,000 abstracts of journal articles present in Inspec between the years 1998 and 2002. The data set contains keyphrases (i.e. controlled and uncontrolled terms) assigned by professional indexers -1,000 for training, 500 for validation and 500 for testing. <ref type="bibr" target="#b13">Nguyen and Kan (2007)</ref> collected a dataset containing 120 computer science articles, ranging in length from 4 to 12 pages. The articles contain author-assigned keyphrases as well as reader-assigned keyphrases contributed by undergraduate CS students. In the general newswire domain, <ref type="bibr" target="#b18">Wan and Xiao (2008)</ref> developed a dataset of 308 documents taken from DUC 2001 which contain up to 10 manually-assigned keyphrases per document. Several databases, including the ACM Digital Library, IEEE Xplore, Inspec and PubMed provide articles with authorassigned keyphrases and, occasionally, readerassigned ones. <ref type="bibr" target="#b11">Medelyan (2009)</ref> automatically generated a dataset using tags assigned by the users of the collaborative citation platform CiteU-Like. This dataset additionally records how many people have assigned the same keyword to the same publication. In total, 180 full-text publications were annotated by over 300 users. <ref type="bibr">3</ref> Despite the availability of these datasets, a standardized benchmark dataset with a well-defined train-2 All data sets listed below are available for download from http://github.com/snkim/ AutomaticKeyphraseExtraction 3 http://bit.ly/maui-datasets ing and test split is needed to maximize comparability of results.</p><p>For the SemEval-2010 Task 5, we have compiled a set of 284 scientific articles with keyphrases carefully chosen by both their authors and readers. The participants' task was to develop systems which automatically produce keyphrases for each paper. Each team was allowed to submit up to three system runs, to benchmark the contributions of different parameter settings and approaches. Each run consisted of extracting a ranked list of 15 keyphrases from each document, ranked by their probability of being readerassigned keyphrases.</p><p>In the remainder of the paper, we describe the competition setup, including how data collection was managed and the evaluation methodology (Section 2). We present the results of the shared task, and discuss the immediate findings of the competition in Section 3. In Section 4 we assess the human performance by comparing readerassigned keyphrases to those assigned by the authors. This gives an approximation of an upperbound performance for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Competition Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>We collected trial, training and test data from the ACM Digital Library (conference and workshop papers). The input papers ranged from 6 to 8 pages, including tables and pictures. To ensure a variety of different topics was represented in the corpus, we purposefully selected papers from four different research areas for the dataset. In particular, the selected articles belong to the following four 1998 ACM classifications: C2.4 (Distributed Systems), H3.3 (Information Search and Retrieval), I2.11 (Distributed Artificial Intelligence -Multiagent Systems) and J4 (Social and Behavioral Sciences -Economics). All three datasets (trial, training and test) had an equal distribution of documents from among the categories (see Table <ref type="table" target="#tab_1">1</ref>). This domain specific information was provided with the papers (e.g. I2.4-1 or H3.3-2), in case participant systems wanted to utilize this information. We specifically decided to straddle different areas to see whether participant approaches would work better within specific areas.</p><p>Participants were provided with 40, 144, and 100 articles, respectively, in the trial, training and test data, distributed evenly across the four re-search areas in each case. Note that the trial data is a subset of the training data. Since the original format for the articles was PDF, we converted them into (UTF-8) plain text using pdftotext, and systematically restored full words that were originally hyphenated and broken across two lines. This policy potentially resulted in valid hyphenated forms having their hyphen (-) removed.</p><p>All collected papers contain author-assigned keyphrases, part of the original PDF file. We additionally collected reader-assigned keyphrases for each paper. We first performed a pilot annotation task with a group of students to check the stability of the annotations, finalize the guidelines, and discover and resolve potential issues that may occur during the actual annotation. To collect the actual reader-assigned keyphrases, we then hired 50 student annotators from the Computer Science department of the National University of Singapore.</p><p>We assigned 5 papers to each annotator, estimating that assigning keyphrases to each paper should take about 10-15 minutes. Annotators were explicitly told to extract keyphrases that actually appear in the text of each paper, rather than to create semantically-equivalent phrases, but could extract phrases from any part of the document (including headers and captions). In reality, on average 15% of the reader-assigned keyphrases did not appear in the text of the paper, but this is still less than the 19% of author-assigned keyphrases that did not appear in the papers. These values were computed using the test documents only. In other words, the maximum recall that the participating systems can achieve on these documents is 85% and 81% for the reader-and author-assigned keyphrases, respectively.</p><p>As some keyphrases may occur in multiple forms, in our evaluation we accepted two different versions of genitive keyphrases: A of B → B A (e.g. policy of school = school policy) and A's B → A B (e.g. school's policy = school policy). In certain cases, such alternations change the semantics of the candidate phrase (e.g., matter of fact vs. ?fact matter). We judged borderline cases by committee and do not include alternations that were judged to be semantically distinct.</p><p>Table <ref type="table" target="#tab_1">1</ref> shows the distribution of the trial, training and test documents over the four different research areas, while   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation Method and Baseline</head><p>Traditionally, automatic keyphrase extraction systems have been assessed using the proportion of top-N candidates that exactly match the goldstandard keyphrases <ref type="bibr" target="#b16">Turney, 1999)</ref>. In some cases, inexact matches, or near-misses, have also been considered. Some have suggested treating semanticallysimilar keyphrases as correct based on similarities computed over a large corpus <ref type="bibr" target="#b6">(Jarmasz and Barriere, 2004;</ref><ref type="bibr" target="#b12">Mihalcea and Tarau, 2004)</ref>, or using semantic relations defined in a thesaurus <ref type="bibr" target="#b10">(Medelyan and Witten, 2006)</ref>. <ref type="bibr" target="#b20">Zesch and Gurevych (2009)</ref> compute near-misses using an ngram based approach relative to the gold standard. For our shared task, we follow the traditional exact match evaluation metric. That is, we match the keyphrases in the answer set with those the systems provide, and calculate micro-averaged precision, recall and F-score (β = 1). In the evaluation, we check the performance over the top 5, 10 and 15 candidates returned by each system. We rank the participating systems by F-score over the top 15 candidates. Participants were required to extract existing phrases from the documents.</p><p>Since it is theoretically possible to retrieve authorassigned keyphrases from the original PDF articles, we evaluate the participating systems over the independently-generated and held-out reader-assigned keyphrases, as well as the combined set of keyphrases (author-and reader-assigned).</p><p>All keyphrases in the answer set are stemmed using the English Porter stemmer for both the training and test dataset. <ref type="bibr">4</ref> We computed a TF×IDF n-gram based baseline using both supervised and unsupervised learning systems. We use 1, 2, 3-grams as keyphrase candidates, used Naïve Bayes (NB) and Maximum Entropy (ME) classifiers to learn two supervised baseline systems based on the keyphrase candidates and gold-standard annotations for the training documents. In total, there are three baselines: two supervised and one unsupervised. The performance of the baselines is presented in Table <ref type="table" target="#tab_4">3</ref>, where R indicates reader-assigned keyphrases and C indicates combined (both author-and readerassigned) keyphrases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Competition Results</head><p>The trial data was downloaded by 73 different teams, of which 36 teams subsequently downloaded the training and test data. 21 teams participated in the final competition, of which two teams withdrew their systems.</p><p>Table <ref type="table" target="#tab_5">4</ref> shows the performance of the final 19 submitted systems. 5 teams submitted one run, 6 teams submitted two runs and 8 teams submitted the maximum number of three runs. We rank the best-performing system from each team by micro-averaged F-score over the top 15 candidates. We also show system performance over reader-assigned keywords in Table <ref type="table" target="#tab_7">5</ref>, and over author-assigned keywords in Table <ref type="table" target="#tab_8">6</ref>. In all these tables, P, R and F denote precision, recall and Fscore, respectively.</p><p>The best results over the reader-assigned and combined keyphrase sets are 23.5% and 27.5%, respectively, achieved by the HUMB team. Most systems outperformed the baselines. Systems also generally did better over the combined set, as the presence of a larger gold-standard answer set improved recall.</p><p>In Tables <ref type="table" target="#tab_10">7 and 8</ref>, we ranked the teams by Fscore, computed over the top 15 candidates for each of the four ACM document classifications. The numbers in brackets are the actual F-scores   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion of the Upper-Bound Performance</head><p>The current evaluation is a testament to the gains made by keyphrase extraction systems. The system performance over the different keyword categories (reader-assigned and author-assigned) and numbers of keyword candidates (top 5, 10 and 15 candidates) attest to this fact. The top-performing systems return F-scores in the upper twenties. Superficially, this number is low, and it is instructive to examine how much room there is for improvement. Keyphrase extraction is a subjective task, and an F-score of 100% is infeasible. On the author-assigned keyphrases in our test collection, the highest a system could theoretically achieve was 81% recall 5 and 100% precision, which gives a maximum F-score of 89%. However, such a high value would only be possible if the number of keyphrases extracted per document could vary; in our task, we fixed the thresholds at 5, 10 and 15 keyphrases.</p><p>Another way of computing the upper-bound performance would be to look into how well people perform the same task. We analyzed the performance of our readers, taking the authorassigned keyphrases as the gold standard. The authors assigned an average of 4 keyphrases to each paper, whereas the readers assigned 12 on average. These 12 keyphrases cover 77.8% of the authors' keyphrases, which corresponds to a precision of 21.5%. The F-score achieved by the readers on the author-assigned keyphrases is 33.6%, whereas the F-score of the best-performing system on the same data is 19.3% (for top 15, not top 12 keyphrases, see Table <ref type="table" target="#tab_8">6</ref>).</p><p>We conclude that there is definitely still room for improvement, and for any future shared tasks, we recommend against fixing any threshold on the number of keyphrases to be extracted per document. Finally, as we use a strict exact matching metric for evaluation, the presented evaluation figures are a lower bound for performance, as semantically equivalent keyphrases are not counted as correct. For future runs of this challenge, we believe a more semantically-motivated evaluation should be employed to give a more accurate impression of keyphrase acceptability.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper has described Task 5 of the Workshop on Semantic Evaluation 2010 (SemEval-2010), focusing on keyphrase extraction. We outlined the design of the datasets used in the shared task and the evaluation metrics, before presenting the official results for the task and summarising the immediate findings. We also analyzed the upperbound performance for this task, and demonstrated that there is still room for improvement over the task. We look forward to future advances in automatic keyphrase extraction based on this and other datasets.   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>shows the distribution</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Number of documents per topic in the trial, training and test datasets, across the four ACM document classifications</figDesc><table><row><cell>Dataset</cell><cell cols="3">Author Reader Combined</cell></row><row><cell>Trial</cell><cell>149</cell><cell>526</cell><cell>621</cell></row><row><cell>Training</cell><cell>559</cell><cell>1824</cell><cell>2223</cell></row><row><cell>Test</cell><cell>387</cell><cell>1217</cell><cell>1482</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Number of author-and reader-assigned</cell></row><row><cell>keyphrases in the different datasets</cell></row><row><cell>keywords, 125 keywords match exactly with</cell></row><row><cell>reader-assigned keywords, while many more near-</cell></row><row><cell>misses (i.e. partial matches) occur.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Baseline keyphrase extraction performance for one unsupervised (TF×IDF) and two supervised (NB and ME) systems</figDesc><table><row><cell>System</cell><cell>Rank</cell><cell cols="3">Top 5 candidates</cell><cell cols="3">Top 10 candidates</cell><cell cols="3">Top 15 candidates</cell></row><row><cell></cell><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>HUMB</cell><cell>1</cell><cell>39.0%</cell><cell>13.3%</cell><cell>19.8%</cell><cell>32.0%</cell><cell>21.8%</cell><cell>26.0%</cell><cell>27.2%</cell><cell>27.8%</cell><cell>27.5%</cell></row><row><cell>WINGNUS</cell><cell>2</cell><cell>40.2%</cell><cell>13.7%</cell><cell>20.5%</cell><cell>30.5%</cell><cell>20.8%</cell><cell>24.7%</cell><cell>24.9%</cell><cell>25.5%</cell><cell>25.2%</cell></row><row><cell>KP-Miner</cell><cell>3</cell><cell>36.0%</cell><cell>12.3%</cell><cell>18.3%</cell><cell>28.6%</cell><cell>19.5%</cell><cell>23.2%</cell><cell>24.9%</cell><cell>25.5%</cell><cell>25.2%</cell></row><row><cell>SZTERGAK</cell><cell>4</cell><cell>34.2%</cell><cell>11.7%</cell><cell>17.4%</cell><cell>28.5%</cell><cell>19.4%</cell><cell>23.1%</cell><cell>24.8%</cell><cell>25.4%</cell><cell>25.1%</cell></row><row><cell>ICL</cell><cell>5</cell><cell>34.4%</cell><cell>11.7%</cell><cell>17.5%</cell><cell>29.2%</cell><cell>19.9%</cell><cell>23.7%</cell><cell>24.6%</cell><cell>25.2%</cell><cell>24.9%</cell></row><row><cell>SEERLAB</cell><cell>6</cell><cell>39.0%</cell><cell>13.3%</cell><cell>19.8%</cell><cell>29.7%</cell><cell>20.3%</cell><cell>24.1%</cell><cell>24.1%</cell><cell>24.6%</cell><cell>24.3%</cell></row><row><cell>KX FBK</cell><cell>7</cell><cell>34.2%</cell><cell>11.7%</cell><cell>17.4%</cell><cell>27.0%</cell><cell>18.4%</cell><cell>21.9%</cell><cell>23.6%</cell><cell>24.2%</cell><cell>23.9%</cell></row><row><cell>DERIUNLP</cell><cell>8</cell><cell>27.4%</cell><cell>9.4%</cell><cell>13.9%</cell><cell>23.0%</cell><cell>15.7%</cell><cell>18.7%</cell><cell>22.0%</cell><cell>22.5%</cell><cell>22.3%</cell></row><row><cell>Maui</cell><cell>9</cell><cell>35.0%</cell><cell>11.9%</cell><cell>17.8%</cell><cell>25.2%</cell><cell>17.2%</cell><cell>20.4%</cell><cell>20.3%</cell><cell>20.8%</cell><cell>20.6%</cell></row><row><cell>DFKI</cell><cell>10</cell><cell>29.2%</cell><cell>10.0%</cell><cell>14.9%</cell><cell>23.3%</cell><cell>15.9%</cell><cell>18.9%</cell><cell>20.3%</cell><cell>20.7%</cell><cell>20.5%</cell></row><row><cell>BUAP</cell><cell>11</cell><cell>13.6%</cell><cell>4.6%</cell><cell>6.9%</cell><cell>17.6%</cell><cell>12.0%</cell><cell>14.3%</cell><cell>19.0%</cell><cell>19.4%</cell><cell>19.2%</cell></row><row><cell>SJTULTLAB</cell><cell>12</cell><cell>30.2%</cell><cell>10.3%</cell><cell>15.4%</cell><cell>22.7%</cell><cell>15.5%</cell><cell>18.4%</cell><cell>18.4%</cell><cell>18.8%</cell><cell>18.6%</cell></row><row><cell>UNICE</cell><cell>13</cell><cell>27.4%</cell><cell>9.4%</cell><cell>13.9%</cell><cell>22.4%</cell><cell>15.3%</cell><cell>18.2%</cell><cell>18.3%</cell><cell>18.8%</cell><cell>18.5%</cell></row><row><cell>UNPMC</cell><cell>14</cell><cell>18.0%</cell><cell>6.1%</cell><cell>9.2%</cell><cell>19.0%</cell><cell>13.0%</cell><cell>15.4%</cell><cell>18.1%</cell><cell>18.6%</cell><cell>18.3%</cell></row><row><cell>JU CSE</cell><cell>15</cell><cell>28.4%</cell><cell>9.7%</cell><cell>14.5%</cell><cell>21.5%</cell><cell>14.7%</cell><cell>17.4%</cell><cell>17.8%</cell><cell>18.2%</cell><cell>18.0%</cell></row><row><cell>LIKEY</cell><cell>16</cell><cell>29.2%</cell><cell>10.0%</cell><cell>14.9%</cell><cell>21.1%</cell><cell>14.4%</cell><cell>17.1%</cell><cell>16.3%</cell><cell>16.7%</cell><cell>16.5%</cell></row><row><cell>UvT</cell><cell>17</cell><cell>24.8%</cell><cell>8.5%</cell><cell>12.6%</cell><cell>18.6%</cell><cell>12.7%</cell><cell>15.1%</cell><cell>14.6%</cell><cell>14.9%</cell><cell>14.8%</cell></row><row><cell>POLYU</cell><cell>18</cell><cell>15.6%</cell><cell>5.3%</cell><cell>7.9%</cell><cell>14.6%</cell><cell>10.0%</cell><cell>11.8%</cell><cell>13.9%</cell><cell>14.2%</cell><cell>14.0%</cell></row><row><cell>UKP</cell><cell>19</cell><cell>9.4%</cell><cell>3.2%</cell><cell>4.8%</cell><cell>5.9%</cell><cell>4.0%</cell><cell>4.8%</cell><cell>5.3%</cell><cell>5.4%</cell><cell>5.3%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Performance of the submitted systems over the combined author-and reader-assigned keywords, ranked by F-score for each team. Note that in the case of a tie in F-score, we ordered teams by descending F-score over all the data.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Performance of the submitted systems over the reader-assigned keywords, ranked by F-score</figDesc><table><row><cell>System</cell><cell>Rank</cell><cell cols="3">Top 5 candidates</cell><cell cols="3">Top 10 candidates</cell><cell cols="3">Top 15 candidates</cell></row><row><cell></cell><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>HUMB</cell><cell>1</cell><cell>21.2%</cell><cell>27.4%</cell><cell>23.9%</cell><cell>15.4%</cell><cell>39.8%</cell><cell>22.2%</cell><cell>12.1%</cell><cell>47.0%</cell><cell>19.3%</cell></row><row><cell>KP-Miner</cell><cell>2</cell><cell>19.0%</cell><cell>24.6%</cell><cell>21.4%</cell><cell>13.4%</cell><cell>34.6%</cell><cell>19.3%</cell><cell>10.7%</cell><cell>41.6%</cell><cell>17.1%</cell></row><row><cell>ICL</cell><cell>3</cell><cell>17.0%</cell><cell>22.0%</cell><cell>19.2%</cell><cell>13.5%</cell><cell>34.9%</cell><cell>19.5%</cell><cell>10.5%</cell><cell>40.6%</cell><cell>16.6%</cell></row><row><cell>Maui</cell><cell>4</cell><cell>20.4%</cell><cell>26.4%</cell><cell>23.0%</cell><cell>13.7%</cell><cell>35.4%</cell><cell>19.8%</cell><cell>10.2%</cell><cell>39.5%</cell><cell>16.2%</cell></row><row><cell>SEERLAB</cell><cell>5</cell><cell>18.8%</cell><cell>24.3%</cell><cell>21.2%</cell><cell>13.1%</cell><cell>33.9%</cell><cell>18.9%</cell><cell>10.1%</cell><cell>39.0%</cell><cell>16.0%</cell></row><row><cell>SZTERGAK</cell><cell>6</cell><cell>14.6%</cell><cell>18.9%</cell><cell>16.5%</cell><cell>12.2%</cell><cell>31.5%</cell><cell>17.6%</cell><cell>9.9%</cell><cell>38.5%</cell><cell>15.8%</cell></row><row><cell>WINGNUS</cell><cell>7</cell><cell>18.6%</cell><cell>24.0%</cell><cell>21.0%</cell><cell>12.6%</cell><cell>32.6%</cell><cell>18.2%</cell><cell>9.3%</cell><cell>36.2%</cell><cell>14.8%</cell></row><row><cell>DERIUNLP</cell><cell>8</cell><cell>12.6%</cell><cell>16.3%</cell><cell>14.2%</cell><cell>9.7%</cell><cell>25.1%</cell><cell>14.0%</cell><cell>9.3%</cell><cell>35.9%</cell><cell>14.7%</cell></row><row><cell>KX FBK</cell><cell>9</cell><cell>13.6%</cell><cell>17.6%</cell><cell>15.3%</cell><cell>10.0%</cell><cell>25.8%</cell><cell>14.4%</cell><cell>8.5%</cell><cell>32.8%</cell><cell>13.5%</cell></row><row><cell>BUAP</cell><cell>10</cell><cell>5.6%</cell><cell>7.2%</cell><cell>6.3%</cell><cell>8.1%</cell><cell>20.9%</cell><cell>11.7%</cell><cell>8.3%</cell><cell>32.0%</cell><cell>13.2%</cell></row><row><cell>JU CSE</cell><cell>11</cell><cell>12.0%</cell><cell>15.5%</cell><cell>13.5%</cell><cell>8.5%</cell><cell>22.0%</cell><cell>12.3%</cell><cell>7.5%</cell><cell>29.0%</cell><cell>11.9%</cell></row><row><cell>UNPMC</cell><cell>12</cell><cell>7.0%</cell><cell>9.0%</cell><cell>7.9%</cell><cell>7.7%</cell><cell>19.9%</cell><cell>11.1%</cell><cell>7.1%</cell><cell>27.4%</cell><cell>11.2%</cell></row><row><cell>DFKI</cell><cell>13</cell><cell>12.8%</cell><cell>16.5%</cell><cell>14.4%</cell><cell>8.5%</cell><cell>22.0%</cell><cell>12.3%</cell><cell>6.6%</cell><cell>25.6%</cell><cell>10.5%</cell></row><row><cell>SJTULTLAB</cell><cell>14</cell><cell>9.6%</cell><cell>12.4%</cell><cell>10.8%</cell><cell>7.8%</cell><cell>20.2%</cell><cell>11.3%</cell><cell>6.2%</cell><cell>24.0%</cell><cell>9.9%</cell></row><row><cell>Likey</cell><cell>15</cell><cell>11.6%</cell><cell>15.0%</cell><cell>13.1%</cell><cell>7.9%</cell><cell>20.4%</cell><cell>11.4%</cell><cell>5.9%</cell><cell>22.7%</cell><cell>9.3%</cell></row><row><cell>UvT</cell><cell>16</cell><cell>11.4%</cell><cell>14.7%</cell><cell>12.9%</cell><cell>7.6%</cell><cell>19.6%</cell><cell>11.0%</cell><cell>5.8%</cell><cell>22.5%</cell><cell>9.2%</cell></row><row><cell>UNICE</cell><cell>17</cell><cell>8.8%</cell><cell>11.4%</cell><cell>9.9%</cell><cell>6.4%</cell><cell>16.5%</cell><cell>9.2%</cell><cell>5.5%</cell><cell>21.5%</cell><cell>8.8%</cell></row><row><cell>POLYU</cell><cell>18</cell><cell>3.8%</cell><cell>4.9%</cell><cell>4.3%</cell><cell>4.1%</cell><cell>10.6%</cell><cell>5.9%</cell><cell>4.1%</cell><cell>16.0%</cell><cell>6.6%</cell></row><row><cell>UKP</cell><cell>19</cell><cell>1.6%</cell><cell>2.1%</cell><cell>1.8%</cell><cell>0.9%</cell><cell>2.3%</cell><cell>1.3%</cell><cell>0.8%</cell><cell>3.1%</cell><cell>1.3%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Performance of the submitted systems over the author-assigned keywords, ranked by F-score</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>System ranking (and F-score) for each ACM classification: combined keywords</figDesc><table><row><cell>Rank</cell><cell>Group C</cell><cell>Group H</cell><cell>Group I</cell><cell>Group J</cell></row><row><cell>1</cell><cell>ICL(23.3%)</cell><cell>HUMB(25.0%)</cell><cell>HUMB(21.7%)</cell><cell>HUMB(24.7%)</cell></row><row><cell>2</cell><cell>KX FBK(23.3%)</cell><cell>WINGNUS(23.5%)</cell><cell>KX FBK(21.4%)</cell><cell>WINGNUS(24.4%)</cell></row><row><cell>3</cell><cell>HUMB(22.7%)</cell><cell>SEERLAB(23.2%)</cell><cell>SEERLAB(21.1%)</cell><cell>SZTERGAK(24.4%)</cell></row><row><cell>4</cell><cell>SZTERGAK(22.7%)</cell><cell>KP-Miner(22.4%)</cell><cell>WINGNUS(19.9%)</cell><cell>KX FBK(24.4%)</cell></row><row><cell>5</cell><cell>DERIUNLP(21.5%)</cell><cell>SZTERGAK(21.8%)</cell><cell>KP-Miner(19.6%)</cell><cell>UNICE(23.8%)</cell></row><row><cell>6</cell><cell>KP-Miner(21.2%)</cell><cell>KX FBK(21.2%)</cell><cell>SZTERGAK(19.6%)</cell><cell>ICL(23.5%)</cell></row><row><cell>7</cell><cell>WINGNUS(20.0%)</cell><cell>ICL(20.1%)</cell><cell>ICL(19.6%)</cell><cell>KP-Miner(22.6%)</cell></row><row><cell>8</cell><cell>SEERLAB(19.4%)</cell><cell>DERIUNLP(20.1%)</cell><cell>DFKI(18.5%)</cell><cell>SEERLAB(22.0%)</cell></row><row><cell>9</cell><cell>DFKI(19.4%)</cell><cell>DFKI(19.5%)</cell><cell>SJTULTLAB(17.6%)</cell><cell>DFKI(21.7%)</cell></row><row><cell>10</cell><cell>JU CSE(17.0%)</cell><cell>SJTULTLAB(19.5%)</cell><cell>DERIUNLP(17.3%)</cell><cell>BUAP(19.6%)</cell></row><row><cell>11</cell><cell>Likey(16.4%)</cell><cell>UNICE(19.2%)</cell><cell>JU CSE(16.7%)</cell><cell>DERIUNLP(19.0%)</cell></row><row><cell>12</cell><cell>SJTULTLAB(15.8%)</cell><cell>Maui(18.1%)</cell><cell>BUAP(16.4%)</cell><cell>Maui(17.8%)</cell></row><row><cell>13</cell><cell>BUAP(15.5%)</cell><cell>UNPMC(18.1%)</cell><cell>UNPMC(16.1%)</cell><cell>JU CSE(17.9%)</cell></row><row><cell>14</cell><cell>Maui(15.2%)</cell><cell>Likey(16.9%)</cell><cell>Maui(14.9%)</cell><cell>Likey(17.5%)</cell></row><row><cell>15</cell><cell>UNICE(14.0%)</cell><cell>UvT(16.4%)</cell><cell>UNICE(14.0%)</cell><cell>UNPMC(16.6%)</cell></row><row><cell>16</cell><cell>UvT(14.0%)</cell><cell>POLYU(15.5%)</cell><cell>POLYU(11.9%)</cell><cell>SJTULTLAB(16.3%)</cell></row><row><cell>17</cell><cell>UNPMC(13.4%)</cell><cell>BUAP(14.9%)</cell><cell>Likey(10.4%)</cell><cell>POLYU(13.3%)</cell></row><row><cell>18</cell><cell>POLYU(12.5%)</cell><cell>JU CSE(12.6%)</cell><cell>UvT(9.5%)</cell><cell>UvT(13.0%)</cell></row><row><cell>19</cell><cell>UKP(4.5%)</cell><cell>UKP(4.3%)</cell><cell>UKP(5.4%)</cell><cell>UKP(6.9%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>System ranking (and F-score) for each ACM classification: reader-assigned keywords</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Using the Perl implementation available at http:// tartarus.org/˜martin/PorterStemmer/; we informed participants that this was the stemmer we would be using for the task, to avoid possible stemming variations between implementations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The remaining 19% of keyphrases do not actually appear in the documents and thus cannot be extracted.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using noun phrase heads to extract document keyphrases</title>
		<author>
			<persName><forename type="first">Ken</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadia</forename><surname>Corrnacchia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BCCSCSI : Advances in Artificial Intelligence</title>
				<meeting>BCCSCSI : Advances in Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using lexical chains for text summarization</title>
		<author>
			<persName><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL/EACL Workshop on Intelligent Scalable Text Summarization</title>
				<meeting>ACL/EACL Workshop on Intelligent Scalable Text Summarization</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="10" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Keyphrase-Based Approach to Summarization: the LAKE System at DUC-2005</title>
		<author>
			<persName><forename type="first">D'avanzo</forename><surname>Ernesto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernado</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of DUC</title>
				<meeting>DUC</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Nevill-Manning. Domain Specific Keyphrase Extraction</title>
		<author>
			<persName><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><forename type="middle">W</forename><surname>Paynter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Craig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
				<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="668" to="673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Improved automatic keyword extraction given more linguistic knowledge</title>
		<author>
			<persName><forename type="first">Annette</forename><surname>Hulth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
				<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="216" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enhancing Linguistically Oriented Automatic Keyword Extraction</title>
		<author>
			<persName><forename type="first">Annette</forename><surname>Hulth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT/NAACL</title>
				<meeting>HLT/NAACL</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using semantic similarity over tera-byte corpus, compute the performance of keyphrase extraction</title>
		<author>
			<persName><forename type="first">Mario</forename><surname>Jarmasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Barriere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CLINE</title>
				<meeting>CLINE</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Finding Topic Words for Hierarchical Summarization</title>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Lawrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SIGIR</title>
				<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Clustering to Find Exemplar Terms for Keyphrase Extraction</title>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yabin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sun</forename><surname>Maosong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
				<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="257" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Keyword Extraction from a Single Document using Word Cooccurrence Statistical Information</title>
		<author>
			<persName><forename type="first">Yutaka</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitsuru</forename><surname>Ishizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal on Artificial Intelligence Tools</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="157" to="169" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Thesaurus based automatic keyphrase indexing</title>
		<author>
			<persName><forename type="first">Olena</forename><surname>Medelyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM/IEED-CS JCDL</title>
				<meeting>ACM/IEED-CS JCDL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="296" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Human-competitive automatic topic indexing</title>
		<author>
			<persName><forename type="first">Olena</forename><surname>Medelyan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Waikato</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD Thesis</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">TextRank: Bringing Order into Texts</title>
		<author>
			<persName><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Tarau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
				<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Key phrase Extraction in Scientific Publications</title>
		<author>
			<persName><forename type="first">Thuy</forename><forename type="middle">Dung</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICADL</title>
				<meeting>ICADL</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="317" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An ontology-based approach for key phrase extraction</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Chau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuoi</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL-IJCNLP</title>
				<meeting>the ACL-IJCNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Automatic Glossary Extraction Beyond Terminology Identification</title>
		<author>
			<persName><forename type="first">Youngja</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roy</forename><forename type="middle">J</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Branimir</forename><surname>Boguraev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
				<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to Extract Keyphrases from Text</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
		<idno>ERB-1057</idno>
	</analytic>
	<monogr>
		<title level="m">National Research Council, Institute for Information Technology</title>
				<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Coherent keyphrase extraction via Web mining</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IJCAI</title>
				<meeting>IJCAI</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="434" to="439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CollabRank: towards a collaborative approach to single-document keyphrase extraction</title>
		<author>
			<persName><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianguo</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
				<meeting>COLING</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="969" to="976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">KEA:Practical Automatic Key phrase Extraction</title>
		<author>
			<persName><forename type="first">H</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eibe</forename><surname>Paynter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Car</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graig</forename><surname>Gutwin</surname></persName>
		</author>
		<author>
			<persName><surname>Nevill-Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM conference on Digital libraries</title>
				<meeting>ACM conference on Digital libraries</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="254" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Approximate Matching for Evaluating Keyphrase Extraction</title>
		<author>
			<persName><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP</title>
				<meeting>RANLP</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
