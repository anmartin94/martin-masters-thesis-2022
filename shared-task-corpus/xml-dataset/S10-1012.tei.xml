<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2010 Task: Japanese WSD</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Manabu</forename><surname>Okumura</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tokyo Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kiyoaki</forename><surname>Shirai</surname></persName>
							<email>kshirai@jaist.ac.jp</email>
							<affiliation key="aff1">
								<orgName type="department">Japan Advanced Institute of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kanako</forename><surname>Komiya</surname></persName>
							<email>kkomiya@cc.tuat.ac.jp</email>
							<affiliation key="aff2">
								<orgName type="department">Tokyo University of Agriculture and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hikaru</forename><surname>Yokono</surname></persName>
							<email>yokono@lr.pi.titech.ac.jp</email>
							<affiliation key="aff3">
								<orgName type="institution">Tokyo Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2010 Task: Japanese WSD</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An overview of the SemEval-2 Japanese WSD task is presented. It is a lexical sample task, and word senses are defined according to a Japanese dictionary, the Iwanami Kokugo Jiten. This dictionary and a training corpus were distributed to participants. The number of target words was 50, with 22 nouns, 23 verbs, and 5 adjectives. Fifty instances of each target word were provided, consisting of a total of 2,500 instances for the evaluation. Nine systems from four organizations participated in the task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper reports an overview of the SemEval-2 Japanese Word Sense Disambiguation (WSD) task. It can be considered an extension of the SENSEVAL-2 Japanese monolingual dictionarybased task <ref type="bibr" target="#b8">(Shirai, 2001)</ref>, so it is a lexical sample task. Word senses are defined according to the Iwanami Kokugo Jiten <ref type="bibr" target="#b7">(Nishio et al., 1994)</ref>, a Japanese dictionary published by Iwanami Shoten. It was distributed to participants as a sense inventory. Our task has the following two new characteristics:</p><p>1. All previous Japanese sense-tagged corpora were from newspaper articles, while sensetagged corpora were constructed in English on balanced corpora, such as Brown corpus and BNC corpus. The first balanced corpus of contemporary written Japanese (BCCWJ corpus) is now being constructed as part of a national project in Japan <ref type="bibr" target="#b5">(Maekawa, 2008)</ref>, and we are now constructing a sense-tagged corpus based on it. Therefore, the task will use the first balanced Japanese sense-tagged corpus.</p><p>Because a balanced corpus consists of documents from multiple genres, the corpus can be divided into multiple sub-corpora of a genre. In supervised learning approaches on word sense disambiguation, because word sense distribution might vary across different sub-corpora, we need to take into account the genres of training and test corpora. Therefore, word sense disambiguation on a balanced corpus requires tackling a kind of domain (genre) adaptation problem <ref type="bibr" target="#b1">(Chang and Ng, 2006;</ref><ref type="bibr" target="#b0">Agirre and de Lacalle, 2008)</ref>.</p><p>2. In previous WSD tasks, systems have been required to select a sense from a given set of senses in a dictionary for a word in one context (an instance). However, the set of senses in the dictionary is not always complete. New word senses sometimes appear after the dictionary has been compiled. Therefore, some instances might have a sense that cannot be found in the dictionary's set. The task will take into account not only the instances that have a sense in the given set but also the instances that have a sense that cannot be found in the set. In the latter case, systems should output that the instances have a sense that is not in the set.</p><p>Training data, a corpus that consists of three genres (books, newspaper articles, and white papers) and is manually annotated with sense IDs, was also distributed to participants. For the evaluation, we distributed a corpus that consists of four genres (books, newspaper articles, white papers, and documents from a Q&amp;A site on the WWW) with marked target words as test data. Participants were requested to assign one or more sense IDs to each target word, optionally with associated probabilities. The number of target words was 50, with 22 nouns, 23 verbs, and 5 adjectives. Fifty instances of each target word were provided, con-sisting of a total of 2,500 instances for the evaluation.</p><p>In what follows, section two describes the details of the data used in the Japanese WSD task. Section three describes the process to construct the sense tagged data, including the analysis of an inter-annotator agreement. Section four briefly introduces participating systems and section five describes their results. Finally, section six concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>In the Japanese WSD task, three types of data were distributed to all participants: a sense inventory, training data, and test data 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sense Inventory</head><p>As described in section one, word senses are defined according to a Japanese dictionary, the Iwanami Kokugo Jiten. The number of headwords and word senses in the Iwanami Kokugo Jiten is 60,321 and 85,870.</p><p>As described in the task description of SENSEVAL-2 Japanese dictionary task <ref type="bibr" target="#b8">(Shirai, 2001)</ref>, the Iwanami Kokugo Jiten has hierarchical structures in word sense descriptions. The Iwanami Kokugo Jiten has at most three hierarchical layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training Data</head><p>An annotated corpus was distributed as the training data. It consists of 240 documents of three genres (books, newspaper articles, and white papers) from the BCCWJ corpus. The annotated information in the training data is as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Morphological information</head><p>The document was annotated with morphological information (word boundaries, a partof-speech (POS) tag, a base form, and a reading) for all words. All the morphological information was automatically annotated using chasen 2 with unidic and was manually postedited.</p><p>• Genre code Each document was assigned a code indicating its genre from the aforementioned list.</p><p>• Word sense IDs 3,437 word types in the data were annotated for sense IDs, and the data contain 31,611 sense-tagged instances that include 2,500 instances for the 50 target words. Words assigned with sense IDs satisfied the following conditions:</p><p>1. The Iwanami Kokugo Jiten gave their sense description. 2. Their POSs were either a noun, a verb, or an adjective. 3. They were ambiguous, that is, there were more than two word senses for them in the dictionary.</p><p>Word sense IDs were manually annotated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Test Data</head><p>The test data consists of 695 documents of four genres (books, newspaper articles, white papers, and documents from a Q&amp;A site on the WWW) from the BCCWJ corpus, with marked target words. The documents used for the training and test data are not mutually exclusive. The number of overlapping documents between the training and test data is 185. The instances used for the evaluation were not provided as the training data 3 . The annotated information in the test data is as follows:</p><p>• Morphological information Similar to the training data, the document was annotated with morphological information (word boundaries, a POS tag, a base form, and a reading) for all words. All morphological information was automatically annotated using chasen with unidic and was manually post-edited.</p><p>• Genre code As in the training data, each document was assigned a code indicating its genre from the aforementioned list.</p><p>• Word sense IDs Word sense IDs were manually annotated for the target words 4 .</p><p>The number of target words was 50, with 22 nouns, 23 verbs, and 5 adjectives. Fifty instances of each target word were provided, consisting of a total of 2,500 instances for the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Word Sense Tagging</head><p>Except for the word sense IDs, the data described in section two was developed by the National Institute of Japanese Language. However, the word sense IDs were newly annotated on the data. This section presents the process of annotating the word sense IDs, and the analysis of the inter-annotator agreement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sampling Target Words</head><p>When we chose target words, we considered the following conditions:</p><p>• The POSs of target words were either a noun, a verb, or an adjective.</p><p>• We chose words that occurred more than 50 times in the training data.</p><p>• The relative "difficulty" in disambiguating the sense of words was taken into account.</p><p>The difficulty of the word w was defined by the entropy of the word sense distribution E(w) in the test data <ref type="bibr" target="#b3">(Kilgarriff and Rosenzweig, 2000)</ref>. Obviously, the higher E(w) is, the more difficult the WSD for w is.</p><p>• The number of instances for a new sense was also taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Manual Annotation</head><p>Nine annotators assigned the correct word sense IDs for the training and test data. All of them had a certain level of linguistic knowledge. The process of manual annotation was as follows:</p><p>1. An annotator chose a sense ID for each word separately in accordance with the following guidelines:</p><p>• One sense ID was to be chosen for each word.</p><p>• Sense IDs at any layers in the hierarchical structures were assignable.</p><p>• The "new word sense" tag was to be chosen only when all sense IDs were not absolutely applicable.</p><p>2. For the instances that had a 'new word sense' tag, another annotator reexamined carefully whether those instances really had a new sense.</p><p>Because a fragment of the corpus was tagged by multiple annotators in a preliminary annotation, the inter-annotator agreement between the two annotators in step 1 was calculated with Kappa statistics. It was 0.678.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Methodology</head><p>The evaluation was returned in the following two ways:</p><p>1. The outputted sense IDs were evaluated, assuming the 'new sense' as another sense ID.</p><p>The outputted sense IDs were compared to the given gold standard word senses, and the usual precision measure for supervised word sense disambiguation systems was computed using the scorer. The Iwanami Kokugo Jiten has three levels for sense IDs, and we used the middle-level sense in the task. Therefore, the scoring in the task was 'middle-grained scoring.'</p><p>2. The ability of finding the instances of new senses was evaluated, assuming the task as classifying each instance into a 'known sense' or 'new sense' class. The outputted sense IDs (same as in 1.) were compared to the given gold standard word senses, and the usual accuracy for binary classification was computed, assuming all sense IDs in the dictionary were in the 'known sense' class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Participating Systems</head><p>In the Japanese WSD task, 10 organizations registered for participation. However, only the nine systems from four organizations submitted the results. In what follows, we outline them with the following description:</p><p>1. learning algorithm used, 2. features used, 3. language resources used, 4. level of analysis performed in the system, 5. whether and how the difference in the text genre was taken into account, 6. method to detect new senses of words, if any.</p><p>Note that most of the systems used supervised learning techniques.</p><p>• HIT-1 1. Naive Bayes, 2. Word form/POS of the target word, word form/POS before or after the target word, content words in the context, classes in a thesaurus for those words in the context, the text genre, 3. 'Bunrui-Goi-Hyou', a Japanese thesaurus (National Institute of Japanese Language, 1964), 4. Morphological analysis, 5. A genre is included in the features. 6. Assuming that the posterior probability has a normal distribution, the system judges those instances deviating from the distribution at the 0.05 significance level as a new word sense</p><p>• JAIST-1 1. Agglomerative clustering, 2. Bag-ofwords in context, etc. 3. None, 4. Morphological analysis, 5. The system does not merge example sentences in different genre sub-corpus into a cluster. 6. First, the system makes clusters of example sentences, then measures the similarity between a cluster and a sense in the dictionary, finally regarding the cluster as a collection of new senses when the similarity is small. For WSD, the system chooses the most similar sense for each cluster, then it considers all the instances in the cluster to have that sense.</p><p>• JAIST-2 1. SVM, 2. Word form/POS before or after the target word, content words in the context, etc. 3. None, 4. Morphological analysis, 5.</p><p>The system was trained with the feature set where features are distinguished whether or not they are derived from only one genre subcorpus. 6. 'New sense' is treated as one of the sense classes.</p><p>• JAIST-3</p><p>The system is an ensemble of JAIST-1 and JAIST-2. The judgment of a new sense is performed by JAIST-1. The output of JAIST-1 is chosen when the similarity between a cluster and a sense in the dictionary is sufficiently high. Otherwise, the output of JAIST-2 is used.</p><p>• MSS-1,2,3 1. Maximum entropy, 2. Three word forms/lemmas/POSs before or after the target word, bigrams, and skip bigrams in the context, bag-of-words in the document, a class of the document categorized by a topic classifier, etc. 3. None, 4. None, 5. For each target word, the system selected the genre and dictionary examples combinations for training data, which got the best results in crossvalidation. 6. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Their Results</head><p>The evaluation results of all the systems are shown in tables 1 and 2. "Baseline" for WSD indicates the results of the baseline system that used SVM with the following features:</p><p>• Morphological features Bag-of-words (BOW), Part-of-speech (POS), and detailed POS classification. We extract these features from the target word itself and the two words to the right and left of it.</p><p>• Syntactic features -If the POS of a target word is a noun, extract the verb in a grammatical dependency relation with the noun.  • Figures in Bunrui-Goi-Hyou 4 and 5 digits regarding the content word to the right and left of the target word.</p><p>The baseline system did not take into account any information on the text genre. "Baseline" for new sense detection (NSD) indicates the results of the baseline system, which outputs a sense in the dictionary and never outputs the new sense tag. Precision and recall for NSD are shown just for reference. Because relatively few instances for a new word sense were found (39 out of 2500), the task of the new sense detection was found to be rather difficult. Tables <ref type="table" target="#tab_3">3 and 4</ref> show the results for nouns, verbs, and adjectives. In our comparison of the baseline system scores for WSD, the score for nouns was the biggest, and the score for verbs was the smallest (table 3). However, the average entropy of nouns was the second biggest (0.7257), and that  We set up three word classes, D dif f (E(w) ≥ 1), D mid (0.5 ≤ E(w) &lt; 1), and D easy (E(w) &lt; 0.5). D dif f , D mid , and D easy consist of 20, 19 and 11 words, respectively. Tables <ref type="table">5 and 6</ref> show the results for each word class. The results of WSD are quite natural in that the higher E(w) is, the more difficult WSD is, and the more the performance degrades.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper reported an overview of the SemEval-2 Japanese WSD task. The data used in this task will be available when you contact the task organizer and sign a copyright agreement form. We hope this valuable data helps many researchers improve their WSD systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">: Results: Word sense disambiguation</cell></row><row><cell></cell><cell>Precision</cell></row><row><cell>Baseline</cell><cell>0.7528</cell></row><row><cell>HIT-1</cell><cell>0.6612</cell></row><row><cell>JAIST-1</cell><cell>0.6864</cell></row><row><cell>JAIST-2</cell><cell>0.7476</cell></row><row><cell>JAIST-3</cell><cell>0.7208</cell></row><row><cell>MSS-1</cell><cell>0.6404</cell></row><row><cell>MSS-2</cell><cell>0.6384</cell></row><row><cell>MSS-3</cell><cell>0.6604</cell></row><row><cell>RALI-1</cell><cell>0.7592</cell></row><row><cell>RALI-2</cell><cell>0.7636</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">: Results: New sense detection</cell><cell></cell></row><row><cell></cell><cell cols="3">Accuracy Precision Recall</cell></row><row><cell>Baseline</cell><cell>0.9844</cell><cell>-</cell><cell>0</cell></row><row><cell>HIT-1</cell><cell>0.9132</cell><cell cols="2">0.0297 0.0769</cell></row><row><cell>JAIST-1</cell><cell>0.9512</cell><cell cols="2">0.0337 0.0769</cell></row><row><cell>JAIST-2</cell><cell>0.9872</cell><cell cols="2">1 0.1795</cell></row><row><cell>JAIST-3</cell><cell>0.9532</cell><cell cols="2">0.0851 0.2051</cell></row><row><cell>MSS-1</cell><cell>0.9416</cell><cell cols="2">0.1409 0.5385</cell></row><row><cell>MSS-2</cell><cell>0.9384</cell><cell cols="2">0.1338 0.5385</cell></row><row><cell>MSS-3</cell><cell>0.9652</cell><cell cols="2">0.2333 0.5385</cell></row><row><cell>RALI-1</cell><cell>0.9864</cell><cell cols="2">0.7778 0.1795</cell></row><row><cell>RALI-2</cell><cell>0.9872</cell><cell cols="2">0.8182 0.2308</cell></row><row><cell cols="4">-If the POS of a target word is a verb, ex-</cell></row><row><cell cols="4">tract the noun in a grammatical depen-</cell></row><row><cell cols="3">dency relation with the verb.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell cols="4">Results for each POS (Precision): Word</cell></row><row><cell cols="2">sense disambiguation</cell><cell></cell></row><row><cell></cell><cell>Noun</cell><cell cols="2">Verb Adjective</cell></row><row><cell cols="3">Baseline 0.8255 0.6878</cell><cell>0.732</cell></row><row><cell>HIT-1</cell><cell cols="2">0.7436 0.5739</cell><cell>0.7</cell></row><row><cell cols="3">JAIST-1 0.7645 0.5957</cell><cell>0.76</cell></row><row><cell>JAIST-2</cell><cell cols="2">0.84 0.6626</cell><cell>0.732</cell></row><row><cell cols="3">JAIST-3 0.8236 0.6217</cell><cell>0.724</cell></row><row><cell>MSS-1</cell><cell cols="2">0.7 0.5504</cell><cell>0.792</cell></row><row><cell>MSS-2</cell><cell cols="2">0.6991 0.5470</cell><cell>0.792</cell></row><row><cell>MSS-3</cell><cell cols="2">0.7218 0.5713</cell><cell>0.8</cell></row><row><cell cols="3">RALI-1 0.8236 0.6965</cell><cell>0.764</cell></row><row><cell cols="3">RALI-2 0.8127 0.7191</cell><cell>0.752</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="4">: Results for each POS (Accuracy): New</cell></row><row><cell>sense detection</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Noun</cell><cell cols="2">Verb Adjective</cell></row><row><cell>Baseline</cell><cell cols="2">0.97 0.9948</cell><cell>1</cell></row><row><cell>HIT-1</cell><cell cols="2">0.8881 0.9304</cell><cell>0.944</cell></row><row><cell cols="3">JAIST-1 0.9518 0.9470</cell><cell>0.968</cell></row><row><cell cols="3">JAIST-2 0.9764 0.9948</cell><cell>1</cell></row><row><cell cols="3">JAIST-3 0.9564 0.9470</cell><cell>0.968</cell></row><row><cell>MSS-1</cell><cell cols="2">0.9355 0.9409</cell><cell>0.972</cell></row><row><cell>MSS-2</cell><cell cols="2">0.9336 0.9357</cell><cell>0.972</cell></row><row><cell>MSS-3</cell><cell cols="2">0.96 0.9670</cell><cell>0.98</cell></row><row><cell cols="3">RALI-1 0.9745 0.9948</cell><cell>1</cell></row><row><cell cols="3">RALI-2 0.9764 0.9948</cell><cell>1</cell></row><row><cell cols="3">of verbs was the biggest (1.194) 5 .</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Due to space limits, we unfortunately cannot present the statistics of the training and test data, such as the number of instances in different genres, the number of instances for a new word sense, and the Jensen Shannon (JS) divergence<ref type="bibr" target="#b4">(Lin, 1991;</ref><ref type="bibr" target="#b2">Dagan et al., 1997)</ref> between the word sense distributions of two different genres. We hope we will present them in another paper in the near future.2 http://chasen-legacy.sourceforge.jp/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The word sense IDs for them were hidden from the participants.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">They were hidden from the participants during the formal run.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The average entropy of adjectives was 0.6326.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank all the participants and the annotators for constructing this sense tagged corpus.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On robustness and domain adaptation using svd for word sense disambiguation</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oier</forename><surname>Lopez De Lacalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of COLING&apos;08</title>
				<meeting>of COLING&apos;08</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Estimating class priors in domain adaptation for wsd</title>
		<author>
			<persName><forename type="first">Yee</forename><surname>Seng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of ACL&apos;06</title>
				<meeting>of ACL&apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Similarity-based methods for word sense disambiguation</title>
		<author>
			<persName><forename type="first">Lillian</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fernando</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics</title>
				<meeting>the Thirty-Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="56" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">English senseval: Report and results</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kilgarriff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rosenzweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. LREC&apos;00</title>
				<meeting>LREC&apos;00</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Divergence measures based on the shannon entropy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Balanced corpus of contemporary written japanese</title>
		<author>
			<persName><forename type="first">Kikuo</forename><surname>Maekawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th Workshop on Asian Language Resources (ALR)</title>
				<meeting>the 6th Workshop on Asian Language Resources (ALR)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="101" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Bunruigoihyou. Shuuei Shuppan</title>
		<imprint>
			<date type="published" when="1964" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Japanese Language</orgName>
		</respStmt>
	</monogr>
	<note>In Japanese</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Iwanami Kokugo Jiten Dai Go Han. Iwanami Publisher</title>
		<author>
			<persName><forename type="first">Minoru</forename><surname>Nishio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Etsutaro</forename><surname>Iwabuchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizuo</forename><surname>Mizutani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>In Japanese</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Senseval-2 japanese dictionary task</title>
		<author>
			<persName><forename type="first">Kiyoaki</forename><surname>Shirai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems</title>
				<meeting>SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
