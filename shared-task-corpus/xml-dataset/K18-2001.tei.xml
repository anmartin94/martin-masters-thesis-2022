<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Popel</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<email>martin.potthast@uni-leipzig.de</email>
							<affiliation key="aff1">
								<orgName type="institution">Universität Leipzig</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Mathematics and Physics</orgName>
								<orgName type="institution">Charles University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Turku</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
							<email>joakim.nivre@lingfil.uu.se</email>
							<affiliation key="aff3">
								<orgName type="institution">Uppsala University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Google AI Language</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/K18-2001</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Every year, the Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their learning systems on the same data sets. In 2018, one of two tasks was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on the input. All test sets followed the unified annotation scheme of Universal Dependencies (Nivre et al., 2016). This shared task constitutes a 2 nd edition-the first one took place in 2017 ; the main metric from 2017 was kept, allowing for easy comparison, and two new main metrics were introduced. New datasets added to the Universal Dependencies collection between mid-2017 and the spring of 2018 contributed to the increased difficulty of the task this year. In this overview paper, we define the task and the updated evaluation methodology, describe data preparation, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The 2017 CoNLL shared task on universal dependency parsing  picked up the thread from the influential shared tasks in 2006 and 2007 <ref type="bibr" target="#b4">(Buchholz and Marsi, 2006;</ref><ref type="bibr" target="#b22">Nivre et al., 2007)</ref> and evolved it in two ways: (1) the parsing process started from raw text rather than gold standard tokenization and part-of-speech tagging, and (2) the syntactic representations were consistent across languages thanks to the Universal Dependencies framework <ref type="bibr" target="#b20">(Nivre et al., 2016)</ref>. The 2018 CoNLL shared task on universal dependency parsing starts from the same premises but adds a focus on morphological analysis as well as data from new languages.</p><p>Like last year, participating systems minimally had to find labeled syntactic dependencies between words, i.e., a syntactic head for each word, and a label classifying the type of the dependency relation. In addition, this year's task featured new metrics that also scored a system's capacity to predict a morphological analysis of each word, including a part-of-speech tag, morphological features, and a lemma. Regardless of metric, the assumption was that the input should be raw text, with no gold-standard word or sentence segmentation, and no gold-standard morphological annotation. However, for teams who wanted to concentrate on one or more subtasks, segmentation and morphology predicted by the baseline UDPipe system <ref type="bibr" target="#b34">(Straka et al., 2016)</ref> was made available just like last year.</p><p>There are eight new languages this year: Afrikaans, Armenian, Breton, Faroese, Naija, Old French, Serbian, and Thai; see Section 2 for more details. The two new evaluation metrics are described in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>In general, we wanted the participating systems to be able to use any data that is available free of charge for research and educational purposes (so that follow-up research is not obstructed). We deliberately did not place upper bounds on data sizes (in contrast to e.g. <ref type="bibr" target="#b22">Nivre et al. (2007)</ref>), despite the fact that processing large amounts of data may be difficult for some teams. Our primary objective was to determine the capability of current parsers provided with large amounts of freely available data.</p><p>In practice, the task was formally closed, i.e., we listed the approved data resources so that all participants were aware of their options. However, the selection was rather broad, ranging from Wikipedia dumps over the OPUS parallel corpora <ref type="bibr" target="#b36">(Tiedemann, 2012)</ref> to morphological transducers. Some of the resources were proposed by the participating teams.</p><p>We provided dependency-annotated training and test data, and also large quantities of crawled raw texts. Other language resources are available from third-party servers and we only referred to the respective download sites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Training Data: UD 2.2</head><p>Training and development data came from the Universal Dependencies (UD) 2.2 collection . This year, the official UD release immediately followed the test phase of the shared task. The training and development data were available to the participating teams as a prerelease; these treebanks were then released exactly in the state in which they appeared in the task. <ref type="bibr">1</ref> The participants were instructed to only use the UD data from the package released for the shared task. In theory, they could locate the (yet unreleased) test data in the development repositories on GitHub, but they were trusted that they would not attempt to do so.</p><p>82 UD treebanks in 57 languages were included in the shared task; 2 however, nine of the smaller treebanks consisted solely of test data, with no data at all or just a few sentences available for training. 16 languages had two or more treebanks from different sources, often also from different domains. <ref type="bibr">3</ref> See Table <ref type="table" target="#tab_1">1</ref> for an overview.</p><p>61 treebanks contain designated development data. Participants were asked not to use it for training proper but only for evaluation, development, tuning hyperparameters, doing error analysis etc. Seven treebanks have reasonablysized training data but no development data; only two of them, Irish and North Sámi, are the sole treebanks of their respective languages. For those treebanks cross-validation had to be used during development, but the entire dataset could be used for training once hyperparameters were determined. Five treebanks consist of extra test sets: they have no training or development data of their own, but large training data exist in other treebanks of the same languages (Czech-PUD, English-PUD, Finnish-PUD, Japanese-Modern and Swedish-PUD, respectively). The remaining nine treebanks are low-resource languages. Their "training data" was either a tiny sample of a few dozen sentences (Armenian, Buryat, Kazakh, Kurmanji, Upper Sorbian), or there was no training data at all <ref type="bibr">(Breton, Faroese, Naija, Thai)</ref>. Unlike in the 2017 task, these languages were not "surprise languages", that is, the participants knew well in advance what languages to expect. The last two languages are particularly difficult: Naija is a pidgin spoken in Nigeria; while it can be expected to bear some similarity to English, its spelling is significantly different from standard English, and no resources were available to learn it. Even harder was Thai with a writing system that does not separate words by spaces; the Facebook word vectors were probably the only resource among the approved additional data where participants could learn something about words in Thai <ref type="bibr" target="#b29">(Rosa and Mareček, 2018;</ref><ref type="bibr" target="#b32">Smith et al., 2018)</ref>. It was also possible to exploit the fact that there is a 1-1 sentence mapping between the Thai test set and the other four PUD test sets. <ref type="bibr">4</ref> Participants received the training and development data with gold-standard tokenization, sentence segmentation, POS tags and dependency re-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Supporting Data</head><p>To enable the induction of custom embeddings and the use of semi-supervised methods in general, the participants were provided with supporting resources primarily consisting of large text corpora for many languages in the task, as well as embeddings pre-trained on these corpora. In total, 5.9 M sentences and 90 G words in 45 languages are available in CoNLL-U format ; the per-language sizes of the corpus are listed in Table <ref type="table" target="#tab_3">2</ref>.</p><p>See  for more details on how the raw texts and embeddings were processed. Note that the resource was originally prepared for the 2017 task and it was not extended to include the eight new languages; however, some of the new languages are covered by the word vectors provided by Facebook <ref type="bibr" target="#b2">(Bojanowski et al., 2016)</ref> and approved for the shared task.  Each of the 82 treebanks mentioned in Section 2.1 has a test set. Test sets from two different treebanks of one language were evaluated separately as if they were different languages. Every test set contains at least 10,000 words (including punctuation marks). UD 2.2 treebanks that were smaller than 10,000 words were excluded from the shared task. There was no upper limit on the test data; the largest treebank had a test set comprising 170K words. The test sets were officially released as a part of UD 2.2 immediately after the shared task. 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation Metrics</head><p>There are three main evaluation scores, dubbed LAS, MLAS and BLEX. All three metrics reflect word segmentation and relations between content words. LAS is identical to the main metric of the 2017 task, allowing for easy comparison; the other two metrics include part-of-speech tags, morphological features and lemmas. Participants who wanted to decrease task complexity could concentrate on improvements in just one metric; however, all systems were evaluated with all three metrics, and participants were strongly encouraged to output all relevant annotation, even if they just copy values predicted by the baseline model. When parsers are applied to raw text, the metric must be adjusted to the possibility that the number of nodes in gold-standard annotation and in the system output vary. Therefore, the evaluation starts with aligning system nodes and gold nodes. A dependency relation cannot be counted as correct if one of the nodes could not be aligned to a gold node. See Section 3.4 and onward for more details on alignment.</p><p>The evaluation software is a Python script that computes the three main metrics and a number of additional statistics. It is freely available for download from the shared task website. 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">LAS: Labeled Attachment Score</head><p>The standard evaluation metric of dependency parsing is the labeled attachment score (LAS), i.e., the percentage of nodes with correctly assigned reference to the parent node, including the label (type) of the relation. For scoring purposes, only <ref type="bibr">Content nsubj, obj, iobj, csubj, ccomp, xcomp, obl, vocative, expl, dislocated, advcl, advmod, discourse, nmod, appos, nummod, acl, amod, conj, fixed, flat, compound, list, parataxis, orphan, goeswith, reparandum, root, dep Function aux, cop, mark, det, clf, case, cc</ref> Ignored punct  universal dependency labels were taken into account, which means that language-specific subtypes such as expl:pv (pronoun of a pronominal verb), a subtype of the universal relation expl (expletive), were truncated to expl both in the gold standard and in the system output before comparing them.</p><p>In the end-to-end evaluation of our task, LAS is re-defined as the harmonic mean (F 1 ) of precision P and recall R, where</p><formula xml:id="formula_0">P = #correctRelations #systemNodes (1) R = #correctRelations #goldNodes (2) LAS = 2P R P + R<label>(3)</label></formula><p>Note that attachment of all nodes including punctuation is evaluated. LAS is computed separately for each of the 82 test files and a macro-average of all these scores is used to rank the systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">MLAS: Morphology-Aware Labeled</head><p>Attachment Score MLAS aims at cross-linguistic comparability of the scores. It is an extension of CLAS <ref type="bibr" target="#b21">(Nivre and Fang, 2017)</ref>, which was tested experimentally in the 2017 task. CLAS focuses on dependencies between content words and disregards attachment of function words; in MLAS, function words are not ignored, but they are treated as features of content words. In addition, part-of-speech tags and morphological features are evaluated, too.</p><p>The idea behind MLAS is that function words often correspond to morphological features in other languages. Furthermore, languages with many function words (e.g., English) have longer sentences than morphologically rich languages (e.g., Finnish), hence a single error in Finnish costs the parser significantly more than an error in English according to LAS.</p><p>The core part is identical to LAS (Section 3.1): for aligned system and gold nodes, their respective parent nodes are considered; if the system parent is not aligned with the gold parent, or if the universal relation label differs, the word is not counted as correctly attached. Unlike LAS, certain types of relations (Table <ref type="table" target="#tab_4">3</ref>) are not evaluated directly. Words attached via such relations (in either system or gold data) are not counted as independent words. Instead, they are treated as features of the content words they belong to. Therefore, a system-produced word counts as correct if it is aligned and attached correctly, its universal POS tag and selected morphological features (Table 4) are correct, all its function words are attached correctly, and their POS tags and features are also correct. Punctuation nodes are neither content nor function words; their attachment is ignored in MLAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">BLEX: Bilexical Dependency Score</head><p>BLEX is similar to MLAS in that it focuses on relations between content words. Instead of morphological features, it incorporates lemmatization in the evaluation. It is thus closer to semantic content and evaluates two aspects of UD annota-tion that are important for language understanding: dependencies and lexemes. The inclusion of this metric should motivate the competing teams to model lemmas, the last important piece of annotation that is not captured by the other metrics. A system that scores high in all three metrics will thus be a general-purpose language-analysis tool that tackles segmentation, morphology and surface syntax.</p><p>Computation of BLEX is analogous to LAS and MLAS. Precision and recall of correct attachments is calculated, attachment of function words and punctuation is ignored (Table <ref type="table" target="#tab_4">3</ref>). An attachment is correct if the parent and child nodes are aligned to the corresponding nodes in gold standard, if the universal dependency label is correct, and if the lemma of the child node is correct.</p><p>A few UD treebanks lack lemmatization (or, as in Uyghur, have lemmas only for some words and not for others). A system may still be able to predict the lemmas if it learns them in other treebanks. Such system should not be penalized just because no gold standard is available; therefore, if the gold lemma is a single underscore character (" "), any system-produced lemma is considered correct.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Token Alignment</head><p>UD defines two levels of token/word segmentation. The lower level corresponds to what is usually understood as tokenization. However, unlike some popular tokenization schemes, it does not include any normalization of the non-whitespace characters. We can safely assume that any two tokenizations of a text differ only in whitespace while the remaining characters are identical. There is thus a 1-1 mapping between gold and system nonwhitespace characters, and two tokens are aligned if all their characters match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Syntactic Word Alignment</head><p>The higher segmentation level is based on the notion of syntactic word. Some languages contain multi-word tokens (MWT) that are regarded as contractions of multiple syntactic words. For example, the German token zum is a contraction of the preposition zu "to" and the article dem "the".</p><p>Syntactic words constitute independent nodes in dependency trees. As shown by the example, it is not required that the MWT is a pure concatenation of the participating words; the simple token alignment thus does not work when MWTs are involved. Fortunately, the CoNLL-U file format used in UD clearly marks all MWTs so we can detect them both in system output and in gold data. Whenever one or more MWTs have overlapping spans of surface character offsets, the longest common subsequence algorithm is used to align syntactic words within these spans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Sentence Segmentation</head><p>Words are aligned and dependencies are evaluated in the entire file without considering sentence segmentation. Still, the accuracy of sentence boundaries has an indirect impact on attachment scores: any missing or extra sentence boundary necessarily makes one or more dependency relations incorrect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Invalid Output</head><p>If a system fails to produce one of the 82 files or if the file is not valid CoNLL-U format, the score of that file (counting towards the system's macroaverage) is zero.</p><p>Formal validity is defined more leniently than for UD-released treebanks. For example, a nonexistent dependency type does not render the whole file invalid, it only costs the system one incorrect relation. However, cycles and multi-root sentences are disallowed. A file is also invalid if there are character mismatches that could make the token-alignment algorithm fail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Extrinsic Parser Evaluation</head><p>The metrics described above are all intrinsic measures: they evaluate the grammatical analysis task per se, with the hope that better scores correspond to output that is more useful for downstream NLP applications. Nevertheless, such correlations are not automatically granted. We thus seek to complement our task with an extrinsic evaluation, where the output of parsing systems is exploited by applications like biological event extraction, opinion analysis and negation scope resolution.</p><p>This optional track involves English only. It is organized in collaboration with the EPE initiative; 7 for details see <ref type="bibr" target="#b8">Fares et al. (2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">TIRA: The System Submission Platform</head><p>Similarly to our 2017 task and to some other recent CoNLL shared tasks, we employed the cloud-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7</head><p>based evaluation platform TIRA <ref type="bibr" target="#b27">(Potthast et al., 2014)</ref>, <ref type="bibr">8</ref> which implements the evaluation as a service paradigm <ref type="bibr" target="#b10">(Hanbury et al., 2015)</ref>. Instead of processing test data on their own hardware and submitting the outputs, participants submit working software. Naturally, software submissions bring about additional overhead for both organizers and participants, whereas the goal of an evaluation platform like TIRA is to reduce this overhead to a bearable level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Blind Evaluation</head><p>Traditionally, evaluations in shared tasks are halfblind (the test data are shared with participants while the ground truth is withheld). TIRA enables fully blind evaluation, where the software is locked in a datalock together with the test data, its output is recorded but all communication channels to the outside are closed or tightly moderated. The participants do not even see the input to their software. This feature of TIRA was not too important in the present task, as UD data is not secret, and the participants were simply trusted that they would not exploit any knowledge of the test data they might have access to. However, closing down all communication channels also has its downsides, since participants cannot check their running software; before the system run completes, even the task moderator does not see whether the system is really producing output and not just sitting in an endless loop. In order to alleviate this extra burden, we made two modifications compared to the previous year: 1. Participants were explicitly advised to invoke shorter runs that process only a subset of the test files. The organizers would then stitch the partial runs into one set of results. 2. Participants were able to see their scores on the test set rounded to the nearest multiple of 5%. This way they could spot anomalies possibly caused by illselected models. The exact scores remained hidden because we did not want the participants to fine-tune their systems against the test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Replicability</head><p>It is desirable that published experiments can be re-run yielding the same results, and that the algorithms can be tested on alternative test data in the future. Ensuring both requires that a to-beevaluated software is preserved in working con-dition for as long as possible. TIRA supplies participants with a virtual machine, offering a range of commonly used operating systems. Once deployed and tested, the virtual machines are archived to preserve the software within.</p><p>In addition, some participants agreed to share their code so that we decided to collect the respective projects in an open source repository hosted on GitHub. 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Baseline System</head><p>We prepared a set of baseline models using UD-Pipe 1.2 <ref type="bibr" target="#b35">(Straka and Straková, 2017)</ref>.</p><p>The baseline models were released together with the UD 2. In addition to the treebank-specific models, we also trained a "mixed model" on samples from all treebanks. Specifically, we utilized the first 200 training sentences of each treebank (or less in case of small treebanks) as training data, and at most 20 sentences from each treebank's development set as development data.</p><p>The baseline models, together with all information needed to replicate them (hyperparameters, the modified train-dev split where applicable, and pre-computed word embeddings for the parser) are available from http://hdl.handle.net/11234/ 1-2859.</p><p>Additionally, the released archive also contains the training and development data with predicted morphology. Morphology in development data was predicted using the baseline models, morphology in training data via "jack-knifing" (split the training set into 10 parts, train a model on 9 parts, use it to predict morphology in the tenth part, repeat for all 10 target parts). The same hyperparameters were used as those used to train the baseline model on the entire training set.</p><p>The UDPipe baseline models are able to reconstruct nearly all annotation from CoNLL-U files -they can generate segmentation, tokenization,  6 Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Official Parsing Results</head><p>Table <ref type="table" target="#tab_9">6</ref> gives the main ranking of participating systems by the LAS F 1 score macro-averaged over all 82 test files. The table also shows the performance of the baseline UDPipe system; 17 of the 25 systems managed to outperform it. The baseline is comparatively weaker than in the 2017 task (only 12 out of 32 systems beat the baseline there).</p><p>The ranking of the baseline system by MLAS is similar (Table <ref type="table" target="#tab_11">7</ref>) but in BLEX, the baseline jumps to rank 13 (Table <ref type="table" target="#tab_13">8</ref>). Besides the simple explanation that UDPipe 1.2 is good at lemmatization, we could also hypothesize that some teams put less effort in building lemmatization models (see also the last column in Table <ref type="table" target="#tab_1">10</ref>). Each ranking has a different winning system, although the other two winners are typically closely following. The same 8-10 systems occupy best positions in all three tables, though with variable mutual ranking. Some teams seem to have deliberately neglected some of the evaluated attributes: Uppsala is rank 7 in LAS and MLAS, but 24 in Team LAS 1. HIT-SCIR <ref type="bibr">(Che et al.)</ref> 75.84 2. TurkuNLP <ref type="bibr">(Kanerva et al.)</ref> 73.28 3. UDPipe Future <ref type="bibr">(Straka)</ref> 73.11 LATTICE <ref type="bibr">(Lim et al.)</ref> 73.02 ICS PAS <ref type="bibr">(Rybak and Wróblewska)</ref>   While the LAS scores on individual treebanks are comparable to the 2017 task, the macro average is not, because the set of treebanks is different, and the impact of low-resource languages seems to be higher in the present task.</p><p>We used bootstrap resampling to compute 95% confidence intervals: they are in the range ±0.11 to ±0.16 (% LAS/MLAS/BLEX) for all systems except SParse (where it is ±0.00).  We used paired bootstrap resampling to compute whether the difference between two neighboring systems is significant (p &lt; 0.05). 10</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Secondary Metrics</head><p>In addition to the main LAS ranking, we evaluated the systems along multiple other axes, which may shed more light on their strengths and weaknesses. This section provides an overview of selected secondary metrics for systems matching or surpassing the baseline; a large number of additional results are available at the shared task website. <ref type="bibr">11</ref> The website also features a LAS ranking of unofficial system runs, i.e. those that were not 10 Using Udapi  eval.Conll18, marked by the presence or absence of horizontal lines in Tables <ref type="table" target="#tab_9">6-8</ref>  marked by their teams as primary runs, or were even run after the official evaluation phase closed and test data were unblinded. The difference from the official results is much less dramatic than in 2017, with the exception of the team SParse, who managed to fix their software and produce more valid output files.</p><p>As an experiment, we also applied the 2017 system submissions to the 2018 test data. This allows us to test how many systems can actually be used to produce new data without a glitch, as well as to see to what extent the results change over one year and two releases of UD. Here it should be noted that not all of the 2018 task languages and treebanks were present in the 2017 task, therefore causing many systems fail due to an unknown language or treebank code. The full results of this experiment are available on the shared task website. 12 Table <ref type="table">9</ref> evaluates detection of tokens, syntactic words and sentences. About a third of the systems trusted the baseline segmentation; this is less than in 2017. For most languages and in aggregate, the segmentation scores are very high and their impact on parsing scores is not easy to prove; but it likely played a role in languages where segmentation is hard. For example, HIT-SCIR's word segmentation in Vietnamese surpasses the second system by a margin of 6 percent points; likewise, the system's advantage in LAS and MLAS (but not in BLEX!) amounts to 7-8 points. Similarly, Uppsala and ParisNLP achieved good segmenta- tion scores (better than their respective macroaverages) on Arabic. They were able to translate it into better LAS, but not MLAS and BLEX, where there were too many other chances to make an error.</p><p>The complexity of the new metrics, especially MLAS, is further underlined by Table <ref type="table" target="#tab_1">10</ref>: Uppsala is the clear winner in both UPOS tags and morphological features, but 6 other teams had better dependency relations and better MLAS. Note that as with segmentation, morphology predicted by the baseline system was available, though only a few systems seem to have used it without attempting to improve it. Regarding ranking, the Stanford system makes a remarkable jump when it does not have to carry the load of underresourced languages: from rank 8 to 2 in LAS, from 3 to 1 in MLAS and from 5 to 2 in BLEX.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Partial Results</head><p>Table <ref type="table" target="#tab_1">12</ref> gives the LAS F 1 score on the nine low-resource languages only. Here we have a true specialist: The team CUNI x-ling lives up to its name and wins in all three scores, although in the overall ranking they fall even slightly behind the baseline. On the other hand, the scores are extremely low and the outputs are hardly useful for any downstream application. Especially morphol- surprise languages and had higher scores there. <ref type="bibr">13</ref> This is because in 2017, the segmentation, POS tags and morphology UDPipe models were trained on the test data, applied to it via cross-validation, and made available to the systems. Such an approach makes the conditions unrealistic, therefore it was not repeated this year. Consequently, parsing these languages is now much harder.</p><p>In contrast, the results on the 7 treebanks with "small" training data and no development data (Table <ref type="table" target="#tab_1">13</ref>  <ref type="bibr">BLEX)</ref>. There are also two treebanks that are the sole representatives of their languages: Irish and North Sámi. Their best LAS is around 70%: com-parable to Nynorsk LIA but much better than SST. ICS PAS is the most successful system in the domain of small treebanks, especially when judged by MLAS and BLEX.</p><p>Table <ref type="table" target="#tab_1">14</ref> gives the average LAS on the 5 extra test sets (no own training data, but other treebanks of the same language exist). Four of them come from the Parallel UD (PUD) collection introduced in the 2017 task . The fifth, Japanese Modern, turned out to be one of the toughest test sets in this shared task. There is another Japanese treebank, GSD, with over 160K training tokens, but the Modern dataset seems almost inapproachable with models trained on GSD. A closer inspection reveals why: despite its name, it is actually a corpus of historical Japanese, although from the relatively recent Meiji and Taishō periods . An average sentence in GSD is about 1.3× longer than in Modern. GSD has significantly more tokens tagged as auxiliaries, but more importantly, the top ten AUX lemmas in the two treebanks are completely disjoint sets. Some other words are out-of-vocabulary because their preferred spelling changed. For instance, the demonstrative pronoun sore is written using hiragana in GSD, but a kanji character is used in Modern. Striking differences can be observed also in dependency relations: in GSD, 3.7% relations are nsubj (subject), and 1.2% are cop (copula). In Modern, there is just 0.13% of subjects, and not a single occurrence of a copula.</p><p>See Tables <ref type="table" target="#tab_1">15, 16</ref> and 17 for a ranking of all test sets by the best scores achieved on them by any parser. Note that this cannot be directly interpreted as a ranking of languages by their parsing difficulty: many treebanks have high ranks simply because the corresponding training data is large. Table <ref type="table" target="#tab_1">18</ref> compares average LAS and MLAS for each treebank.</p><p>Finally, Tables <ref type="table" target="#tab_1">19 and 20</ref> show the treebanks where word and sentence segmentation was extremely difficult (judged by the average parser score). Not surprisingly, word segmentation is difficult for the low-resource languages and for languages like Chinese, Vietnamese, Japanese and Thai, where spaces do not separate words. Notably the Japanese GSD set is not as difficult, but whoever trusted it, crashed on the "Modern" set. Sentence segmentation was particularly hard for treebanks without punctuation, i.e., most of the classical languages and spoken data.       </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis of Submitted Systems</head><p>Table <ref type="table" target="#tab_1">21</ref> gives an overview of 24 of the systems evaluated in the shared task. The overview is based on a post-evaluation questionnaire to which 24 of 25 teams responded. Systems are ordered alphabetically by name and their LAS rank is indicated in the second column.</p><p>Looking first at word and sentence segmentation, we see that, while a clear majority of systems (19/24) rely on the baseline system for segmentation, slightly more than half (13/24) have developed their own segmenter, or tuned the baseline segmenter, for at least a subset of languages. This is a development from 2017, where only 7 out of 29 systems used anything other than the baseline segmenter.</p><p>When it comes to morphological analysis, including universal POS tags, features and lemmas, all systems this year include some such component, and only 6 systems rely entirely on the base-   MultiLing = multilingal models used for low-resource (L) or small (S) languages. In all columns, Base (or B) refers to the Baseline UDPipe system or the baseline word embeddings provided by the organizers, while None means that there is no corresponding component in the system.</p><p>line UDPipe system. This is again quite different from 2017, where more than half the systems either just relied on the baseline tagger (13 systems) or did not predict any morphology at all (3 systems). We take this to be primarily a reflection of the fact that two out of three official metrics included (some) morphological analysis this year, although 3 systems did not predict the lemmas required for the BLEX metric (and 2 systems only predicted universal POS tags, no features). As far as we can tell from the questionnaire responses, only 3 systems used a model where morphology and syntax were predicted jointly. <ref type="bibr">14</ref> For syntactic parsing, most teams (19) use a single parsing model, while 5 teams, including the winning HIT-SCIR system, build ensemble models, either for all languages or a subset of them. When it comes to the type of parsing model, we observe that graph-based models are more popular than transition-based models this year, while the opposite was true in 2017. We hypothesize that this is due to the superior performance of the Stanford graph-based parser in last year's shared task, and many of the high-performing systems this year either incorporate that parser or a reimplementation of it. <ref type="bibr">15</ref> The majority of parsers make use of pre-trained word embeddings. Most popular are the Facebook embeddings, which are used by 17 systems, followed by the baseline embeddings provided by the organizers (11), and embeddings trained on web crawl data (4). <ref type="bibr">16</ref> When it comes to additional data, over and above the treebank training sets and pretrained word embeddings, the most striking observation is that a majority of systems ( <ref type="formula">16</ref>) did not use any at all. Those that did primarily used OPUS (5), Wikipedia dumps (3), Apertium morphological analyzers (2), and Universal Morphological Lattices (2). The CUNI x-ling system, which focused on low-resource languages, also exploited UniMorph and WALS (in addition to OPUS and Wikipedia).</p><p>Finally, we note that a majority of systems make use of models trained on multiple languages to improve parsing for languages with little or no training data. According to the questionnaire responses, 15 systems use multilingual models for the languages classified as "low-resource", while 7 systems use them for the languages classified as "small". <ref type="bibr">17</ref> Only one system relied on the baseline delexicalized parser trained on data from all languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>The CoNLL 2018 Shared Task on UD parsing, the second in the series, was novel in several respects. Besides using cross-linguistically consistent linguistic representations, emphasizing end-to-end processing of text, and in using a multiply parallel test set, as in 2017, it was unusual also in featuring an unprecedented number of languages and treebanks and in integrating cross-lingual learning for resource-poor languages. Compared to the first edition of the task in 2017, this year several languages were provided with little-to-no resources, whereas in 2017, predicted morphology trained on the language in question was available for all of the languages. The most extreme example of these is Thai, where the only accessible resource was the Facebook Research Thai embeddings model and the OPUS parallel corpora. This year's task also introduced two additional metrics that take into account morphology and lemmatization. This encouraged the development of truly end-to-end full parsers, producing complete parses including morphological features and lemmas in addition to the syntactic tree. This also aimed to improve the utility of the systems developed in the shared task for later downstream applications. For most UD languages, these parsers represent a new state of the art for end-to-end dependency parsing.</p><p>The analysis of the shared task results has so far only scratched the surface, and we refer to the system description papers for more in-depth analysis of individual systems and their performance. For many previous CoNLL shared tasks, the task itself has only been the starting point of a long and fruitful research strand, enabled by the resources created for the task. We hope and believe that the 2017 and 2018 UD parsing tasks will join this tradition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>2 training data. For each of the 73 treebanks with non-empty training data we trained one UDPipe model, utilizing training data for training and development data for hyperparameter tuning. If a treebank had no development data, we cut 10% of the training sentences and considered it as development data for the purpose of tuning hyperparameters of the baseline model (employing only the remainder of the original training data for the actual training in that case).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>21: Classification of participating systems. R = LAS ranking. Segment = word/sentence segmentation. Morph = morphological analysis, including universal POS tags [U], features [F] and lemmas [L], with subscripts for subsets [Joint = morphological component trained jointly with syntactic parser]. Syntax = syntactic parsing [Single = single parser; Ensemble (or Ens) = parser ensemble; G = graph-based; T = transition-based]. WEmb = pre-trained word embeddings [FB = Facebook; Crawl = trained on web crawl data provided by the organizers; Wiki = trained on Wikipedia data; Train = trained on treebank training data]. Additional Data = data used in addition to treebank training sets [OPUS (or O) = OPUS, Aper = Apertium morphological analysers, Wikt = Wiktionary, Wiki = Wikipedia, UM = UniMorph, UML = Universal Morphological Lattices, WALS = World Atlas of Language Structures].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell>the nearest</cell></row></table><note>Overview of the 82 test treebanks. TbkCode = Treebank identifier, consisting of the ISO 639 language code followed by a treebank-specific code. 2017 = Code of the corresponding treebank in the 2017 task if applicable ("NA" otherwise). TrWrds = Size of training data, rounded to</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Supporting data overview: Number of</cell></row><row><cell>words (M = million; K = thousand) for each lan-</cell></row><row><cell>guage.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Universal dependency relations considered as pertaining to content words and function words,</cell></row><row><cell>respectively, in MLAS. Content word relations are evaluated directly; words attached via functional</cell></row><row><cell>relations are treated as features of their parent nodes.</cell></row><row><cell>Features PronType, NumType, Poss, Reflex, Foreign, Abbr, Gender,</cell></row><row><cell>Animacy, Number, Case, Definite, Degree, VerbForm, Mood,</cell></row><row><cell>Tense, Aspect, Voice, Evident, Polarity, Person, Polite</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Universal features whose values are evaluated in MLAS. Any other features are ignored.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Substitution models of the baseline systems for treebanks without training data. multi-word token splitting, morphological annotation (lemmas, UPOS, XPOS and FEATS) and dependency trees. Participants were free to use any part of the model in their systems -for all test sets, we provided UDPipe processed variants in addition to raw text inputs.Baseline UDPipe Shared Task System The shared task baseline system employs the UDPipe 1.2 baseline models. For the nine treebanks without their own training data, a substitution model according to Table5was used.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Ranking of the participating systems by the labeled attachment F 1 -score (LAS), macroaveraged over 82 test sets. Pairs of systems with significantly (p &lt; 0.05) different LAS are separated by a line. Citations refer to the corresponding system-description papers in this volume.</figDesc><table /><note>BLEX; IBM NY is rank 13 in LAS but 24 in MLAS and 23 in BLEX.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc></figDesc><table /><note>Ranking of the participating systems by MLAS, macro-averaged over 82 test sets. Pairs of systems with significantly (p &lt; 0.05) different MLAS are separated by a line.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table /><note>Ranking of the participating systems by BLEX, macro-averaged over 82 test sets. Pairs of systems with significantly (p &lt; 0.05) different BLEX are separated by a line.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell>gives the three main scores averaged over</cell></row><row><cell>the 61 "big" treebanks (training data larger than</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head></head><label></label><figDesc>) are higher on average, but again the variance is significant. The smallest treebank</figDesc><table><row><cell>Team</cell><cell cols="3">LAS MLAS BLEX</cell></row><row><cell>1. HIT-SCIR</cell><cell cols="3">74.20 55.52 62.34</cell></row><row><cell>2. Stanford</cell><cell cols="3">73.14 58.75 61.96</cell></row><row><cell>3. LATTICE</cell><cell cols="3">72.34 55.60 60.42</cell></row><row><cell>4. Uppsala</cell><cell cols="3">72.27 57.80 29.73</cell></row><row><cell>5. ICS PAS</cell><cell cols="3">72.18 58.07 60.97</cell></row><row><cell>6. TurkuNLP</cell><cell cols="3">71.78 57.54 63.25</cell></row><row><cell>7. UDPipe Future</cell><cell cols="3">71.57 57.93 61.52</cell></row><row><cell>8. CEA LIST</cell><cell cols="3">70.45 54.99 57.83</cell></row><row><cell>9. NLP-Cube</cell><cell cols="3">69.83 55.01 54.15</cell></row><row><cell>10. IBM NY</cell><cell cols="3">69.40 46.59 38.12</cell></row><row><cell>11. AntNLP</cell><cell cols="3">68.87 53.47 57.71</cell></row><row><cell>12. UniMelb</cell><cell cols="3">68.72 52.05 56.77</cell></row><row><cell>13. Phoenix</cell><cell cols="3">66.97 52.26 55.69</cell></row><row><cell cols="4">14. BASELINE UDPipe 66.63 51.75 54.87</cell></row><row><cell>15. KParse</cell><cell cols="3">66.55 51.29 54.45</cell></row><row><cell>16. SLT-Interactions</cell><cell cols="3">64.73 48.47 54.90</cell></row><row><cell>17. CUNI x-ling</cell><cell cols="3">64.70 49.71 52.72</cell></row><row><cell>18. ParisNLP</cell><cell cols="3">64.09 48.79 53.16</cell></row><row><cell>19. Fudan</cell><cell cols="3">63.54 45.54 50.73</cell></row><row><cell>20. LeisureX</cell><cell cols="3">61.05 41.95 50.60</cell></row><row><cell>21. BOUN</cell><cell cols="3">56.46 41.91 45.12</cell></row><row><cell>22. HUJI</cell><cell cols="3">56.35 46.52 50.10</cell></row><row><cell>23. iParse</cell><cell cols="3">44.20 33.43 38.18</cell></row><row><cell>24. ONLP lab</cell><cell cols="3">43.33 30.20 20.08</cell></row><row><cell>25. ArmParser</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>SParse</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell cols="4">Table 14: Average attachment score on the 5 addi-</cell></row><row><cell cols="4">tional test sets for high-resource languages: Czech</cell></row><row><cell cols="4">PUD, English PUD, Finnish PUD, Japanese Mod-</cell></row><row><cell cols="4">ern and Swedish PUD (ordered by LAS F 1 scores;</cell></row><row><cell cols="4">out-of-order scores in the other two columns are</cell></row><row><cell>bold).</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">in the group, Norwegian Nynorsk LIA, has only</cell></row><row><cell cols="4">3583 training words. There are two larger Nor-</cell></row><row><cell cols="4">wegian treebanks that could be used as additional</cell></row><row><cell cols="4">training sources. However, the LIA treebank con-</cell></row><row><cell cols="4">sists of spoken dialects and is probably quite dis-</cell></row><row><cell cols="4">similar to the other treebanks. The same can be</cell></row><row><cell cols="4">said about Slovenian SST and the other Slove-</cell></row><row><cell cols="4">nian treebank; SST is the most difficult dataset</cell></row><row><cell cols="4">in the group, despite of having almost 20K of its</cell></row><row><cell cols="4">own training words. Other treebanks, like Rus-</cell></row><row><cell cols="4">sian Taiga and Galician TreeGal, have much bet-</cell></row><row><cell cols="4">ter scores (74% LAS, about 61% MLAS and 64%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 15 :</head><label>15</label><figDesc>Treebank ranking by best parser LAS (Avg=average LAS over all systems, out-of-order scores in bold).</figDesc><table><row><cell>Treebank</cell><cell>MLAS Best system</cell><cell>Avg StDev</cell></row><row><cell>1. pl lfg</cell><cell cols="2">86.93 UDPipe Future 73.73 ± 7.29</cell></row><row><cell>2. ru syntagrus</cell><cell cols="2">86.76 UDPipe Future 71.63 ± 9.36</cell></row><row><cell>3. cs pdt</cell><cell cols="2">85.10 UDPipe Future 73.61 ± 6.32</cell></row><row><cell>4. cs fictree</cell><cell>84.23 ICS PAS</cell><cell>69.91 ± 7.77</cell></row><row><cell>5. ca ancora</cell><cell cols="2">84.07 UDPipe Future 74.62 ± 7.69</cell></row><row><cell>6. es ancora</cell><cell>83.93 Stanford</cell><cell>74.61 ± 7.43</cell></row><row><cell>7. it isdt</cell><cell>83.89 Stanford</cell><cell>77.14 ± 8.89</cell></row><row><cell>8. fi pud</cell><cell>83.78 Stanford</cell><cell>62.38 ±14.83</cell></row><row><cell>9. no bokmaal</cell><cell cols="2">83.68 UDPipe Future 70.75 ± 8.92</cell></row><row><cell>10. cs cac</cell><cell cols="2">83.42 UDPipe Future 71.39 ± 6.89</cell></row><row><cell>11. bg btb</cell><cell cols="2">83.12 UDPipe Future 73.18 ± 7.15</cell></row><row><cell>12. fr sequoia</cell><cell>82.55 Stanford</cell><cell>70.42 ± 9.04</cell></row><row><cell>13. sl ssj</cell><cell>82.38 Stanford</cell><cell>62.41 ± 9.18</cell></row><row><cell>14. no nynorsk</cell><cell cols="2">81.86 UDPipe Future 68.62 ± 9.45</cell></row><row><cell>15. ko kaist</cell><cell>81.29 HIT-SCIR</cell><cell>70.18 ± 9.36</cell></row><row><cell>16. ko gsd</cell><cell>80.85 HIT-SCIR</cell><cell>63.73 ±16.02</cell></row><row><cell>17. fi tdt</cell><cell>80.84 Stanford</cell><cell>65.27 ± 9.22</cell></row><row><cell>18. fa seraji</cell><cell cols="2">80.83 UDPipe Future 71.23 ± 7.77</cell></row><row><cell>19. pl sz</cell><cell>80.77 Stanford</cell><cell>64.80 ± 8.49</cell></row><row><cell>20. fro srcmf</cell><cell cols="2">80.28 UDPipe Future 65.19 ±16.58</cell></row><row><cell>21. la ittb</cell><cell>79.84 ICS PAS</cell><cell>67.77 ± 8.37</cell></row><row><cell>22. fi ftb</cell><cell>79.65 TurkuNLP</cell><cell>66.11 ± 8.86</cell></row><row><cell>23. sv talbanken</cell><cell>79.32 Stanford</cell><cell>68.05 ± 8.49</cell></row><row><cell>24. ro rrt</cell><cell>78.68 TurkuNLP</cell><cell>67.43 ± 7.24</cell></row><row><cell>25. el gdt</cell><cell>78.66 Stanford</cell><cell>64.29 ± 8.28</cell></row><row><cell>26. fr gsd</cell><cell>78.44 Stanford</cell><cell>69.33 ± 8.59</cell></row><row><cell>27. hi hdtb</cell><cell cols="2">78.30 UDPipe Future 68.48 ± 5.88</cell></row><row><cell>28. sr set</cell><cell cols="2">77.73 UDPipe Future 67.33 ± 5.96</cell></row><row><cell>29. da ddt</cell><cell>77.31 Stanford</cell><cell>65.00 ± 6.89</cell></row><row><cell>30. et edt</cell><cell>76.97 TurkuNLP</cell><cell>63.59 ± 8.34</cell></row><row><cell>31. nl alpino</cell><cell>76.52 Stanford</cell><cell>62.82 ± 9.81</cell></row><row><cell>32. en ewt</cell><cell>76.33 Stanford</cell><cell>66.84 ± 5.86</cell></row><row><cell>33. pt bosque</cell><cell>75.94 Stanford</cell><cell>66.22 ± 6.76</cell></row><row><cell>34. cs pud</cell><cell cols="2">75.81 UDPipe Future 60.47 ±11.36</cell></row><row><cell>35. af afribooms</cell><cell cols="2">75.67 UDPipe Future 63.76 ± 7.06</cell></row><row><cell>36. sk snk</cell><cell>75.01 Stanford</cell><cell>56.82 ± 8.32</cell></row><row><cell>37. en pud</cell><cell>74.86 Stanford</cell><cell>63.05 ± 7.89</cell></row><row><cell cols="2">38. nl lassysmall 74.11 Stanford</cell><cell>61.95 ± 9.12</cell></row><row><cell>39. hr set</cell><cell>73.44 Stanford</cell><cell>60.08 ± 7.07</cell></row><row><cell>40. en gum</cell><cell>73.24 ICS PAS</cell><cell>61.72 ± 7.69</cell></row><row><cell>41. ja gsd</cell><cell>72.62 HIT-SCIR</cell><cell>59.52 ± 6.20</cell></row><row><cell>42. uk iu</cell><cell cols="2">72.27 UDPipe Future 55.45 ± 8.08</cell></row><row><cell>43. en lines</cell><cell>72.25 ICS PAS</cell><cell>62.35 ± 8.04</cell></row><row><cell>44. eu bdt</cell><cell cols="2">71.73 UDPipe Future 58.49 ± 8.62</cell></row><row><cell>45. gl ctg</cell><cell>70.92 Stanford</cell><cell>57.92 ±14.10</cell></row><row><cell>46. ar padt</cell><cell>68.54 Stanford</cell><cell>53.28 ± 6.12</cell></row><row><cell>47. it postwita</cell><cell>68.50 Stanford</cell><cell>51.72 ± 8.80</cell></row><row><cell>48. id gsd</cell><cell>68.36 Stanford</cell><cell>61.03 ± 6.49</cell></row><row><cell>49. lv lvtb</cell><cell>67.89 Stanford</cell><cell>53.31 ± 7.96</cell></row><row><cell>50. hu szeged</cell><cell cols="2">67.13 UDPipe Future 53.08 ± 8.01</cell></row><row><cell>51. zh gsd</cell><cell>66.62 HIT-SCIR</cell><cell>50.42 ± 5.87</cell></row><row><cell>52. sv lines</cell><cell>66.58 Stanford</cell><cell>57.40 ± 7.43</cell></row><row><cell>53. fr spoken</cell><cell>64.67 HIT-SCIR</cell><cell>53.17 ± 5.61</cell></row><row><cell>54. he htb</cell><cell>63.38 Stanford</cell><cell>45.22 ± 4.94</cell></row><row><cell>55. cu proiel</cell><cell>63.31 Stanford</cell><cell>50.28 ± 6.69</cell></row><row><cell>56. ru taiga</cell><cell>61.59 ICS PAS</cell><cell>37.16 ± 7.53</cell></row><row><cell>57. gl treegal</cell><cell cols="2">60.63 UDPipe Future 47.35 ± 5.93</cell></row><row><cell>58. grc proiel</cell><cell>60.27 Stanford</cell><cell>47.62 ±11.82</cell></row><row><cell>59. la proiel</cell><cell>59.36 Stanford</cell><cell>47.79 ± 6.90</cell></row><row><cell>60. de gsd</cell><cell>58.04 TurkuNLP</cell><cell>39.13 ±10.35</cell></row><row><cell>61. ur udtb</cell><cell>57.98 TurkuNLP</cell><cell>49.64 ± 4.21</cell></row><row><cell cols="2">62. no nynorsklia 57.51 ICS PAS</cell><cell>37.08 ± 7.78</cell></row><row><cell>63. sme giella</cell><cell>57.47 TurkuNLP</cell><cell>38.29 ±12.37</cell></row><row><cell>64. got proiel</cell><cell cols="2">56.45 UDPipe Future 46.18 ± 5.36</cell></row><row><cell>65. tr imst</cell><cell>55.73 Stanford</cell><cell>45.26 ± 6.15</cell></row><row><cell>66. grc perseus</cell><cell>54.98 HIT-SCIR</cell><cell>35.65 ±12.31</cell></row><row><cell>67. sv pud</cell><cell>51.74 TurkuNLP</cell><cell>39.41 ± 7.78</cell></row><row><cell>68. la perseus</cell><cell>49.77 ICS PAS</cell><cell>28.67 ± 8.06</cell></row><row><cell>69. vi vtb</cell><cell>47.61 HIT-SCIR</cell><cell>32.45 ± 7.28</cell></row><row><cell>70. sl sst</cell><cell>45.93 ICS PAS</cell><cell>33.12 ± 5.33</cell></row><row><cell>71. ga idt</cell><cell>45.79 TurkuNLP</cell><cell>33.70 ± 5.18</cell></row><row><cell>72. ug udt</cell><cell cols="2">45.78 UDPipe Future 35.08 ± 5.96</cell></row><row><cell>73. br keb</cell><cell>13.91 Uppsala</cell><cell>1.52 ± 3.34</cell></row><row><cell>74. hy armtdp</cell><cell>13.36 CUNI x-ling</cell><cell>5.94 ± 2.92</cell></row><row><cell>75. ja modern</cell><cell>11.82 Uppsala</cell><cell>6.45 ± 2.59</cell></row><row><cell>76. hsb ufal</cell><cell>9.09 LATTICE</cell><cell>4.66 ± 2.37</cell></row><row><cell>77. kk ktb</cell><cell>8.93 CUNI x-ling</cell><cell>5.04 ± 2.34</cell></row><row><cell>78. kmr mg</cell><cell>7.98 IBM NY</cell><cell>4.01 ± 1.96</cell></row><row><cell>79. th pud</cell><cell>6.29 CUNI x-ling</cell><cell>0.42 ± 1.27</cell></row><row><cell>80. pcm nsc</cell><cell>5.30 KParse</cell><cell>3.00 ± 1.30</cell></row><row><cell>81. bxr bdt</cell><cell>2.98 AntNLP</cell><cell>1.33 ± 0.72</cell></row><row><cell>82. fo oft</cell><cell>1.07 CUNI x-ling</cell><cell>0.37 ± 0.21</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 16 :</head><label>16</label><figDesc>Treebank ranking by best parser MLAS.</figDesc><table><row><cell>Treebank</cell><cell>BLEX Best system</cell><cell>Avg StDev</cell></row><row><cell>1. pl lfg</cell><cell>90.42 TurkuNLP</cell><cell>72.81 ±16.96</cell></row><row><cell>2. ru syntagrus</cell><cell>88.65 TurkuNLP</cell><cell>68.57 ±18.07</cell></row><row><cell>3. cs pdt</cell><cell>87.91 HIT-SCIR</cell><cell>74.41 ±14.88</cell></row><row><cell>4. cs fictree</cell><cell>87.81 ICS PAS</cell><cell>71.10 ±16.26</cell></row><row><cell>5. cs cac</cell><cell>86.79 TurkuNLP</cell><cell>71.61 ±18.18</cell></row><row><cell>6. hi hdtb</cell><cell>86.74 HIT-SCIR</cell><cell>75.80 ± 9.28</cell></row><row><cell>7. pl sz</cell><cell>86.29 TurkuNLP</cell><cell>67.33 ±17.15</cell></row><row><cell>8. no bokmaal</cell><cell cols="2">85.82 UDPipe Future 69.52 ±13.54</cell></row><row><cell>9. ca ancora</cell><cell cols="2">85.47 UDPipe Future 72.60 ±12.31</cell></row><row><cell>10. es ancora</cell><cell>84.92 HIT-SCIR</cell><cell>72.10 ±12.71</cell></row><row><cell>11. it isdt</cell><cell>84.76 ICS PAS</cell><cell>75.42 ±10.72</cell></row><row><cell>12. fr sequoia</cell><cell>84.67 ICS PAS</cell><cell>70.63 ±11.66</cell></row><row><cell>13. no nynorsk</cell><cell>84.44 TurkuNLP</cell><cell>67.43 ±14.10</cell></row><row><cell>14. la ittb</cell><cell>84.37 TurkuNLP</cell><cell>68.10 ±17.85</cell></row><row><cell>15. bg btb</cell><cell>84.31 TurkuNLP</cell><cell>68.13 ±15.02</cell></row><row><cell>16. fro srcmf</cell><cell cols="2">84.11 UDPipe Future 70.46 ±16.40</cell></row><row><cell>17. sr set</cell><cell>83.28 TurkuNLP</cell><cell>65.62 ±17.61</cell></row><row><cell>18. sl ssj</cell><cell>83.23 Stanford</cell><cell>62.54 ±17.20</cell></row><row><cell>19. fi ftb</cell><cell>82.44 TurkuNLP</cell><cell>59.66 ±16.50</cell></row><row><cell>20. fi pud</cell><cell>82.44 TurkuNLP</cell><cell>52.25 ±18.50</cell></row><row><cell cols="2">21. sv talbanken 81.44 TurkuNLP</cell><cell>66.45 ±13.18</cell></row><row><cell>22. fi tdt</cell><cell>81.24 TurkuNLP</cell><cell>54.70 ±17.25</cell></row><row><cell>23. fr gsd</cell><cell>81.18 HIT-SCIR</cell><cell>69.61 ±10.58</cell></row><row><cell>24. ro rrt</cell><cell>80.97 TurkuNLP</cell><cell>63.53 ±15.84</cell></row><row><cell>25. sk snk</cell><cell>80.74 TurkuNLP</cell><cell>58.35 ±15.07</cell></row><row><cell>26. pt bosque</cell><cell>80.62 TurkuNLP</cell><cell>68.71 ±11.27</cell></row><row><cell>27. en pud</cell><cell>80.53 LATTICE</cell><cell>64.73 ±10.88</cell></row><row><cell>28. cs pud</cell><cell>80.53 ICS PAS</cell><cell>64.62 ±16.03</cell></row><row><cell>29. hr set</cell><cell>80.50 TurkuNLP</cell><cell>64.64 ±17.13</cell></row><row><cell>30. fa seraji</cell><cell>80.44 Stanford</cell><cell>68.38 ± 7.39</cell></row><row><cell>31. el gdt</cell><cell>80.09 TurkuNLP</cell><cell>63.26 ±15.60</cell></row><row><cell>32. ko kaist</cell><cell>79.55 TurkuNLP</cell><cell>57.32 ±20.78</cell></row><row><cell>33. et edt</cell><cell>79.37 TurkuNLP</cell><cell>57.06 ±16.14</cell></row><row><cell>34. nl alpino</cell><cell>79.15 HIT-SCIR</cell><cell>64.29 ±10.83</cell></row><row><cell>35. en ewt</cell><cell>78.44 HIT-SCIR</cell><cell>67.53 ± 8.47</cell></row><row><cell>36. uk iu</cell><cell>78.38 TurkuNLP</cell><cell>57.78 ±15.95</cell></row><row><cell>37. eu bdt</cell><cell>78.15 TurkuNLP</cell><cell>60.52 ±15.24</cell></row><row><cell>38. da ddt</cell><cell>78.07 TurkuNLP</cell><cell>63.16 ±11.41</cell></row><row><cell>39. sv lines</cell><cell>77.01 ICS PAS</cell><cell>63.13 ±11.72</cell></row><row><cell>40. id gsd</cell><cell>76.56 Stanford</cell><cell>62.52 ± 7.89</cell></row><row><cell cols="2">41. nl lassysmall 76.54 HIT-SCIR</cell><cell>60.92 ±11.93</cell></row><row><cell cols="2">42. af afribooms 76.44 TurkuNLP</cell><cell>63.87 ± 9.62</cell></row><row><cell>43. ko gsd</cell><cell>76.31 TurkuNLP</cell><cell>54.13 ±17.78</cell></row><row><cell>44. en lines</cell><cell>75.29 HIT-SCIR</cell><cell>62.29 ± 9.27</cell></row><row><cell>45. gl ctg</cell><cell>75.14 Stanford</cell><cell>60.86 ±10.82</cell></row><row><cell>46. ur udtb</cell><cell>73.79 TurkuNLP</cell><cell>62.93 ± 6.42</cell></row><row><cell>47. ja gsd</cell><cell>73.79 HIT-SCIR</cell><cell>60.87 ± 6.04</cell></row><row><cell>48. en gum</cell><cell>73.57 ICS PAS</cell><cell>61.02 ± 8.59</cell></row><row><cell>49. hu szeged</cell><cell>73.17 TurkuNLP</cell><cell>55.42 ±10.95</cell></row><row><cell>50. zh gsd</cell><cell>72.97 HIT-SCIR</cell><cell>55.66 ± 6.26</cell></row><row><cell>51. lv lvtb</cell><cell>72.40 TurkuNLP</cell><cell>53.42 ±14.56</cell></row><row><cell>52. de gsd</cell><cell>71.40 HIT-SCIR</cell><cell>54.86 ±14.99</cell></row><row><cell>53. cu proiel</cell><cell>71.31 Stanford</cell><cell>51.27 ±15.35</cell></row><row><cell>54. ar padt</cell><cell>70.06 Stanford</cell><cell>49.13 ±18.98</cell></row><row><cell>55. it postwita</cell><cell>69.34 HIT-SCIR</cell><cell>50.97 ± 8.76</cell></row><row><cell>56. grc proiel</cell><cell>69.03 TurkuNLP</cell><cell>48.58 ±19.91</cell></row><row><cell>57. la proiel</cell><cell>67.60 TurkuNLP</cell><cell>51.03 ±14.56</cell></row><row><cell>58. sv pud</cell><cell>66.12 TurkuNLP</cell><cell>50.20 ±11.30</cell></row><row><cell>59. fr spoken</cell><cell>65.63 HIT-SCIR</cell><cell>52.57 ± 7.29</cell></row><row><cell>60. he htb</cell><cell>65.04 Stanford</cell><cell>47.22 ± 6.60</cell></row><row><cell>61. ru taiga</cell><cell>64.36 ICS PAS</cell><cell>39.32 ±10.49</cell></row><row><cell>62. gl treegal</cell><cell cols="2">64.29 UDPipe Future 49.38 ± 8.18</cell></row><row><cell>63. got proiel</cell><cell>63.98 Stanford</cell><cell>48.79 ±13.77</cell></row><row><cell cols="2">64. no nynorsklia 60.98 ICS PAS</cell><cell>41.20 ± 8.64</cell></row><row><cell>65. tr imst</cell><cell>60.13 TurkuNLP</cell><cell>45.39 ±10.38</cell></row><row><cell>66. sme giella</cell><cell>60.10 TurkuNLP</cell><cell>35.76 ±12.68</cell></row><row><cell>67. grc perseus</cell><cell>58.68 TurkuNLP</cell><cell>36.48 ±16.03</cell></row><row><cell>68. ug udt</cell><cell>55.42 HIT-SCIR</cell><cell>41.64 ± 8.09</cell></row><row><cell>69. ga idt</cell><cell>55.18 TurkuNLP</cell><cell>37.83 ± 7.61</cell></row><row><cell>70. la perseus</cell><cell>52.75 ICS PAS</cell><cell>30.16 ±11.05</cell></row><row><cell>71. sl sst</cell><cell>50.94 ICS PAS</cell><cell>37.20 ± 6.87</cell></row><row><cell>72. vi vtb</cell><cell>44.02 Stanford</cell><cell>35.50 ± 3.74</cell></row><row><cell>73. pcm nsc</cell><cell>26.04 CUNI x-ling</cell><cell>12.07 ± 5.63</cell></row><row><cell>74. hsb ufal</cell><cell>21.09 LATTICE</cell><cell>11.26 ± 4.97</cell></row><row><cell>75. br keb</cell><cell>20.70 TurkuNLP</cell><cell>4.19 ± 4.93</cell></row><row><cell>76. hy armtdp</cell><cell>19.04 CUNI x-ling</cell><cell>10.68 ± 4.37</cell></row><row><cell>77. fo oft</cell><cell>14.40 CUNI x-ling</cell><cell>7.32 ± 3.33</cell></row><row><cell>78. ja modern</cell><cell>13.79 Stanford</cell><cell>7.70 ± 2.86</cell></row><row><cell>79. kmr mg</cell><cell>13.66 LATTICE</cell><cell>8.44 ± 3.11</cell></row><row><cell>80. kk ktb</cell><cell>11.33 CUNI x-ling</cell><cell>6.75 ± 2.95</cell></row><row><cell>81. th pud</cell><cell>10.77 CUNI x-ling</cell><cell>0.91 ± 2.11</cell></row><row><cell>82. bxr bdt</cell><cell>6.65 AntNLP</cell><cell>3.39 ± 1.61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 17 :</head><label>17</label><figDesc>Treebank ranking by best parser BLEX.</figDesc><table><row><cell>Treebank</cell><cell cols="2">LAS MLAS Diff Language</cell></row><row><cell>1. de gsd</cell><cell cols="2">70.13 39.13 31.01 German</cell></row><row><cell>2. sv pud</cell><cell cols="2">67.02 39.41 27.61 Swedish</cell></row><row><cell>3. fo oft</cell><cell>27.87</cell><cell>0.37 27.50 Faroese</cell></row><row><cell>4. ur udtb</cell><cell cols="2">75.89 49.64 26.25 Urdu</cell></row><row><cell>5. ga idt</cell><cell cols="2">58.37 33.70 24.66 Irish</cell></row><row><cell>6. grc perseus</cell><cell cols="2">59.01 35.65 23.36 Ancient Greek</cell></row><row><cell>7. hsb ufal</cell><cell>26.48</cell><cell>4.66 21.82 Upper Sorbian</cell></row><row><cell>8. sk snk</cell><cell cols="2">76.53 56.82 19.71 Slovak</cell></row><row><cell>9. ug udt</cell><cell cols="2">54.27 35.08 19.20 Uyghur</cell></row><row><cell>10. ru taiga</cell><cell cols="2">56.27 37.16 19.12 Russian</cell></row><row><cell>11. hr set</cell><cell cols="2">78.37 60.08 18.29 Croatian</cell></row><row><cell>12. la perseus</cell><cell cols="2">46.91 28.67 18.24 Latin</cell></row><row><cell>13. grc proiel</cell><cell cols="2">65.02 47.62 17.40 Ancient Greek</cell></row><row><cell>14. gl treegal</cell><cell cols="2">64.65 47.35 17.30 Galician</cell></row><row><cell>15. uk iu</cell><cell cols="2">72.47 55.45 17.01 Ukrainian</cell></row><row><cell>16. hi hdtb</cell><cell cols="2">85.16 68.48 16.68 Hindi</cell></row><row><cell>17. pl sz</cell><cell cols="2">81.47 64.80 16.67 Polish</cell></row><row><cell>18. hy armtdp</cell><cell>22.39</cell><cell>5.94 16.45 Armenian</cell></row><row><cell>19. el gdt</cell><cell cols="2">80.65 64.29 16.36 Greek</cell></row><row><cell>20. sv lines</cell><cell cols="2">73.76 57.40 16.36 Swedish</cell></row><row><cell>21. kmr mg</cell><cell>20.27</cell><cell>4.01 16.26 Kurmanji</cell></row><row><cell>22. nl alpino</cell><cell cols="2">77.76 62.82 14.95 Dutch</cell></row><row><cell>23. gl ctg</cell><cell cols="2">72.46 57.92 14.55 Galician</cell></row><row><cell>24. lv lvtb</cell><cell cols="2">67.76 53.31 14.45 Latvian</cell></row><row><cell>25. got proiel</cell><cell cols="2">60.55 46.18 14.37 Gothic</cell></row><row><cell>26. pt bosque</cell><cell cols="2">80.49 66.22 14.27 Portuguese</cell></row><row><cell>27. ja gsd</cell><cell cols="2">73.68 59.52 14.16 Japanese</cell></row><row><cell>28. kk ktb</cell><cell>19.11</cell><cell>5.04 14.07 Kazakh</cell></row><row><cell>29. hu szeged</cell><cell cols="2">67.05 53.08 13.96 Hungarian</cell></row><row><cell>30. sl sst</cell><cell cols="2">47.07 33.12 13.95 Slovenian</cell></row><row><cell>31. eu bdt</cell><cell cols="2">72.08 58.49 13.59 Basque</cell></row><row><cell>32. he htb</cell><cell cols="2">58.73 45.22 13.51 Hebrew</cell></row><row><cell>33. la proiel</cell><cell cols="2">61.25 47.79 13.46 Latin</cell></row><row><cell cols="3">34. no nynorsklia 50.33 37.08 13.25 Norwegian</cell></row><row><cell>35. it postwita</cell><cell cols="2">64.95 51.72 13.22 Italian</cell></row><row><cell cols="3">36. nl lassysmall 75.08 61.95 13.14 Dutch</cell></row><row><cell cols="3">37. af afribooms 76.61 63.76 12.84 Afrikaans</cell></row><row><cell>38. sme giella</cell><cell cols="2">51.10 38.29 12.82 North Sámi</cell></row><row><cell>39. cs pud</cell><cell cols="2">73.24 60.47 12.77 Czech</cell></row><row><cell>40. sl ssj</cell><cell cols="2">75.00 62.41 12.59 Slovenian</cell></row><row><cell>41. sr set</cell><cell cols="2">79.84 67.33 12.50 Serbian</cell></row><row><cell>42. en gum</cell><cell cols="2">74.20 61.72 12.48 English</cell></row><row><cell>43. ja modern</cell><cell>18.92</cell><cell>6.45 12.47 Japanese</cell></row><row><cell>44. cu proiel</cell><cell cols="2">62.64 50.28 12.36 Old Church Slavonic</cell></row><row><cell>45. cs fictree</cell><cell cols="2">82.10 69.91 12.19 Czech</cell></row><row><cell>46. pl lfg</cell><cell cols="2">85.89 73.73 12.17 Polish</cell></row><row><cell>47. id gsd</cell><cell cols="2">73.05 61.03 12.02 Indonesian</cell></row><row><cell>48. br keb</cell><cell>13.27</cell><cell>1.52 11.75 Breton</cell></row><row><cell>49. fr spoken</cell><cell cols="2">64.66 53.17 11.49 French</cell></row><row><cell>50. en pud</cell><cell cols="2">74.51 63.05 11.46 English</cell></row><row><cell>51. cs cac</cell><cell cols="2">82.69 71.39 11.29 Czech</cell></row><row><cell>52. ar padt</cell><cell cols="2">64.07 53.28 10.79 Arabic</cell></row><row><cell>53. fi ftb</cell><cell cols="2">76.89 66.11 10.78 Finnish</cell></row><row><cell>54. it isdt</cell><cell cols="2">87.61 77.14 10.47 Italian</cell></row><row><cell>55. tr imst</cell><cell cols="2">55.61 45.26 10.34 Turkish</cell></row><row><cell>56. pcm nsc</cell><cell>13.19</cell><cell>3.00 10.19 Naija</cell></row><row><cell>57. fr sequoia</cell><cell cols="2">80.55 70.42 10.13 French</cell></row><row><cell>58. bxr bdt</cell><cell>11.45</cell><cell>1.33 10.12 Buryat</cell></row><row><cell>59. fr gsd</cell><cell cols="2">79.43 69.33 10.10 French</cell></row><row><cell>60. da ddt</cell><cell cols="2">75.02 65.00 10.02 Danish</cell></row><row><cell>61. no nynorsk</cell><cell cols="2">78.55 68.62 9.93 Norwegian</cell></row><row><cell>62. en lines</cell><cell cols="2">72.28 62.35 9.93 English</cell></row><row><cell>63. zh gsd</cell><cell cols="2">60.32 50.42 9.90 Chinese</cell></row><row><cell cols="3">64. sv talbanken 77.71 68.05 9.66 Swedish</cell></row><row><cell>65. bg btb</cell><cell cols="2">82.52 73.18 9.34 Bulgarian</cell></row><row><cell>66. la ittb</cell><cell cols="2">77.00 67.77 9.23 Latin</cell></row><row><cell>67. fro srcmf</cell><cell cols="2">74.38 65.19 9.18 Old French</cell></row><row><cell>68. en ewt</cell><cell cols="2">75.99 66.84 9.15 English</cell></row><row><cell cols="3">69. no bokmaal 79.80 70.75 9.05 Norwegian</cell></row><row><cell>70. ca ancora</cell><cell cols="2">83.61 74.62 8.99 Catalan</cell></row><row><cell>71. cs pdt</cell><cell cols="2">82.18 73.61 8.57 Czech</cell></row><row><cell>72. et edt</cell><cell cols="2">72.08 63.59 8.50 Estonian</cell></row><row><cell>73. ro rrt</cell><cell cols="2">75.77 67.43 8.33 Romanian</cell></row><row><cell>74. fi tdt</cell><cell cols="2">73.55 65.27 8.28 Finnish</cell></row><row><cell>75. es ancora</cell><cell cols="2">82.84 74.61 8.23 Spanish</cell></row><row><cell>76. ko gsd</cell><cell cols="2">71.88 63.73 8.15 Korean</cell></row><row><cell cols="3">77. ru syntagrus 79.68 71.63 8.05 Russian</cell></row><row><cell>78. vi vtb</cell><cell cols="2">40.40 32.45 7.95 Vietnamese</cell></row><row><cell>79. fa seraji</cell><cell cols="2">78.71 71.23 7.48 Persian</cell></row><row><cell>80. ko kaist</cell><cell cols="2">77.10 70.18 6.92 Korean</cell></row><row><cell>81. fi pud</cell><cell cols="2">68.87 62.38 6.49 Finnish</cell></row><row><cell>82. th pud</cell><cell>1.38</cell><cell>0.42 0.96 Thai</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 18 :</head><label>18</label><figDesc>Treebank ranking by difference between average parser LAS and MLAS.</figDesc><table><row><cell cols="3">Treebank Best Best system Avg StDev</cell></row><row><cell>70. bxr bdt</cell><cell>99.24 IBM NY</cell><cell>88.64 ± 8.09</cell></row><row><cell>71. fi pud</cell><cell>99.69 Uppsala</cell><cell>88.13 ±10.81</cell></row><row><cell>72. zh gsd</cell><cell>96.71 HIT-SCIR</cell><cell>86.91 ± 3.83</cell></row><row><cell>73. fo oft</cell><cell cols="2">99.47 CUNI x-ling 86.76 ±10.68</cell></row><row><cell>74. ar padt</cell><cell>96.81 Stanford</cell><cell>86.62 ± 7.00</cell></row><row><cell cols="2">75. kmr mg 96.97 Uppsala</cell><cell>86.61 ± 7.16</cell></row><row><cell>76. kk ktb</cell><cell>97.40 Uppsala</cell><cell>85.55 ± 7.45</cell></row><row><cell>77. br keb</cell><cell cols="2">92.45 TurkuNLP 83.76 ± 7.37</cell></row><row><cell>78. he htb</cell><cell>93.98 Stanford</cell><cell>82.45 ± 3.80</cell></row><row><cell>79. vi vtb</cell><cell>93.46 HIT-SCIR</cell><cell>81.71 ± 3.73</cell></row><row><cell cols="3">80. pcm nsc 99.71 CEA LIST 79.94 ±10.69</cell></row><row><cell cols="2">81. ja modern 75.69 HIT-SCIR</cell><cell>59.40 ± 7.70</cell></row><row><cell>82. th pud</cell><cell>69.93 Uppsala</cell><cell>17.16 ±20.57</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 19 :</head><label>19</label><figDesc>Treebanks with most difficult word segmentation (by average parser F 1 ).</figDesc><table><row><cell cols="3">Treebank Best Best system Avg StDev</cell></row><row><cell cols="3">73. grc proiel 51.84 HIT-SCIR 42.46 ± 7.33</cell></row><row><cell cols="2">74. cu proiel 48.67 Stanford</cell><cell>35.54 ± 4.02</cell></row><row><cell cols="2">75. la proiel 39.61 Stanford</cell><cell>33.40 ± 5.39</cell></row><row><cell cols="2">76. got proiel 38.23 Stanford</cell><cell>27.22 ± 4.47</cell></row><row><cell cols="2">77. it postwita 65.90 Stanford</cell><cell>25.25 ±14.30</cell></row><row><cell>78. sl sst</cell><cell cols="2">24.43 NLP-Cube 20.92 ± 4.70</cell></row><row><cell cols="2">79. fr spoken 24.17 Stanford</cell><cell>20.43 ± 2.89</cell></row><row><cell>80. th pud</cell><cell>12.37 TurkuNLP</cell><cell>1.75 ± 3.68</cell></row><row><cell>81. pcm nsc</cell><cell>0.93 Stanford</cell><cell>0.06 ± 0.19</cell></row><row><cell cols="2">82. ja modern 0.23 Stanford</cell><cell>0.01 ± 0.04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 20 :</head><label>20</label><figDesc>Treebanks with most difficult sentence segmentation (by average parser F 1 ).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">UD 2.2 also contains other treebanks that were not included in the task for various reasons, and that may have been further developed even during the duration of the task.2 Compare with the 81 treebanks and 49 languages in the 2017 task.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We distinguish treebanks of the same language by their short names or acronyms. Hence, the two treebanks of Ancient Greek are identified as Perseus and PROIEL, the three treebanks of Latin are ITTB, Perseus and PROIEL, etc.4 While the test datasets were not available to the teams when they developed their systems, the documentation of the treebanks was supplied together with the training data, hence the teams could learn that the PUD treebanks were parallel.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">http://hdl.handle.net/11234/1-2837 6 http://universaldependencies.org/ conll18/conll18_ud_eval.py</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">http://epe.nlpl.eu/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">http://www.tira.io/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">https://github.com/CoNLL-UD-2018   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">The fourth surprise language, North Sámi, has now additional training data and does not fall in the low-resource category.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">The ONLP lab system also has a joint model but in the end used the baseline morphology as it gave better results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">This is true of at least 3 of the 5 best performing systems.16  The baseline embeddings were the same as in 2017 and therefore did not cover new languages, which may partly explain the greater popularity of the Facebook embeddings this year.17  We know that some teams used them also for clusters involving high-resource languages, but we have no detailed statistics on this usage.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to all the contributors to Universal Dependencies; without their effort a task like this simply wouldn't be possible.</p><p>The work described herein, including data preparation for the CoNLL 2018 UD Shared Task, has been supported by the following grants and projects: "CRACKER," H2020 Project No. 645357 of the European Commission; "MANYLA," Grant No. GA15-10472S of the Grant Agency of the Czech Republic; FIN-CLARIN; and the LINDAT/CLARIN research infrastructure project funded by the Ministry of Education, Youth and Sports of the Czech Republic, Project. No. LM2015071. The data for the CoNLL 2018 UD Shared Task are available also via the LINDAT/CLARIN repository.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards JointUD: Part-ofspeech tagging and lemmatization using recurrent neural networks</title>
		<author>
			<persName><forename type="first">Gor</forename><surname>Arakelyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Hambardzumyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hrant</forename><surname>Khachatrian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The SLT-Interactions parsing system at the CoNLL 2018 shared task</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<editor>
			<persName><forename type="first">Ahmad</forename><surname>Riyaz</surname></persName>
			<persName><forename type="first">Irshad</forename><forename type="middle">Ahmad</forename><surname>Bhat</surname></persName>
			<persName><forename type="first">Srinivas</forename><surname>Bhat</surname></persName>
			<persName><surname>Bangalore</surname></persName>
		</editor>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<title level="m">Enriching word vectors with subword information arXiv preprint</title>
				<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">NLP-Cube: End-to-end raw text processing with neural networks</title>
		<author>
			<persName><forename type="first">Tiberiu</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><forename type="middle">Daniel</forename><surname>Dumitrescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruxandra</forename><surname>Burtica</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">CoNLL-X shared task on multilingual dependency parsing</title>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erwin</forename><surname>Marsi</surname></persName>
		</author>
		<ptr target="http://anthology.aclweb.org/W/W06/W06-29.pdf#page=165" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X). Association for Computational Linguistics</title>
				<meeting>the 10th Conference on Computational Natural Language Learning (CoNLL-X). Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="149" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Towards better UD parsing: Deep contextualized word embeddings, ensemble, and treebank concatenation</title>
		<author>
			<persName><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A simple yet effective joint training method for cross-lingual universal dependency parsing</title>
		<author>
			<persName><forename type="first">Danlu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengxiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CEA LIST : Processing low-resource languages for CoNLL</title>
		<author>
			<persName><forename type="first">Elie</forename><surname>Duthoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Mesnard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The 2018 shared task on extrinsic parser evaluation: On the downstream utility of English universal dependency parsers</title>
		<author>
			<persName><forename type="first">Murhaf</forename><surname>Fares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephan</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilja</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jari</forename><surname>Björne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Johansson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-1989" />
		<title level="m">CoNLL 2017 shared taskautomatically annotated raw texts and word embeddings. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics</title>
				<imprint>
			<date type="published" when="2017" />
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Evaluation-as-a-Service: Overview and Outlook</title>
		<author>
			<persName><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krisztian</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Torben</forename><surname>Brodt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ivan</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noriko</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1512.07454" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Universal dependency parsing with a general transition-based DAG parser</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omri</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ari</forename><surname>Rappoport</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ELMoLex: Connecting ELMo and lexicon features for dependency parsing</title>
		<author>
			<persName><forename type="first">Ganesh</forename><surname>Jawahar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amal</forename><surname>Fethi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Éric de La Clergerie, Benoît Sagot, and Djamé Seddah. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">AntNLP at CoNLL 2018 shared task: A graph-based parser for universal dependency parsing</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yufang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Man</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Turku neural parser pipeline: An end-to-end system for the CoNLL 2018 shared task</title>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niko</forename><surname>Miekka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akseli</forename><surname>Leino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tapio</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tree-stack LSTM in transition based dependency parsing</title>
		<author>
			<persName><forename type="first">Omer</forename><surname>Kırnap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erenay</forename><surname>Dayanık</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Joint learning of pos and dependencies for multilingual universal dependency parsing</title>
		<author>
			<persName><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SEx BiST: A multi-source trainable parser with deep contextualized lexical representations</title>
		<author>
			<persName><forename type="first">Kyungtae</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheoneum</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changki</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Poibeau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An improved neural network model for joint pos tagging and dependency parsing</title>
		<author>
			<persName><forename type="first">Karin</forename><surname>Dat Quoc Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mitchell</forename><surname>Abrams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Željko</forename><surname>Agić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lars</forename><surname>Ahrenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lene</forename><surname>Antonsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">Jesus</forename><surname>Aranzabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gashaw</forename><surname>Arutie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masayuki</forename><surname>Asahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luma</forename><surname>Ateyah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammed</forename><surname>Attia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitziber</forename><surname>Atutxa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liesbeth</forename><surname>Augustinus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Badmaeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esha</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Bank</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbu</forename><surname>Verginica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Mititelu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kepa</forename><surname>Bellato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Riyaz</forename><forename type="middle">Ahmad</forename><surname>Bengoetxea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Erica</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eckhard</forename><surname>Biagetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rogier</forename><surname>Bick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Victoria</forename><surname>Blokland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><surname>Bobicev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cristina</forename><surname>Börstell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gosse</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Bouma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriane</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aljoscha</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><surname>Burchardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><surname>Candito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gauthier</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gülşen</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giuseppe</forename><forename type="middle">G A</forename><surname>Cebiroglu Eryigit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Savas</forename><surname>Celano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabricio</forename><surname>Cetin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jinho</forename><surname>Chalub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yongseok</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayeol</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvie</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aurélie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName><surname>Collomb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miriam</forename><surname>Agrı Çöltekin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marine</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Courtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Davidson ; Carly Dickerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaja</forename><surname>Dirix</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Dobrovoljc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kira</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Puneet</forename><surname>Droganova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marhaba</forename><surname>Dwivedi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ali</forename><surname>Eli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyam</forename><surname>Elkahky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomaž</forename><surname>Ephrem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aline</forename><surname>Erjavec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richárd</forename><surname>Etienne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Fernandez Alcalde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cláudia</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarína</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gajdošová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Galbraith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moa</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Gärdenfors</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Gerdes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iakes</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koldo</forename><surname>Goenaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Memduh</forename><surname>Gojenola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Gökırmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><forename type="middle">Gómez</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Berta</forename><forename type="middle">Gonzáles</forename><surname>Guinovart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matias</forename><surname>Saavedra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Normunds</forename><surname>Grioni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bruno</forename><surname>Grūzītis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Céline</forename><surname>Guillaume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nizar</forename><surname>Guillot-Barbance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName><surname>Hajič Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Na-Rae</forename><surname>Linh Hà Mỹ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dag</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barbora</forename><surname>Haug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaroslava</forename><surname>Hladká</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florinel</forename><surname>Hlaváčová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petter</forename><surname>Hociung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jena</forename><surname>Hohle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomáš</forename><surname>Irimia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anders</forename><surname>Jelínek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fredrik</forename><surname>Johannsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hüner</forename><surname>Jørgensen</surname></persName>
		</author>
		<author>
			<persName><surname>Kaşıkara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Sylvain Kahane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tolga</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Václava</forename><surname>Kayadelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Kettnerová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Kotsyba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sookyoung</forename><surname>Krek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lorenzo</forename><surname>Laippala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatiana</forename><surname>Lambertino</surname></persName>
		</author>
		<author>
			<persName><surname>Lando</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><surname>Septina Dian Larasati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Lavrentiev</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Phương Lê Hồng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saran</forename><surname>Lenci</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herman</forename><surname>Lertpradit</surname></persName>
		</author>
		<author>
			<persName><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Cheuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyungtae</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikola</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stina</forename><surname>Ljubešić ; Hanna Nurmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adédayọ</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mai</forename><surname>Olúòkun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Petya</forename><surname>Omura</surname></persName>
		</author>
		<author>
			<persName><surname>Osenova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilja</forename><surname>Robertöstling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niko</forename><surname>Øvrelid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Partanen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Pascual</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Agnieszka</forename><surname>Passarotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyao</forename><surname>Patejuk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cenel-Augusto</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Perrier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jussi</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emily</forename><surname>Piitulainen</surname></persName>
		</author>
		<author>
			<persName><surname>Pitler</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-2837" />
		<title level="m">Gunta Nešpore-Bērzkalne, Lương Nguyễn Thị, Huyền Nguyễn Thị Minh, Vitaly Nikolaev, Rattima Nitisaroj</title>
				<editor>
			<persName><forename type="first">Marat</forename><forename type="middle">M</forename><surname>Yan</surname></persName>
			<persName><forename type="first">Zhuoran</forename><surname>Yavrumyan</surname></persName>
			<persName><surname>Yu</surname></persName>
			<persName><forename type="first">Amir</forename><surname>Zdeněkžabokrtský</surname></persName>
			<persName><forename type="first">Daniel</forename><surname>Zeldes</surname></persName>
			<persName><forename type="first">Manying</forename><surname>Zeman</surname></persName>
			<persName><forename type="first">Hanzhi</forename><surname>Zhang</surname></persName>
			<persName><surname>Zhu</surname></persName>
		</editor>
		<meeting><address><addrLine>Olga Loginova, Olga Lyashevskaya, Teresa Lynn, Vivien Macketanz, Aibek Makazhanov, Michael Mandl, Christopher Manning, Ruli Manurung, Cătălina Mărănduc, David Mareček, Katrin Marheinecke, Héctor Martínez Alonso, André Martins, Jan Mašek, Yuji Matsumoto, Ryan McDonald, Gustavo Mendonça, Niko Miekka, Anna Missilä, Cătălin Mititelu, Yusuke Miyao, Simonetta Montemagni, Amir More, Laura Moreno Romero, Shinsuke Mori, Bjartur Mortensen, Bohdan Moskalevskyi, Kadri Muischnek, Yugo Murawaki, Kaili Müürisep, Pinkey Nainwani, Juan Ignacio Navarro Horñiacek, Anna Nedoluzhko; Barbara Plank; Natalia Silveira, Maria Simi, Radu Simionescu, Katalin Simkó, MáriaŠimková, Kiril Simov, Aaron Smith, Isabela Soares-Bastos, Antonio Stella, Milan Straka, Jana Strnadová, Alane Suhr, Umut Sulubacak, Zsolt Szántó, Dima Taji, Yuta Takahashi, Takaaki Tanaka, Isabelle Tellier, Trond Trosterud, Anna Trukhina, Reut Tsarfaty, Francis Tyers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
		<respStmt>
			<orgName>Marie-Catherine de Marneffe, Valeria de Paiva, Arantza Diaz de Ilarraza, ; Sumire Uematsu, Zdeňka Urešová, Larraitz Uria, Hans Uszkoreit, Sowmya Vajjala, Daniel van Niekerk, Gertjan van Noord, Viktor Varga, Veronika Vincze, Lars Wallin, Jonathan North Washington, Seyi Williams, Mats Wirén, Tsegay Woldemariam, Tak-sum Wong ; Charles University</orgName>
		</respStmt>
	</monogr>
	<note>Faculty of Mathematics and Physics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Universal Dependencies v1: A multilingual treebank collection</title>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Silveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2016/summaries/348.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)</title>
				<meeting>the 10th International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1659" to="1666" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Universal dependency evaluation</title>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiao-Ting</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies</title>
				<meeting>the NoDaLiDa 2017 Workshop on Universal Dependencies</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="86" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The CoNLL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<ptr target="http://www.aclweb.org/anthology/D/D07/D07-" />
		<title level="m">Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</title>
				<meeting>the CoNLL Shared Task Session of EMNLP-CoNLL</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="915" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">SParse: Koç University graph-based parsing system for the CoNLL 2018 shared task</title>
		<author>
			<persName><forename type="first">Berkay</forename><surname>Furkanönder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Can</forename><surname>Gümeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A morphology-based representation model for LSTM-based dependency parsing of agglutinative languages</title>
		<author>
			<persName><surname>Betülözateş</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tunga</forename><surname>Arzucanözgür</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balkızöztürk</forename><surname>Güngör</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Udapi: Universal API for universal dependencies</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zdeněkžabokrtský</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Vojtek</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/W/W17/W17-0412.pdf" />
	</analytic>
	<monogr>
		<title level="j">Workshop on Universal Dependencies. Göteborgs universitet</title>
		<imprint>
			<biblScope unit="page" from="96" to="101" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improving the reproducibility of PAN&apos;s shared tasks: Plagiarism detection, author identification, and author profiling</title>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-11382-1_{}22</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-11382-1_22" />
	</analytic>
	<monogr>
		<title level="m">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 5th International Conference of the CLEF Initiative</title>
				<editor>
			<persName><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
			<persName><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</editor>
		<meeting><address><addrLine>Paul Clough, Mark Sanderson, Mark Hall, Allan Hanbury, and Elaine Toms; Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="268" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Universal dependency parsing from scratch</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">CUNI x-ling: Parsing under-resourced languages in CoNLL 2018 UD shared task</title>
		<author>
			<persName><forename type="first">Rudolf</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mareček</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semisupervised neural system for tagging, parsing and lematization</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Rybak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alina</forename><surname>Wróblewska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Universal morpho-syntactic parsing and the contribution of lexica: Analyzing the ONLP submission to the CoNLL 2018 shared task</title>
		<author>
			<persName><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amir</forename><surname>More</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">82 treebanks, 34 models: Universal dependency parsing with multi-treebank models</title>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Miryam De Lhoneux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yan</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><surname>Stymne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL</title>
				<meeting>the CoNLL</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>UDPipe 2.0 prototype at CoNLL 2018 UD shared task</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">UD-Pipe: trainable pipeline for processing CoNLL-U files performing tokenization, morphological analysis, POS tagging and parsing</title>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jana</forename><surname>Straková</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation</title>
				<meeting>the 10th International Conference on Language Resources and Evaluation<address><addrLine>Portorož</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="Slove" to=" nia" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Tokenizing, POS tagging, lemmatizing and parsing UD 2.0 with UDPipe</title>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jana</forename><surname>Straková</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in OPUS</title>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bente</forename><surname>Mehmet Ugur Dogan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Maegaard</surname></persName>
		</author>
		<author>
			<persName><surname>Mariani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12). European Language Resources Association (ELRA)</title>
				<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12). European Language Resources Association (ELRA)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-01" />
		</imprint>
	</monogr>
	<note>Nicoletta Calzolari (Conference Chair)</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">IBM Research at the CoNLL 2018 shared task on multilingual parsing</title>
		<author>
			<persName><forename type="first">Hui</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young-Suk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vittorio</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multilingual universal dependency parsing from raw text with low-resource language enhancement</title>
		<author>
			<persName><forename type="first">Yingting</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia-Jun</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
				<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juhani</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Slav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elena</forename><surname>Badmaeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Memduh</forename><surname>Gökırmak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Nedoluzhko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvie</forename><surname>Cinková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Hajič Jr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaroslava</forename><surname>Hlaváčová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Václava</forename><surname>Kettnerová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zdeňka</forename><surname>Urešová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenna</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stina</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Missilä</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dima</forename><surname>Taji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Herman</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Simi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Josie</forename><surname>Li</surname></persName>
		</author>
		<title level="m">Proceedings of the CoNLL</title>
				<editor>
			<persName><forename type="first">Kira</forename><surname>Valeria De Paiva</surname></persName>
			<persName><surname>Droganova</surname></persName>
			<persName><surname>Héctor Martínez Alonso</surname></persName>
			<persName><forename type="first">Umut</forename><surname>Agrı Çöltekin</surname></persName>
			<persName><forename type="first">Hans</forename><surname>Sulubacak</surname></persName>
			<persName><forename type="first">Vivien</forename><surname>Uszkoreit</surname></persName>
			<persName><forename type="first">Aljoscha</forename><surname>Macketanz</surname></persName>
			<persName><forename type="first">Kim</forename><surname>Burchardt</surname></persName>
			<persName><forename type="first">Katrin</forename><surname>Harris</surname></persName>
			<persName><forename type="first">Georg</forename><surname>Marheinecke</surname></persName>
			<persName><forename type="first">Tolga</forename><surname>Rehm</surname></persName>
			<persName><forename type="first">Mohammed</forename><surname>Kayadelen</surname></persName>
			<persName><forename type="first">Ali</forename><surname>Attia</surname></persName>
			<persName><forename type="first">Zhuoran</forename><surname>Elkahky</surname></persName>
			<persName><forename type="first">Emily</forename><surname>Yu</surname></persName>
			<persName><forename type="first">Saran</forename><surname>Pitler</surname></persName>
			<persName><forename type="first">Michael</forename><surname>Lertpradit</surname></persName>
			<persName><forename type="first">Jesse</forename><surname>Mandl</surname></persName>
			<persName><forename type="first">Hector</forename><surname>Kirchner</surname></persName>
			<persName><forename type="first">Jana</forename><surname>Fernandez Alcalde</surname></persName>
			<persName><forename type="first">Esha</forename><surname>Strnadova</surname></persName>
			<persName><forename type="first">Ruli</forename><surname>Banerjee</surname></persName>
			<persName><surname>Manurung</surname></persName>
		</editor>
		<meeting>the CoNLL<address><addrLine>Stella, Atsuko Shimada, Sookyoung Kwak, Gustavo Mendonça, Tatiana Lando</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Rattima Nitisaroj,. shared task: Multilingual parsing from raw text to universal dependencies</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<ptr target="http://www.aclweb.org/anthology/K17-3001" />
		<title level="m">Multilingual Parsing from Raw Text to Universal Dependencies. Association for Computational Linguistics</title>
				<meeting><address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
