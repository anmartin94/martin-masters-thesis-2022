<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Introduction to the CoNLL-2004 Shared Task: Semantic Role Labeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
							<email>carreras@lsi.upc.es</email>
							<affiliation key="aff0">
								<orgName type="institution">TALP Research Centre Technical University of Catalonia (UPC)</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
							<email>lluism@lsi.upc.es</email>
							<affiliation key="aff0">
								<orgName type="institution">TALP Research Centre Technical University of Catalonia (UPC)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Introduction to the CoNLL-2004 Shared Task: Semantic Role Labeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the CoNLL-2004 shared task: semantic role labeling. We introduce the specification and goal of the task, describe the data sets and evaluation methods, and present a general overview of the systems that have contributed to the task, providing comparative description.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years there has been an increasing interest in semantic parsing of natural language, which is becoming a key issue in Information Extraction, Question Answering, Summarization, and, in general, in all NLP applications requiring some kind of semantic interpretation.</p><p>The shared task of CoNLL-2004 1 concerns the recognition of semantic roles, for the English language. We will refer to it as Semantic Role Labeling (SRL). Given a sentence, the task consists of analyzing the propositions expressed by some target verbs of the sentence. In particular, for each target verb all the constituents in the sentence which fill a semantic role of the verb have to be extracted (see Figure <ref type="figure" target="#fig_3">1</ref> for a detailed example). Typical semantic arguments include Agent, Patient, Instrument, etc. and also adjuncts such as Locative, Temporal, Manner, Cause, etc.</p><p>Most existing systems for automatic semantic role labeling make use of a full syntactic parse of the sentence in order to define argument boundaries and to extract relevant information for training classifiers to disambiguate between role labels. Thus, the task has been usually approached as a two phase procedure consisting of recognition and labeling of arguments.</p><p>Regarding the learning component of the systems, we find pure probabilistic models <ref type="bibr" target="#b8">(Gildea and Jurafsky, 2002;</ref><ref type="bibr" target="#b9">Gildea and Palmer, 2002;</ref><ref type="bibr" target="#b7">Gildea and Hockenmaier, 2003)</ref>, Maximum Entropy <ref type="bibr" target="#b6">(Fleischman et al., 2003)</ref>, generative models <ref type="bibr" target="#b23">(Thompson et al., 2003)</ref>, Decision Trees <ref type="bibr" target="#b22">(Surdeanu et al., 2003;</ref><ref type="bibr" target="#b3">Chen and Rambow, 2003)</ref>, and Support Vector Machines <ref type="bibr" target="#b11">(Hacioglu and Ward, 2003;</ref><ref type="bibr" target="#b18">Pradhan et al., 2003a;</ref><ref type="bibr" target="#b20">Pradhan et al., 2003b)</ref>.</p><p>There have also been some attempts at relaxing the necessity of using syntactic information derived from full parse trees. For instance, in <ref type="bibr" target="#b18">(Pradhan et al., 2003a;</ref><ref type="bibr" target="#b11">Hacioglu and Ward, 2003)</ref>, a SVM-based SRL system is devised which performs an IOB sequence tagging using only shallow syntactic information at the level of phrase chunks.</p><p>Nowadays, there exist two main English corpora with semantic annotations from which to train SRL systems: PropBank <ref type="bibr" target="#b16">(Palmer et al., 2004)</ref> and FrameNet <ref type="bibr" target="#b5">(Fillmore et al., 2001</ref>). In the CoNLL-2004 shared task we concentrate on the PropBank corpus, which is the Penn Treebank corpus enriched with predicate-argument structures. It addresses predicates expressed by verbs and labels core arguments with consecutive numbers (A0 to A5), trying to maintain coherence along different predicates. A number of adjuncts, derived from the Treebank functional tags, are also included in PropBank annotations.</p><p>To date, the best results reported on the PropBank correspond to a F 1 measure slightly over 83, when using the gold standard parse trees from Penn Treebank as the main source of information <ref type="bibr" target="#b20">(Pradhan et al., 2003b)</ref>. This performance drops to 77 when a real parser is used instead. Comparatively, the best SRL system based solely on shallow syntactic information <ref type="bibr" target="#b18">(Pradhan et al., 2003a)</ref> performs more than 15 points below. Although these results are not directly comparable to the ones obtained in the CoNLL-2004 shared task (different datasets, different version of PropBank, etc.) they give an idea about the state-of-the art results on the task.</p><p>The challenge for CoNLL-2004 shared task is to come up with machine learning strategies which address the SRL problem on the basis of only partial syntactic information, avoiding the use of full parsers and external lexico-semantic knowledge bases. The annotations provided for the development of systems include, apart from the argument boundaries and role labels, the levels of processing treated in the previous editions of the CoNLL shared task, i.e., words, PoS tags, base chunks, clauses, and named entities.</p><p>The rest of the paper is organized as follows. Section 2 describes the general setting of the task. Section 3 provides a detailed description of training, development and test data. Participant systems are described and compared in section 4. In particular, information about learning techniques, SRL strategies, and feature development is provided, together with performance results on the development and test sets. Finally, section 5 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Description</head><p>The goal of the task is to develop a machine learning system to recognize arguments of verbs in a sentence, and label them with their semantic role. A verb and its set of arguments form a proposition in the sentence, and typically, a sentence will contain a number of propositions.</p><p>There are two properties that characterize the structure of the arguments in a proposition. First, arguments do not overlap, and are organized sequentially. Second, an argument may appear split into a number of non-contiguous phrases. For instance, in the sentence "[ A1 The apple], said John, [ C−A1 is on the table]", the utterance argument (labeled with type A1) appears split into two phrases. Thus, there is a set of non-overlapping arguments labeled with semantic roles associated with each proposition. The set of arguments of a proposition can be seen as a chunking of the sentence, in which chunks are parts of the semantic roles of the proposition predicate.</p><p>In practice, number of target verbs are marked in a sentence, each governing one proposition. A system has to recognize and label the arguments of each target verb.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Methodological Setting</head><p>Training and development data are provided to build the learning system. Apart from the correct output, both data sets contain the correct input, as well as predictions of the input made by state-of-the-art processors. The training set is used for training systems, whereas the development set is used to tune parameters of the learning systems and select the best model. Systems have to be developed strictly with the data provided, which consists of input and output data and the official external resources (described below). Since the correct annotations for the input data are provided, a system is allowed either to be trained to predict the input part, or to make use of an external tool developed strictly within this setting, such as previous CoNLL shared task systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation</head><p>Evaluation is performed on a separate test set, which includes only predicted input data. A system is evaluated with respect to precision, recall and the F 1 measure. Precision (p) is the proportion of arguments predicted by a system which are correct. Recall (r) is the proportion of correct arguments which are predicted by a system. Finally, the F 1 measure computes the harmonic mean of precision and recall, and is the final measure to compare the performance of systems. It is formulated as:</p><formula xml:id="formula_0">F β=1 = 2pr/(p + r).</formula><p>For an argument to be correctly recognized, the words spanning the argument as well as its semantic role have to be correct. <ref type="bibr">2</ref> As an exceptional case, the verb argument of each proposition is excluded from the evaluation. This argument is the lexicalization of the predicate of the proposition. Most of the time, the verb corresponds to the target verb of the proposition, which is provided as input, and only in few cases the verb participant spans more words than the target verb.</p><p>Except for non-trivial cases, this situation makes the verb fairly easy to identify and, since there is one verb with each proposition, evaluating its recognition overestimates the overall performance of a system. For this reason, the verb argument is excluded from evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data</head><p>The data consists of six sections of the Wall Street Journal part of the Penn Treebank <ref type="bibr" target="#b15">(Marcus et al., 1993)</ref>, and follows the setting of past editions of the CoNLL shared task: training set (sections 15-18), development set (section 20) and test set (section 21). We first describe annotations related to argument structure. Then, we describe the preprocessing of input data. Finally, we describe the format of the data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PropBank</head><p>The Proposition Bank (PropBank) <ref type="bibr" target="#b16">(Palmer et al., 2004)</ref> annotates the Penn Treebank with verb argument structure. The semantic roles covered by PropBank are the following:</p><p>• Numbered arguments (A0-A5, AA): Arguments defining verb-specific roles. Their semantics depends on the verb and the verb usage in a sentence, or verb sense. In general, A0 stands for the agent and A1 corresponds to the patient or theme of the proposition, and these two are the most frequent roles. However, no consistent generalization can be made across different verbs or different senses of the same verb. PropBank takes the definition of verb senses from VerbNet, and for each verb and each sense defines the set of possible roles for that verb usage, called the roleset. The definition of rolesets is provided in the PropBank Frames files, which is made available for the shared task as an official resource to develop systems.</p><p>• • Verbs (V): Participant realizing the verb of the proposition, with exactly one verb for each one.</p><p>We used the February 2004 release of PropBank. Most predicative verbs were annotated, although not all of them (for example, most of the occurrences of the verb "to have" and "to be" were not annotated). We applied procedures to check consistency of propositions, looking for overlapping arguments, and incorrect semantic role labels. Also, co-referenced arguments were annotated as a single item in PropBank, and we automatically distinguished between the referent and the reference with simple rules matching pronominal expressions, which were tagged as R arguments. A total number of 68 propositions were not compliant with our procedures, and were filtered out from the CoNLL data sets. The predicateargument annotations, thus, are not necessarily complete in a sentence. Table <ref type="table">1</ref> provides counts of the number of sentences, annotated propositions, distinct verbs and arguments in the three data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Preprocessing</head><p>In this section we describe the pipeline of processors to compute the annotations which form the input part of the data: part-of-speech (PoS) tags, chunks, clauses and named entities. The preprocessors correspond to the following state-of-the-art systems for each level of annota- </p><formula xml:id="formula_1">R-A3 8 0 1 R-AA 1 0 0 R-AM-ADV 1 0 0 R-AM-LOC 27 4 4 R-AM-MNR 4 0 1 R-AM-PNC 1 0 1 R-AM-TMP 35 6 14</formula><p>Table <ref type="table">1</ref>: Counts on the three data sets.</p><p>• PoS tagger: <ref type="bibr" target="#b10">(Giménez and Màrquez, 2003)</ref>, based on Support Vector Machines, and trained on Penn Treebank sections 0-18.</p><p>• Chunker and Clause Recognizer: <ref type="bibr" target="#b1">(Carreras and Màrquez, 2003)</ref>, based on Voted Perceptrons, and following the CoNLL settings of 2000 and 2001 tasks <ref type="bibr" target="#b24">(Tjong Kim Sang and Buchholz, 2000;</ref><ref type="bibr" target="#b26">Tjong Kim Sang and Déjean, 2001)</ref>. These two processors form a coherent partial syntax of a sentence, that is, chunks and clauses form a tree.</p><p>• Named entities with <ref type="bibr" target="#b4">(Chieu and Ng, 2003)</ref>, based on Maximum-Entropy classifiers, and following the CoNLL-2003 task setting <ref type="bibr" target="#b25">(Tjong Kim Sang and De Meulder, 2003)</ref>. Such processors were ran in a pipeline, from PoS tags, to chunks, clauses and finally named entities. Table <ref type="table">2</ref> summarizes the performance of the processors on the development and test sections. These figures differ from the original results in the original due to a better quality of the input information in our runs. The figures of the named entity extractor are based on the corpus of the CoNLL-2003 shared task, since gold annotations of named entities were not available for the current corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Format</head><p>Figure <ref type="figure" target="#fig_3">1</ref> shows an example of a fully-annotated sentence. Annotations of a sentence are given using a flat representation in columns, separated by spaces. Each column encodes an annotation by associating a tag with every word. For each sentence, the following columns are provided: 1. Words. 2. Part of Speech tags. 3. Chunks in IOB2 format. 4. Clauses in Start-End format. 5. Named Entities in IOB2 format. 6. Target verbs, marking n predicative verbs. This column, provided as input, specifies the governing verbs of the propositions to be analyzed. Each target verb is in the base form. Occasionally this column does not mark any verb (i.e., n may be 0). 7. For each of the n target verbs, a column in Start-End format specifying the arguments of the proposition. These columns are the output of a system, that is, the ones to be predicted, and are not available for the test set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Start-End format.</head><p>Represents non-overlapping phrases (clauses or arguments) which may be embed-ded 3 inside one another. Each tag indicates whether a clause starts or ends at that word and is of the form START*END. The START part is a concatenation of (k parentheses, each representing that a phrase of type k starts at that word. The END part is a concatenation of k) parentheses, each representing that a phrase of type k ends at that word. For example, the * tag represents a word with no starts and ends; the (A0*A0) tag represents a word constituting an A0 argument; and the (S(S*S) tag represents a word which constitutes a base clause (labeled S) and starts another higher-level clause. Finally, the concatenation of all tags constitutes a well-formed bracketing. For the particular case of split arguments, of type k, the first part appears as a phrase with label k, and the remaining as phrases with label C-k (continuation prefix). See examples of annotations at columns 4th, 7th and 8th of Figure <ref type="figure" target="#fig_3">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Participating Systems</head><p>Ten systems have participated in the CoNLL-2004 shared task. They approached the task in several ways, using different learning components and labeling strategies. The following subsections briefly summarize the most important properties of each system and provide a qualitative comparison between them, together with a quantitative evaluation on the development and test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Learning techniques</head><p>Up to six different learning algorithms have been applied in the CoNLL-2004 shared task. None of them is new with respect to the past editions. Two teams used the Maximum Entropy (ME) statistical framework <ref type="bibr" target="#b0">(Baldewein et al., 2004;</ref><ref type="bibr" target="#b14">Lim et al., 2004)</ref>. Two teams used Brill's Transformation-based Error-driven Learning (TBL) <ref type="bibr" target="#b13">(Higgins, 2004;</ref><ref type="bibr" target="#b28">Williams et al., 2004)</ref>. Two other groups applied Memory-Based Learning (MBL) (van den <ref type="bibr" target="#b27">Bosch et al., 2004;</ref><ref type="bibr">Kouchnir, 2004)</ref> As a main difference with respect to past editions, less effort has been put into combining different learning algorithms and outputs. Instead, the main effort of participants went into developing useful SRL strategies and into the development of features (see sections 4.2 and 4.3). As an exception, van den Bosch et al. ( <ref type="formula">2004</ref>   <ref type="formula">4th</ref>) and named entities (5th). The 6th column marks target verbs, and their propositions are found in remaining columns. According to the PropBank Frames, for issue (7th), the A0 annotates the issuer, and the A1 the thing issued, which appears split into two parts. For fill (8th), A1 is the the destination, and A2 the theme.</p><p>voting strategy to derive the final sequence tagging as a voted combination of three overlapping n-gram output sequences. The same team also applied a meta-learning step, by using iterative classifier stacking, for correcting systematic errors committed by the low-level classifiers. This work is also worth mentioning because of the extensive work done on parameter tuning and feature selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">SRL approaches</head><p>SRL is a complex task which has to be decomposed into a number of simpler decisions and tagging schemes in order to be addressed by learning techniques. One first issue is the annotation of the different propositions of a sentence. Most of the groups treated the annotation of semantic roles for each verb predicate as an independent problem. An exception is the system of <ref type="bibr" target="#b2">Carreras et al. (2004)</ref>, which performs the annotation of all propositions simultaneously. As a consequence, the former teams treat the problem as the recognition of sequential structures (a.k.a. chunking), while the latter directly derives a hierarchical structure formed by the arguments of all propositions. Table <ref type="table" target="#tab_4">3</ref> summarizes the main properties of each system regarding the SRL strategy implemented. This property corresponds to the first column.</p><p>Regarding the labeling strategy, we can distinguish at least three different strategies. The first one consists of performing role identification directly by a IOB-type sequence tagging. The second approach consists of dividing the problem into two independent phases: recognition, in which the arguments are recognized, and label-ing, in which the already recognized arguments are assigned role labels. The third approach also proceeds in two phases: filtering, in which a set of argument candidates are decided and labeling, in which the set of optimal arguments is derived from the proposed candidates. As a variant of the first two-phase strategy, <ref type="bibr" target="#b27">van den Bosch et al. (2004)</ref> first perform a direct classification of chunks into argument labels, and then decide the actual arguments in a post-process by joining previously classified argument fragments. All this information is summarized in the second column of Table <ref type="table" target="#tab_4">3</ref>.</p><p>An implication of implementing the two-phase strategy is the ability to work with argument candidates in the second phase, allowing to develop feature patterns for complete arguments. Regarding the first phase, the recognition of candidate arguments is performed by means of a IOB or open-close tagging using classifiers, either argument-independent, or specialized by argument type.</p><p>It is also worth noting that all participant systems performed learning of predicate-independent classifiers instead of specializing by the verb predicate. Information about verb predicates is captured through features and some global restrictions.</p><p>Another important issue is the granularity at which the sentence elements are processed. It has become very clear that a good election for this problem is phrase-byphrase processing (P-by-P, using the notation introduced by <ref type="bibr" target="#b12">Hacioglu et al. (2004)</ref>) instead of word-by-word (Wby-W). The motivation is twofold: (1) phrase boundaries are almost always consistent with argument boundaries;</p><p>(2) P-by-P processing is computationally less expensive and allows to explore a relatively larger context. Most of the groups performed a P-by-P processing, but admitting a processing by words within the target verb chunks. The system by <ref type="bibr" target="#b0">Baldewein et al. (2004)</ref> works with a bit more general elements called "chunk sequences", extracted in a preprocess using heuristic rules. This information is presented in the third column of Table <ref type="table" target="#tab_4">3</ref>.</p><p>Information regarding clauses has proven to be very useful, as can be seen in section 4.3. All systems captured some kind of clause information through feature codification. However, some of the systems restrict the search for arguments only to the immediate clause <ref type="bibr" target="#b28">Williams et al., 2004)</ref> and others use the clause hierarchy to guide the exploration of the sentence <ref type="bibr" target="#b14">(Lim et al., 2004;</ref><ref type="bibr" target="#b2">Carreras et al., 2004)</ref>.</p><p>Very relevant to the SRL strategy is the availability of global sentential information when decisions are taken. Almost all of the systems try to capture some global level information by collecting features describing the target predicate and its context, the "syntactic path" from the element under consideration to the predicate, etc. (see section 4.3). But only some of them include a global optimization procedure at sentence level in the labeling strategy. The systems working with Maximum Entropy Models <ref type="bibr" target="#b0">(Baldewein et al., 2004;</ref><ref type="bibr" target="#b14">Lim et al., 2004</ref>) use beam search to find taggings that maximize the probability of the output sequence. <ref type="bibr" target="#b2">Carreras et al. (2004)</ref> and <ref type="bibr" target="#b21">Punyakanok et al. (2004)</ref> also define a global scoring function to maximize. At this point, the system of <ref type="bibr" target="#b21">Punyakanok et al. (2004)</ref> deserves special consideration, since it formally implements a set of structural and linguistic constraints directly in the global cost function to maximize. These constraints act as a filter for valid output sequences and ensure coherence of the output. Authors refer to this part of the system as the inference layer and they implement it using integer linear programming. The iterative classifier stacking mechanism used by van den Bosch et al. ( <ref type="formula">2004</ref>) also tries to alleviate the problem of locality of the low-level classifiers. This information is found in the fourth column of Table <ref type="table" target="#tab_4">3</ref>.</p><p>Finally, some systems use some kind of postprocessing to ensure coherence of the final labeling, correct some systematic errors, or to treat some types of adjunctive arguments. In most of the cases, this postprocess is performed on the basis of simple ad-hoc rules. This information is included in the last column of Table <ref type="table" target="#tab_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Features</head><p>With a very few exceptions all the participant systems have used all levels of linguistic information provided in the training data sets, that is, words, PoS and chunk labels, clauses, and named entities.</p><p>It is worth mentioning that the general type of features  derived from the basic information are strongly inspired by previous works on the SRL task <ref type="bibr" target="#b8">(Gildea and Jurafsky, 2002;</ref><ref type="bibr" target="#b22">Surdeanu et al., 2003;</ref><ref type="bibr" target="#b18">Pradhan et al., 2003a)</ref>. Many systems used the same kind of ideas but implemented in different ways, since the particular learning strategies used (see section 4.2) impose different constraints on the type of information available or the way of expressing it. As a general idea, we can divide the features into four types: (1) basic features, evaluating some kind of local information on the context of the word or constituent being treated; (2) Features characterizing the internal structure of a candidate argument; (3) Features describing properties of the target verb predicate; (4) Features that capture the relations between the verb predicate and the constituent under consideration.</p><p>All systems used some kind of basic features. Roughly speaking, they consist of words, PoS tags, chunks, clause labels, and named entities extracted from a windowbased context. These values can be considered with or without the relative position with respect to the element under consideration, and some n-grams of them can also be computed. If the granularity of the system is at phrase level then typically a representative head word of the phrase is used as lexical information. As an exception to the general approach, the system of <ref type="bibr" target="#b28">Williams et al. (2004)</ref> does not make use of word forms.</p><p>The rest of the features are more interesting since they are task dependent, and deserve special attention. Table <ref type="table">4</ref> summarizes the type of features exploited by systems.</p><p>To represent an argument itself, few attributes are of general usage. Some systems count the length of it, with different granularities. Others make use of heuristics to derive its syntactic type. There are systems that extract a structured representation of the argument, either homogeneous (capturing different sequences of head words, PoS tags, chunks or clauses), or heterogeneous (combining all elements, based on the syntactic hierarchy). A few systems have captured the existence of neighboring arguments, previously identified in the process. Interestingly, the system of <ref type="bibr" target="#b14">Lim et al. (2004)</ref> represents the context of an argument relative to the syntactic hierarchy by means of relative constituent sequences and syntactic levels. Concerning lexicalization of the argument, most of the techniques rely on head word rules based on Collins', or content word rules as in <ref type="bibr" target="#b22">Surdeanu et al. (2003)</ref>. Only <ref type="bibr" target="#b2">Carreras et al. (2004)</ref> decide to use a bag-of-words model, apart from heuristicbased lexicalization.</p><p>Regarding the target verb, the voice feature of the verb is generally used, in addition to basic features capturing the form and PoS tag of the verb. Some systems captured statistics on frequent argument patterns for each predicate. Also, systems represented the elements in the proximity of the target verb, inspired by local subcategorization patterns of a predicate.</p><p>As for features related to a constituent-predicate pair, all systems use the simple feature describing the relative position between them, and to a lesser degree, the distance and the difference in clausal levels. Again, there is a general tendency to describe the structured path from the argument to the verb. Its design goes from simple homogeneous sequences of head words or chunks, to more sophisticated paths combining chunks and clauses, and capturing hierarchical properties. The system of  also tracks the number of different syntactic elements found between the pair. Remarkably, the system of <ref type="bibr" target="#b0">Baldewein et al. (2004)</ref> uses an EM clustering technique to derive features representing the affinity of an argument and a predicate.</p><p>On top of basic feature extraction, all teams working with SVM and VP used polynomial kernels of degree 2. Similar in expressiveness, the system designed by <ref type="bibr" target="#b21">Punyakanok et al. (2004)</ref> expanded the feature space with all pairs of basic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation</head><p>A baseline rate was computed for the task. It was produced by a system developed by Erik Tjong Kim Sang, from the University of Antwerp, Belgium. The baseline processor finds semantic roles based on the following seven rules:</p><p>• Tag target verb and successive particles as V.</p><p>• Tag not and n't in target verb chunk as AM-NEG.</p><p>• Tag modal verbs in target verb chunk as AM-MOD.</p><p>• Tag first NP before target verb as A0.</p><p>• Tag first NP after target verb as A1.</p><p>• Tag that, which and who before target verb as R-A0. • Switch A0 and A1, and R-A0 and R-A1 if the target verb is part of a passive VP chunk. A VP chunk is considered in passive voice if it contains a form of to be and the verb does not end in ing.</p><p>Table <ref type="table" target="#tab_8">5</ref> presents the overall results obtained by the ten participating systems, on the development and test sets. The best performance was obtained by the SVMbased IOB tagger of <ref type="bibr" target="#b12">(Hacioglu et al., 2004)</ref>, which almost reached the performance of 70 in F 1 on the test. The seven best systems obtained F 1 scores in the range of 60-70, and only three systems scored below that.</p><p>Comparing the results across development and test corpora, most systems experienced a decrease in performance between 1.5 and 3 points. As in previous editions of the shared task, we attribute this behavior to a greater difficulty of the test set instead of an overfitting effect. Interestingly, the three systems performing below 60 in the development set did not experienced this decrease. In fact <ref type="bibr" target="#b28">(Williams et al., 2004)</ref> and <ref type="bibr" target="#b0">(Baldewein et al., 2004)</ref> even improved the results on the test set.</p><p>Table <ref type="table">6</ref> details the performance of systems for the A0-A4 arguments, on the test set. Consistently, the best performing system of the task also outperforms all other systems on these semantic roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have described the CoNLL-2004 shared task on semantic role labeling. The task was based on the Prop-Bank corpus, and the challenge was to come up with machine learning techniques to recognize and label semantic roles on the basis of partial syntactic structure. Ten systems have participated to the task, contributing with a variety of standard or novel learning architectures. The best system, presented by the most experienced group on the task <ref type="bibr" target="#b12">(Hacioglu et al., 2004)</ref>, achieved a moderate performance of 69.49 at the F 1 measure. It is based on a SVM tagging system, performing IOB decisions on the chunks of the sentence, and exploiting a wide variety of features based on partial syntax.</p><p>Most of the systems advance the state-of-the-art on semantic role labeling on the basis of partial syntax. However, state-of-the-art systems working with full syntax still perform substantially better, although far from a desired behavior for real-task application.   <ref type="table">4</ref>: Main feature types used by the 10 participating systems in the CoNLL-2004 shared task, sorted by performance on the test set. "sy": use of partial syntax (all levels); "ne": use of named entities; "al": argument length; "at": argument type; "as": argument internal structure; "aw": head-word lexicalization of arguments; "an": neighboring arguments; "vv": verb voice; "vs": verb statistics; "vf": verb features derived from PropBank frames; "vc": verb local context; "rp": relative position; "di": distance (horizontal or in the hierarchy); "pa": path; "ex": feature expansion.</p><p>most contributed to the performance of systems.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Adjuncts (AM-): General arguments that any verb may take optionally. There are 13 types of adjuncts: AM-ADV : general-purpose AM-MOD : modal verb AM-CAU : cause AM-NEG : negation marker AM-DIR : direction AM-PNC : purpose AM-DIS : discourse marker AM-PRD : predication AM-EXT : extent AM-REC : reciprocal AM-LOC : location AM-TMP : temporal AM-MNR : manner • References (R-): Arguments representing arguments realized in other parts of the sentence. The role of a reference is the same as the role of the referenced argument. The label is an R-tag prefixed to the label of the referent, e.g. R-A1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>IOB2 format .</head><label>format</label><figDesc>Represents chunks which do not overlap nor embed. Words outside a chunk receive the tag O. For words forming a chunk of type k, the first word receives the B-k tag (Begin), and the remaining words receive the tag I-k (Inside).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>. The remaining four teams employed vector-based linear classifiers of different types: Hacioglu et al. (2004) and Park et al. (2004) used Support Vector Machines (SVM) with polynomial kernels, Carreras et al. (2004) used Voted Perceptrons (VP) also with polynomial kernels, and finally, Punyakanok et al. (2004) used SNoW, a Winnow-based network of linear separators. Additionally, the team of Baldewein et al. (2004) used a EM-based clustering algorithm for feature development (see section 4.3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of an annotated sentence, in columns. Input consists of words (1st), PoS tags (2nd), base chunks (3rd), clauses (4th) and named entities (5th). The 6th column marks target verbs, and their propositions are found in remaining columns. According to the PropBank Frames, for issue (7th), the A0 annotates the issuer, and the A1 the thing issued, which appears split into two parts. For fill (8th), A1 is the the destination, and A2 the theme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: Main properties of the SRL strategies imple-</cell></row><row><cell>mented by the ten participant teams (sorted by perfor-</cell></row><row><cell>mance on the test set). "prop." stands for the treatment of</cell></row><row><cell>all propositions of a sentence; possible values are: s (sep-</cell></row><row><cell>arate) and j (joint). "lab." stands for labeling strategy;</cell></row><row><cell>possible values are: t (one step tagging), rc (recognition</cell></row><row><cell>+ classification), fl (filtering + labeling), cj (classifica-</cell></row><row><cell>tion + joining). "gran." stands for granularity; "glob."</cell></row><row><cell>stands for global optimization. "post" stands for post-</cell></row><row><cell>processing.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Two questions remain open: which syntactic structures are needed as input for the task, and what other sources of information are required to obtain a real-world, accurate performance.As a future line, a more thorough experimental evaluation is required to see which are the components that sy ne al at as aw an vv vs vf vc rp di pa ex</figDesc><table><row><cell>hacioglu</cell><cell>+</cell><cell cols="2">+ + --</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell cols="2">+ + +</cell><cell>+</cell></row><row><cell>punyakanok</cell><cell>+</cell><cell cols="2">+ + + +</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>+ -</cell><cell>+</cell><cell>+</cell></row><row><cell>carreras</cell><cell>+</cell><cell>-</cell><cell>--+</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>+ -</cell><cell>+</cell><cell>+</cell></row><row><cell>lim</cell><cell>+</cell><cell>-</cell><cell>---</cell><cell>+</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>+ -</cell><cell>+</cell><cell>-</cell></row><row><cell>park</cell><cell>+</cell><cell>-</cell><cell>---</cell><cell>-</cell><cell>-</cell><cell>+</cell><cell>-</cell><cell>-</cell><cell>+</cell><cell cols="2">+ + +</cell><cell>+</cell></row><row><cell>higgins</cell><cell>+</cell><cell>+</cell><cell>---</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">+ + +</cell><cell>-</cell></row><row><cell cols="2">van den bosch +</cell><cell>+</cell><cell>---</cell><cell>-</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>-</cell><cell>+ +</cell><cell>-</cell><cell>-</cell></row><row><cell>kouchnir</cell><cell>+</cell><cell>-</cell><cell>+ -+</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>-</cell><cell>+ +</cell><cell>-</cell><cell>-</cell></row><row><cell>baldewein</cell><cell>+</cell><cell cols="2">+ + + +</cell><cell>+</cell><cell>-</cell><cell>+</cell><cell>+</cell><cell>-</cell><cell>-</cell><cell>+ +</cell><cell>-</cell><cell>-</cell></row><row><cell>williams</cell><cell>+</cell><cell>+</cell><cell>---</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>+ -</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Overall precision, recall and F 1 rates obtained by the ten participating systems in the CoNLL-2004 shared task on the development and test sets.BeataKouchnir. 2004. A memory-based approach for semantic role labeling. In Proceedings ofCoNLL- 2004.   </figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1"> CoNLL-2004  Shared Task web page -with data, software and systems' outputs available-at http://cnts.uia.ac.be/conll2004/roles .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The srl-eval.pl program is the official program to evaluate the performance of a system. It is available at the Shared Task web page.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Arguments in data do not embed, though format allows so.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Authors would like to thank the following people and institutions. The PropBank team, and specially Martha Palmer and Scott Cotton, for making the corpus available. The CoNLL-2004 board for fruitful discussions and suggestions. In particular, Erik Tjong Kim Sang for useful comments from his valuable experience, and for making the baseline SRL processor available. Lluís Padró and Mihai Surdeanu, Grzegorz Chrupała, and Hwee Tou Ng for helping us in the reviewing process and the preparation of this document. Finally, the teams contributing to shared task, for their great interest in participating.</p><p>This work has been partially funded by the European Commission (Meaning, IST-2001-34460)  and the Spanish Research Department (Aliado, TIC2002-04447-C02). Xavier Carreras is supported by a pre-doctoral grant from the Catalan Research Department.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semantic role labeling with chunk sequences</title>
		<author>
			<persName><forename type="first">Ulrike</forename><surname>Baldewein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Padó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Detlef</forename><surname>Prescher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Phrase recognition by filtering and ranking with perceptrons</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP-2003</title>
				<meeting>RANLP-2003<address><addrLine>Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hierarchical recognition of propositional arguments with perceptrons</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Chrupała</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Use of deep linguistic features for the recognition and labeling of semantic arguments</title>
		<author>
			<persName><forename type="first">John</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2003</title>
				<meeting>EMNLP-2003<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Named entity recognition with a maximum entropy approach</title>
		<author>
			<persName><forename type="first">Hai</forename><surname>Leong Chieu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2003</title>
				<meeting>CoNLL-2003<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Building a large lexical databank which provides deep semantics</title>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Wooters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><forename type="middle">F</forename><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Pacific Asian Conference on Language, Informa tion and Computation</title>
				<meeting>the Pacific Asian Conference on Language, Informa tion and Computation<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximum entropy models for framenet classification</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Fleischman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Namhee</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2003</title>
				<meeting>EMNLP-2003<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Identifying semantic roles using combinatory categorial grammar</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Hockenmaier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP-2003</title>
				<meeting>EMNLP-2003<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="288" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The necessity of parsing for predicate argument recognition</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
				<meeting>ACL<address><addrLine>Philadelphia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast and accurate part-of-speech tagging: The svm approach revisited</title>
		<author>
			<persName><forename type="first">Jesús</forename><surname>Giménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP-2003</title>
				<meeting>RANLP-2003<address><addrLine>Borovets</addrLine></address></meeting>
		<imprint>
			<publisher>Bulgaria</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Target word detection and semantic role chunking using support vector machines</title>
		<author>
			<persName><forename type="first">Kadri</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of HLT-NAACL 2003</title>
				<meeting>HLT-NAACL 2003<address><addrLine>Edmonton, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semantic role labeling by tagging syntactic chunks</title>
		<author>
			<persName><forename type="first">Kadri</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A transformation-based approach to argument labeling</title>
		<author>
			<persName><forename type="first">Derrick</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semantic role labeling using maximum entropy model</title>
		<author>
			<persName><forename type="first">Joon-Ho</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young-Sook</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">So-Young</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hae-Chang</forename><surname>Rim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: the Penn Treebank</title>
		<author>
			<persName><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The proposition bank: An annotated corpus of semantic roles. Computational Linguistics</title>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Submitted</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Two-phase semantic role labeling based on support vector machines</title>
		<author>
			<persName><forename type="first">Kyung-Mi</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Young-Sook</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hae-Chang</forename><surname>Rim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Support vector learning for semantic argument classification</title>
		<author>
			<persName><forename type="first">Kadri</forename><surname>Sameer Pradhan</surname></persName>
			<affiliation>
				<orgName type="collaboration">A1 A2 A3 A4 hacioglu 81</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Valerie</forename><surname>Hacioglu</surname></persName>
			<affiliation>
				<orgName type="collaboration">A1 A2 A3 A4 hacioglu 81</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Krugler</surname></persName>
			<affiliation>
				<orgName type="collaboration">A1 A2 A3 A4 hacioglu 81</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Ward</surname></persName>
			<affiliation>
				<orgName type="collaboration">A1 A2 A3 A4 hacioglu 81</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Martin</surname></persName>
			<affiliation>
				<orgName type="collaboration">A1 A2 A3 A4 hacioglu 81</orgName>
			</affiliation>
		</author>
		<author>
			<persName><surname>Jurafsky</surname></persName>
			<affiliation>
				<orgName type="collaboration">A1 A2 A3 A4 hacioglu 81</orgName>
			</affiliation>
		</author>
		<idno>66.67 punyakanok 79.38 68.16 46.69 34.04 65.22 carreras 79.05 66.96 43.28 31.22 62.07 lim 77.42 66.00 49.07 41.77 54.55 park 76.38 66.14 46.57 42.32 51.76 higgins 70.67 62.72 45.52 40.00 39.64 van den bosch 74.95 60.83 40.41 37.44 62.37 kouchnir 65.49 54.48 30.95 19.71 36.07 baldewein 66.76 53.37 37.60 22.89 27.69 williams 56.24 49.05 00.00 00.00 00.00 baseline 57.65 34.19 00.00 00.00 00.00</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page">51</biblScope>
		</imprint>
		<respStmt>
			<orgName>Center for Spoken Language Research, University of Colorado</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m">Table 6: F 1 scores on the most frequent core argument types obtained by the ten participating systems in the CoNLL-2004 shared task on the test set. Systems sorted by overall performance on the test set</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semantic role parsing: Adding semantic structure to unstructured text</title>
		<author>
			<persName><forename type="first">Kadri</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Data Mining (ICDM-2003)</title>
				<meeting>the International Conference on Data Mining (ICDM-2003)<address><addrLine>Melbourne, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semantic role labeling via generalized inference over classifiers</title>
		<author>
			<persName><forename type="first">Vasin</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dav</forename><surname>Zimak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuancheng</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using predicate-argument structures for information extraction</title>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Aarseth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2003</title>
				<meeting>ACL 2003<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A generative model for semantic role labeling</title>
		<author>
			<persName><forename type="first">Cynthia</forename><forename type="middle">A</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roger</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ECML&apos;03</title>
				<meeting>ECML&apos;03<address><addrLine>Dubrovnik, Croatia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2000 shared task: Chunking</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Tjong Kim Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Buchholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Conference on Natural Language Learning</title>
				<meeting>the 4th Conference on Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Languageindependent named entity recognition</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2003</title>
				<meeting>CoNLL-2003</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2001 shared task: Clause identification</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hervé</forename><surname>Déjean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Conference on Natural Language Learning</title>
				<meeting>the 5th Conference on Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Memory-based semantic role labeling: Optimizing features, algorithm, and output</title>
		<author>
			<persName><forename type="first">Antal</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sander</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><surname>Canisius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Walter Daelemans, Iris Hendrickx, and Erik Tjong Kim Sang</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning transformation rules for semantic role labeling</title>
		<author>
			<persName><forename type="first">Ken</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Dozier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mcculloh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2004</title>
				<meeting>CoNLL-2004</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
