<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2007 Task 16: Evaluation of Wide Coverage Knowledge Resources</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Montse</forename><surname>Cuadros</surname></persName>
							<email>cuadros@lsi.upc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">TALP Research Center Universitat Polit√©cnica de Catalunya Barcelona</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">German</forename><surname>Rigau</surname></persName>
							<email>german.rigau@ehu.es</email>
							<affiliation key="aff1">
								<orgName type="laboratory">IXA NLP Group Euskal Herriko Unibersitatea Donostia</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2007 Task 16: Evaluation of Wide Coverage Knowledge Resources</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This task tries to establish the relative quality of available semantic resources (derived by manual or automatic means). The quality of each large-scale knowledge resource is indirectly evaluated on a Word Sense Disambiguation task. In particular, we use Senseval-3 and SemEval-2007 English Lexical Sample tasks as evaluation bechmarks to evaluate the relative quality of each resource. Furthermore, trying to be as neutral as possible with respect the knowledge bases studied, we apply systematically the same disambiguation method to all the resources. A completely different behaviour is observed on both lexical data sets (Senseval-3 and SemEval-2007).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Using large-scale knowledge bases, such as <ref type="bibr">Word-Net (Fellbaum, 1998)</ref>, has become a usual, often necessary, practice for most current Natural Language Processing (NLP) systems. Even now, building large and rich enough knowledge bases for broad-coverage semantic processing takes a great deal of expensive manual effort involving large research groups during long periods of development. In fact, dozens of person-years have been invested in the development of wordnets for various languages <ref type="bibr">(Vossen, 1998)</ref>. For example, in more than ten years of manual construction (from version 1.5 to 2.1), WordNet passed from 103,445 semantic relations to 245,509 semantic relations 1 . That is, around one thousand new relations per month. But this data does not seems to be rich enough to support advanced concept-based NLP applications directly. It seems that applications will not scale up to working in open domains without more detailed and rich general-purpose (and also domain-specific) semantic knowledge built by automatic means.</p><p>Fortunately, during the last years, the research community has devised a large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora. Among others we can mention eXtended WordNet <ref type="bibr" target="#b13">(Mihalcea and Moldovan, 2001)</ref>, large collections of semantic preferences acquired from SemCor <ref type="bibr" target="#b1">(Agirre and Martinez, 2001;</ref><ref type="bibr" target="#b2">Agirre and Martinez, 2002)</ref> or acquired from British National Corpus (BNC) <ref type="bibr" target="#b12">(McCarthy, 2001)</ref>, largescale Topic Signatures for each synset acquired from the web <ref type="bibr" target="#b0">(Agirre and de la Calle, 2004)</ref> or acquired from the BNC <ref type="bibr" target="#b5">(Cuadros et al., 2005)</ref>. Obviously, these semantic resources have been acquired using a very different set of methods, tools and corpora, resulting on a different set of new semantic relations between synsets (or between synsets and words).</p><p>Many international research groups are working on knowledge-based WSD using a wide range of approaches <ref type="bibr" target="#b14">(Mihalcea, 2006)</ref>. However, less attention has been devoted on analysing the quality of each semantic resource. In fact, each resource presents different volume and accuracy figures <ref type="bibr" target="#b6">(Cuadros et al., 2006)</ref>.</p><p>In this paper, we evaluate those resources on the SemEval-2007 English Lexical Sample task. For comparison purposes, we also include the results of the same resources on the Senseval-3 English Lexical sample task. In both cases, we used only the nominal part of both data sets and we also included some basic baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation Framework</head><p>In order to compare the knowledge resources, all the resources are evaluated as Topic Signatures (TS).</p><p>That is, word vectors with weights associated to a particular synset. Normally, these word vectors are obtained by collecting from the resource under study the word senses appearing as direct relatives. This simple representation tries to be as neutral as possible with respect to the resources studied. A common WSD method has been applied to all knowledge resources on the test examples of Senseval-3 and SemEval-2007 English lexical sample tasks. A simple word overlapping counting is performed between the Topic Signature and the test example. The synset having higher overlapping word counts is selected. In fact, this is a very simple WSD method which only considers the topical information around the word to be disambiguated. Finally, we should remark that the results are not skewed (for instance, for resolving ties) by the most frequent sense in WN or any other statistically predicted knowledge.</p><p>As an example, table 1 shows a test example of SemEval-2007 corresponding to the first sense of the noun capital. In bold there are the words that appear in its corresponding Topic Signature acquired from the web.</p><p>Note that although there are several important related words, the WSD process implements exact word form matching (no preprocessing is performed).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Basic Baselines</head><p>We have designed a number of basic baselines in order to establish a complete evaluation framework for comparing the performance of each semantic resource on the English WSD tasks.</p><p>RANDOM: For each target word, this method selects a random sense. This baseline can be considered as a lower-bound.  Train Topic Signatures (TRAIN): This baseline uses the training corpus to directly build a Topic Signature using TFIDF measure for each word sense. Note that this baseline can be considered as an upper-bound of our evaluation.</p><p>Table <ref type="table" target="#tab_1">2</ref> presents the precision (P), recall (R) and F1 measure (harmonic mean of recall and precision) of the different baselines in the English Lexical Sample exercise of Senseval-3. In this table, TRAIN has been calculated with a vector size of at maximum 450 words. As expected, RANDOM baseline obtains the poorest result. The most frequent senses obtained from SemCor (SEMCOR-MFS) and WN (WN-MFS) are both below the most frequent sense of the training corpus (TRAIN-MFS). However, all of them are far below the Topic Signatures acquired using the training corpus (TRAIN).</p><p>Table <ref type="table" target="#tab_3">3</ref> presents the precision (P), recall (R) and F1 measure (harmonic mean of recall and precision) of the different baselines in the English Lexical Sample exercise of SemEval-2007. Again, TRAIN has been calculated with a vector size of at maximum 450 words. As before, RANDOM baseline obtains the poorest result. The most frequent senses obtained from SemCor (SEMCOR-MFS) and WN (WN-MFS) are both far below the most frequent sense of the training corpus (TRAIN-MFS), and all of them are below the Topic Signatures acquired using the training corpus (TRAIN).</p><p>Comparing both lexical sample sets, SemEval-2007 data appears to be more skewed and simple for WSD systems than the data set from Senseval-3: less &lt;instance id="19:0@11@wsj/01/wsj 0128@wsj@en@on" docsrc="wsj"&gt; &lt;context&gt; " A sweeping restructuring of the industry is possible . " Standard &amp; Poor 's Corp. says First Boston , Shearson and Drexel Burnham Lambert Inc. , in particular , are likely to have difficulty shoring up their credit standing in months ahead . What worries credit-rating concerns the most is that Wall Street firms are taking long-term risks with their own &lt;head&gt; capital &lt;/head&gt; via leveraged buy-out and junk bond financings . That 's a departure from their traditional practice of transferring almost all financing risks to investors . Whereas conventional securities financings are structured to be sold quickly , Wall Street 's new penchant for leveraged buy-outs and junk bonds is resulting in long-term lending commitments that stretch out for months or years . &lt;/context&gt; &lt;/instance&gt;  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Large scale knowledge Resources</head><p>The evaluation presented here covers a wide range of large-scale semantic resources: WordNet (WN) <ref type="bibr">(Fellbaum, 1998)</ref>, eXtended WordNet <ref type="bibr" target="#b13">(Mihalcea and Moldovan, 2001)</ref>, large collections of semantic preferences acquired from SemCor <ref type="bibr" target="#b1">(Agirre and Martinez, 2001;</ref><ref type="bibr" target="#b2">Agirre and Martinez, 2002)</ref>   <ref type="bibr">, 2006)</ref>. Although these resources have been derived using different WN versions, using the technology for the automatic alignment of wordnets <ref type="bibr" target="#b7">(Daud√© et al., 2003)</ref>, most of these resources have been integrated into a common resource called Multilingual Central Repository (MCR) <ref type="bibr" target="#b3">(Atserias et al., 2004)</ref> maintaining the compatibility among all the knowledge resources which use a particular WN version as a sense repository. Furthermore, these mappings al-low to port the knowledge associated to a particular WN version to the rest of WN versions.</p><p>The current version of the MCR contains 934,771 semantic relations between synsets, most of them acquired by automatic means. This represents almost four times larger than the Princeton WordNet (245,509 unique semantic relations in WordNet 2.1).</p><p>Hereinafter we will refer to each semantic resource as follows:</p><p>WN <ref type="bibr">(Fellbaum, 1998)</ref>: This resource uses the direct relations encoded in WN1.6 or WN2.0 (for instance, tree#n#1-hyponym-&gt;teak#n#2). We also tested WN 2 (using relations at distances 1 and 2), WN 3 (using relations at distances 1 to 3) and WN 4 (using relations at distances 1 to 4).</p><p>XWN <ref type="bibr" target="#b13">(Mihalcea and Moldovan, 2001</ref>): This resource uses the direct relations encoded in eXtended WN (for instance, teak#n#2-gloss-&gt;wood#n#1).</p><p>WN+XWN: This resource uses the direct relations included in WN and XWN. We also tested (WN+XWN) 2 (using either WN or XWN relations at distances 1 and 2, for instance, tree#n#1-related-&gt;wood#n#1).</p><p>spBNC <ref type="bibr" target="#b12">(McCarthy, 2001)</ref>: This resource contains 707,618 selectional preferences acquired for subjects and objects from BNC.</p><p>spSemCor <ref type="bibr" target="#b2">(Agirre and Martinez, 2002)</ref>: This resource contains the selectional preferences acquired for subjects and objects from SemCor (for instance, read#v#1-tobj-&gt;book#n#1).</p><p>MCR <ref type="bibr" target="#b3">(Atserias et al., 2004)</ref>: This resource uses the direct relations included in MCR but excluding spBNC because of its poor performance. Thus, MCR contains the direct relations from WN (as tree#n#1-hyponym-&gt;teak#n#2), XWN (as teak#n#2-gloss-&gt;wood#n#1), and spSemCor (as read#v#1-tobj-&gt;book#n#1) but not the indi-  rect relations of (WN+XWN) 2 (tree#n#1-related-&gt;wood#n#1). We also tested MCR 2 (using relations at distances 1 and 2), which also integrates (WN+XWN) 2 relations. Table <ref type="table" target="#tab_6">4</ref> shows the number of semantic relations between synset pairs in the MCR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Topic Signatures</head><p>Topic Signatures (TS) are word vectors related to a particular topic <ref type="bibr" target="#b11">(Lin and Hovy, 2000)</ref>. Topic Signatures are built by retrieving context words of a target topic from large corpora. In our case, we consider word senses as topics.</p><p>For this study, we use two different large-scale Topic Signatures. The first constitutes one of the largest available semantic resource with around 100 million relations (between synsets and words) acquired from the web <ref type="bibr" target="#b0">(Agirre and de la Calle, 2004)</ref>. The second has been derived directly from SemCor.</p><p>TSWEB 2 : Inspired by the work of , these Topic Signatures were constructed using monosemous relatives from WordNet (synonyms, hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the words with distinctive frequency using TFIDF. For these experiments, we used at maximum the first 700 words of each TS.</p><p>TSSEM: These Topic Signatures have been constructed using the part of SemCor having all words tagged by PoS, lemmatized and sense tagged according to WN1.6 totalizing 192,639 words. For each word-sense appearing in SemCor, we gather all sentences for that word sense, building a TS using TFIDF for all word-senses co-occurring in those sentences.  In table 5, there is an example of the first wordsenses we calculate from party#n#1.</p><p>The total number of relations between WN synsets acquired from SemCor is 932,008.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluating each resource</head><p>Table <ref type="table" target="#tab_10">6</ref> presents ordered by F1 measure, the performance of each knowledge resource on Senseval-3 and the average size of the TS per word-sense. The average size of the TS per word-sense is the number of words associated to a synset on average. Obviously, the best resources would be those obtaining better performances with a smaller number of associated words per synset. The best results for precision, recall and F1 measures are shown in bold. We also mark in italics those resources using non-direct relations. Surprisingly, the best results are obtained by TSSEM (with F1 of 52.4). The lowest result is obtained by the knowledge directly gathered from WN mainly because of its poor coverage (R of 18.4 and F1 of 26.1). Also interesting, is that the knowledge integrated in the MCR although partly derived by automatic means performs much better in terms of precision, recall and F1 measures than using them separately (F1 with 18.4 points higher than WN, 9.1 than XWN and 3.7 than spSemCor).</p><p>Despite its small size, the resources derived from SemCor obtain better results than its counterparts using much larger corpora (TSSEM vs. TSWEB and spSemCor vs. spBNC).</p><p>Regarding the basic baselines, all knowledge resources surpass RANDOM, but none achieves neither WN-MFS, TRAIN-MFS nor TRAIN. Only  Table <ref type="table" target="#tab_12">7</ref> presents ordered by F1 measure, the performance of each knowledge resource on SemEval-2007 and its average size of the TS per word-sense 3 . The best results for precision, recall and F1 measures are shown in bold. We also mark in italics those resources using non-direct relations.</p><p>Interestingly, on SemEval-2007, all the knowledge resources behave differently. Now, the best results are obtained by (WN+XWN) 2 (with F1 of 52.9), followed by TSWEB (with F1 of 51.0). The lowest result is obtained by the knowledge encoded in spBNC mainly because of its poor precision <ref type="bibr">(P of 24.4 and F1 of 20.8)</ref>.</p><p>Regarding the basic baselines, spBNC, WN (and also WN 2 and WN 4 ) and spSemCor do not surpass RANDOM, and none achieves neither WN-MFS, TRAIN-MFS nor TRAIN. Now, WN+XWN, XWN, TSWEB and (WN+XWN) 2 obtain better results than SEMCOR-MFS but far below the most frequent sense of WN (WN-MFS) and the training (TRAIN-MFS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Combination of Knowledge Resources</head><p>In order to evaluate deeply the contribution of each knowledge resource, we also provide some results of the combined outcomes of several resources. The 3 The average size is different with respect Senseval-3 because the words selected for this task are different    <ref type="bibr" target="#b4">(Brody et al., 2006)</ref>.</p><p>Rank-Based Combination (Rank): Each semantic resource provides a ranking of senses of the word to be disambiguated. For each sense, its placements according to each of the methods are summed and the sense with the lowest total placement (closest to first place) is selected.</p><p>Table <ref type="table" target="#tab_13">8</ref> presents the F1 measure result with respect this method when combining four different semantic resources on the Senseval-3 test set.</p><p>Regarding the basic baselines, this combination outperforms the most frequent sense of SemCor (SEMCOR-MFS with F1 of 49.1), WN (WN-MFS with F1 of 53.0) and, the training data (TRAIN-MFS with F1 of 54.5).</p><p>Table <ref type="table">9</ref> presents the F1 measure result with respect the rank mthod when combining the same four different semantic resources on the SemEval-2007 test set. <ref type="bibr">KB</ref> Rank MCR+(WN+XWN) 2 +TSWEB+TSSEM 38.9</p><p>Table 9: F1 fine-grained results for the 4 systemcombinations on <ref type="bibr">SemEval-2007</ref> In this case, the combination of the four resources obtains much lower result. Regarding the baselines, this combination performs lower than the most frequent senses from SEMCOR, WN or the training data. This could be due to the poor individual performance of the knowledge derived from SemCor (spSemCor, TSSEM and MCR, which integrates spSemCor). Possibly, in this case, the knowledge comming from SemCor is counterproductive. Interestingly, the knowledge derived from other sources (XWN from WN glosses and TSWEB from the web) seems to be more robust with respect corpus changes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Although this task had no participants, we provide the performances of a large set of knowledge resources on two different test sets: Senseval-3 and SemEval-2007 English Lexical Sample task. We also provide the results of a system combination of four large-scale semantic resources. When evaluated on Senseval-3, the combination of knowledge sources surpass the most-frequent classifiers. However, a completely different behaviour is observed on SemEval-2007 data test. In fact, both corpora present very different characteristics. The results show that some resources seems to be less dependant than others to corpus changes.</p><p>Obviously, these results suggest that much more research on acquiring, evaluating and using largescale semantic resources should be addressed.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: P, R and F1 results for English Lexical Sam-</cell></row><row><cell>ple Baselines of Senseval-3</cell></row><row><cell>SemCor MFS (SEMCOR-MFS): This method</cell></row><row><cell>selects the most frequent sense of the target word</cell></row><row><cell>in SemCor.</cell></row><row><cell>WordNet MFS (WN-MFS): This method selects</cell></row><row><cell>the first sense in WN1.6 of the target word.</cell></row><row><cell>TRAIN-MFS: This method selects the most fre-</cell></row><row><cell>quent sense in the training corpus of the target word.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Example of test id for capital#n which its correct sense is 1</figDesc><table><row><cell>Baselines</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>TRAIN</cell><cell cols="3">87.6 87.6 87.6</cell></row><row><cell>TRAIN-MFS</cell><cell cols="3">81.2 79.6 80.4</cell></row><row><cell>WN-MFS</cell><cell cols="3">66.2 59.9 62.9</cell></row><row><cell cols="4">SEMCOR-MFS 42.4 38.4 40.3</cell></row><row><cell>RANDOM</cell><cell cols="3">27.4 27.4 27.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>P, R and F1 results for English Lexical Sample Baselines of SemEval-2007 polysemous (as shown by the RANDOM baseline), less similar than SemCor word sense frequency distributions (as shown by SemCor-MFS), more similar to the first sense of WN (as shown by WN-MFS), much more skewed to the first sense of the training corpus (as shown by TRAIN-MFS), and much more easy to be learned (as shown by TRAIN).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Semantic relations uploaded in the MCR</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Topic Signatures for party#n#1 obtained</cell></row><row><cell>from Semcor (11 out of 719 total word senses)</cell></row></table><note>.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>: P, R and F1 fine-grained results for the</cell></row><row><cell>resources evaluated individually at Senseval-03 En-</cell></row><row><cell>glish Lexical Sample Task.</cell></row><row><cell>TSSEM obtains better results than SEMCOR-MFS</cell></row><row><cell>and is very close to the most frequent sense of WN</cell></row><row><cell>(WN-MFS) and the training (TRAIN-MFS).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell cols="2">: P, R and F1 fine-grained results for the</cell></row><row><cell cols="2">resources evaluated individually at SemEval-2007,</cell></row><row><cell>English Lexical Sample Task .</cell><cell></cell></row><row><cell>KB</cell><cell>Rank</cell></row><row><cell cols="2">MCR+(WN+XWN) 2 +TSWEB+TSSEM 55.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>: F1 fine-grained results for the 4 system-</cell></row><row><cell>combinations on Senseval-3</cell></row><row><cell>combinations are performed following a very basic</cell></row><row><cell>strategy</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Symmetric relations are counted only once.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://ixa.si.ehu.es/Ixa/resources/ sensecorpus</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgements</head><p>We want to thank the valuable comments of the anonymous reviewers. This work has been partially supported by the projects KNOW (TIN2006-15049-C03-01) and ADIMEN (EHU06/113).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Publicly available topic signatures for all wordnet nominal senses</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lopez De La Calle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
				<meeting>LREC<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning class-to-class selectional preferences</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL</title>
				<meeting>CoNLL<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Integrating selectional preferences in wordnet</title>
		<author>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GWC</title>
				<meeting>GWC<address><addrLine>Mysore, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The meaning multilingual central repository</title>
		<author>
			<persName><forename type="first">J</forename><surname>Atserias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Villarejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piek</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GWC</title>
				<meeting>GWC<address><addrLine>Brno, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ensemble methods for unsupervised wsd</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING-ACL</title>
				<meeting>COLING-ACL</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Comparing methods for automatic acquisition of topic signatures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cuadros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Padr√≥</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP</title>
				<meeting>RANLP<address><addrLine>Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An empirical study for automatic acquisition of topic signatures</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cuadros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Padr√≥</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of GWC</title>
				<meeting>GWC</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="51" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Validation and Tuning of Wordnet Mapping Techniques</title>
		<author>
			<persName><forename type="first">J</forename><surname>Daud√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Padr√≥</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of RANLP</title>
				<meeting>RANLP<address><addrLine>Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">WordNet. An Electronic Lexical Database</title>
		<editor>C. Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Building a semantic concordance of english. In WordNet: An electronic lexical database and some applications</title>
		<author>
			<persName><forename type="first">S</forename><surname>Landes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tengi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="97" to="104" />
			<pubPlace>Cambridge,MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using Corpus Statistics and WordNet Relations for Sense Identification</title>
		<author>
			<persName><forename type="first">C</forename><surname>Leacock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chodorow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="166" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The automated acquisition of topic signatures for text summarization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING</title>
				<meeting>COLING<address><addrLine>Strasbourg, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Lexical Acquisition at the Syntax-Semantics Interface: Diathesis Aternations, Subcategorization Frames and Selectional Preferences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mccarthy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>University of Sussex</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moldovan</surname></persName>
		</author>
		<title level="m">Proceedings of NAACL Workshop on WordNet and Other Lexical Resources</title>
				<meeting>NAACL Workshop on WordNet and Other Lexical Resources<address><addrLine>Pittsburgh, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note type="report_type">Progress report</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation: Algorithms and applications</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech and Language Technology</title>
				<editor>
			<persName><forename type="first">E</forename><surname>Agirre</surname></persName>
			<persName><forename type="first">P</forename><surname>Edmonds</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
	<note>Knowledge based methods for word sense disambiguation</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">EuroWordNet: A Multilingual Database with Lexical Semantic Networks</title>
		<editor>P. Vossen</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Kluwer Academic Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
