<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Report on the Complex Word Identification Shared Task 2018</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Seid</forename><forename type="middle">Muhie</forename><surname>Yimam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<settlement>Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Hamburg</orgName>
								<address>
									<settlement>Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Harvard Medical School</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Gustavo</forename><forename type="middle">H</forename><surname>Paetzold</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Sanjaštajner</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Mannheim</orgName>
								<address>
									<settlement>Germany</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anaïs</forename><surname>Tack</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Université catholique de Louvain and KU Leuven</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">University of Wolverhampton</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Report on the Complex Word Identification Shared Task 2018</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report the findings of the second Complex Word Identification (CWI) shared task organized as part of the BEA workshop colocated with NAACL-HLT'2018. The second CWI shared task featured multilingual and multi-genre datasets divided into four tracks: English monolingual, German monolingual, Spanish monolingual, and a multilingual track with a French test set, and two tasks: binary classification and probabilistic classification. A total of 12 teams submitted their results in different task/track combinations and 11 of them wrote system description papers that are referred to in this report and appear in the BEA workshop proceedings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The most common first step in lexical simplification pipelines is identifying which words are considered complex by a given target population <ref type="bibr" target="#b32">(Shardlow, 2013)</ref>. This task is known as complex word identification (CWI) and it has been attracting attention from the research community in the past few years.</p><p>In this paper we present the findings of the second Complex Word Identification (CWI) shared task organized as part of the thirteenth Workshop on Innovative Use of NLP for Building Educational Applications (BEA) co-located with NAACL-HLT'2018. The second CWI shared task follows a successful first edition featuring 21 teams organized at SemEval'2016 <ref type="bibr" target="#b25">(Paetzold and Specia, 2016a)</ref>. While the first CWI shared task targeted an English dataset, the second edition focused on multilingualism providing datasets containing four languages: English, German, French, and Spanish.</p><p>In an evaluation paper <ref type="bibr" target="#b39">(Zampieri et al., 2017)</ref>, it has been shown that the performance of an ensemble classifier built on top of the predictions of the participating systems in the 2016 task degraded, the more systems were added. The low performance of the CWI systems that competed in the first CWI task left much room for improvement and was one of the reasons that motivated us to organize this second edition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Task Description</head><p>The goal of the CWI shared task of 2018 is to predict which words challenge non-native speakers based on the annotations collected from both native and non-native speakers. To train their systems, participants received a labeled training set where words in context were annotated regarding their complexity. One month later, an unlabeled test set was provided and participating teams were required to upload their predictions for evaluation. More information about the data collection is presented in Section 3.</p><p>Given the multilingual dataset provided, the CWI challenge was divided into four tracks:</p><p>• English monolingual CWI;</p><p>• German monolingual CWI;</p><p>• Spanish monolingual CWI; and</p><p>• Multilingual CWI with a French test set.</p><p>For the first three tracks, participants were provided with training and testing data for the same language. For French, participants were provided only with a French test set and no French training data. In the CWI 2016, the task was cast as binary classification. To be able to capture complexity as a continuum, in our CWI 2018 shared task, we additionally included a probabilistic classification task. The two tasks are summarized as follows:</p><p>• Binary classification task: Participants were asked to label the target words in context as complex (1) or simple (0).</p><p>• Probabilistic classification task: Participants were asked to assign the probability of target words in context being complex.</p><p>Participants were free to choose the task/track combinations they would like to participate in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Until the appearance of the CWI shared task of 2016, there was no manually annotated and verified CWI dataset. The 2016 shared task brought us one of the largest CWI datasets to that date, consisting of a total of 9,200 sentences manually annotated by 400 different non-native English speakers. In total, 200 sentences are used as a training set where each target is annotated by 20 annotators. The rest of the dataset (9,000 sentences) are used for test set where each target is annotated by a single annotator from the entire pool of 400 annotators.</p><p>The approaches used in the first SemEval 2016 Task 11: Complex Word Identification are described in Table <ref type="table" target="#tab_1">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>We have used the CWIG3G2 datasets from <ref type="bibr">(Yimam et al., 2017b,a)</ref> for the complex word identification (CWI) shared task 2018. The datasets are collected for multiple languages (English, German, Spanish). The English datasets cover different text genres, namely News (professionally written news), WikiNews (news written by amateurs), and Wikipedia articles. Below, we will briefly describe the annotation process and the statistics of collected datasets. For detail explanation of the datasets, please refer to the works of <ref type="bibr">Yimam et al. (2017b,a)</ref> Furthermore, to bolster the cross-lingual CWI experiment, we have collected a CWI dataset for French. The French dataset was collected through the same method used for the CWIG3G2 corpus <ref type="bibr">(Yimam et al., 2017b,a)</ref>. The dataset contains Wikipedia texts extracted from a comparable simplified corpus collected by <ref type="bibr" target="#b6">Brouwers et al. (2014)</ref>. Similar to CWIG3G2, for each article, all paragraphs containing between 5 and 10 sentences were extracted. From this pool of paragraphs, only the best paragraph was selected via a ranking procedure maximizing sentence length and lexical richness, and minimizing the ratio of named entities and foreign words. From this large selection of best paragraphs per article, an optimal subset of 100 paragraphs was then selected using a greedy search procedure similar to that of <ref type="bibr" target="#b34">Tack et al. (2016)</ref>, minimizing the vocabulary overlap between pairs of paragraphs using the Jaccard coefficient. Finally, a random test split of 24 paragraphs was selected to be annotated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Annotation Process</head><p>Annotations were collected using the Amazon Mechanical Turk (MTurk). Instead of showing a single sentence, we presented 5 to 10 sentences to the annotator in a single HIT (Human Intelligence Task) and requested them to highlight words or phrases that could pose difficulty in understanding the paragraph. The annotation system is unique in many aspects such as: 1) The instruction makes clear that the annotators should assume a given target reader such as children, language learners or people with reading impairments. 2) A bonus reward is offered when the user's selection matches at least half of the other annotations to encourage extra care during the complex word or phrase (CP) selection. 3) The maximum number of annotations allowed is limited to 10 so that we could prohibit an arbitrarily large number of selections intending to attain the bonus reward. 4) For the English dataset, more than 20 annotators were able to annotate the same HIT, among which are at least 10 native English speakers and 10 non-native English speakers so that it is possible to investigate if native and non-native speakers have different CWI needs. 5) Complex words are not pre-highlighted, as in previous contributions, so that annotators are not biased to the pre-selection of the complex phrases. 6) In addition to single words, we allowed the annotation of multi-word expressions (MWE), up to a size of 50 characters.</p><p>Table <ref type="table" target="#tab_2">2</ref> shows the total, native, and non-native number of annotators that participated in the annotation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analysis of Collected Datasets</head><p>Table <ref type="table" target="#tab_3">3</ref> shows statistics of the datasets for the English (combinations of three genres), German, Spanish and French (test set only) CWI tasks.    An analysis of the English dataset shows that around 90% of complex phrases have been selected by at least two annotators (both native and non-native). When separated by language, the percentage of agreements decreases to 83% at the lowest. This might be because native and non-native annotators have a different perspective what is a complex phrase. Furthermore, we have seen that native annotators agree more within their group (84% and above) than non-native speakers (83% and above). We also see that the absolute agreement between native and non-native annotators is very low (70%), which further indicates that the two user groups might have different CWI needs.</p><p>For the German annotation task, we have fewer annotators than the other languages. As it can be seen from Table <ref type="table" target="#tab_2">2</ref>, there are more native annotators, but they participate on fewer HITs than the non-native annotators (on average, 6.1 nonnative speakers and 3.9 native speakers participated in a HIT). Unlike the English annotation task, non-native annotators have a higher interannotator agreement (70.66%) than the native annotators (58.5%).</p><p>The Spanish annotation task is different from both the English and the German annotation tasks since its annotations come almost exclusively from native annotators. In general, Spanish annotators have shown lower agreements than the English and German annotators. Also the Spanish annotators highlight more MWEs than the English and German annotators.</p><p>Regarding the French annotation task, we observe a comparable distribution in the number of native and non-native annotators compared to the German annotation task (Table <ref type="table" target="#tab_2">2</ref>). There were slightly more non-native participants than native ones, but the number of native annotators who completed the same number of HITs was considerably larger. This means that although there were more non-native participants, they did not participate equally in all HITs.  A striking difference that can be observed in the French dataset pertains to the proportion of identified complex words. Compared to the other languages, we have a considerably lower relative count of complex instances (Table <ref type="table" target="#tab_5">4</ref>). However, this does not necessarily mean that the texts were simpler for French than for the other languages. Looking at the proportion of MWEs annotated as complex (Table <ref type="table" target="#tab_7">5</ref>), we observe that the French dataset contains more MWE annotations than single words compared to the other datasets. One plausible explanation for this could be attributed to the limitation of allowing at most 10 unique annotations per HIT in MTurk. Indeed, a number of annotators highlighted the fact that they sometimes found more than 10 possible annotations of complex words. As a result, in order to account for all of these possibilities, the annotators sometimes grouped nearly adjacent single complex words as one sequence, leading to a larger relative proportion of MWE (3-gram+) annotations. Another explanation for this disparity could be attributed to the lower number of annotators for French com-pared to English or Spanish. If we had had a similar number of annotators for French, we would probably also have obtained a more varied sample and hence a higher relative amount of different complex word annotations.  In this section, we briefly describe the systems from all 11 teams that have participated in the 2018 CWI shared task and wrote a system description paper to be presented at the BEA conference. Table <ref type="table" target="#tab_9">6</ref> and 7 shows the results of all systems for the monolingual and multilingual binary classification tasks while Table <ref type="table">8</ref> and 9 presents the probabilistic classification results for the monolingual and multilingual tracks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline Systems</head><p>For both the binary and probabilistic classification tasks, we build a simple baseline system that uses only the most basic features described in <ref type="bibr">Yimam et al. (2017b,a)</ref>  The pipeline consists of feature extraction, computing a kernel matrix and applying an SVM classifier.</p><p>The feature sets include low-level features such as character n-grams, and high-level features such semantic properties extracted from lexical resources and word embeddings. The low-level features were extracted based on the target complex word, and include count of characters, count of vowels, count of consonants, count of repeating characters, and count of character n-grams (up to 4 characters).</p><p>The first set of word embedding features take into account the word's context which is obtained by computing the cosine similarity between the complex word and each of the other words in the sentence (minimum, maximum and mean similarity values are used). Furthermore, sense embeddings are used, which are computed based on WordNet synsets. Lastly, using word embeddings, additional features were designed based on the location of the complex word in a dimensionally reduced embedding space. For this, they used PCA to reduce the dimension of the embeddings from 300 to 2 dimensions.</p><p>Once features are extracted, kernel-based learning algorithms are employed. For the binary classification setup, the SVM classifiers based on the Lib-SVM were used. For the regression setup, they used v-Support Vector Regression (v-SVR). For both setups, different parameters were tuned using the development dataset. SB@GU systems <ref type="bibr" target="#b1">(Alfter and Pilán, 2018)</ref> are adapted from a previous system, which was used to classify Swedish words into different language proficiency levels and participated on the multilingual binary classification part of the shared task. For each target word or MWE, the following set of feature categories were extracted: 1) count and word form features such as length of the target, number of syllables, n-gram probabilities based on Wikipedia, binary features such as "is MWE" or "is number", and so on 2) morphological features, mainly part-of-speech tag and suffix length, 3) semantic features, such as the number of synsets, number of hypernyms, and number of hyponyms, 4) context features, like topic distributions and word embeddings, and 5) psycholinguistic features, such as British National Corpus frequency, reaction time, bigram frequency, trigram frequency, and so on. For MWE, they averaged the feature values for each word in them.</p><p>For English datasets, experiments are conducted with context-free, context-only and context-sensitive features, mainly by excluding word embeddings, using only word embeddings, and combining all features explained above respectively. Classifiers such as Random Forest, Extra Trees, convolutional networks, and recurrent convolutional neural networks were tested. Furthermore, feature selection is performed using the SelectFromModel feature selection method from scikit-learn library. The best performing features includes word frequency, word sense and topics, and language model probabilities.</p><p>For the German, Spanish, and French datasets, features such as character-level n-grams were extracted from n-gram models trained on Wikipedia. For the French dataset, the n-gram models from English, German and Spanish were used to obtain n-gram probabilities of each entry. They configured two setups to extract features for the French dataset: 1) Uses English, German and Spanish classifiers and apply majority voting to get the final label, 2) Uses only the Spanish classifier as French and Spanish are both Romance languages.</p><p>An Extra Tree classifier with 1000 and estimators was their best classifier.</p><p>hu-berlin The systems <ref type="bibr" target="#b29">(Popović, 2018</ref>) mainly explored the use of character n-gram features using a multinomial Naive Bayes classifier specifically designed for the multilingual binary classification task. For each target word, all the character n-grams of a given length and their frequencies were extracted and the target word was represented as a "bag of n-grams". Different lengths of n-grams such as a combination of 2-gram, 3gram, 4-gram, and 5-grams have been experimented with. The experimental results show that the combinations of 2-gram and 4-gram features are the best character level n-gram features for the binary classification task.</p><p>For the English datasets, they combined all the training datasets (NEWS, WIKINEWS, and WIKIPEDIA), used 3-gram, 4-gram and 5-gram character level n-gram features in order to maximize performance. The results show that character level n-gram features do not work well for cross-language complex word identification as the performance generally degraded.</p><p>For English, two variants of results were submitted, one classified using the corresponding indomain training corpus and the second one classified using the concatenated training data. For German and Spanish, one result was submitted using the corresponding training data sets. For French, four submissions were made 1) one classified with English Wikipedia training, 2) one classified with all three English datasets, 3) one classified with Spanish data, and 4) one classified with German data.</p><p>NILC present systems <ref type="bibr" target="#b13">(Hartmann and dos Santos, 2018)</ref> for the monolingual binary and probabilistic classification tasks. Three approaches were created by 1) using traditional feature engineering-based machine learning methods, 2) using the average embedding of target words as an input to a neural network, and 3) modeling the context of the target words using an LSTM.</p><p>For the feature engineering-based systems, features such as linguistic, psycholinguistic, and language model features were used to train different binary and probabilistic classifiers. Lexical features include word length, number of syllables, and number of senses, hypernyms, and hyponyms in WordNet. For N-gram features, probabilities of the n-gram containing the target words were computed based on language models trained on the BookCorpus dataset and One Billion Word dataset. Furthermore, psycholinguistic features such as familiarity, age of acquisition, correctness and imagery values were used. Based on these features (38 in total), models were trained using Linear Regression, Logistic Regression, Decision Trees, Gradient Boosting, Extra Trees, AdaBoost, and XGBoost classifiers.</p><p>For embedding-based systems, a pre-trained GloVe model <ref type="bibr" target="#b28">(Pennington et al., 2014)</ref> was used to get the vector representations of target words. For MWE, the average of the vectors is used. In the first approach, the resulting vector is passed on to a neural network with two ReLu layers followed by a sigmoid layer, which predicted the probability of the target word being complex.</p><p>Their experiments show that the feature engineering approach achieved the best results using the XGBoost classifier for the binary classification task. They submitted four systems using XG-Boost, average embeddings, LSTMs with transfer learning, and a voting system that combines the other three. For the probabilistic classification task, their LSTMs achieve the best results.</p><p>TMU submitted multilingual and cross-lingual CWI systems for both of the binary and probabilistic classification tasks <ref type="bibr" target="#b15">(Kajiwara and Komachi, 2018)</ref>. The systems use two variants of frequency features from the learner corpus (Lang-8 corpus) from <ref type="bibr" target="#b22">Mizumoto et al. (2011)</ref> and from the general domain corpus (Wikipedia and WikiNews). The list of features used in building the model include the number of characters in the target word, number of words in the target phrase, and frequency of the target word in learner corpus (Lang-8 corpus) and general domain corpus (Wikipedia and WikiNews).</p><p>Random forest classifiers are used for the binary classification task while random forest regressors are used for the probabilistic classification task using the scikit-learn library. Feature ablation shows that both the length, frequency, and probability features (based on corpus statistics) are important for the binary and probabilistic classification tasks. They also discover that features obtained from the learner corpus are more influential than the general domain features for the CWI tasks. The systems perform very well both for the binary and probabilistic classification tasks, winning 5 out of the 12 tracks.</p><p>ITEC addresses both the binary and probabilistic classification task for the English and Spanish multilingual datasets <ref type="bibr" target="#b10">(De Hertog and Tack, 2018)</ref>. They have used 5 different aspects of the target word in the process of feature extractions, namely, word embedding, morphological structure, psychological measures, corpus counts, and topical information. Psychological measures are obtained from the MRC Psycholinguistic Database, which includes age of acquisition, imageability, concreteness, and meaningfulness of the target word. Word frequencies and embedding features are computed based on a web corpus. The word embedding model is computed using the gensim implementation of word2vec, with 300 dimensional embedding space, window-size of 5 and minimum frequency threshold of 20.</p><p>They have employed deep learning structure using the keras deep learning library with the tensorflow gpu as a backend. Word embeddings are employed in two input layers, first to replace target words with the appropriate embeddings and second to represent the entire sentences as an input sequence which is considered the topical approximation using contextual cues. The final layer takes into account morphological features based on character embeddings that are trained with a convolutional network. The systems perform reasonably better than the average systems, for both of the binary and probabilistic classification tasks.</p><p>Camb describes different systems <ref type="bibr" target="#b12">(Gooding and Kochmar, 2018)</ref> they have developed for the monolingual English datasets both for the binary and probabilistic classification tasks. They have used features that are based on the insights of the CWI shared task 2016 <ref type="bibr" target="#b25">(Paetzold and Specia, 2016a</ref>) such as lexical features (word length, number of syllables, WordNet features such as the number of synsets), word n-gram and POS tags, and dependency parse relations. In addition, they have used features such as the number of words grammatically related to the target word, psycholinguistic features from the MRC database, CEFR (Common European Framework of Reference for Languages) levels extracted from the Cambridge Advanced Learner Dictionary (CALD), and Google N-gram word frequencies using the Datamuse API The MCR features include word familiarity rating, number of phonemes, thorndike-lorge written frequency, imageability rating, concreteness rating, number of categories, samples, and written frequencies, and age of acquisition.</p><p>For the binary classification task, they have used a feature union pipeline to combine the range of heterogeneous features extracted from different categories of feature types. The best performing classification algorithms are obtained based on the ensemble techniques where AdaBoost classifier with 5000 estimators achieves the highest results, followed by the bootstrap aggregation classifier of Random Forest. All the features are used for the NEWS and WIKINEWS datasets, but for the WIKIPEDIA dataset, MCR psycholinguistic features are excluded. For the probabilistic classification task, the same feature setups are used and the Linear Regression algorithm is used to estimate values of targets.</p><p>As it can be seen from Tables <ref type="table" target="#tab_9">6, 7</ref>, 8, and 9, most of the systems submitted ranked first for English monolingual binary and probabilistic classification tasks.</p><p>CoastalCPH describe systems developed for multilingual and cross-lingual domains for the binary and probabilistic classification tasks <ref type="bibr" target="#b3">(Bingel and Bjerva, 2018)</ref>. Unlike most systems, they have focused mainly on German, Spanish, and French datasets in order to investigate if multitask learning can be applied to the cross-lingual CWI task. They have devised two models, using languageagnostic approach with an ensemble that comprises of Random Forests (random forest classifiers for the binary classification task and random forest regressors for the probabilistic classification tasks, with 100 trees) and feed-forward neural networks.</p><p>Most of the features are similar for all languages except some of them are language-specific features. The set of features incorporated include 1) log-probability features: unigram frequencies as a log-probabilities from language-specific Wikipedia dumps computed using KenLM, character perplexity, number of synsets, hypernym chain. 2) Inflectional complexity: number of suffixes appended to a word stem. 3) Surface features: length of the target and lower-case information. 4) Bag-of-POS: for each tag based on Universal Parts-of-Speech project, count the number of words in a candidate that belong to the respective class. 5) Target-sentence similarity: the cosine similarity between averaged word embeddings for the target word or phrase and the rest of the words  in the sentence where out-of-vocabulary problems are addressed using a pre-trained sub-word embeddings <ref type="bibr" target="#b14">(Heinzerling and Strube, 2017)</ref>. They have made qualitative and quantitative error analysis, mainly for the cross-lingual French dataset experiments and reported that: 1) The system picks longer targets as positive examples. 2) Short targets are predicted as false negative but they are potentially unknown named entities and technical terms. 3) Complex words are generally longer than simple words. 4) Language models produce lower log-probability for complex words.</p><p>The systems submitted performed the best out of all systems for the cross-lingual task (the French dataset) both for the binary and probabilistic classification tasks, showing a promising direction in the creation of CWI dataset for new languages.</p><p>LaSTUS/TALN present systems for the monolingual English binary classification task <ref type="bibr">(AbuRa'ed and Saggion, 2018)</ref>. Two different systems are designed, the first system is based on a set of lexical, semantic and contextual features, and the second system incorporates word embedding features. The word embedding features are obtained from a pre-trained word2vec model 1 .</p><p>For each sentence, the centroid of the dimensions of the context before the target word, the target word itself, and the context after the target word are computed using word2vec embedding vectors (300 dimensions each), resulting in a total of 900 feature dimensions. Furthermore, two extra features are generated using the embedding vectors, which represent the distance between the target word and the context before and after the target word respectively. These features are computed using the cosine similarity measures between each pair of the vectors.</p><p>A large set of shallow lexical and semantic features are also used in addition to the embedding features. These features include target word length (number of characters), the position of the target word in the sentence, number of words in the sentence, word depth in the dependency tree, parent word length in dependency relation, frequency features based on the BNC, Wikipedia, and Dale and Chall list corpora, number of synsets and senses in WordNet, and so on.</p><p>The experiment is conducted using the Weka machine learning framework using the Support vector machine (with linear and radial basis function kernels), Naïve Bayes, Logistic Regression, Random Tree, and Random Forest classification algorithms. The final experiments employ Support Vector Machines and Random Forest classifiers.</p><p>CFILT IITB Developed ensemble-based classification systems for the English monolingual binary classification task <ref type="bibr" target="#b35">(Wani et al., 2018)</ref>. Lexical features based on WordNet for the target word are extracted as follows: 1) Degree of Polysemy: number of senses of the target word in WordNet, 2) Hyponym and Hypernym Tree Depth: the position of the word in WordNet's hierarchical tree, and 3) Holonym and Meronym Counts: based on the relationship of the target word to its components (meronyms) or to the things it is contained in (Holonym's). Additional feature classes include size-based features such as word count, word length, vowel counts, and syllable counts. They also use vocabulary-based features such as Ogden Basic (from Ogden's Basic Word list), Ogden Frequency (Ogden's Frequent Word List), and Barron's Wordlist (Barron's 5000 GRE Word List).</p><p>They have used 8 classifiers namely Random Forest, Random Tree, REP Tree, Logistic Model Tree, J48 Decision Tree, JRip Rules Tree, PART, and SVM. Using these classifiers, a hard voting approach is used to predict a label for the target word. Voting of the positive or negative class is decided if more than 4 classifiers agree on the label. Word-embedding-based classifier is used to decide in the case of a 4-4 tie.</p><p>An ablation test shows that size-based features such as word length, vowel counts, and syllable counts, word counts constitute the four top impor-tant features. Their best system shows an average performance compared to the other systems in the shared task for the monolingual English binary classification track.</p><p>NLP-CIC present systems for the English and Spanish multilingual binary classification tasks <ref type="bibr">(Aroyehun et al., 2018)</ref>. The feature sets include morphological features such as frequency counts of target word on large corpora such as Wikipedia and Simple Wikipedia, syntactic and lexical features, psycholinguistic features from the MRC psycholinguistic database and entity features using the OpenNLP and CoreNLP tools, and word embedding distance as a feature which is computed between the target word and the sentence.</p><p>Tree learners such as Random Forest, Gradient Boosted, and Tree Ensembles are used to train different classifiers. Furthermore, a deep learning approach based on 2D convolutional (CNN) and word embedding representations of the target text and its context is employed.</p><p>Their best system ranked 10 th , 5 th , and 16 th for the NEWS, WIKINEWS, and WIKIPEDIA monolingual English tracks, which is better than the average systems in the shared task. The system based on the CNN model on the Spanish monolingual dataset ranked 2 nd .</p><p>(though they of course cannot be directly compared) to the German and Spanish datasets, when the system uses either one or several training datasets from the other languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">: SemEval 2016 CWI -Systems and approaches</cell></row><row><cell cols="4">Language Native Non-native Total</cell></row><row><cell>English</cell><cell>134</cell><cell>49</cell><cell>183</cell></row><row><cell>German</cell><cell>12</cell><cell>11</cell><cell>23</cell></row><row><cell>Spanish</cell><cell>48</cell><cell>6</cell><cell>54</cell></row><row><cell>French</cell><cell>10</cell><cell>12</cell><cell>22</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>guages</cell><cell cols="4">: The number of annotators for different lan-</cell></row><row><cell></cell><cell cols="2">Language Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell></cell><cell>English</cell><cell cols="3">27,299 3,328 4,252</cell></row><row><cell></cell><cell>German</cell><cell>6,151</cell><cell>795</cell><cell>959</cell></row><row><cell></cell><cell>Spanish</cell><cell cols="3">13,750 1,622 2,233</cell></row><row><cell></cell><cell>French</cell><cell>-</cell><cell>-</cell><cell>2,251</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: The number of instances for each training, de-velopment and test set</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>The number (#) and ratio (%) of complex instances per language</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>The distribution of single and MWE annotations of complex words per language</figDesc><table /><note>4 System Descriptions and Results</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>, namely only frequency and length features. The Nearest Centroid classifier and the Linear Regression algorithms from the scikit-learn machine learning library are used for the binary and probabilistic classification tasks resp. For the binary classification task, we have used the accuracy and macro-averaged F1 evaluation metrics. For the probabilistic classification task, the Mean Absolute Error (MAE) measure is used. The baseline results are shown in Table6, 7, 8, and 9 for the monolingual and multilingual tracks.</figDesc><table><row><cell>News</cell><cell>F-1</cell><cell cols="2">Rank WikiNews</cell><cell>F-1</cell><cell cols="2">Rank Wikipedia</cell><cell>F-1</cell><cell>Rank</cell></row><row><cell>Camb</cell><cell>0.8736</cell><cell>1</cell><cell>Camb</cell><cell>0.84</cell><cell>1</cell><cell>Camb</cell><cell>0.8115</cell><cell>1</cell></row><row><cell>Camb</cell><cell>0.8714</cell><cell>2</cell><cell>Camb</cell><cell>0.8378</cell><cell>2</cell><cell>NILC</cell><cell>0.7965</cell><cell>2</cell></row><row><cell>Camb</cell><cell>0.8661</cell><cell>3</cell><cell>Camb</cell><cell>0.8364</cell><cell>4</cell><cell>UnibucKernel</cell><cell>0.7919</cell><cell>3</cell></row><row><cell>ITEC</cell><cell>0.8643</cell><cell>4</cell><cell>Camb</cell><cell>0.8378</cell><cell>3</cell><cell>NILC</cell><cell>0.7918</cell><cell>4</cell></row><row><cell>ITEC</cell><cell>0.8643</cell><cell>4</cell><cell>NLP-CIC</cell><cell>0.8308</cell><cell>5</cell><cell>Camb</cell><cell>0.7869</cell><cell>5</cell></row><row><cell>TMU</cell><cell>0.8632</cell><cell>6</cell><cell>NLP-CIC</cell><cell>0.8279</cell><cell>6</cell><cell>Camb</cell><cell>0.7862</cell><cell>6</cell></row><row><cell>ITEC</cell><cell>0.8631</cell><cell>7</cell><cell>NILC</cell><cell>0.8277</cell><cell>7</cell><cell>SB@GU</cell><cell>0.7832</cell><cell>7</cell></row><row><cell>NILC</cell><cell>0.8636</cell><cell>5</cell><cell>NILC</cell><cell>0.8270</cell><cell>8</cell><cell>ITEC</cell><cell>0.7815</cell><cell>8</cell></row><row><cell>NILC</cell><cell>0.8606</cell><cell>9</cell><cell>NLP-CIC</cell><cell>0.8236</cell><cell>9</cell><cell>SB@GU</cell><cell>0.7812</cell><cell>9</cell></row><row><cell>Camb</cell><cell>0.8622</cell><cell>8</cell><cell>CFILT IITB</cell><cell>0.8161</cell><cell>10</cell><cell>UnibucKernel</cell><cell>0.7804</cell><cell>10</cell></row><row><cell>NLP-CIC</cell><cell>0.8551</cell><cell>10</cell><cell>CFILT IITB</cell><cell>0.8161</cell><cell>10</cell><cell>Camb</cell><cell>0.7799</cell><cell>11</cell></row><row><cell>NLP-CIC</cell><cell>0.8503</cell><cell>12</cell><cell>CFILT IITB</cell><cell>0.8152</cell><cell>11</cell><cell>CFILT IITB</cell><cell>0.7757</cell><cell>12</cell></row><row><cell>NLP-CIC</cell><cell>0.8508</cell><cell>11</cell><cell>CFILT IITB</cell><cell>0.8131</cell><cell>12</cell><cell>CFILT IITB</cell><cell>0.7756</cell><cell>13</cell></row><row><cell>NILC</cell><cell>0.8467</cell><cell>15</cell><cell>UnibucKernel</cell><cell>0.8127</cell><cell>13</cell><cell>CFILT IITB</cell><cell>0.7747</cell><cell>14</cell></row><row><cell>CFILT IITB</cell><cell>0.8478</cell><cell>13</cell><cell>ITEC</cell><cell>0.8110</cell><cell>14</cell><cell>NLP-CIC</cell><cell>0.7722</cell><cell>16</cell></row><row><cell>CFILT IITB</cell><cell>0.8478</cell><cell>13</cell><cell>SB@GU</cell><cell>0.8031</cell><cell>15</cell><cell>NLP-CIC</cell><cell>0.7721</cell><cell>17</cell></row><row><cell>CFILT IITB</cell><cell>0.8467</cell><cell>14</cell><cell>NILC</cell><cell>0.7961</cell><cell>17</cell><cell>NLP-CIC</cell><cell>0.7723</cell><cell>15</cell></row><row><cell>SB@GU</cell><cell>0.8325</cell><cell>17</cell><cell>NILC</cell><cell>0.7977</cell><cell>16</cell><cell>NLP-CIC</cell><cell>0.7723</cell><cell>15</cell></row><row><cell>SB@GU</cell><cell>0.8329</cell><cell>16</cell><cell>CFILT IITB</cell><cell>0.7855</cell><cell>20</cell><cell>SB@GU</cell><cell>0.7634</cell><cell>18</cell></row><row><cell>Gillin Inc.</cell><cell>0.8243</cell><cell>19</cell><cell>TMU</cell><cell>0.7873</cell><cell>19</cell><cell>TMU</cell><cell>0.7619</cell><cell>19</cell></row><row><cell>Gillin Inc.</cell><cell>0.8209</cell><cell>24</cell><cell>SB@GU</cell><cell>0.7878</cell><cell>18</cell><cell>NILC</cell><cell>0.7528</cell><cell>20</cell></row><row><cell>Gillin Inc.</cell><cell>0.8229</cell><cell>20</cell><cell>UnibucKernel</cell><cell>0.7638</cell><cell>23</cell><cell>UnibucKernel</cell><cell>0.7422</cell><cell>24</cell></row><row><cell>Gillin Inc.</cell><cell>0.8221</cell><cell>21</cell><cell>hu-berlin</cell><cell>0.7656</cell><cell>22</cell><cell>hu-berlin</cell><cell>0.7445</cell><cell>22</cell></row><row><cell>hu-berlin</cell><cell>0.8263</cell><cell>18</cell><cell>SB@GU</cell><cell>0.7691</cell><cell>21</cell><cell>SB@GU</cell><cell>0.7454</cell><cell>21</cell></row><row><cell>Gillin Inc.</cell><cell>0.8216</cell><cell>22</cell><cell cols="2">LaSTUS/TALN 0.7491</cell><cell>25</cell><cell>UnibucKernel</cell><cell>0.7435</cell><cell>23</cell></row><row><cell>UnibucKernel</cell><cell>0.8178</cell><cell>26</cell><cell cols="2">LaSTUS/TALN 0.7491</cell><cell>25</cell><cell cols="2">LaSTUS/TALN 0.7402</cell><cell>25</cell></row><row><cell>UnibucKernel</cell><cell>0.8178</cell><cell>26</cell><cell>SB@GU</cell><cell>0.7569</cell><cell>24</cell><cell cols="2">LaSTUS/TALN 0.7402</cell><cell>25</cell></row><row><cell>CFILT IITB</cell><cell>0.8210</cell><cell>23</cell><cell>hu-berlin</cell><cell>0.7471</cell><cell>26</cell><cell>NILC</cell><cell>0.7360</cell><cell>26</cell></row><row><cell>CFILT IITB</cell><cell>0.8210</cell><cell>23</cell><cell>Gillin Inc.</cell><cell>0.7319</cell><cell>28</cell><cell>hu-berlin</cell><cell>0.7298</cell><cell>27</cell></row><row><cell>hu-berlin</cell><cell>0.8188</cell><cell>25</cell><cell>Gillin Inc.</cell><cell>0.7275</cell><cell>30</cell><cell>CoastalCPH</cell><cell>0.7206</cell><cell>28</cell></row><row><cell>UnibucKernel</cell><cell>0.8111</cell><cell>28</cell><cell>Gillin Inc.</cell><cell>0.7292</cell><cell>29</cell><cell cols="2">LaSTUS/TALN 0.6964</cell><cell>29</cell></row><row><cell>NILC</cell><cell>0.8173</cell><cell>27</cell><cell>Gillin Inc.</cell><cell>0.7180</cell><cell>31</cell><cell>Gillin Inc.</cell><cell>0.6604</cell><cell>30</cell></row><row><cell cols="2">LaSTUS/TALN/TALN 0.8103</cell><cell>29</cell><cell cols="2">LaSTUS/TALN 0.7339</cell><cell>27</cell><cell>Gillin Inc.</cell><cell>0.6580</cell><cell>31</cell></row><row><cell>LaSTUS/TALN</cell><cell>0.8103</cell><cell>29</cell><cell>Gillin Inc.</cell><cell>0.7083</cell><cell>32</cell><cell>Gillin Inc.</cell><cell>0.6520</cell><cell>32</cell></row><row><cell>LaSTUS/TALN</cell><cell>0.7892</cell><cell>31</cell><cell>UnibucKernel</cell><cell>0.6788</cell><cell>33</cell><cell>Gillin Inc.</cell><cell>0.6329</cell><cell>33</cell></row><row><cell>UnibucKernel</cell><cell>0.7728</cell><cell>33</cell><cell>SB@GU</cell><cell>0.5374</cell><cell>34</cell><cell>SB@GU</cell><cell>0.5699</cell><cell>34</cell></row><row><cell>SB@GU</cell><cell>0.7925</cell><cell>30</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>CoastalCPH</cell><cell>0.5020</cell><cell>35</cell></row><row><cell>SB@GU</cell><cell>0.7842</cell><cell>32</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">LaSTUS/TALN 0.3324</cell><cell>36</cell></row><row><cell>LaSTUS/TALN</cell><cell>0.7669</cell><cell>34</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>UnibucKernel</cell><cell>0.5158</cell><cell>36</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SB@GU</cell><cell>0.5556</cell><cell>35</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>LaSTUS/TALN</cell><cell>0.2912</cell><cell>37</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>LaSTUS/TALN</cell><cell>0.1812</cell><cell>38</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>LaSTUS/TALN</cell><cell>0.1761</cell><cell>39</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Baseline</cell><cell>0.7579</cell><cell>-</cell><cell>Baseline</cell><cell>0.7106</cell><cell>-</cell><cell>Baseline</cell><cell>0.7179</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">4.2 Shared Task Systems</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">UnibucKernel The UnibucKernel (Butnaru and Ionescu, 2018) team participated on the monolin-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">gual CWI shared task, specifically on the NEWS,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">WIKINEWS, and WIKIPEDIA domain datasets.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Binary classification results for the monolingual English tracks.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>German</cell><cell>F-1</cell><cell cols="2">Rank Spanish</cell><cell>F-1</cell><cell cols="2">Rank French</cell><cell>F-1</cell><cell>Rank</cell></row><row><cell>TMU</cell><cell>0.7451</cell><cell>1</cell><cell>TMU</cell><cell>0.7699</cell><cell>1</cell><cell cols="2">CoastalCPH 0.7595</cell><cell>1</cell></row><row><cell>SB@GU</cell><cell>0.7427</cell><cell>2</cell><cell>ITEC</cell><cell>0.7637</cell><cell>3</cell><cell>TMU</cell><cell>0.7465</cell><cell>2</cell></row><row><cell>hu-berlin</cell><cell>0.6929</cell><cell>4</cell><cell>NLP-CIC</cell><cell>0.7672</cell><cell>2</cell><cell>SB@GU</cell><cell>0.6266</cell><cell>3</cell></row><row><cell>SB@GU</cell><cell>0.6992</cell><cell>3</cell><cell cols="2">CoastalCPH 0.7458</cell><cell>5</cell><cell>SB@GU</cell><cell>0.6130</cell><cell>4</cell></row><row><cell cols="2">CoastalCPH 0.6619</cell><cell>5</cell><cell cols="2">CoastalCPH 0.7458</cell><cell>5</cell><cell>hu-berlin</cell><cell>0.5738</cell><cell>6</cell></row><row><cell>Gillin Inc.</cell><cell>0.5548</cell><cell>10</cell><cell>NLP-CIC</cell><cell>0.7468</cell><cell>4</cell><cell>SB@GU</cell><cell>0.5891</cell><cell>5</cell></row><row><cell>Gillin Inc.</cell><cell>0.5459</cell><cell>11</cell><cell>NLP-CIC</cell><cell>0.7419</cell><cell>6</cell><cell>hu-berlin</cell><cell>0.5343</cell><cell>7</cell></row><row><cell>Gillin Inc.</cell><cell>0.5398</cell><cell>12</cell><cell>SB@GU</cell><cell>0.7281</cell><cell>7</cell><cell>hu-berlin</cell><cell>0.5238</cell><cell>8</cell></row><row><cell>Gillin Inc.</cell><cell>0.5271</cell><cell>14</cell><cell>SB@GU</cell><cell>0.7259</cell><cell>8</cell><cell>hu-berlin</cell><cell>0.5124</cell><cell>9</cell></row><row><cell>Gillin Inc.</cell><cell>0.5275</cell><cell>13</cell><cell cols="2">CoastalCPH 0.7238</cell><cell>9</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CoastalCPH 0.6078</cell><cell>6</cell><cell>hu-berlin</cell><cell>0.7080</cell><cell>11</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CoastalCPH 0.5818</cell><cell>7</cell><cell cols="2">CoastalCPH 0.7153</cell><cell>10</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CoastalCPH 0.5778</cell><cell>8</cell><cell>Gillin Inc.</cell><cell>0.6804</cell><cell>13</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CoastalCPH 0.5771</cell><cell>9</cell><cell>Gillin Inc.</cell><cell>0.6784</cell><cell>14</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell>Gillin Inc.</cell><cell>0.6722</cell><cell>15</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell>Gillin Inc.</cell><cell>0.6669</cell><cell>16</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell>Gillin Inc.</cell><cell>0.6547</cell><cell>17</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">CoastalCPH 0.6918</cell><cell>12</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Baseline</cell><cell>0.7546</cell><cell>-</cell><cell>Baseline</cell><cell>0.7237</cell><cell>-</cell><cell>Baseline</cell><cell>0.6344</cell><cell>-</cell></row></table><note>: Binary classification results for the multilingual German, Spanish and French tracks.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :Table 9 :</head><label>89</label><figDesc>Probablistic classification results for the monolingual English tracks. Probablistic classification results for the multilingual German, Spanish, and French tracks.</figDesc><table><row><cell>German</cell><cell cols="3">MAE Rank Spanish</cell><cell cols="3">MAE Rank French</cell><cell cols="2">MAE Rank</cell></row><row><cell>TMU</cell><cell>0.0610</cell><cell>1</cell><cell>TMU</cell><cell>0.0718</cell><cell>1</cell><cell cols="2">CoastalCPH 0.0660</cell><cell>1</cell></row><row><cell cols="2">CoastalCPH 0.0747</cell><cell>2</cell><cell>ITEC</cell><cell>0.0733</cell><cell>2</cell><cell cols="2">CoastalCPH 0.0660</cell><cell>1</cell></row><row><cell cols="2">CoastalCPH 0.0751</cell><cell>3</cell><cell cols="2">CoastalCPH 0.0789</cell><cell>3</cell><cell cols="2">CoastalCPH 0.0762</cell><cell>2</cell></row><row><cell>Gillin Inc.</cell><cell>0.1905</cell><cell>4</cell><cell cols="2">CoastalCPH 0.0808</cell><cell>4</cell><cell>TMU</cell><cell>0.0778</cell><cell>3</cell></row><row><cell>Gillin Inc.</cell><cell>0.2099</cell><cell>5</cell><cell>Gillin Inc.</cell><cell>0.2513</cell><cell>5</cell><cell cols="2">CoastalCPH 0.0866</cell><cell>4</cell></row><row><cell>Gillin Inc.</cell><cell>0.2102</cell><cell>6</cell><cell>Gillin Inc.</cell><cell>0.2634</cell><cell>6</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Gillin Inc.</cell><cell>0.2122</cell><cell>7</cell><cell>Gillin Inc.</cell><cell>0.2638</cell><cell>7</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell>Gillin Inc.</cell><cell>0.2644</cell><cell>8</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">CoastalCPH 0.2724</cell><cell>9</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="2">CoastalCPH 0.2899</cell><cell>10</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Baseline</cell><cell>0.0816</cell><cell>-</cell><cell>Baseline</cell><cell>0.0892</cell><cell>-</cell><cell>Baseline</cell><cell>0.0891</cell><cell>-</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://code.google.com/archive/p/word2vec/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to thank all participants of the CWI shared task, as well as the BEA workshop organizers for hosting and providing all the necessary support for the organization of the shared task. The dataset collection was funded as part of the DFG-SemSch project (BI-1544/3).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper presented the results and findings of the second CWI shared task. Thirty teams enrolled to participate in the competition and 12 of them submitted their results. Subsequently, 11 teams wrote system description papers that have been reviewed in this report.</p><p>Overall, traditional feature engineering-based approaches (mostly based on length and frequency features) perform better than neural network and word embedding-based approaches. However, compared to the SemEval 2016 Task 11 shared task systems presented in Table <ref type="table">1</ref>, we have observed that more systems employed deep learning approaches and the results are getting better for the CWI task; the difference is less pronounced for the probabilistic classification tasks.</p><p>One of our most important findings is that crosslingual experimental results are very promising, which we think implies in fundamental progress for CWI research. Despite the fact that we do not provide a training dataset for French, the results obtained have superior or equivalent scores</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">LaS-TUS/TALN at Complex Word Identification (CWI) 2018 Shared Task</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<editor>
			<persName><forename type="first">Ahmed</forename><surname>Abura</surname></persName>
			<persName><forename type="first">'</forename><surname>Ed</surname></persName>
			<persName><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</editor>
		<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SB@GU at the Complex Word Identification 2018 Shared Task</title>
		<author>
			<persName><forename type="first">David</forename><surname>Alfter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ildikó</forename><surname>Pilán</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Complex Word Identification: Convolutional Neural Network vs. Feature Engineering</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<editor>
			<persName><forename type="first">Jason</forename><surname>Segun Taofeek Aroyehun</surname></persName>
			<persName><forename type="first">Daniel Alejandro Prez</forename><surname>Angel</surname></persName>
			<persName><forename type="first">Alexander</forename><surname>Alvarez</surname></persName>
			<persName><surname>Gelbukh</surname></persName>
		</editor>
		<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Crosslingual complex word identification with multitask learning</title>
		<author>
			<persName><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">CoastalCPH at SemEval-2016 Task 11: The importance of designing your Neural Networks right</title>
		<author>
			<persName><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalie</forename><surname>Schluter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Héctor Martínez</forename><surname>Alonso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1028" to="1033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Melbourne at SemEval 2016 Task 11: Classifying Type-level Word Complexity using Random Forests with Corpus and Word List Features</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Uitdenbogerd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="975" to="981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Syntactic Sentence Simplification for French</title>
		<author>
			<persName><forename type="first">Laetitia</forename><surname>Brouwers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Delphine</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne-Laure</forename><surname>Ligozat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>François</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR)</title>
				<meeting>the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR)<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">UnibucKernel: A kernel-based learning method for complex word identification</title>
		<author>
			<persName><forename type="first">Andrei</forename><surname>Butnaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radu Tudor</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Garuda &amp; Bhasha at SemEval-2016 Task 11: Complex Word Identification Using Aggregated Learning Models</title>
		<author>
			<persName><forename type="first">Prafulla</forename><surname>Choubey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Pateria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1006" to="1010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CLaC at SemEval-2016 Task 11: Exploring linguistic and psycho-linguistic Features for Complex Word Identification</title>
		<author>
			<persName><forename type="first">Elnaz</forename><surname>Davoodi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leila</forename><surname>Kosseim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="982" to="985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep Learning Architecture for Complex Word Identification</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>De Hertog</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anaïs</forename><surname>Tack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sensible at SemEval-2016 Task 11: Neural Nonsense Mangled in Ensemble Mess</title>
		<author>
			<persName><forename type="first">Nat</forename><surname>Gillin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="963" to="968" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">CAMB at CWI Shared Task 2018: Complex Word Identification with Ensemble-Based Voting</title>
		<author>
			<persName><forename type="first">Sian</forename><surname>Gooding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Kochmar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">NILC at CWI 2018: Exploring Feature Engineering and Feature Learning</title>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Borges</surname></persName>
		</author>
		<author>
			<persName><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages</title>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Heinzerling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
		<idno>abs/1710.02187</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Complex Word Identification Based on Frequency in a Learner Corpus</title>
		<author>
			<persName><forename type="first">Tomoyuki</forename><surname>Kajiwara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Pomona at SemEval-2016 Task 11: Predicting Word Complexity Based on Corpus Frequency</title>
		<author>
			<persName><forename type="first">David</forename><surname>Kauchak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1047" to="1051" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">UWB at SemEval-2016 Task 11: Exploring Features for Complex Word Identification</title>
		<author>
			<persName><forename type="first">Michal</forename><surname>Konkol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1038" to="1041" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">AI-KU at SemEval-2016 Task 11: Word Embeddings and Substring Features for Complex Word Identification</title>
		<author>
			<persName><forename type="first">Onur</forename><surname>Kuru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1042" to="1046" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">LTG at SemEval-2016 Task 11: Complex Word Identification with Classifier Ensembles</title>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="996" to="1000" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MAZA at SemEval-2016 Task 11: Detecting Lexical Complexity Using a Decision Stump Meta-Classifier</title>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="991" to="995" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">USAAR at SemEval-2016 Task 11: Complex Word Identification with Sense Entropy and Sentence Perplexity</title>
		<author>
			<persName><forename type="first">José</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martínez</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liling</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="958" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mining Revision Log of Language Learning SNS for Automated Japanese Error Correction of Second Language Learners</title>
		<author>
			<persName><forename type="first">Tomoya</forename><surname>Mizumoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 5th International Joint Conference on Natural Language Processing</title>
				<meeting>5th International Joint Conference on Natural Language Processing<address><addrLine>Chiang Mai, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Niloy</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dipankar</forename><surname>Braja Gopal Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sivaji</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JU NLP at</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identifying Complex Words in a Sentence</title>
		<author>
			<persName><forename type="first">-</forename><surname>Semeval</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="986" to="990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SemEval 2016 Task 11: Complex Word Identification</title>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="560" to="569" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SV000gg at SemEval-2016 Task 11: Heavy Gauge Complex Word Identification with System Voting</title>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="969" to="974" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">IIIT at SemEval-2016 Task 11: Complex Word Identification using Nearest Centroid Classification</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Palakurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Radhika</forename><surname>Mamidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1017" to="1021" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Glove: Global Vectors for Word Representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Complex Word Identification using Character n-grams</title>
		<author>
			<persName><forename type="first">Maja</forename><surname>Popović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">HMC at SemEval-2016 Task 11: Identifying Complex Words Using Depth-limited Decision Trees</title>
		<author>
			<persName><forename type="first">Maury</forename><surname>Quijada</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><surname>Medero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1034" to="1037" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">TALN at SemEval-2016 Task 11: Modelling Complex Words by Contextual, Lexical and Semantic Features</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<editor>
			<persName><forename type="first">Francesco</forename><surname>Ronzano</surname></persName>
			<persName><forename type="first">Ahmed</forename><surname>Abura'ed</surname></persName>
			<persName><forename type="first">Luis</forename><surname>Espinosa Anke</surname></persName>
			<persName><forename type="first">Horacio</forename><surname>Saggion</surname></persName>
		</editor>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1011" to="1016" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A comparison of techniques to automatically identify complex words</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Shardlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">51st Annual Meeting of the Association for Computational Linguistics Proceedings of the Student Research Workshop</title>
				<meeting><address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="103" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">AmritaCEN at SemEval-2016 Task 11: Complex Word Identification using Word Embedding</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anand</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Soman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1022" to="1027" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Evaluating Lexical Simplification and Vocabulary Knowledge for Learners of French: Possibilities of Using the FLELex Resource</title>
		<author>
			<persName><forename type="first">Anaïs</forename><surname>Tack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>François</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne-Laure</forename><surname>Ligozat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cédrick</forename><surname>Fairon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Language Resources and Evaluation (LREC 2016)</title>
				<meeting>the 10th International Conference on Language Resources and Evaluation (LREC 2016)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="230" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The Whole is Greater than the Sum of its Parts: Towards the Effectiveness of Voting Ensemble Classifiers for Complex Word Identification</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Wani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandeep</forename><surname>Mathias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jayashree</forename><forename type="middle">Aanand</forename><surname>Gajjam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications</title>
				<meeting>the 13th Workshop on Innovative Use of NLP for Building Educational Applications<address><addrLine>New Orleans, United States</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">PLUJAGH at SemEval-2016 Task 11: Simple System for Complex Word Identification</title>
		<author>
			<persName><forename type="first">Krzysztof</forename><surname>Wróbel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="953" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">CWIG3G2 -Complex Word Identification Task across Three Text Genres and Two User Groups</title>
		<author>
			<persName><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Sanjaštajner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
				<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="401" to="407" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multilingual and Cross-Lingual Complex Word Identification</title>
		<author>
			<persName><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Sanjaštajner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
				<meeting>the International Conference Recent Advances in Natural Language Processing<address><addrLine>Varna, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="813" to="822" />
		</imprint>
	</monogr>
	<note>INCOMA Ltd</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Complex Word Identification: Challenges in Data Annotation and System Performance</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Paetzold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucia</forename><surname>Specia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)</title>
				<meeting>the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="59" to="63" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">MacSaar at SemEval-2016 Task 11: Zipfian and Character Features for ComplexWord Identification</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liling</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1001" to="1005" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
