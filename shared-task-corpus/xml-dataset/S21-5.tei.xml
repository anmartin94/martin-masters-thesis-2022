<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2021 Task 5: Toxic Spans Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economic and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Google Jigsaw</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Léo</forename><surname>Laugier</surname></persName>
							<email>leo.laugier@telecom-paris.fr</email>
						</author>
						<author>
							<persName><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">Athens University of Economic and Business</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and System Sciences</orgName>
								<orgName type="institution">Stockholm University</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Télécom Paris</orgName>
								<address>
									<settlement>Institut Polytechnique de Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2021 Task 5: Toxic Spans Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Toxic Spans Detection task of SemEval-2021 required participants to predict the spans of toxic posts that were responsible for the toxic label of the posts. The task could be addressed as supervised sequence labeling, using training data with gold toxic spans provided by the organisers. It could also be treated as rationale extraction, using classifiers trained on potentially larger external datasets of posts manually annotated as toxic or not, without toxic span annotations. For the supervised sequence labeling approach and evaluation purposes, posts previously labeled as toxic were crowd-annotated for toxic spans. Participants submitted their predicted spans for a held-out test set, and were scored using character-based F1. This overview summarises the work of the 36 teams that provided system descriptions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Discussions online often host toxic posts, meaning posts that are rude, disrespectful, or unreasonable; and which can make users want to leave the conversation <ref type="bibr" target="#b5">(Borkan et al., 2019a)</ref>. Current toxicity detection systems classify whole posts as toxic or not <ref type="bibr" target="#b31">(Schmidt and Wiegand, 2017;</ref><ref type="bibr" target="#b25">Pavlopoulos et al., 2017;</ref><ref type="bibr" target="#b39">Zampieri et al., 2019)</ref>, often to assist human moderators, who may be required to review only posts classified as toxic, when reviewing all posts is infeasible. In such cases, human moderators could be assisted even more by automatically highlighting spans of the posts that made the system classify the posts as toxic. This would allow the moderators to more quickly identify objectionable parts of the posts, especially in long posts, and more easily approve or reject the decisions of the toxicity detection systems. As a first step along this direction, Task 5 of SemEval 2021 provided the participants with posts previously rated to be toxic, and required them to identify toxic spans, i.e., spans that were responsible for the toxicity of the posts, when identifying such spans was possible. Note that a post may include no toxic span and still be marked as toxic. On the other hand, a non toxic post may comprise spans that are considered toxic in other toxic posts. We provided a dataset of English posts with gold annotations of toxic spans, and evaluated participating systems on a held-out test subset using character-based F1. The task could be addressed as supervised sequence labeling, training on the provided posts with gold toxic spans. It could also be treated as rationale extraction <ref type="bibr" target="#b17">(Li et al., 2016;</ref><ref type="bibr" target="#b28">Ribeiro et al., 2016)</ref>, using classifiers trained on larger external datasets of posts manually annotated as toxic or not, without toxic span annotations. There were almost 500 individual participants, and 36 out of the 92 teams that were formed submitted reports and results that we survey here. Most teams adopted the supervised sequence labeling approach. Hence, there is still scope for further work on the rationale extraction approach. We also discuss other possible improvements in the definition and data of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Competition Dataset Creation</head><p>During 2015, when many publications were closing down comment sections due to moderation burdens, a start up named Civil Comments launched <ref type="bibr" target="#b11">(Finley, 2016)</ref>. Using a system of peer-based review and flagging, they hoped to crowd source the moderation responsibility. When this effort shut down in 2017 <ref type="bibr" target="#b3">(Bogdanoff, 2017)</ref>, they cited the financial constraints of the competitive publishing industry and the challenges of attaining the necessary scale.</p><p>The founders of Civil Comments, in collaboration with researchers from Google Jigsaw, undertook an effort to open source the collection of more than two million comments that had been collected. After filtering the comments to remove personally identifiable information, a revised version of the annotation system of <ref type="bibr" target="#b38">Wulczyn et al. (2017)</ref> was used on the Appen crowd rating platform to label the comments using a number of attributes including 'toxicity', 'obscene', 'threat <ref type="bibr" target="#b5">' Borkan et al. (2019a)</ref>. The complete dataset, partitioned into training, development, and test sets, was featured in a Kaggle competition, 1 with additional material, including individual rater decisions, published <ref type="bibr" target="#b6">(Borkan et al., 2019b)</ref> after the close of the competition.</p><p>Civil Comments contains about 30k comments marked as toxic by a majority of at least three crowd raters. Toxic comments are rare, especially in fora that are not anonymous and where people have expectations that moderators will be watching and taking action. We undertook an effort to reannotate this subset of comments at the span level, using the following instructions:</p><p>For this task you will be viewing comments that a majority of annotators have already judged as toxic. We would like to know what parts of the comments are responsible for this.</p><p>Extract the toxic word sequences (spans) of the comment below, by highlighting each such span and then clicking the right button. If the comment is not toxic or if the whole comment should have been annotated, check the appropriate box and do not highlight any span. and a custom JavaScript based template, 2 which allowed selection and tagging of comment spans (Fig. <ref type="figure" target="#fig_0">1</ref>). While raters were asked to categorize each span as one of five different categories, this was primarily intended as a priming exercise and all of the highlighted spans were collapsed into a single category. The lengths of the highlighted spans were decided by the raters. Seven raters were employed per post, but there were posts where fewer were eventually assigned. On the test subset (Table <ref type="table" target="#tab_1">1</ref>), we verified that the number of raters per post varied from three to seven; on the trial and train subsets this number varied from two to seven. All raters were warned the content might by explicit, and only raters who allowed adult content were selected. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Inter-annotator Agreement</head><p>We measured inter-annotator agreement, initially, on a small set of 35 posts and we found 0.61 average Cohen's Kappa. That is, we computed the mean pairwise Kappa per post, by using character offsets as instances being classified in two classes, toxic and non-toxic. And then we averaged Kappa over the 35 posts. On later experiments with larger samples (up to 1,000 posts) we observed equally moderate agreement and always higher than 0.55. Given the highly subjective nature of the task we consider this agreement to be reasonably high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extracting the ground truth</head><p>Each post comprises sets of annotated spans, one per rater. Each span is assigned a binary (toxic, nontoxic) label, based on whether the respective rater  found the span to be insulting, threatening, identitybased attack, profane/obscene, or otherwise toxic.</p><p>If the span was annotated with any of those types, the span is considered toxic according to the rater, otherwise not. For each post, we extracted the character offsets of each toxic span of each rater.</p><p>In each post, the ground truth considers a character offset as toxic if the majority of the raters included it in their toxic spans, otherwise the ground truth of the character offset is non-toxic. A toxic span (Table <ref type="table" target="#tab_1">1</ref>) in the ground truth of a post is a maximal sequence of contiguous toxic character-offsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Exploratory analysis</head><p>After discarding duplicates and posts used as quiz questions to check the reliability of candidate annotators, we split the data into trial, train, and test (Table <ref type="table" target="#tab_1">1</ref>). Compared to the trial and training sets, the test set comprises posts with fewer characters and spans, but also shorter spans on average. When studying the toxicity subtypes, we find that the vast majority of posts are annotated as insulting. In the training set, more than 6,000 posts are annotated as insulting, and the same high fraction is observed in the trial and test sets. Most of the toxic spans in the training set are single-word terms. The most frequent of them, such as 'stupid' and 'idiot', occur hundreds of times and remain frequent in the trial and test sets. Multi-word terms, such as 'white trash', 'mentally ill', are less frequent and vary across the three sets.</p><p>In an analysis of the test set, <ref type="bibr" target="#b24">Palomino et al. (2021)</ref> used an emotion classifier that returns five scores per post, one for each of the following emotions: anger, happiness, sadness, surprise, fear. 4 Fear and sadness were reported to be the emotions with the highest average scores, a finding that we verified by repeating the experiment (see Fig. <ref type="figure" target="#fig_1">2</ref>). 5 Interestingly, the emotion with the highest average score after sadness and fear is surprise, not anger, and happiness has the lowest score. <ref type="bibr">4</ref> pypi.org/project/text2emotion 5 A post with a high sadness score (100%) is the following: "Such thin skin. Pathetic."; the toxic span shown in red. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task description</head><p>The objective of this task is the detection of the spans that make a post toxic, when detecting such spans is possible. Systems had to extract a list of toxic spans, or an empty list, per post. A toxic span was defined to be a sequence of words that attribute to the post's toxicity. Although we defined the task at the word level, gold labels were provided at the character level counting from zero (see Table <ref type="table">2</ref>). The evaluation period started on January 10, 2021 and finished on January 31, 2021. The first week, 10 submissions were allowed per day per team. The second week this number was reduced to 5, and it was reduced further to 1 during the final week. We chose to allow an extended evaluation period combined with multiple team submissions, to promote the competition. However, we also chose a decreasing submission limit to make it harder for participants to overfit the test set. As shown in Fig. <ref type="figure" target="#fig_2">3</ref>, the number of submissions dropped over time, due to this constraint, but the interest was what a dummy, dummy has no regard for the law. you cannot brutalize a suspect. he has complete lack of respect for any law and is acting like a dictator. he is trying to emulate putin. {12, . . . , 17, 94, . . . , 102}</p><p>People make stupid decisions and then expect the gov't to bail them out. There is no cure for stupidity. {14, . . . , 20, 29, . . . , 35} Nah, the only asshole is the asshole firing a rifle within city limits.</p><p>Table <ref type="table">2</ref>: Examples of toxic test posts and their ground truth toxic spans (shown in red). The left column shows the character offsets of the toxic spans. The top three posts have no toxic spans, the next three have one each, while the remaining three posts have two toxic spans each. continuous, and there were submissions until the last day. Despite the decreasing total number of submissions per day, the top daily score increased, reaching its maximum on the last day (see Fig. <ref type="figure" target="#fig_3">4</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Participation overview</head><p>We received 479 individual participation requests, 92 team formations, and 1,449 submissions. 91 teams submitted valid predictions (1,385 valid submissions in total) and were scored; out of these, only 36 submitted system descriptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The HITSZ-HLT submission</head><p>The best performing team (HITSZ-HLT) formulated the problem as a combination of token label-ing and span extraction <ref type="bibr" target="#b41">(Zhu et al., 2021)</ref>.</p><p>For their token labeling approach, the team used two systems based on BERT <ref type="bibr" target="#b9">(Devlin et al., 2019)</ref>. Both systems had a Conditional Random Field (CRF) layer <ref type="bibr" target="#b35">(Sutton and McCallum, 2006)</ref> on top, but one of the two also had an LSTM layer <ref type="bibr" target="#b14">(Hochreiter and Schmidhuber, 1997)</ref> between BERT and the CRF layer. In both approaches, word-level BIO tags were used, i.e., words were labelled as B (beginning word of a toxic span), I (inside word of a toxic span), or O (outside of any toxic span).</p><p>For their span extraction approach, the team also used BERT. Roughly speaking, in this case BERT produces probabilities indicating how likely it is for each token to be the beginning or end of a toxic span. Then a heuristic search algorithm, originally developed for target extraction in sentiment analysis by <ref type="bibr" target="#b15">Hu et al. (2019)</ref>, selects the best combinations of candidate begin and end tokens, aiming to output the most likely set of toxic spans per post.</p><p>The character predictions of the three systems described above were combined with majority voting per character. That is, if any two systems considered a character to be part of a toxic span, then the ensemble classified the character as toxic, otherwise the ensemble classified it as non-toxic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The S-NLP submission</head><p>The team with the second best performing system (S-NLP) consists of individual participants who grouped and submitted an ensemble of their sys-tems . The ensemble combines two approaches, both of which are based on a RoBERTa model <ref type="bibr" target="#b18">(Liu et al., 2019)</ref>. The latter is first fine-tuned to classify posts as toxic or nontoxic, using three Kaggle toxicity datasets. <ref type="bibr">6</ref> For toxic span detection, RoBERTa's subword representations from three different layers (1, 6, 12) are summed to produce the corresponding word embeddings. A binary classifier on top of RoBERTa, operating on the word embeddings, predicts whether a word belongs to a toxic span or not.</p><p>For the first component of the ensemble, the word embeddings obtained from RoBERTa's subword representations are concatenated with FLAIR <ref type="bibr" target="#b0">(Akbik et al., 2019)</ref> and FastText <ref type="bibr" target="#b4">(Bojanowski et al., 2017)</ref> embeddings. <ref type="bibr">7</ref> The resulting embeddings are passed on to a two-layer stacked BiLSTM with a CRF layer on top to generate a BIO tag per word.</p><p>The second component of the ensemble used the RoBERTa model as a teacher to produce silver toxic spans for 30,000 unlabelled toxic posts <ref type="bibr" target="#b5">(Borkan et al., 2019a)</ref>. RoBERTa was then retrained as a student on the augmented dataset (30k posts with silver labels and the training posts provided by the organisers) to predict toxic offsets.</p><p>The ensemble returns the intersection of the toxic spans identified by the two components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Additional interesting approaches</head><p>We now discuss some of the most interesting alternative approaches tried by the participants, even if they did not lead to high scores. Rationales Some participants experimented with training toxicity classifiers on external datasets containing posts labeled as toxic or non-toxic; and then employing model-specific or model-agnostic rationale extraction mechanisms to produce toxic spans as explanations of the decisions of the classifier. The model-specific rationale mechanism of Rusert (2021) used the attention scores of an LSTM toxicity classifier to detect the toxic spans. Pluciński and Klimczak (2021) used the same approach, but also employed an orthogonalisation technique <ref type="bibr" target="#b22">(Mohankumar et al., 2020)</ref>. The model-agnostic rationale mechanism of <ref type="bibr" target="#b29">Rusert (2021)</ref> combined an LSTM classifier with a token-masking approach that we call Input Erasure (IE), due to its similarities to the method of <ref type="bibr" target="#b17">Li et al. (2016)</ref>. The model-agnostic approach of Pluciński and Klimczak (2021) combined SHAP <ref type="bibr" target="#b19">(Lundberg and Lee, 2017)</ref> with a fine-tuned BERT model. <ref type="bibr" target="#b10">Ding and Jurgens (2021)</ref> and <ref type="bibr">Benlahbib et al. (</ref> <ref type="formula">2021</ref>) also experimented with model-agnostic approaches, but they combined LIME <ref type="bibr" target="#b28">(Ribeiro et al., 2016)</ref> with a Logistic Regression (LR) or with a linear Support Vector Machine (SVM) toxicity classifier. All the above mentioned approaches used a threshold to turn the explanation scores (e.g., attention or LIME scores) of the words into binary decisions (toxic/non-toxic words). Lexicon-based No team relied on a purely lexiconbased approach, but few experimented with lexiconbased baselines <ref type="bibr" target="#b41">(Zhu et al., 2021;</ref><ref type="bibr" target="#b24">Palomino et al., 2021)</ref> or used such components in ensembles <ref type="bibr" target="#b27">(Ranasinghe et al., 2021)</ref>. Three kinds of lexiconbased methods were used. First, the lexicon was handcrafted by domain experts <ref type="bibr" target="#b33">(Smedt et al., 2020)</ref> and it was simply employed as a list of toxic words for lookup operations <ref type="bibr" target="#b24">(Palomino et al., 2021)</ref>. Second, the lexicon was compiled using the set of tokens labeled as toxic in our span-annotated training set and it was used as a lookup table <ref type="bibr" target="#b7">(Burtenshaw and Kestemont, 2021)</ref>, possibly also storing the frequency of each lexicon token in the training set <ref type="bibr" target="#b41">(Zhu et al., 2021)</ref>. The former two were also combined <ref type="bibr" target="#b27">(Ranasinghe et al., 2021)</ref>. Third, the least supervised lexicons were built with statistical analysis on the occurrences of tokens in a training set solely annotated at the comment level (toxic/nontoxic post) <ref type="bibr" target="#b29">(Rusert, 2021</ref>). An added value of these approaches is that easy to use resources (toxicity lexicons) are built and shared publicly, such as the one suggested by <ref type="bibr" target="#b26">Pluciński and Klimczak (2021)</ref>. <ref type="bibr">8</ref> Custom losses Zhen Wang and Liu (2021) experimented with a new custom loss, which weighted false toxicity predictions based on their location in the text. If a false prediction was located near a ground truth toxic span, then it would contribute less to the overall loss for that post, compared to one located further away. The loss function used by <ref type="bibr" target="#b16">Kuyumcu et al. (2021)</ref> to train their system is the Tversky Similarity Index <ref type="bibr" target="#b36">(Tversky, 1977)</ref>, a generalisation of the Sørensen-Dice coefficient and the Jaccard index, which was adjusted by the authors to weigh up false negatives. Data augmentation The vast majority of the participating teams employed additional training data annotated at the post level. That is, either to build lexicons <ref type="bibr" target="#b29">(Rusert, 2021)</ref>, to leverage unsupervised rationale extraction methods <ref type="bibr" target="#b29">(Rusert, 2021;</ref><ref type="bibr" target="#b26">Pluciński and Klimczak, 2021;</ref><ref type="bibr" target="#b10">Ding and Jurgens, 2021;</ref><ref type="bibr" target="#b2">Benlahbib et al., 2021)</ref>, or to filter posts (Luu and Nguyen, 2021) that were not labeled as toxic by a toxicity classifier. Suman and Jain (2021) astutely produced silver data from external sources to augment the initial golden annotated dataset, training their model iteratively in a semi-supervised manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation</head><p>This section focuses on the evaluation framework of the task. First, the official measure that was used to evaluate the participating systems is described. Then, we discuss baseline models that were selected as benchmarks for comparison reasons. Finally, the results are presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Official evaluation measure</head><p>Following the work of Martino et al. ( <ref type="formula">2019</ref>), systems were evaluated in terms of F1 computed on character offsets. For each system, we computed the F1 score per post, between the predicted and the ground truth character offsets. Then, we returned the macro-averaged (over test posts) score. When the ground truth set of character offsets was empty, we assigned a perfect score (F 1 = 1) to the post in question if the predicted set of character offsets was also empty, and a zero score otherwise. 9</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Benchmarks</head><p>We report the results of some baselines, developed by us or the participants, to act as benchmarks.</p><p>BENCHMARK I was developed by . It is based on a RoBERTa model, fine-tuned to predict if a post is toxic or not (Section 4.2) and further fine-tuned to predict toxic spans by using a CRF layer on top.</p><p>BENCHMARK II is a lexicon-based system, developed by <ref type="bibr" target="#b41">Zhu et al. (2021)</ref>, which extracts likely toxic words from the training data and simply tags them during inference. The lexicon comprises words that appear frequently inside ground truth toxic spans and not outside.</p><p>BENCHMARK III is a random baseline, which assigns a random label (toxic/non-toxic) per character offset (50% chance of being toxic). 10 <ref type="formula">9</ref>The evaluation code can be found in our GitHub repository (github.com/ipavlopoulos/toxic_spans). <ref type="bibr">10</ref> The code of this baseline is also in the task's repository.  Table <ref type="table" target="#tab_4">3</ref> shows the scores and ranks of all participating teams that described their approach, i.e., 36 out of 91 teams that participated. HITSZ-HLT (Section 4.1) was ranked first, followed by S-NLP (Section 4.2) that scored 0.06% lower. The rest of the teams followed with scores lower than 70%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>The score of the median is 67.58%, which is not far below the top scored team (-3.22 percent units), while it is far above the last two (+17.52 percent units). The standard deviation of system scores above the median is much lower (0.94) than that of the systems below the median (4.12). Most teams that were excluded from the table (because they did not describe their methods) score lower than the median. However, there were also top scoring teams among those that were excluded, such as a team with a RoBERTa-based token-level ensemble that was ranked 4th. <ref type="bibr">11</ref> BENCHMARK I achieves a considerably high score and, hence, is very highly ranked. Combining BERT with a CRF or a span extraction method (two of the individual methods of the HITSZ-HLT ensemble, Section 4.1, not shown in Table <ref type="table" target="#tab_4">3</ref>) also performs well <ref type="bibr" target="#b41">(Zhu et al., 2021)</ref>, but these methods would be ranked two positions lower than BENCH-MARK I. Nguyen et al. ( <ref type="formula">2021</ref>) explored the benefits of further enhancing these word embeddings by concatenating them with FLAIR <ref type="bibr" target="#b0">(Akbik et al., 2019)</ref> and FastText <ref type="bibr" target="#b4">(Bojanowski et al., 2017)</ref> embeddings (Section 4.2). As shown in Fig. <ref type="figure" target="#fig_4">5</ref>, the F1 score is slightly improved, reaching a maximum when both FLAIR and FastText embeddings are added. <ref type="bibr">12</ref> We note that the same beneficial effect of enhancing the word embeddings was reported when using BERT as the base model (Sans and Farràs, 2021). The lexicon-based BENCHMARK II and the random BENCHMARK III scored very low. The latter outperformed only one submission (MACECH), which sent the predictions in the wrong order. As noted in their report <ref type="bibr">(Cech, 2021)</ref>, if the predictions had been submitted in the correct order, the team's score would have been 54%, and BENCHMARK III would have been the worst system in Table <ref type="table" target="#tab_4">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis and discussion</head><p>Overall the organisers were happy to see the degree of involvement in this shared task, and the resulting diversity of approaches to this problem. We include some of our observations regarding the administration of the evaluation and what we have learned from the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Participation</head><p>The authors reached out to teams that decided not to submit a description paper and the vast majority were students who were time-limited. The fact that students participated in the task is promising and we plan to consider more ways to introduce SemEval tasks in classrooms. On the other hand, 60% of the participants chose not to describe their approach, which is problematic and should be addressed. A team could take advantage of such an option to create duplicate submissions and bypass any submission limits. More importantly, potentially interesting approaches are not discussed and properly compared to others.</p><p>It is also worth mentioning that the extended timeline allowed participants to join forces. For instance, a number of participants decided to combine their systems and form the 2nd ranked S-NLP. Their ensemble scored higher than all their standalone systems, though their best standalone system would still be ranked 2nd. In any case, we welcome the collaboration between participants, which may provide further insights regarding effective combinations of architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">General remarks on the approaches</head><p>Except for lexicon-based baselines, we observed that the vast majority of systems adopted the recent paradigm in NLP: fine-tuning large off-the-shelf Transformers <ref type="bibr" target="#b37">(Vaswani et al., 2017)</ref> pre-trained on massive corpora. Non-Transformer based approaches, mostly LSTMs with pre-trained word embeddings were also used. The nature of the task, similar to the well-studied Named Entity Recognition (NER) task, led many competitors to use a CRF layer on top of the model (e.g., Transformers or LSTMs) of their choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Performance</head><p>The winning team (HITSZ-HLT) combined BERT with two approaches for their ensemble: a token labeling approach (two versions, with/without an LSTM between BERT and the CRF) and a span ex-traction approach (Section 4.1). The comparison of the two showed that span extraction is slightly better on posts with a single span, but token labeling is clearly better on multi-span posts <ref type="bibr" target="#b41">(Zhu et al., 2021)</ref>. The complementary nature of the two approaches is probably what makes even a simple majority voting ensemble better than its competitors.</p><p>The system that was ranked second (S-NLP) also employed an ensemble, using a RoBERTa model initially fine-tuned to classify posts as toxic or nontoxic as the starting point . The ensemble combined (i) the resulting RoBERTa model, now fine-tuned to predict toxic spans, with additional FLAIR and FastText embeddings, and (ii) a RoBERTa model retrained as a student to predict toxic spans (Section 4.2). Although the two standalone models achieved higher scores than the standalone models of the top-ranked team (HITSZ-HLT), the ensemble did not yield significant improvements. This may be due to the student's decisions not being that complementary to the teacher's, as the team notes   Teams that experimented with rationale extraction mechanisms (Section 4.3) did not find this approach advantageous compared to supervised sequence labeling in terms of F1 scores. However, the reported results of the rationale-based systems show that this approach is promising, especially because it does not require any data annotated at the span-level. Hence, there is scope for future work that could explore this direction further. Table 4 shows the F1 scores of all the rationale-based systems that were reported by participants. The binary toxic post classifiers that were used were LSTM, Logistic Regression (LR), Support Vector Machines (SVM), and BERT. The attention scores of an LSTM were used with <ref type="bibr" target="#b26">(Pluciński and Klimczak, 2021)</ref> and without an orthogonality method <ref type="bibr" target="#b29">(Rusert, 2021)</ref>, with the latter being slightly bet-ter; these are model-specific rational extraction methods (Section 4.3). Model-agnostic approaches (Input Erasure, LIME, SHAP) were better than the model-specific ones. The best rationale-based method employed a BERT model, fine-tuned for toxic post classification, and SHAP.  Lexicon-based approaches were only used as baselines or components in ensembles, as already noted. In principle, all lexicon-based systems are extremely efficient and interpretable. Table <ref type="table" target="#tab_8">5</ref> shows they can also achieve surprisingly high scores. Recall that we used the best performing lexicon-based system, developed by <ref type="bibr" target="#b41">Zhu et al. (2021)</ref>, as BENCHMARK II. Its score is included in Table <ref type="table" target="#tab_4">3</ref>. Despite the fact that it is low ranked, its F1 score is less than 6 percent points lower that that of the best submission. We also note that BENCHMARK II is a high-precision classifier; it outperforms even the best system in terms of precision <ref type="bibr" target="#b41">(Zhu et al., 2021)</ref>. Attempts to expand its lexicon using WordNet and GloVe, improved recall, but eventually harmed precision and its F1 score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Error analysis</head><p>A common theme across many competitor reports was the serious challenge posed by comments with no toxic spans. It is not readily evident why this is a common occurrence in the task, and certainly the way that annotation consensus is used to combine annotations can be a contributing factor. However, many systems seemed determined to tag some spans and many authors noted that performance on posts with no tagged span was extremely poor compared to performance on posts with tagged spans.</p><p>Many systems were also reluctant to tag function words like 'of' and 'and', which can be included in multi-word spans (e.g., 'piece of crap'), leading to a decline in performance as measured by the chosen F1 measure. The overwhelming presence of single word gold spans in the training set favors short spans. But the majority of the short spans comprises common cuss or clearly abusive words, which can be directly classified as toxic <ref type="bibr" target="#b12">(Ghosh and Kumar, 2021)</ref>; by contrast, the infrequent longer spans are rather context dependent and more challenging to detect. This probably also contributed to the performance of the best system (HITSZ-HLT), since one of the two components of that ensemble handled better long spans, as already discussed in Section 6.3.</p><p>Other error analysis highlighted challenges intrinsic to the task. The strong dependency of toxicity on context makes it particularly difficult to solve with systems based on vocabulary. Toxicity, when expressed with subtle language, can appear through non-local text features: some comments are toxic without showing any obvious toxic span in them. Such posts made the task more difficult for participants, because systems had learnt to label the words bearing the most negative sentiment <ref type="bibr" target="#b1">(Bansal et al., 2021)</ref>. Annotation mistakes were also reported (Table <ref type="table">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INCONSISTENCIES</head><p>Not all the occurrences of the same toxic span are annotated in the same post.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FALSE NEGATIVES</head><p>Toxic words missed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FALSE POSITIVES</head><p>Non-toxic words labelled.</p><p>Table <ref type="table">6</ref>: The types and descriptions of the annotation mistakes that were detected by some of the participants.</p><p>Participants that were notable for their effort in error analysis include <ref type="bibr" target="#b1">Bansal et al. (2021)</ref>, Hoang and Nguyen (2021), <ref type="bibr" target="#b10">Ding and Jurgens (2021)</ref>, and <ref type="bibr" target="#b12">Ghosh and Kumar (2021)</ref>, where an additional effort was made to examine their model's ability to correctly tag words in toxic and non-toxic contexts. Interestingly Sans and Farràs (2021) also noted in their analysis that racial and ethnic terms are labeled in biased ways that reflect patterns not only in the training toxic spans, but also in external data used to pre-train underlying Transformer models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>We provided 10,629 posts that were annotated for toxic spans and we defined the task of toxic span detection. The task was popular, attracting almost 500 individual participants. Eventually 91 teams were formed, out of which 36 submitted a description report. This overview described the approaches of these 36 teams and discussed their results.</p><p>Pre-trained Transformers, fine-tuned by viewing the task as a sequence labelling one, performed well and solutions that combined these models within an ensemble were highly-rated. The performance of these models increases further with the help of pre-trained word embeddings or by using multiple Transformer layers to embed words.</p><p>Long toxic spans were more likely contextdependent and less frequent in the dataset compared to single-word spans, which made their detection a challenge. The winners included in their ensemble an approach that performed better on long spans, but we note that the problem of detecting long uncommon toxic spans is far from solved.</p><p>Of particular interest were approaches that employed rationale extraction mechanisms, which do not require any training data annotated at the span level. They performed much worse than sequence labeling approaches, but this is a promising direction that was considered by only a few participants.</p><p>Future similar competitions could benefit from tracks that separate supervised from unsupervised solutions. The development of datasets created with the help of crowd annotators should focus on addressing ambiguity, bias, inconsistencies, and misannotations. This could be accomplished by adding more annotators per post. Future competitions could also require participants to both classify posts as toxic or not, and detect toxic spans only when posts are classified as toxic, instead of providing the participants only with posts already classified as toxic. Finally, future competitions could require participants to distinguish toxic posts of different kinds (e.g., insult, threat, profanity, along with supporting spans), which are sometimes easier to define compared to the more general umbrella toxicity term we (and others) have used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Screenshot of the Appen labeling interface that was used to annotate toxic spans.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Emotion scores of the test posts. Emotion scores were obtained using an off-the-shelf emotion classifier, following Palomino et al. (2021).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Number of submissions per evaluation day.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The evaluation score (character F1) of the best submission per day during the evaluation period.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: F1 of BENCHMARK I<ref type="bibr" target="#b41">(Zhu et al., 2021)</ref> when FLAIR and FastText word embeddings are concatenated with the embeddings obtained from RoBERTa's subword representations (from layers 1, 6, 12).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the trial, training, and test subsets of the dataset. Lengths are calculated in characters.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>OFFSETS POST {} I will stand by my statement that liberalism is what smart looks like to stupid people. The letter posted yesterday states the real problem clearly enough. "It doesn't matter if it was protected by the First Amendment." I have legal news flash for the University of Oregon. Because the University is public and receives government tax dollars it is indeed bound to abide by the US constitution with All OF IT'S PROTECTION INCLUDED. Which should tell everyone right off the signatories are anti-American, and perhaps even anti-America in their twisted PC nonsense. {} Fits the despicable piece of trash like a glove. {} No he shot someone so he shouldn't be free. He should be locked up like He is for the next decade. You holla like its no big deal but what if it was your little brother who was shot? Then your dumb ass wouldnrlt be screaming free ace g or whatever gay nickname he has. That is the lamest gangster name ever. Do you think that name scares people? Ace clown is what i will now call him. {55, 56, 57, 58} Time to give the opposition weapons and overthrow this jerk. {31, . . . , 39} you are a paid liberal hack of stupidity shore living the liberal lie every day {9, . . . , 13} Youre an idiot. {7, 8, . . . , 11, 14, 15, . . . , 18}</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Official rank and F1 score (%) of the 36 participating teams that submitted system description papers.</figDesc><table /><note>(There were 91 teams with sumbissions in total.) The median is shown in blue and benchmarks in red.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>).</figDesc><table><row><cell>TBC</cell><cell>RE</cell><cell>F1 (%)</cell><cell>Report</cell></row><row><cell>LSTM</cell><cell>IE</cell><cell>38.29</cell><cell>Rusert (2021)</cell></row><row><cell>LSTM</cell><cell>ATT</cell><cell>49.70</cell><cell>Pluciński and Klimczak (2021)</cell></row><row><cell>LSTM</cell><cell>ATT</cell><cell>50.07</cell><cell>Rusert (2021)</cell></row><row><cell>LR</cell><cell>LIME</cell><cell>58.88</cell><cell>Benlahbib et al. (2021)</cell></row><row><cell>SVM</cell><cell>LIME</cell><cell>59.21</cell><cell>Benlahbib et al. (2021)</cell></row><row><cell>BERT</cell><cell>SHAP</cell><cell>59.87</cell><cell>Pluciński and Klimczak (2021)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: F1 on the evaluation set for systems employing</cell></row><row><cell>rationale extraction (RE) mechanisms combined with</cell></row><row><cell>post-level toxicity binary classifiers (TBC). Rationales</cell></row><row><cell>are obtained via Input Erasure (IE), Attention (ATT),</cell></row><row><cell>LIME, or SHAP. The binary classifier is an LSTM, Lo-</cell></row><row><cell>gistic Regression (LR), SVM, or BERT.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>F1 on the evaluation set for lexicon-based systems. Systems that are followed by † and ‡ use exclusively external and internal resources respectively.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">www.kaggle.com/c/jigsaw-unintendedbias-in-toxicity-classification 2 github.com/ipavlopoulos/toxic_spans</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The full dataset and annotations for ToxicSpans is released (github.com/ipavlopoulos/toxic_spans) with a CC0 licence. The previously released Civil Comments dataset, on which the new dataset is based, was filtered to remove any potential personally identifiable information.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">github.com/unitaryai/detoxify 7 In the latter case, in-vocabulary word embeddings were imported to Word2Vec for efficiency, and out of vocabulary words were handled with BPEs<ref type="bibr" target="#b32">(Sennrich et al., 2016)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">github.com/Orthrus-Lexicon/Toxic</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">We asked for details from participants that did not submit a description paper, but not all of them replied.12 Out of vocabulary words were tackled by using FastText embeddings of BPEs; consult.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank the participants and the reviewers for their useful comments and suggestions. This research was funded in part by a Google Research Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Flair: An easy-to-use framework for state-of-the-art nlp</title>
		<author>
			<persName><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanja</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL Demonstrations</title>
				<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">IITK@Detox at SemEval-2021 Task 5: Semisupervised learning and dice loss for toxic spans detection</title>
		<author>
			<persName><forename type="first">Archit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhay</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashutosh</forename><surname>Modi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">LISAC FSDM USMBA at SemEval 2021 Task 5: Tackling toxic spans detection challenge with supervised spanBERT-based model and unsupervised LIME-based model</title>
		<author>
			<persName><forename type="first">Abdessamad</forename><surname>Benlahbib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamza</forename><surname>Alami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Alami</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>In SemEval</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Saying goodbye to civil comments</title>
		<author>
			<persName><forename type="first">Aja</forename><surname>Bogdanoff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nuanced metrics for measuring unintended bias with real data for text classification</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Borkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Vasserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<meeting><address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="491" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Exploring the role of human raters in creating nlp datasets</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Borkan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucy</forename><surname>Vasserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">UAntwerp at SemEval-2021 Task 5: Spans are spans, stacking a binary word level approach to toxic span detection</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Burtenshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Kestemont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">2021. macech at SemEval-2021 Task 5: Toxic spans detection</title>
		<author>
			<persName><forename type="first">Maggie</forename><surname>Cech</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In SemEval</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
				<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">HamiltonDinggg at SemEval-2021 Task 5: Investigating toxic span detection using RoBERTa pre-training</title>
		<author>
			<persName><forename type="first">Huiyang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Se-mEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Want to save the comments from trolls? do it yourself</title>
		<author>
			<persName><forename type="first">Kline</forename><surname>Finley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cisco at SemEval-2021 Task 5: What&apos;s toxic?: Leveraging transformers for multiple toxic span extraction from online comments</title>
		<author>
			<persName><forename type="first">Sreyan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonal</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">UIT-E10dot3 at SemEval 2021 Task 5: Toxic spans detection with roberta and spacy&apos;s library base systems</title>
		<author>
			<persName><forename type="first">Gia</forename><surname>Phu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luan Thanh</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Open-domain targeted sentiment analysis via span-based extraction and classification</title>
		<author>
			<persName><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Lv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="537" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sefamerve arge at SemEval-2021 Task 5: Toxic span detection using segmentation based 1-d convolutional neural network model</title>
		<author>
			<persName><forename type="first">Birol</forename><surname>Kuyumcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Selman</forename><surname>Delil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cüneyt</forename><surname>Aksakallı</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Monroe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08220</idno>
		<title level="m">Understanding neural networks through representation erasure</title>
				<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
				<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">Scott</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Su-In</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07874</idno>
		<title level="m">A unified approach to interpreting model predictions</title>
				<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">UIT-ISE-NLP at SemEval-2021 Task 5: Toxic span detection with BiLSTM -CRF and toxic BERT comment classification</title>
		<author>
			<persName><forename type="first">T</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ngan</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fine-grained analysis of propaganda in news article</title>
		<author>
			<persName><forename type="first">Giovanni</forename><surname>Da San</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Seunghak</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alberto</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rostislav</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName><surname>Nakov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
				<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5640" to="5650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Towards transparent and explainable attention models</title>
		<author>
			<persName><forename type="first">Akash</forename><surname>Kumar Mohankumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preksha</forename><surname>Nema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mitesh</surname></persName>
		</author>
		<author>
			<persName><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Balaraman</forename><surname>Balaji Vasan Srinivasan</surname></persName>
		</author>
		<author>
			<persName><surname>Ravindran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4206" to="4216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Huy Dao Quang, and Quang Huu Pham. 2021. S-NLP at semeval-2021 task 5: Toxic spans detection</title>
		<author>
			<persName><forename type="first">Anh</forename><surname>Viet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tam</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">An ensemble approach to identify toxicity in text</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Palomino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawid</forename><surname>Grad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Bedwell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>In SemEval</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deeper attention to abusive user content moderation</title>
		<author>
			<persName><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
				<meeting><address><addrLine>Copenghagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1125" to="1135" />
		</imprint>
	</monogr>
	<note>Prodromos Malakasiotis, and Ion Androutsopoulos</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">GHOST at SemEval-2021 Task 5: Is explanation all you need</title>
		<author>
			<persName><forename type="first">Kamil</forename><surname>Pluciński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanna</forename><surname>Klimczak</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>In SemEval</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">WLV-RIT at SemEval-2021 Task 5: A neural transformer framework for detecting toxic spans</title>
		<author>
			<persName><forename type="first">Diptanu</forename><surname>Tharindu Ranasinghe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Sarkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><surname>Ororbia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Explaining the predictions of any classifier</title>
		<author>
			<persName><forename type="first">Marco</forename><forename type="middle">T</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
				<meeting><address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1135" to="1144" />
		</imprint>
	</monogr>
	<note>Why Should I Trust You?</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">NLP UIOWA at Semeval-2021 Task 5: Transferring toxic sets to tag toxic spans</title>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Rusert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>In SemEval</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">HLE-UPC at SemEval-2021 Task 5: Multi-Depth Distil-BERT for toxic spans detection</title>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<editor>
			<persName><forename type="first">Palliser</forename><surname>Rafel</surname></persName>
			<persName><forename type="first">Albert Rial</forename><surname>Sans</surname></persName>
			<persName><surname>Farràs</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A survey on hate speech detection using natural language processing</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Wiegand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Natural Language Processing for Social Media</title>
				<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
				<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Pierre</forename><surname>Tom De Smedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sylvia</forename><surname>Voué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melina</forename><surname>Jaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guy</forename><forename type="middle">De</forename><surname>Röttcher</surname></persName>
		</author>
		<author>
			<persName><surname>Pauw</surname></persName>
		</author>
		<title level="m">Profanity &amp; offensive words</title>
				<imprint>
			<publisher>POW</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Textgain</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">AS-tarTwice at SemEval-2021 Task 5: Toxic span detection using RoBERTa-CRF, domain specific pretraining and self-training</title>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Thakur Ashutosh Suman</surname></persName>
		</author>
		<author>
			<persName><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">An Introduction to Conditional Random Fields for relational learning. Introduction to statistical relational learning</title>
		<author>
			<persName><forename type="first">Charles</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="93" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Features of similarity. Psychological review</title>
		<author>
			<persName><forename type="first">Amos</forename><surname>Tversky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">327</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
				<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ex machina: Personal attacks seen at scale</title>
		<author>
			<persName><forename type="first">Ellery</forename><surname>Wulczyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
				<meeting><address><addrLine>Perth, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1391" to="1399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)</title>
		<author>
			<persName><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>In SemEval</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">MedAI at SemEval-2021 Task 5: Start-to-end tagging framework for toxic spans detection</title>
		<author>
			<persName><forename type="first">Zhen</forename><surname>Hongjie Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SemEval</title>
				<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">HITSZ-HLT at SemEval-2021 Task 5: Span-based ensemble model with toxic lexicon</title>
		<author>
			<persName><forename type="first">Qinglin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zijie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yice</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingyi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihui</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>In SemEval</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
