<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semeval 2007 Task 18: Arabic Semantic Labeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mona</forename><surname>Diab</surname></persName>
							<email>mdiab@cs.columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
							<email>fellbaum@clarity.princeton.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Musa</forename><surname>Alkhalifa</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Barcelona</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aous</forename><surname>Mansouri</surname></persName>
							<email>aous.mansouri@colorado.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">University of Colorado</orgName>
								<address>
									<settlement>Boulder</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sabri</forename><surname>Elkateb</surname></persName>
							<email>sabri.elkateb@manchester.ac.uk</email>
							<affiliation key="aff4">
								<orgName type="institution">University of Manchester</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
							<email>martha.palmer@colorado.edu</email>
							<affiliation key="aff5">
								<orgName type="institution">University of Colorado</orgName>
								<address>
									<settlement>Boulder</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Semeval 2007 Task 18: Arabic Semantic Labeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present the details of the Arabic Semantic Labeling task. We describe some of the features of Arabic that are relevant for the task. The task comprises two subtasks: Arabic word sense disambiguation and Arabic semantic role labeling. The task focuses on modern standard Arabic.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent years have witnessed a surge in available resources for the Arabic language. <ref type="bibr">1</ref> The computational linguistics community is just about starting to exploit these resources toward several interesting scientific and engineering goals. The Arabic language is interesting from a computational linguistic perspective. It is significantly different from English hence creating a challenge for existing technology to be easily portable to Arabic. The Arabic language is inherently complex due to its rich morphology and relative free word order. Moreover, with the existence of several interesting varieties, the spoken vernaculars, we are witnessing the emergence of written dialectal Arabic everyday on the web, however there are no set standards for these varieties.</p><p>We have seen many successful strides towards functional systems for Arabic enabling technologies, but we are yet to read about large Arabic NLP applications such as Machine Translation and Information Extraction that are on par with performance on the English language. The problem is not the existence of data, but rather the existence of data annotated with the relevant level of information that 1 Author 1 is supported by DARPA contract Contract No. HR0011-06-C-0023. Authors 2, 3 and 4 are supported by the US Central Intelligence Service.</p><p>is useful for NLP. This task attempts a step towards the goal of creating resources that could be useful for such applications.</p><p>In this task, we presented practitioners in the field with challenge of labeling Arabic text with semantic labels. The labels constitute two levels of granularity: sense labels and semantic role labels. We specifically chose data that overlapped such that we would have the same data annotated for different types of semantics, lexical and structural. The overall task of Arabic Semantic Labeling was subdivided into 4 sub-tasks: Arabic word sense disambiguation (AWSD), English to Arabic WSD task (EAWSD), argument detection within the context of semantic role labeling, and argument semantic role classification.</p><p>Such a set of tasks would not have been feasible without the existence of several crucial resources: the Arabic Treebank (ATB) <ref type="bibr" target="#b7">(Maamouri et al., 2004)</ref>, the Arabic WordNet (AWN) <ref type="bibr" target="#b3">(Elkateb et al., 2006)</ref>, and the Pilot Arabic Propbank (APB). <ref type="bibr">2</ref> This paper is laid out as follows: Section 2 will describe some facts about the Arabic language; Section 3 will present the overall description of the tasks; Section 4 describes the word sense disambiguation task; Section 5 describes the semantic role labeling task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Arabic Language</head><p>In the context of our tasks, we only deal with MSA. <ref type="bibr">3</ref> Arabic is a Semitic language. It is known for its templatic morphology where words are made up of roots and affixes. Clitics agglutinate to words. For instance, the surface word</p><formula xml:id="formula_0">¢ ¡ ¤ £ ¥ § ¦ ©</formula><p>wbHsnAthm 4 'and by their virtues[fem.]', can be split into the conjunction w 'and', preposition b 'by', the stem HsnAt 'virtues [fem.]', and possessive pronoun hm 'their'. Arabic is different from English from both the morphological and syntactic perspectives which make it a challenging language to the existing NLP technology that is too tailored to the English language.</p><p>From the morphological standpoint, Arabic exhibits rich morphology. Similar to English, Arabic verbs are marked explicitly for tense, voice and person, however in addition, Arabic marks verbs with mood (subjunctive, indicative and jussive) information. For nominals (nouns, adjectives, proper names), Arabic marks case (accusative, genitive and nominative), number, gender and definiteness features. Depending on the genre of the text at hand, not all of those features are explicitly marked on naturally occurring text.</p><p>Arabic writing is known for being underspecified for short vowels. Some of the case, mood and voice features are marked only using short vowels. Hence, if the genre of the text were religious such as the Quran or the Bible, or pedagogical such as children's books in Arabic, it would be fully specified for all the short vowels to enhance readability and disambiguation.</p><p>From the syntactic standpoint, Arabic, different from English, is considered a pro-drop language, where the subject of a verb may be implicitly encoded in the verb morphology. Hence, we observe sentences such as</p><formula xml:id="formula_1">¦ £ ! £ "# % $ &amp; ( ' 0 ) 2 1 3 '</formula><p>Akl AlbrtqAl 'ate-[he] the-oranges', where the verb Akl encodes that the subject is a 3rd person masculine singular. This sentence is exactly equivalent to</p><formula xml:id="formula_2">¦ £ ! £ "# $ &amp; 4 ' 0 ) 1 3 ' 6 5 8 7</formula><p>hw Akl Al-brtqAl 'he ate the-oranges'. In the Arabic Treebank (ATB), we observe that 30% of all sentences are pro-dropped for subject.</p><p>Also Arabic is different from English in that it exhibits a larger degree of free word order. For example, Arabic allows for subject-verb-object (SVO) and verb-subject-object (VSO) argument orders, as well as, OSV and OVS. In the ATB, we observe an equal distribution of both VSO and SVO orders each equally 35% of the time. Akl AlrjAl AlbrtqAl 'ate the-men the-oranges'.</p><p>Arabic exhibits more complex noun phrases than English mainly to express possession. These constructions are known as idafa constructions. In these complex structures an indefinite noun is followed by a definite noun. For example,</p><formula xml:id="formula_3">£ C E D F &amp; ( ' G ) A ( H</formula><p>rjl Albyt 'man the-house' meaning 'man of the house'. Accordingly, MSA does not have a special prepositional use to express possession in a manner similar to English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overall Tasks Description</head><p>Given the differences between English and Arabic, we anticipate that the process of automatically tagging text with semantic information might take more than just applying an English semantic labeler to Arabic. With this in mind, we decided to design a set of tasks that target different types of semantic annotations. We designed an all-words style word sense disambiguation (WSD) task for all the nouns and verbs in Arabic running text. Moreover, we designed another task where the participants are asked to detect and classify semantic role labels (SRL) for a large portion of newswire text. The WSD texts are chosen from the same set used for SRL. All the data is from the Arabic Treebank III ver. 2 (ATB). The ATB consists of MSA newswire data from Annhar newspaper, from the months of July through November of 2002. The ATB is fully annotated with morphological information as well syntactic structural information. The released data for the subtasks is unvowelized and romanized using the Buckwalter transliteration scheme. The part of speech (POS) tag set used in the released data for both the WSD and the SRL sub-tasks is the reduced tag set that is officially released with the ATB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task: WSD</head><p>In the context of this task, word sense disambiguation is the process by which words in context are tagged with their specific meaning definitions from a predefined lexical resource such as a dictionary or taxonomy. The NLP field has gone through a very long tradition of algorithms designed for solving this problem <ref type="bibr" target="#b6">(Ide and Veronis, 1998)</ref>. Most of the systems however target English since it is the language with most resources. In fact a big push forward dawned on English WSD with the wide release of significant resources such as WordNet.</p><p>Arabic poses some interesting challenges for WSD since it has an inherent complexity in its writing system. As mentioned earlier, written MSA is underspecified for short vowels and diacritics. These short vowels and diacritics convey both lexical and inflectional information. For example,</p><formula xml:id="formula_4">£ F@1</formula><p>klyp could mean three different things, 'all', 'kidney' and 'college'. Due to the undiacritized, unvowelized writing system, the three meanings are conflated. If diacritics are explicitly present, we would observe a better distinction made between</p><formula xml:id="formula_5">£ ¢ ¡ F@1</formula><p>kly∼p 'all' or 'college', and</p><formula xml:id="formula_6">£ F@1</formula><p>klyp 'kidney'. Hence, full diacritization may be viewed as a level of WSD. But crucially, naturally occurring Arabic text conflates more words due to the writing system.</p><p>To date, very little work has been published on Arabic WSD. This is mainly attributed to the lack in lexical resources for the Arabic language. But this picture is about to change with the new release of an Arabic WordNet (AWN).</p><p>Arabic WordNet Arabic WordNet (AWN) is a lexical resource for modern standard Arabic. AWN is based on the design and contents of Princeton WordNet (PWN) <ref type="bibr" target="#b4">(Fellbaum, 1998)</ref> and can be mapped onto PWN as well as a number of other wordnets, enabling translation on the lexical level to and from dozens of other languages.</p><p>AWN focuses on the the Common Base Concepts <ref type="bibr" target="#b10">(Tufis, 2004)</ref>, as well as extensions specific to Arabic and Named Entities. The Base Concepts are translated manually by authors 2 and 3 into Arabic. Encoding is bi-directional: Arabic concepts for all senses are determined in PWN and encoded in AWN; when a new Arabic verb is added, extensions are made from verbal entries, including verbal derivations, nominalizations, verbal nouns, etc.</p><p>To date, the database comprises over 8,000 synsets with over 15,000 words; about 1,400 synsets refer to Named Entities.</p><p>Task design With the release of the AWN, we set out to design a sub-task on Arabic WSD. The task had only trial and test data released in an XML compliant format marking instance, sentence and document boundaries. The relevant words are marked with their gross part of speech and underlying lemma and English gloss information.</p><p>The participants are required to annotate the chosen instances with the synset information from AWN. Many of the entries in AWN are directly mapped to PWN 2.0 via the byte offset for the synsets.</p><p>The two subtasks data comprised 1176 verb and noun instances: 256 verbs and 920 nouns. The annotators were only able to annotate 888 instances for both English and Arabic due to gaps in the AWN. Hence, the final data set comprised 677 nouns and 211 verbs. The gold standard data is annotated authors 2 and 3 of Arabic (the annotators who created the AWN). There was always an overlap in the data of around 300 instances. In the English Arabic WSD task, participants are provided with a specific English word in translation to an Arabic instance. They are also given the full English translation of the Arabic document. Unfortunately, there were no participants in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Task: Semantic Role Labeling (SRL)</head><p>Shallow approaches to text processing have been garnering a lot of attention recently. Specifically, shallow approaches to semantic processing are making large strides in the direction of efficiently and effectively deriving tacit semantic information from text. Semantic Role Labeling (SRL) is one such approach. With the advent of faster and powerful computers, more effective machine learning algorithms, and importantly, large data resources annotated with relevant levels of semantic information FrameNet <ref type="bibr" target="#b0">(Baker et al., 1998)</ref> and ProbBank corpora <ref type="bibr" target="#b8">(Palmer et al., 2005)</ref>, we are seeing a surge in efficient approaches to SRL <ref type="bibr" target="#b2">(Carreras and Màrquez, 2005)</ref>. SRL is the process by which predicates and their arguments are identified and their roles defined in a sentence.</p><p>To date, most of the reported SRL systems are for English. We do see some headway for other languages such as German and Chinese. The systems for the other languages follow the successful models devised for English, <ref type="bibr" target="#b5">(Gildea and Jurafsky, 2002;</ref><ref type="bibr" target="#b11">Xue and Palmer, 2004;</ref><ref type="bibr" target="#b9">Pradhan et al., 2003)</ref>. However, no SRL systems exist for Arabic.</p><p>Challenges of Arabic for SRL Given the deep difference between such languages, this method may not be straightforward.</p><p>To clarify this point, let us consider Figure <ref type="figure" target="#fig_0">1</ref>.</p><p>It illustrates a sample Arabic syntactic tree with the relevant part of speech tags and arguments defined.</p><p>The sentence is As exemplified earlier in Section 2, there are several crucial structural differences between English and Arabic. These differences can make the SRL task much harder to resolve than it is for English.</p><formula xml:id="formula_7"># § $ £ ¡ £ ¢ ¦¤ ' £ ¦ ¥ # ! &amp; ( ' £ § ¦£ " ' © £ F © " ¦¡ ¥ £ @ ¤ # ¡ £ £ ' ¤ ! ' # " # $ % &amp;¤ m$rwE</formula><p>Pro-drop could cause a problem for Arabic SRL systems that do not annotate traces.</p><p>Passivization is marked with a short vowel that hardly ever appears on unvocalized text. '@"</p><p>'the man reached-told the boy', Alrjl 'the man' could be an ARG0 for the VSO, or ARG1 for an VOS. Or for the following structure</p><formula xml:id="formula_8">) A # &amp; 4 ' '@" &amp;5 8 &amp; ( '</formula><p>Alwld blg Alrjl 'the boy reached the man', Alwld 'the boy' could be an ARG0 if it were a SVO sentence, or could be an ARG1 if it were an OVS sentence.</p><p>Idafa constructions may cause problems for argument boundary detection systems unless the underlying parser is sensitive to these constructions. For example, in the sentence illustrated in Figure <ref type="figure" target="#fig_0">1</ref>, the NP m$rwE AlAmm AlmtHdp 'the United Nations' project' is an idafa construction, so the scope of the NP has to cover all three words and then assign the ARG boundary to the correct NP.</p><p>Arabic Propbank Taking into consideration the possible challenges, an Arabic Propbank (APB) was created. APB comprises 200K words from ATB 3 version 2 annotating the proposition for each verb. The chosen verbs occur at least 12 times in the corpus covering 80% of the data. It provides semantic role annotations for 454 verbal predicates. The predicates are fully specified for diacritization hence no two lexically variant verbs are conflated. APB defines an overall 26 argument types. We have excluded here 4 of these argument types, three of which were absent from the training data and ARGM-TER which marks ATB errors. Once the verbs are chosen, the framers come up with frames based on a combination of syntactic and semantic behaviors expressed by the verb and its core arguments. The framers use their native intuition, look at a sample occurrence in the data, and use external sources to aid them in the frame-creating process. If the verb has more than one sense, it is divided into more than one frame depending on how it relates to its arguments. The arguments themselves are chosen based not only on what is deemed semantically necessary, but on frequency of usage, as well. Figure <ref type="figure" target="#fig_0">1</ref> shows an example predicate and its arguments annotated with semantic role labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Design</head><p>The Arabic SRL task is split into an argument boundary detection task and an argument classification task. We released data for the 95 most frequent verbs. An important characteristic of the data-set is the use of unvowelized Arabic in the Buckwalter transliteration scheme. We released the gold standard parses in the ATB as a source for syntactic parses for the data. The data is annotated with the reduced Bies POS tag set (in the LDC ATB distribution). The data comprises a development set of 886 sentences, a test set of 902 sentences, and a training set of 8,402 sentences. The development set comprises 1710 argument instances, the test data comprises 1657 argument instances, and training data comprises 21,194 argument instances. For evaluation we use the official CoNLL evaluator <ref type="bibr" target="#b2">(Carreras and Màrquez, 2005)</ref>. The evaluation software produces accuracy, precision, recall and F β=1 metrics.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Subtask : Argument Boundary Detection</head><p>In this task, the participating systems are expected to detect the boundaries of arguments associated with designated predicates. The systems are expected to identify the arguments with the correct level of scoping. For instance, in our running example sentence, the argument boundaries for the verb¨ Only one system (CUNIT) participated in the subtask. CUNIT is an SVM based discriminative classification system based on different degrees polynomial kernels. The best CUNIT system (with degree 2 kernel) achieves an F β=1 argument boundary detection score of 93.68% on the development data and 94.06% on the test data. We note that the results on the test data are higher than on the development data indicating that the test data is relatively easier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Subtask: Argument Classification</head><p>In this task, the participating systems are expected to identify the class of the arguments detected in the previous step of argument boundary detection. In this sub task we have 22 argument types. Table <ref type="table" target="#tab_5">1</ref> illustrates the different argument types and their distributions between the dev, train and test sets.</p><p>The most frequent arguments are ARG0, ARG1, ARG2 and ARGM-TMP. This is similar to what we see in the English Propbank. We note the additional ARG types with the extension STR. These are for stranded arguments. The tag STR is used when one constituent cannot be selected and an argument has two or more concatenated constituents. An example of this type of ARG is¨D</p><formula xml:id="formula_9">$ F@1 # " F E F ¡ H G H 5 " F 5 F " E F ¡ # £ ! £ ¦ I '</formula><p>{stqr fy nyw ywrk fy brwklyn 'he settled in New York, in Brooklyn'. In this case, fy nyw ywrk 'in New York' is labeled ARG1 and fy brwklyn 'in Brooklyn' is labeled ARG1-STR.</p><p>Only one system (CUNIT) participated in the SRL subtask. CUNIT is an SVM based discriminative classification system based on different degrees polynomial kernels. The best CUNIT system (with degree 2 kernel) achieves an overall F β=1 score for all arguments classification of 77.84% on the development data and 81.43% on the test data. It is worth noting that these results are run with the automatic argument boundary detection as an initial step. In both the test and the development results, the precision is significantly higher than the recall. For the development set precision is 81.31% and the recall  is 74.67%. For the test set, the precision is 84.71% and the recall is 78.39%. We note that, similar to the boundary detection sub-task, the results on the test data are significantly higher than on the development data which suggests that the test data is relatively easier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we presented a description of Task 18 on Arabic Semantic labeling. Our goal was to rally interest in Arabic Semantic labeling. On the word sense disambiguation front, we have successfully created an all-words sense annotated set of Arabic nouns and verbs in running text. The set is annotated with both Arabic WordNet synset labels and their corresponding English WordNet 2.0 synset labels. Unfortunately, no systems participated in the WSD sub-tasks, however, we have prepared the data for future endeavors and hopefully this will motivate researchers in NLP to start experimenting with Arabic WSD.</p><p>On the task of Semantic Role Labeling, we have created a test, training and development set that has been successfully validated through being employed for building the first Arabic SRL system. Hopefully, this data will help propel research in Arabic SRL. It is also worth noting that we currently have effectively created a data set that is annotated for word senses, lexical information such as full morphological specifications, syntactic and semantic parses as well as English glosses and translations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example SRL annotated tree</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>' are illustrated as follows: [m$rwE AlAmm AlmtHdp] ARG [frD] Lemma:f aroD [mhlp nhA}yp] ARG [l AtAHp Al-frSp AmAm qbrS] ARG . The three relevant arguments are m$rwE AlAmm AlmtHdp 'the United Nations Project', mhlp nhA}yp 'final grace-period', and l AtAHp AlfrSp AmAm qbrS 'as an opportunity for Cyprus'.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 :</head><label>1</label><figDesc>Distribution of training, development and test instances on the different role types.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Funded by DARPA subcontract to BBN Inc. to University of Colorado, LDC-UPenn and Columbia University.3 In this paper we use MSA and Arabic interchangeably.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We use the Buckwalter transliteration scheme to show romanized Arabic<ref type="bibr" target="#b1">(Buckwalter, 2002)</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The berkeley FrameNet project</title>
		<author>
			<persName><forename type="first">Collin</forename><forename type="middle">F</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Fillmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">B</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING-ACL &apos;98: Proceedings of the Conference</title>
				<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="86" to="90" />
		</imprint>
		<respStmt>
			<orgName>held at the University of Montréal</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Buckwalter Arabic Morphological Analyzer Version 1.0. Linguistic Data Consortium</title>
		<author>
			<persName><forename type="first">Tim</forename><surname>Buckwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">LDC Catalog No.</title>
		<imprint>
			<biblScope unit="page" from="C2002L" to="2049" />
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2005 shared task: Semantic role labeling</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2005</title>
				<meeting>CoNLL-2005<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The arabic wordnet project</title>
		<author>
			<persName><forename type="first">S</forename><surname>Elkateb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Vossen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pease</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bertran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Lexical Resources in the European Community</title>
				<meeting>the Conference on Lexical Resources in the European Community<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<ptr target="http://www.cogsci.princeton.edu/˜wn" />
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automatic labeling of semantic roles</title>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="288" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Word sense disambiguation: State of the art</title>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Veronis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics, number 24</title>
				<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The penn arabic treebank : Building a largescale annota ted arabic corpus</title>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Maamouri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Buckwalter</surname></persName>
		</author>
		<author>
			<persName><surname>Wig Dan Mekki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The proposition bank: A corpus anotated with semantic roles</title>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Computational Linguistics Journal, number</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Semantic role parsing: Adding semantic structure to unstructured text</title>
		<author>
			<persName><forename type="first">Kadri</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><surname>Hacioglu</surname></persName>
		</author>
		<author>
			<persName><surname>Ward</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>James</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICDM-2003</title>
				<meeting>ICDM-2003<address><addrLine>Melbourne, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Martin, and Daniel Jurafsky</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The balkanet project</title>
		<author>
			<persName><forename type="first">Dan</forename><surname>Tufis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Special Issue of The Romanian Journal of Information Science and Technology</title>
				<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Calibrating features for semantic role labeling</title>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP 2004</title>
				<editor>
			<persName><forename type="first">Dekang</forename><surname>Lin</surname></persName>
			<persName><forename type="first">Dekai</forename><surname>Wu</surname></persName>
		</editor>
		<meeting>EMNLP 2004<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="88" to="94" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
