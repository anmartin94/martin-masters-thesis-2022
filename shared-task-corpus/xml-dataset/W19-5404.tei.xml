<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Findings of the WMT 2019 Shared Task on Parallel Corpus Filtering for Low-Resource Conditions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
							<email>fguzman@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
							<email>vishrav@fb.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Findings of the WMT 2019 Shared Task on Parallel Corpus Filtering for Low-Resource Conditions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Following the WMT 2018 Shared Task on Parallel Corpus Filtering (Koehn et al., 2018), we posed the challenge of assigning sentencelevel quality scores for very noisy corpora of sentence pairs crawled from the web, with the goal of sub-selecting 2% and 10% of the highest-quality data to be used to train machine translation systems. This year, the task tackled the low resource condition of Nepali-English and Sinhala-English. Eleven participants from companies, national research labs, and universities participated in this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Machine Translation (MT) has experienced significant advances in recent years thanks to improvements in modeling, and in particular neural models <ref type="bibr" target="#b5">(Bahdanau et al., 2015;</ref><ref type="bibr" target="#b16">Gehring et al., 2016;</ref><ref type="bibr" target="#b51">Vaswani et al., 2017)</ref>. Unfortunately, today's neural machine translation models, perform poorly on low-resource language pairs, for which clean, parallel training data is high-quality training data is lacking, by definition <ref type="bibr" target="#b26">(Koehn and Knowles, 2017)</ref>.</p><p>Improving performance on low resource language pairs is very impactful considering that these languages are spoken by a large fraction of the world population. This is a particular challenge for industrial machine translation systems that need to support hundreds of languages in order to provide adequate services to their multilingual user base.</p><p>In face of the scarcity of clean parallel data, learning to translate from any multilingual noisy data such as web-crawls (e.g. from Wikipedia, Paracrawl 1 ) is an important option.</p><p>1 http://www.paracrawl.eu/ Recently, there is an increased interest in the filtering of noisy parallel corpora to increase the amount of data that can be used to train translation systems . While the state-of-the-art methods that use NMT models have proven effective in mining parallel sentences <ref type="bibr" target="#b21">(Junczys-Dowmunt, 2018)</ref> for high-resource languages, their effectiveness has not been tested in low-resource languages. The implications of low availability of training data for parallel-scoring methods is not known yet.</p><p>The Shared Task on Parallel Corpus Filtering at the Conference for Machine Translation (WMT 2019) was organized to promote research to learning from noisy data more viable for low-resource languages. Compared to last year's edition , we only provide about 50-60 million word noisy parallel data, as opposed to 1 billion words. We also provide only a few million words of clean parallel data of varying quality, instead of over 100 million words of high-quality parallel data. Participants developed methods to filter web-crawled Nepali-English and Sinhala-English parallel corpora by assigning a quality score for each sentence pair. These scores are used to filter the web crawled corpora down to fixed sizes (1 million and 5 million English words), trained statistical and neural machine translation systems on these subsets, and measured their quality with the BLEU score on a test set of multi-domain Wikipedia content . This paper gives an overview of the task, presents the results for the participating systems and provides analysis on additional subset sizes and the average sentence length of sub-selected data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Although the idea of crawling the web indiscriminately for parallel data goes back to the 20th century <ref type="bibr" target="#b42">(Resnik, 1999)</ref>, work in the academic community on extraction of parallel corpora from the web has so far mostly focused on large stashes of multilingual content in homogeneous form, such as the Canadian Hansards, Europarl <ref type="bibr" target="#b23">(Koehn, 2005)</ref>, the United Nations <ref type="bibr" target="#b40">(Rafalovitch and Dale, 2009;</ref><ref type="bibr">Ziemski et al., 2015)</ref>, or European Patents <ref type="bibr" target="#b47">(Täger, 2011)</ref>. A nice collection of the products of these efforts is the OPUS web site 2 <ref type="bibr" target="#b49">(Tiedemann, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Parallel Corpus Acquisition</head><p>The Paracrawl project is currently engaged in a large-scale effort to crawl text from the web. That work is funded by the European Union via the Connecting Europe Facility. The Paracrawl infrastructure was used to generate the noisy parallel data for this shared task. In previous years, as part of the Paracrawl effort, a shared task on document alignment <ref type="bibr" target="#b11">(Buck and Koehn, 2016</ref>) and a shared task on parallel corpus filtering was organized .</p><p>Acquiring parallel corpora from the web typically goes through the stages of identifying web sites with parallel text, downloading the pages of the web site, aligning document pairs, and aligning sentence pairs. A final stage of the processing pipeline filters out non parallel sentence pairs. These exist either because the original web site did not have any actual parallel data (garbage in, garbage out), only partial parallel data, or due to failures of earlier processing steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Filtering Noisy Parallel Corpora</head><p>In 2016, a shared task on sentence pair filtering 3 was organized, albeit in the context of cleaning translation memories which tend to be cleaner than the data at the end of a pipeline that starts with web crawls.</p><p>There is a robust body of work on filtering out noise in parallel data. For example <ref type="bibr" target="#b48">: Taghipour et al. (2011)</ref> use an outlier detection algorithm to filter a parallel corpus; <ref type="bibr" target="#b56">Xu and Koehn (2017)</ref> generate synthetic noisy data (inadequate and nonfluent translations) and use this data to train a clas-sifier to identify good sentence pairs from a noisy corpus; and <ref type="bibr" target="#b14">Cui et al. (2013)</ref> use a graph-based random walk algorithm and extract phrase pair scores to weight the phrase translation probabilities to bias towards more trustworthy ones.</p><p>Most of this work was done in the context of statistical machine translation, but more recent work targets neural models. <ref type="bibr" target="#b12">Carpuat et al. (2017)</ref> focus on identifying semantic differences in translation pairs using cross-lingual textual entailment and additional length-based features, and demonstrate that removing such sentences improves neural machine translation performance.</p><p>As <ref type="bibr" target="#b41">Rarrick et al. (2011)</ref> point out, one type of noise in parallel corpora extracted from the web are translations that have been created by machine translation. <ref type="bibr" target="#b53">Venugopal et al. (2011)</ref> propose a method to watermark the output of machine translation systems to aid this distinction, with a negligible loss of quality. <ref type="bibr" target="#b0">Antonova and Misyurev (2011)</ref> report that rule-based machine translation output can be detected due to certain word choices, and statistical machine translation output can be detected due to lack of reordering. It is notable that none of the participants in our shared task have tried to detect machine translation.</p><p>There is a rich literature on data selection which aims at sub-sampling parallel data relevant for a task-specific machine translation system <ref type="bibr" target="#b4">(Axelrod et al., 2011)</ref>. <ref type="bibr" target="#b55">van der Wees et al. (2017)</ref> find that the existing data selection methods developed for statistical machine translation are less effective for neural machine translation. This is different from our goals of handling noise since those methods tend to discard perfectly fine sentence pairs that are just not relevant for the targeted domain. Our task is focused on data quality that is relevant for all domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Impact of Noise on Neural Machine Translation</head><p>Belinkov and Bisk (2017) investigate the impact of noise on neural machine translation. They focus on creating systems that can translate the kinds of orthographic errors (typos, misspellings, etc.) that humans can comprehend. In contrast,  examine noisy training data and focus on types of noise occurring in web-crawled corpora. They carried out a study about how noise that occurs in crawled parallel text impacts statistical and neural machine translation.</p><p>Neural machine translation model training may combine data selection and model training, taking advantage of the increasing quality of the model to better detect noisy data or to increasingly focus on cleaner parts of the data <ref type="bibr" target="#b54">(Wang et al., 2018;</ref><ref type="bibr" target="#b27">Kumar et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Sentence Embeddings</head><p>Bouamor and Sajjad (2018) learned sentence embeddings for the source and target languages and selected the nearest translation from a list of candidate sentences for a given source sentence using a classifier. <ref type="bibr" target="#b18">Guo et al. (2018)</ref> leveraged hard negatives to correctly identify translation pairs. <ref type="bibr" target="#b1">Artetxe and Schwenk (2018)</ref> use multilingual sentence embeddings to compute cosine similarity between the source and the target sentence. They further normalize the score by the average cosine similarity of the nearest neighbors for the given sentence pair. Their method has shown promising results in filtering WMT Paracrawl data and has achieved state-of-the-art performance on the BUCC corpus mining task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Findings of the 2018 Shared Task</head><p>The WMT 2018 Shared Task on Parallel Corpus Filtering  attracted 18 submissions in a high resource setup. Not surprisingly, due to the large number of submissions, many different approaches were explored for this task. However, most participants used a system using three components: (1) pre-filtering rules, (2) scoring functions for sentence pairs, and (3) a classifier that learned weights for feature functions.</p><p>Pre-filtering rules. Some of the training data can be discarded based on simple deterministic filtering rules. These may include rules may consider sentence length, number of real words vs. other tokens, matching names, numbers, dates, email addresses, or URLs, too similar sentences (copied content), and language identification <ref type="bibr" target="#b38">(Pinnis, 2018;</ref><ref type="bibr" target="#b32">Lu et al., 2018;</ref><ref type="bibr" target="#b2">Ash et al., 2018)</ref>.</p><p>Scoring functions. Sentence pairs that pass the pre-filtering stage are assessed with scoring functions which provide scores that hopefully correlate with quality of sentence pairs. Participants used a variety of such scoring functions, including language models, neural translation models and lexical translation probabilities, e.g., IBM Model 1 scores. <ref type="bibr" target="#b21">(Junczys-Dowmunt, 2018;</ref><ref type="bibr" target="#b43">Rossenbach et al., 2018;</ref>.</p><p>Learning weights for scoring functions. Given a large number of scoring functions, simply averaging their resulting scores may be inadequate. Learning weights to optimize machine translation system quality is computationally intractable due to the high cost of training these systems to evaluate different weight settings. A few participants used instead a classifier that learns how to distinguish between high-quality and low-quality sentence pairs. High-quality sentence pairs are selected from existing high-quality parallel corpora, while low-quality sentence pairs are either synthesized by scrambling high-quality sentence pairs or by using the raw crawled data <ref type="bibr" target="#b44">(Sánchez-Cartagena et al., 2018)</ref>.</p><p>Use of embeddings. While the participant's methods were dominated by non-neural components, sometimes using neural machine translation outputs and scores, some participants used word and sentence embeddings. Given crosslingual word embeddings, sentence match scores based on the difference between the average of the word embeddings <ref type="bibr" target="#b34">(Paetzold, 2018)</ref>, or, for each word in the sentence, the closest match in the corresponding sentence <ref type="bibr" target="#b20">(Hangya and Fraser, 2018)</ref>. Matching of word embeddings may also be done monolingually, after machine translating the foreign sentence into English . Cross-lingual word embeddings were obtained using uses monolingual word embedding spaces which were aligned with an unsupervised method, or using pre-trained cross-lingual word embeddings.  used monolingual sentence embedding spaces to discount outliers. <ref type="bibr" target="#b37">Pham et al. (2018)</ref> use a neural model that takes a sentence pair and predicts a matching score.</p><p>Some participants made a distinction between unsupervised methods that did not use existing parallel corpora to train parts of the system, and supervise methods that did. Unsupervised methods have the advantage that they can be readily deployed for language pairs for which no seed parallel corpora exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Low-Resource Corpus Filtering Task</head><p>The shared task tackled the problem of filtering parallel corpora. Given a noisy parallel corpus (crawled from the web), participants developed methods to filter it to a smaller size of high quality sentence pairs. Specifically, we provided a very noisy 50-60 million word (English token count) Nepali-English and Sinhala-English corpora crawled from the web using the Paracrawl processing pipeline (see Section 4.4 for details). We asked participants to generate sentence-level quality scores that allow selecting subsets of sentence pairs that amount to (a) 1 million words, and (b) 5 million words, counted on the English side. These values were chosen as an approximation to the conditions on the WMT 2018 task. The resulting subsets were scored by building a statistical phrase-based machine translation system <ref type="bibr" target="#b24">(Koehn et al., 2007)</ref> and a neural machine translation system  trained on this data, and then measuring their BLEU score on the flores Wikipedia test sets .</p><p>Participants in the shared task submitted a file with quality scores, one per line, corresponding to the sentence pairs. Scores are only required to have the property that higher scores indicate better quality. The scores were uploaded to a Google Drive folder which remains publicly accessible. <ref type="bibr">4</ref> For development purposes, we released configuration files and scripts that mirror the official testing procedure with a development test set. The development pack consists of:</p><p>• A script to subsample corpora based on quality scores. The web site for the shared task 5 provided detailed instructions on how to use these tools to replicate the official testing environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Data</head><p>We provided three types of data for this shared task: (1) clean parallel and monolingual data, including related language data in Hindi, to train models that aid with the filtering task, ( <ref type="formula">2</ref>  parallel data crawled from the web which participants have to score for filtering, and (3) development and test sets that are used to evaluate translation systems trained on filtered data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Clean Parallel Data</head><p>The main distinction between this year's version of the parallel corpus filtering task and last year's version is the amount of provided clean parallel data. For both Nepali-English and Sinhala-English, only few parallel corpora are available and these are of questionable relevance due to their peculiar domains.</p><p>For Nepali (see Table <ref type="table" target="#tab_1">1</ref> for detailed statistics), the largest data sets are the Bible which we provided with two English translations and the GNOME/KDE/Ubuntu localization data collected by OPUS 6 <ref type="bibr" target="#b49">(Tiedemann, 2012)</ref>. The type of text found in these corpora are quite different from language found on the Internet. The data sets with more conventional language, a partial translation of the Penn Tree Bank by the Language Resource Association (GSK) of Japan and International Development Research Center (IDRC) of Canada, through PAN Localization project 7 and the citizen journalist news sites Global Voices 8 , are much smaller (less than 100,000 words each). We also provide a Nepali-English bilingual dictionary with 9,916 entries <ref type="bibr" target="#b36">(Pavlick et al., 2014)</ref>.</p><p>For Sinhala (see Table <ref type="table" target="#tab_3">2</ref> for detailed statistics), we only provide two data sources: a fairly large corpus of volunteer translation of subtitles and the GNOME/KDE/Ubuntu localization data collected by OPUS. The Open Subtitles corpus is of mixed quality and most of the language is casual.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Clean Monolingual Data</head><p>Monolingual data is always available in much larger quantities, and we provided data from two sources: Wikipedia and CommonCrawl. Both contain language that is similar to what is expected in the noisy web data to be filtered.</p><p>We filtered the data to eliminate overlap with the development and test sets. See Table <ref type="table" target="#tab_4">3</ref> for detailed statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Related Language Data</head><p>Nepali uses the same Devanagari script as Hindi and the languages are closely related. Neural machine translation models for low-resource language pairs have particularly benefited from training data in other language pairs, so parallel Hindi-English data and monolingual Hindi data may be beneficial to train models for our shared task.</p><p>As shown in Table <ref type="table" target="#tab_6">4</ref>, we provide a relatively large 20 million word parallel corpus and almost 2 billion words of monolingual Hindi. This data was created from a variety of public domain sources and corpora developed at the Center for Indian Language Technology, IIT Bombay <ref type="bibr" target="#b28">(Kunchukuttan et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Noisy Parallel Data</head><p>The noisy parallel corpora from Paracrawl are the outcome of a processing pipeline that aimed at high recall at the cost of precision, so they are very noisy. They exhibit noise of all kinds: wrong language in source and target, sentence pairs that are   not translations of each other, bad language (incoherent mix of words and non-words), incomplete or bad translations, etc.</p><p>We used the processing pipeline of the Paracrawl project to create the data, using the clean parallel data to train underlying models such as the dictionary used by Hunalign <ref type="bibr" target="#b50">(Varga et al., 2007)</ref> and a statistical translation model used by the document aligner. One modification was necessary to run the pipeline for Nepali due to the end-of-sentence symbol of the script that was previously not recognized by the sentence splitter.</p><p>The provided parallel corpus is the raw output of the crawling pipeline, with sentence pairs deduplicated but otherwise no further filtering performed. See Table <ref type="table" target="#tab_7">5</ref> for statistics of the corpus and Table <ref type="table" target="#tab_9">6</ref> for some example sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Development and Test Sets</head><p>For test and development purposes, we use the flores Wikipedia data-sets for Nepali-English and Sinhala-English . These sets are multi-domain, that is they were sampled from Wikipedia documents with a diverse set of topics. In Table <ref type="table" target="#tab_10">7</ref> we present the statistics of these sets.</p><p>The official scoring of machine translation systems generated from the subsampled data sources is done on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation Protocol</head><p>The testing setup mirrors the development environment that we provided to the participants.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Participants</head><p>We received submissions from 11 different organizations. See Table <ref type="table" target="#tab_12">8</ref> for the complete list of participants. The participant's organizations are quite diverse, with 4 participants from the United States, 2 participants from Spain, and 1 participant each from Canada, Sweden, India, and Finland. 5 of the participants are universities, 4 are companies, and 2 are national research organizations. There was little overlap between this year's shared task and last year's high-resource shared task. Only AFRL, NRC, and Webinterpret participated also last year. Each participant submitted up to 4 different sets of scores, typically a primary and contrastive submission, resulting in a total of 21 different submissions for Nepali and 23 different submissions for Sinhala that we scored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Methods used by Participants</head><p>Almost all submissions used basic filtering rules as a first filtering step. These rules typically involve language identification and length consid-erations to remove too long or length-wise mismatched sentence pairs. Some also remove sentence pairs where a specific number occurred on one side but not the other. For some submissions this removed over 80% of the data <ref type="bibr">(Kurfalı and Ostling, 2019;</ref><ref type="bibr" target="#b46">Soares and Costa-jussà, 2019)</ref>.</p><p>A novel method that was central to the bestperforming submission was the use of crosslingual sentence embeddings that were directly trained from parallel sentence pairs . Other submissions used monolingual word embeddings. These were first trained monolingually for each language from monolingual data. The resulting embedding spaces were mapped either in an unsupervised fashion <ref type="bibr" target="#b46">(Soares and Costa-jussà, 2019)</ref> or based on a dictionary learned from the parallel data <ref type="bibr">(Kurfalı andÖstling, 2019)</ref>. Bernier-Colborne and Lo (2019) use both monolingually trained word embeddings aligned in an unsupervised fashion and bilingually trained word embeddings.</p><p>Another approach is to first train a translation  system on the clean data, then use it to translate the non-English side into English and use monolingual matching methods to compare it against the English side of the parallel corpus. Different matching metrics were used: METEOR <ref type="bibr" target="#b15">(Erdmann and Gwinnup, 2019)</ref>, Levenshtein distance <ref type="bibr" target="#b45">(Sen et al., 2019)</ref>, or BLEU <ref type="bibr" target="#b35">(Parcheta et al., 2019)</ref>, Several submissions considered vocabulary coverage in their methods, preferring to add sentence pairs to the limited set that increase the number of words and n-grams covered <ref type="bibr" target="#b15">(Erdmann and Gwinnup, 2019;</ref><ref type="bibr" target="#b7">Bernier-Colborne and Lo, 2019;</ref><ref type="bibr" target="#b17">González-Rubio, 2019)</ref>.</p><p>One of the best-performing methods under last year's high resource setting was dual conditional cross-entropy, i.e. building neural machine translation models on the clean data and considering the translation scores from forced translation of the parallel corpus. One submission used this method , while others applied the same idea to monolingual language model scores <ref type="bibr" target="#b3">(Axelrod, 2019;</ref><ref type="bibr" target="#b35">Parcheta et al., 2019)</ref>.</p><p>Several other scoring functions were used, to name a few: cross-lingual language models (Bernier-Colborne and Lo, 2019), monolingual language models <ref type="bibr" target="#b52">(Vázquez et al., 2019)</ref>, IBM Model 1 word translation scores <ref type="bibr" target="#b17">(González-Rubio, 2019)</ref>, and the existing off-the-shelf tools like Zipporah and Bicleaner . Some submissions combined multiple scoring functions with ensemble methods which may be optimize to distinguish between clean parallel data and synthetic noise data <ref type="bibr" target="#b7">Bernier-Colborne and Lo, 2019;</ref><ref type="bibr" target="#b52">Vázquez et al., 2019)</ref>.   <ref type="bibr">Devanagari, or Sinhala)</ref>. This removes about 20% of the data which is then word aligned to obtain bilingual dictionaries. In addition to a word alignment score, the noisy training data is filtered with several scoring functions: language models, language identification, ratio of characters in the correct script, punctuation, number matching, and length mismatch.</p><p>Webinterpret González-Rubio ( <ref type="formula">2019</ref>) first apply filtering rules based on language identification and sentence length. Coverage ranking incrementally adds sentence pairs to increase vocabulary and n-gram coverage. Adequacy ranking considers IBM Model 1 word translation scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Subset Selection</head><p>We provided to the participants a file containing one sentence pair per line (see Section 4.4) each for the two languages. A submission to the shared task consists of a file with the same number of lines, with one score per line corresponding to the quality of the corresponding sentence pair.</p><p>To evaluate a submitted score file, we selected subsets of a predefined size, defined by the number of English words (1M or 5M).</p><p>Selecting a subset of sentence pairs is done by finding a threshold score, so that the sentence pairs that will be included in the subset have a quality score at and above this threshold. In some cases, a submission assigned this threshold score to a large number of sentence pairs. Including all of them would yield too large a subset, excluding them yields too small a subset. Hence, we randomly included some of the sentence pairs with the exact threshold score to get the desired size in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation System Training</head><p>Given a selected subset of a given size for a system submission, we built statistical (SMT) and neural machine translation (NMT) systems to evaluate the quality of the selected sentence pairs. SMT For statistical machine translation, we used Moses <ref type="bibr" target="#b24">(Koehn et al., 2007)</ref> with fairly basic settings, such as Good-Turing smoothing of phrase table probabilities, maximum phrase length --arch transformer --share-all-embeddings --encoder-layers 5 --decoder-layers 5 --encoder-embed-dim 512 --decoder-embed-dim 512 --encoder-ffn-embed-dim 2048 --decoder-ffn-embed-dim 2048 --encoder-attention-heads 2 --decoder-attention-heads 2 --encoder-normalize-before --decoder-normalize-before --dropout 0.4 --attention-dropout 0.2 --relu-dropout 0.2 --weight-decay 0.0001 --label-smoothing 0.2 --criterion label smoothed cross entropy --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0 --lr-scheduler inverse sqrt --warmup-update 4000 --warmup-init-lr 1e-7 --lr 1e-3 --min-lr 1e-9 --max-tokens 4000 --update-freq 4 --max-epoch 100 --save-interval 10 Figure <ref type="figure">1</ref>: The baseline flores model settings 9 for the NMT training with fairseq of 5, maximum sentence length of 80, lexicalized reordering (hier-mslr-bidirectional-fe), fastalign for word alignment with grow-diag-final-and symmetrization, tuning with batch-MIRA, no operation sequence model, 5-gram language model trained on the English side of the subset with no additional data, and decoder beam size of 5,000 hypotheses.</p><p>NMT For neural machine translation, we used fairseq  transformer model with the parameter settings shown in Figure <ref type="figure">1</ref>. Preprocessing was done with sentence piece for a 5000 subword vocabulary on tokenized text using the Moses tokenizer (but no truecasing was used). Decoding was done with beam size 5 and length normalization 1.2. Training a system for the 1 million, and 5 million subsets took about 3, and 13 hours, respectively, on a single GTX 1080ti GPU. Scores on the test sets were computed with Sacrebleu <ref type="bibr" target="#b39">(Post, 2018)</ref>. We report case-insensitive scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>In this section we present the final results of the shared task evaluation. We added an additional condition at 2 million English words, to better observe tendencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Core Results</head><p>The official results are reported in Table <ref type="table" target="#tab_1">9 (Nepali)  and Table 10 (</ref> <ref type="bibr">Sinhala)</ref>. The tables contains the BLEU scores for</p><p>• development test set and final test set • statistical and neural machine translation • 1, 2, and 5 million word subsets.</p><p>The official scoring is for the 1 million and 5 million word data settings on the final test set. In the table, we highlight cells for the best scores for each of these settings, as well as scores that are close to it. Results for the unofficial 2 million word baseline are shown without highlighting.</p><p>For both language pairs, the best scores are achieved for the 1 million word data condition for the neural machine translation model (6.9 for Nepali and 6.4 for Sinhala). This is not the case for all submissions. The better performance for neural systems than for statistical systems with this little data is contrary to earlier findings <ref type="bibr" target="#b26">(Koehn and Knowles, 2017)</ref>, indicating that recent progress, such as the Transformer model <ref type="bibr" target="#b51">(Vaswani et al., 2017)</ref>, have addressed this challenge to some degree. However, for some submissions, such as AFRL 50k, SMT scores are higher than NMT scores (4.0 vs. 2.7 for Nepali, 3.8 vs. 3.0 for Sinhala for AFRL 50k).</p><p>Scores between the submissions differ more for neural machine translation systems than for statistical machine translation systems. For instance, for the Nepali 1 million word data condition, the difference between the best and the second best participant's submission is 0.2 for SMT but 1.4 for NMT. For the Nepali 5 million word data condition, almost all systems have BLEU scores around 4 for SMT, but NMT scores range from 0.2 to 3.4. This confirms earlier findings (cite noise) that statistical machine translation is more robust towards noise. So better quality for neural machine translation under low resource conditions requires good noise filtering methods.</p><p>For statistical machine translation, the bigger and noisier 5 million subsets yield better BLEU   scores than the smaller and cleaner 1 million subsets, for almost all submissions. However, for neural machine translation the opposite is true. This is a pretty striking piece of evidence that the adage of more data is better data of the statistical world of yesteryears is no longer true in todays neural age. The best submission's NMT score drops from 6.9 to 2.5 BLEU for Nepali and from 6.4 to 4.0 BLEU for Sinhala between the 1 million and the 5 million conditions. More data may be quite harmful, if it is of lesser quality. Alternatively, more research is needed into making neural machine translation models robust to noise in training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Additional Subset Sizes</head><p>Since we were interested in the shape of the curve of how different corpus sizes impact machine translation performance, we selected additional subset sizes. Specifically, in addition to the 1, 2 and 5 million word corpora, we also selected subset 0.5, 0.7, 1.5, and 3 million words.</p><p>See Figure <ref type="figure" target="#fig_2">2</ref> for results for neural machine translation systems (also broken down by each individual test set) and Figure <ref type="figure" target="#fig_4">3</ref> for statistical machine translation systems. We only computed results for 7 systems due to the computational cost involved.</p><p>The additional data points refine the observation for the three original subset sizes. For neural machine translation, submissions have different optimal subset sizes, ranging from 0.7 million to 3 million words.</p><p>For Nepali, most of the submissions show peak translation quality with 1 million words, although Stockholm's submission peaks at 700,000, Sciling's and AFRL's submission at 3 million. For most submission translation quality deteriorates several BLEU points off their peak.</p><p>For Sinhala, the picture is similar. Most of the submission show peaks at 2 million words, indicating that there is more useful data for this data condition. Peaks range from 1 million for Stockholm's submission to 3 million for Sciling's submission. The curves are somewhat shallower than for Nepali.</p><p>The curves for statistical machine translation look very different. All submissions tend to improve with additional data, outperforming neural machine translation at 5 million, and showing no sign of stopping there. This demonstrates that sta-  tistical machine translation is more robust to noise. Compared to last year's high resource version of the shared task, the peak data selection sizes are smaller. Best translation quality is achieved with about 2-6% of the full set, compared to 10% or more for German-English. This is likely due to the fact that the raw data is noisier, but may be also attributed to the difficulty of devising good quality metrics with little evidence of good translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Average Sentence Length</head><p>Given the quality scores, subsets are selected by including the highest ranked sentence pairs until the total number of English words in these sentences reaches the specified size. So, if a quality scores prefers shorter sentences, more sentences are selected. It is not clear in general, all things being otherwise equal, if shorter or longer sentences are better for training machine translation systems.</p><p>What choices did the participants make in their quality scores? Table <ref type="table" target="#tab_1">11</ref> and Table <ref type="table" target="#tab_1">12</ref> show the number of sentences and the corresponding average number of words per sentence for the official subsets for all submissions.</p><p>The numbers show that the submissions have quite different preferences with regard to sentence length. Even among the best submissions for Nepali, to give two examples, the Facebook main submission in the 5 million data condition includes The charts plot BLEU scores against the size of the subselected corpus (in millions of English words). Different submissions have very different optima, ranging from 1 to 3 million words. The optimal subset size is lower for Nepali (mostly around 1 million) than for Sinhala (mostly around 2 million). Only the 7 best submissions are shown.  The charts plot BLEU scores against the size of the subselected corpus (in millions of English words). All submissions tend to improve with additional data, outperforming neural machine translation at 5 million. This demonstrates that statistical machine translation is more robust to noise.  sentences with an average number of 43.2 words per sentence, while AFRL's 50k submission averages at just 20.7. For other data conditions, differences are not that extreme but do spread out mainly in the range of under 20 to over 30 words per sentence. There is no clear pattern in the preference for shorter and longer sentence lengths for the 1 million and 5 million word subset -for most submissions these two numbers are quite similar. There are outliers, however, such as Facebook's Nepali submission (average length 27.5 vs. 43.2) and Webinterpret's Nepali submission (28.7 vs. 12.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Diversity of Submissions</head><p>The different submissions subselect different sentences, but how different are they?</p><p>Table <ref type="table" target="#tab_1">13</ref>-16 give detailed statistics about how many sentence pairs the subsets of any two submissions for the two languages and two data conditions have in common.</p><p>There is no clear trend. For Nepali, there is more overlap in the 1 million word data condition than the 5 million word data condition. For Sinhala, the opposite is the case. Among the bestperforming submissions, roughly half of the subselected sentence pairs are the same. But what submissions are similar may change drastically between the data conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We report on the findings of the WMT 2019 Shared Task on Parallel Corpus Filtering. Eleven participants used a variety of methods that gave quite different results, as measured by translation quality, optimal subset sizes, suitability for SMT and NMT, sentence length, etc. We hope that this task provides a benchmark for future research and improvements on this task.  There is much less overlap for this data condition, compared to the 1 million word subset. The NRC/Facebook overlap dropped to 32.9% (from 67.9%), NRC's submissions now have more in common with other submissions.</p><p>Table <ref type="table" target="#tab_1">16</ref>: Overlap for Sinhala, 5 million word data condition. For each submission, a row in the table lists the total number of sentence pairs, the ratio of unique sentence pairs that are in included in no other submission, and the ratio of sentence pairs shared with each of the other submissions. For Nepali, there was less overlap in the 5 million word data condition, compared to the 1 million word data condition. Here, for Sinhala, the trend goes the other way.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>• A Moses configuration file to train and test a statistical machine translation system. • fairseq scripts to train and test a neural machine translation system. • The flores-dev set of Wikipedia translations as development set. • The flores-devtest set of Wikipedia translations as development test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>AFRL</head><label></label><figDesc><ref type="bibr" target="#b15">Erdmann and Gwinnup (2019)</ref> use a coverage metric and quality metric. The coverage metric discourages the addition of sentence pairs that have vocabulary already included in the selected set. The quality metric is based on comparing the machine translation of the foreign sentence with the English sentence using the METEOR machine translation metric.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Additional subsets, neural machine translation. The charts plot BLEU scores against the size of the subselected corpus (in millions of English words). Different submissions have very different optima, ranging from 1 to 3 million words. The optimal subset size is lower for Nepali (mostly around 1 million) than for Sinhala (mostly around 2 million). Only the 7 best submissions are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Additional subsets, statistical machine translation. The charts plot BLEU scores against the size of the subselected corpus (in millions of English words). All submissions tend to improve with additional data, outperforming neural machine translation at 5 million. This demonstrates that statistical machine translation is more robust to noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Provided clean parallel data for Nepali.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Provided clean parallel data for Sinhala.</figDesc><table><row><cell>Corpus</cell><cell>Sentences</cell><cell>Words</cell></row><row><cell>Wikipedia</cell><cell></cell><cell></cell></row><row><cell>Sinhala</cell><cell>155,946</cell><cell>4,695,602</cell></row><row><cell>Nepali</cell><cell>92,296</cell><cell>2,804,439</cell></row><row><cell>English</cell><cell cols="2">67,796,935 1,985,175,324</cell></row><row><cell cols="2">CommonCrawl</cell><cell></cell></row><row><cell>Sinhala</cell><cell>5,178,491</cell><cell>110,270,445</cell></row><row><cell>Nepali</cell><cell>3,562,373</cell><cell>102,988,609</cell></row><row><cell cols="3">English 380,409,891 8,894,266,960</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Provided clean monolingual data.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Hindi corpora released as related language data from the IIT Bombay English-Hindi Corpus.</figDesc><table><row><cell>Sentence</cell><cell>English</cell></row><row><cell>Pairs</cell><cell>Words</cell></row><row><cell cols="2">Nepali 2,235,512 58,537,167</cell></row><row><cell cols="2">Sinhala 3,357,018 60,999,374</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Noisy parallel data to be filtered (deduplicated raw output Paracrawl pipeline).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Nepali→English Source previous आधारभू त कु राहरू तपाईंले हाउस सु धार गनर् के गनर् सके न Target previous Basic Things You Could Do To Improve Your House Source यो िभिडयो Batesville मा एक चे ला अब सम्मे लन हो, सु श्री . कृ पया िभिडयो र अिडयो गु णस्तर क्षमा Target This video is from a Disciple Now conference in Batesville, MS. Please forgive the video and audio quality ප% මu . /ටu ව » ස*ප% » ගැස3 ප% ර අංක 2061/10 -2018 මා89 05 වැ: ස;දා -2018.03.05</figDesc><table><row><cell>Sinhala→English</cell><cell></cell></row><row><cell>Source</cell><cell>Paintballing, හා තව% ෙබාෙහ(!</cell></row><row><cell>Target</cell><cell>Paintballing, and many more!</cell></row><row><cell cols="2">Source ස*Target Home » Resources » Gazette NO. 2061/10 -MONDAY, MARCH 05, 2018</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Examples of good sentence pairs from the noisy corpus for Nepali-English and Sinhala-English.</figDesc><table><row><cell></cell><cell>Nepali</cell><cell></cell><cell>Sinhala</cell><cell></cell></row><row><cell></cell><cell cols="4">Sentence Pairs English Words Sentence Pairs English Words</cell></row><row><cell>dev</cell><cell>2,559</cell><cell>46,274</cell><cell>2,898</cell><cell>53,479</cell></row><row><cell>dev test</cell><cell>2,835</cell><cell>51,458</cell><cell>2,766</cell><cell>50,985</cell></row><row><cell>test</cell><cell>2,924</cell><cell>54,062</cell><cell>2,905</cell><cell>52,851</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Statistics for the flores test sets used to evaluate the machine translation systems trained on the subsampled data sets. Word counts are obtained with wc on tokenized text.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Participants in the shared task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9 :</head><label>9</label><figDesc>Results for Nepali: BLEU scores are reported for systems trained on 1, 2, and 5 million word subsets of the data, subsampled based on the quality scores provided by the participants.</figDesc><table><row><cell>Sinhala</cell><cell></cell><cell cols="2">1 million</cell><cell></cell><cell></cell><cell cols="2">2 million</cell><cell></cell><cell></cell><cell cols="2">5 million</cell><cell></cell></row><row><cell></cell><cell cols="2">SMT</cell><cell cols="2">NMT</cell><cell cols="2">SMT</cell><cell cols="2">NMT</cell><cell cols="2">SMT</cell><cell cols="2">NMT</cell></row><row><cell>System</cell><cell cols="4">test devt test devt</cell><cell cols="4">test devt test devt</cell><cell cols="4">test devt test devt</cell></row><row><cell>AFRL 50k</cell><cell>3.8</cell><cell>4.4</cell><cell>3.0</cell><cell>3.5</cell><cell>3.9</cell><cell>4.6</cell><cell>4.2</cell><cell>5.0</cell><cell>4.5</cell><cell>5.2</cell><cell>4.4</cell><cell>4.9</cell></row><row><cell>AFRL 150k</cell><cell>4.1</cell><cell>4.7</cell><cell>3.6</cell><cell>4.1</cell><cell>4.2</cell><cell>4.9</cell><cell>4.5</cell><cell>5.2</cell><cell>4.6</cell><cell>5.4</cell><cell>4.4</cell><cell>4.7</cell></row><row><cell>DiDi</cell><cell>1.3</cell><cell>1.6</cell><cell>0.2</cell><cell>0.2</cell><cell>1.8</cell><cell>2.2</cell><cell>0.1</cell><cell>0.1</cell><cell>3.1</cell><cell>3.7</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>DiDi lmdiff</cell><cell>1.2</cell><cell>1.3</cell><cell>0.1</cell><cell>0.1</cell><cell>1.8</cell><cell>1.7</cell><cell>0.1</cell><cell>0.1</cell><cell>2.8</cell><cell>3.1</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>DiDi lratio</cell><cell>2.5</cell><cell>2.8</cell><cell>0.2</cell><cell>0.1</cell><cell>3.2</cell><cell>3.5</cell><cell>0.2</cell><cell>0.2</cell><cell>3.7</cell><cell>4.2</cell><cell>0.2</cell><cell>0.3</cell></row><row><cell>Facebook main</cell><cell>4.3</cell><cell>5.0</cell><cell>6.4</cell><cell>7.2</cell><cell>4.8</cell><cell>5.2</cell><cell>6.5</cell><cell>7.3</cell><cell>4.9</cell><cell>5.7</cell><cell>4.0</cell><cell>5.0</cell></row><row><cell>Facebook contrastive</cell><cell>4.3</cell><cell>4.8</cell><cell>6.2</cell><cell>6.8</cell><cell>4.5</cell><cell>5.2</cell><cell>6.1</cell><cell>6.7</cell><cell>4.7</cell><cell>5.5</cell><cell>3.8</cell><cell>4.1</cell></row><row><cell>Helsinki</cell><cell>3.3</cell><cell>3.4</cell><cell>1.1</cell><cell>1.4</cell><cell>3.5</cell><cell>4.1</cell><cell>1.1</cell><cell>1.2</cell><cell>4.2</cell><cell>4.7</cell><cell>0.7</cell><cell>0.8</cell></row><row><cell>Helsinki contrastive</cell><cell>2.3</cell><cell>2.4</cell><cell>0.3</cell><cell>0.2</cell><cell>3.2</cell><cell>3.8</cell><cell>0.5</cell><cell>0.4</cell><cell>4.0</cell><cell>4.6</cell><cell>0.6</cell><cell>0.7</cell></row><row><cell>IITP</cell><cell>3.1</cell><cell>3.6</cell><cell>3.2</cell><cell>3.7</cell><cell>4.0</cell><cell>4.6</cell><cell>5.3</cell><cell>6.5</cell><cell>4.4</cell><cell>5.1</cell><cell>3.9</cell><cell>4.5</cell></row><row><cell>IITP geom</cell><cell>3.0</cell><cell>3.5</cell><cell>3.0</cell><cell>3.4</cell><cell>4.0</cell><cell>4.6</cell><cell>5.4</cell><cell>6.2</cell><cell>4.4</cell><cell>5.2</cell><cell>4.3</cell><cell>5.1</cell></row><row><cell>NRC ensemble</cell><cell>4.2</cell><cell>4.7</cell><cell>4.1</cell><cell>4.6</cell><cell>4.3</cell><cell>4.8</cell><cell>2.8</cell><cell>3.2</cell><cell>4.5</cell><cell>5.1</cell><cell>1.4</cell><cell>1.5</cell></row><row><cell>NRC xlm</cell><cell>3.8</cell><cell>4.0</cell><cell>1.6</cell><cell>2.0</cell><cell>4.1</cell><cell>4.5</cell><cell>1.5</cell><cell>1.8</cell><cell>4.4</cell><cell>5.0</cell><cell>0.9</cell><cell>1.2</cell></row><row><cell>NRC yisi-2-sup</cell><cell>3.9</cell><cell>4.7</cell><cell>5.0</cell><cell>5.9</cell><cell>4.2</cell><cell>5.4</cell><cell>4.6</cell><cell>5.2</cell><cell>4.4</cell><cell>5.2</cell><cell>1.6</cell><cell>1.9</cell></row><row><cell>NRC yisi-2-unsup</cell><cell>3.1</cell><cell>3.9</cell><cell>2.4</cell><cell>2.9</cell><cell>3.8</cell><cell>4.4</cell><cell>1.8</cell><cell>2.3</cell><cell>4.3</cell><cell>4.9</cell><cell>0.7</cell><cell>0.9</cell></row><row><cell>Stockholm</cell><cell>3.8</cell><cell>4.3</cell><cell>2.9</cell><cell>3.2</cell><cell>4.1</cell><cell>4.6</cell><cell>2.2</cell><cell>2.4</cell><cell>4.0</cell><cell>4.8</cell><cell>0.5</cell><cell>0.5</cell></row><row><cell>Stockholm ngram</cell><cell>3.3</cell><cell>4.0</cell><cell>2.2</cell><cell>2.5</cell><cell>3.5</cell><cell>4.1</cell><cell>1.7</cell><cell>1.8</cell><cell>3.6</cell><cell>4.3</cell><cell>0.4</cell><cell>0.4</cell></row><row><cell>Sciling</cell><cell>2.4</cell><cell>2.5</cell><cell>2.5</cell><cell>2.6</cell><cell>3.0</cell><cell>3.0</cell><cell>3.5</cell><cell>3.7</cell><cell>3.8</cell><cell>4.1</cell><cell>3.4</cell><cell>3.8</cell></row><row><cell>TALP-UPC primary</cell><cell>0.9</cell><cell>0.9</cell><cell>0.0</cell><cell>0.0</cell><cell>1.4</cell><cell>1.5</cell><cell>0.1</cell><cell>0.1</cell><cell>2.7</cell><cell>3.0</cell><cell>0.1</cell><cell>0.1</cell></row><row><cell>TALP-UPC sec.</cell><cell>0.3</cell><cell>0.2</cell><cell>0.1</cell><cell>0.0</cell><cell>0.2</cell><cell>0.2</cell><cell>0.0</cell><cell>0.0</cell><cell>0.8</cell><cell>0.7</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell>Webinterpret primary</cell><cell>3.7</cell><cell>4.2</cell><cell>2.1</cell><cell>2.3</cell><cell>3.8</cell><cell>4.6</cell><cell>2.0</cell><cell>2.6</cell><cell>4.1</cell><cell>4.8</cell><cell>1.7</cell><cell>1.9</cell></row><row><cell>Webinterpret cov</cell><cell>2.6</cell><cell>3.0</cell><cell>0.1</cell><cell>0.1</cell><cell>3.6</cell><cell>4.0</cell><cell>0.2</cell><cell>0.2</cell><cell>4.0</cell><cell>4.5</cell><cell>1.2</cell><cell>1.4</cell></row><row><cell>Webinterpret prob</cell><cell>3.9</cell><cell>4.6</cell><cell>2.9</cell><cell>3.5</cell><cell>4.2</cell><cell>5.0</cell><cell>4.1</cell><cell>4.7</cell><cell>4.1</cell><cell>4.7</cell><cell>1.4</cell><cell>1.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 10 :</head><label>10</label><figDesc>Results for Sinhala: BLEU scores are reported for systems trained on 1, 2, and 5 million word subsets of the data, subsampled based on the quality scores provided by the participants.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 11</head><label>11</label><figDesc></figDesc><table><row><cell>: Number of sentences and the corresponding</cell></row><row><cell>average sentence length (counting English words) for</cell></row><row><cell>Nepali.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 12 :</head><label>12</label><figDesc>Number of sentences and the corresponding average sentence length (counting English words) for Sinhala.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 13 :</head><label>13</label><figDesc>Overlap for Nepali, 1 million word data condition. For each submission, a row in the table lists the total number of sentence pairs, the ratio of unique sentence pairs that are in included in no other submission, and the ratio of sentence pairs shared with each of the other submissions. Submissions from different participants share up to 67.9% of sentence pairs (NRC ensemble and Facebook main). 4% 32.6% 32.6% 34.5% 30.4% 39.4% 38.8% 30.6% 30.9% 31.0% 31.9% 61.5% 25.7% 26.0% 29.6% 26.7% 12.8% 38.9% 38.9% 38.9% AFRL 150k 236966 1.9% 88.0% -31.1% 31.2% 36.1% 32.4% 38.8% 37.7% 30.8% 31.2% 31.4% 32.4% 60.8% 25.2% 25.9% 29.5% 25.7% 11.7% 38.5% 38.5% 38.5% Facebook main 115673 0.0% 68.0% 63.8% -99.9% 42.5% 34.4% 44.6% 44.8% 43.9% 43.8% 40.0% 44.1% 54.3% 32.5% 28.9% 34.5% 30.0% 9.0% 40.5% 40.5% 40.5% Facebook contr. 115771 0.0% 68.0% 63.8% 99.9% -42.5% 34.4% 44.6% 44.8% 43.9% 43.8% 40.0% 44.1% 54.3% 32.5% 28.9% 34.5% 30.0% 9.0% 40.5% 40.5% 40.5% Helsinki 253834 0.1% 32.8% 33.7% 19.4% 19.4% -86.6% 34.5% 32.5% 32.4% 39.1% 28.5% 26.9% 36.7% 52.2% 64.4% 50.6% 50.0% 27.6% 36.5% 36.5% 36.5% Helsinki contr. 251983 0.5% 29.2% 30.5% 15.8% 15.8% 87.3% -32.1% 30.1% 28.5% 35.1% 26.3% 24.4% 33.3% 50.6% 62.7% 45.8% 51.0% 27.8% 31.0% 31.0% 31.0% IITP 200725 0.6% 47.4% 45.8% 25.7% 25.7% 43.6% 40.4% -89.5% 44.9% 45.7% 44.2% 42.6% 41.5% 45.9% 41.0% 46.6% 35.1% 10.6% 52.1% 52.1% 52.1% IITP geom 185978 0.1% 50.4% 48.1% 27.9% 27.9% 44.4% 40.8% 96.6% -47.0% 47.4% 46.9% 45.5% 42.4% 45.1% 39.3% 45.0% 33.9% 9.5% 51.8% 51.8% 51.8% NRC ensemble 154622 0.3% 47.8% 47.3% 32.9% 32.9% 53.2% 46.4% 58.3% 56.6% -85.1% 64.9% 62.8% 40.7% 47.6% 43.2% 55.6% 37.5% 8.5% 44.9% 44.9% 44.9% NRC xlm 191203 1.6% 39.1% 38.7% 26.5% 26.5% 51.9% 46.2% 48.0% 46.1% 68.8% -48.5% 47.7% 36.4% 46.1% 53.0% 51.2% 36.4% 12.1% 42.2% 42.2% 42.2% NRC yisi-2-sup 161022 4.6% 46.5% 46.1% 28.7% 28.8% 44.9% 41.1% 55.1% 54.2% 62.4% 57.6% -69.4% 37.4% 38.9% 36.0% 40.2% 30.0% 5.9% 36.8% 36.8% 36.8% NRC yisi-2-unsup 148072 2.7% 52.0% 51.9% 34.5% 34.5% 46.0% 41.6% 57.7% 57.1% 65.5% 61.6% 75.5% -40.0% 36.3% 30.4% 43.1% 30.1% 5.6% 38.7% 38.7% 38.7% Sciling 314196 21.1% 47.2% 45.9% 20.0% 20.0% 29.6% 26.7% 26.5% 25.1% 20.0% 22.1% 19.2% 18.9% -28.2% 30.8% 25.3% 25.5% 15.3% 34.2% 34.2% 34.2% Stockholm 272605 1.0% 22.8% 21.9% 13.8% 13.8% 48.6% 46.7% 33.8% 30.8% 27.0% 32.4% 23.0% 19.7% 32.5% -87.1% 49.5% 43.3% 23.4% 35.4% 35.4% 35.4% Stockholm ngram 419335 17.3% 15.0% 14.6% 8.0% 8.0% 39.0% 37.7% 19.6% 17.4% 15.9% 24.2% 13.8% 10.7% 23.0% 56.6% -41.0% 29.3% 19.4% 26.0% 26.0% 26.0% SUNY Buffalo 300627 11.9% 23.8% 23.3% 13.3% 13.3% 42.7% 38.4% 31.1% 27.9% 28.6% 32.6% 21.5% 21.2% 26.5% 44.8% 57.2% -31.3% 19.9% 36.2% 36.2% 36.2% TALP-UPC 246875 3.7% 26.1% 24.7% 14.1% 14.1% 51.4% 52.1% 28.5% 25.5% 23.5% 28.2% 19.5% 18.1% 32.5% 47.8% 49.8% 38.1% -39.8% 30.6% 30.6% 30.6% TALP-UPC sec. 375387 53.2% 8.2% 7.4% 2.8% 2.8% 18.7% 18.6% 5.7% 4.7% 3.5% 6.2% 2.5% 2.2% 12.8% 17.0% 21.7% 15.9% 26.2% -14.8% 14.8% 14.8% Webinterpret 400441 0.0% 23.4% 22.8% 11.7% 11.7% 23.1% 19.5% 26.1% 24.1% 17.3% 20.2% 14.8% 14.3% 26.8% 24.1% 27.2% 27.2% 18.9% 13.9% -100.0% 100.0% Webinterpret cov 400441 0.0% 23.4% 22.8% 11.7% 11.7% 23.1% 19.5% 26.1% 24.1% 17.3% 20.2% 14.8% 14.3% 26.8% 24.1% 27.2% 27.2% 18.9% 13.9% 100.0% -100.0% Webinterpret prob 400441 0.0% 23.4% 22.8% 11.7% 11.7% 23.1% 19.5% 26.1% 24.1% 17.3% 20.2% 14.8% 14.3% 26.8% 24.1% 27.2% 27.2% 18.9% 13.9% 100.0% 100.0% -</figDesc><table><row><cell>Submission</cell><cell>Total Unique</cell><cell>AFRL 50k</cell><cell>AFRL 150k</cell><cell>Facebook main</cell><cell>Facebook contr.</cell><cell>Helsinki</cell><cell>Helsinki contr.</cell><cell>IITP</cell><cell>IITP geom</cell><cell>NRC ensemble</cell><cell>NRC xlm</cell><cell>NRC yisi-2-sup</cell><cell>NRC yisi-2-unsup</cell><cell>Sciling</cell><cell>Stockholm</cell><cell>Stockholm ngram</cell><cell>SUNY Buffalo</cell><cell>TALP-UPC</cell><cell>TALP-UPC sec.</cell><cell>Webinterpret</cell><cell>Webinterpret cov</cell><cell>Webinterpret prob</cell></row><row><cell>AFRL 50k</cell><cell>241513 1.7%</cell><cell></cell><cell>-86.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 14 :</head><label>14</label><figDesc>Overlap for Nepali, 5 million word data condition. For each submission, a row in the table lists the total number of sentence pairs, the ratio of unique sentence pairs that are in included in no other submission, and the ratio of sentence pairs shared with each of the other submissions.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://opus.nlpl.eu 3 NLP4TM 2016: Shared task http://rgcl.wlv.ac.uk/nlp4tm2016/shared-task/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://bit.ly/2IoOXOr 5 http://www.statmt.org/wmt19/ parallel-corpus-filtering.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">http://opus.nlpl.eu/ 7 http://www.PANL10n.net/ 8 https://globalvoices.org/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">https://github.com/facebookresearch/ flores#train-a-baseline-transformer-model</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">MichałZiemski, Marcin Junczys-Dowmunt, and Bruno  Pouliquen. 2015. The united nations parallel corpus v1.0. In International Conference on Language Resources and Evaluation (LREC).</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>-12.7% 1.8% 17.3% 8.6% 27.3% TALP-UPC 89785 50.0% 3.3% 3.5% 0.9% 1.3% 0.9% 4.5% 3.1% 20.2% 19.2% 2.6% 2.4% 0.5% 0.1% 3.9% 4.8% 10.8% 7.6% 6.6% -9.1% 0.4% 0.6% 2.9% TALP-UPC sec. 114990 90.6% 0.8% 0.7% 0.0% 0.1% 0.0% 0.6% 0.5% 1.8% 1.5% 0.5% 0.5% 0.0% 0.0% 0.3% 0.5% 1.9% 0.6% 0.7% 7.1% -0.0% 0.0% 0.3% Webinterpret 35684 5.1% 19.1% 21.1% 5.4% 15.8% 6.2% 34.6% 29.7% 21.8% 10.4% 19.3% 18.7% 33.2% 26.7% 29.6% 21.3% 9.9% 26.5% 22.6% 1.1% 0.1% -44.1% 64.1% Webinterpret cov 29678 24.7% 8.8% 9.9% 9.5% 21.0% 9.4% 13.1% 13.5% 14.1% 6.0% 7.4% 7.1% 20.1% 20.9% 13.4% 11.0% 2.1% 13.4% 13.5% 1.8% 0.1% 53.1% -22.8% Webinterpret prob 64115 11.8% 28.7% 30.6% 1.6% 6.0% 2.1% 42.2% 29.1% 22.8% 9.4% 37.2% 36.6% 20.0% 12.7% 29.7% 23.4% 30.8% 25.7% 19.8% 4.0% 0.6% 35.7% 10.6% - </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Building a web-based parallel corpus and filtering out machine-translated text</title>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Antonova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexey</forename><surname>Misyurev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web</title>
				<meeting>the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web<address><addrLine>Portland, Oregon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Marginbased Parallel Corpus Mining with Multilingual Sentence Embeddings</title>
		<author>
			<persName><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.10464</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The speechmatics parallel corpus filtering system for wmt18</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Ash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Remi</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="866" to="872" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dual monolingual crossentropy delta filtering of noisy parallel data</title>
		<author>
			<persName><forename type="first">Amittai</forename><surname>Axelrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain adaptation via pseudo in-domain data selection</title>
		<author>
			<persName><forename type="first">Amittai</forename><surname>Axelrod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK. As</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="355" to="362" />
		</imprint>
	</monogr>
	<note>sociation for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
				<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Synthetic and natural noise both break neural machine translation</title>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<idno>abs/1711.02173</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nrc parallel corpus filtering system for wmt</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Bernier-Colborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Talp-Upc</forename><surname>Sec</surname></persName>
		</author>
		<idno>9% 0.3% 0.3% 0.1% 0.1% 0.4% 0.4% 0.3% 0.3% 0.0% 0.0% 0.1% 0.1% 1.1% 0.1% 1.8% 2.3% 1.7% 0.0% 0.0% 0.1%</idno>
		<imprint>
			<biblScope unit="volume">84978</biblScope>
			<biblScope unit="page">0</biblScope>
		</imprint>
	</monogr>
	<note>Webinterpret 34873 0.0% 29.9% 29.3% 46.8% 46.8% 24.1% 4.0% 52.9% 52.3% 49.5% 45.5% 48.2% 46.4% 13.2% 43.6% 21.2% 13.2% 0.9% 0.0% 54.0% 82</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Talp-Upc</forename><surname>Sec</surname></persName>
		</author>
		<idno>3% 8.8% 8.0% 2.8% 3.7% 4.1% 3.7% 4.2% 20.4% 20.4% 6.0% 5.5% 4.0% 5.8% 4.3% 6.0% 11.4% 12.0% 20.5% 32.8% 14.3% 16.2% 15.1% Webinterpret 328620 0.0% 39.4% 36.9% 10.6% 18.7% 16.2% 24.1% 24.7% 39.3% 35.9% 45.9% 43.5% 30.3% 31.6% 29.5% 32.8% 51.1% 35.2% 39.1% 34.7% 19.0% 85.7% 96.0% Webinterpret cov 318360 1.9% 34.4% 31.9% 11</idno>
		<imprint>
			<biblScope unit="volume">437636</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>3% 19.9% 17.1% 20.8% 22.3% 38.8% 35.5% 41.3% 39.0% 29.5% 31.0% 28.7% 32.1% 48.9% 35.9% 38.8% 38.1% 22.3% 88.4% 86.5% Webinterpret prob 345536 1.3% 38.1% 35.6% 9.9% 17.6% 15.4% 23.2% 23.4% 40.4% 37.2% 44.3% 42.0% 29.1% 30.7% 28.4% 31.3% 48.7% 34.4% 40.7% 34.2% 19.1% 91.3% 79</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">H2@bucc18: Parallel sentence extraction from comparable corpora using multilingual sentence embeddings</title>
		<author>
			<persName><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)</title>
				<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Findings of the wmt 2016 bilingual document alignment shared task</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
				<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="554" to="563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detecting cross-lingual semantic divergence for neural machine translation</title>
		<author>
			<persName><forename type="first">Marine</forename><surname>Carpuat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yogarshi</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Neural Machine Translation</title>
				<meeting>the First Workshop on Neural Machine Translation</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="69" to="79" />
		</imprint>
	</monogr>
	<note>Vancouver. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lowresource corpus filtering using multilingual sentence embeddings</title>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuqing</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Bilingual data cleaning for SMT using graph-based random walk</title>
		<author>
			<persName><forename type="first">Lei</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="340" to="345" />
		</imprint>
	</monogr>
	<note>Short Papers)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Quality and coverage: The afrl submission to the wmt19 parallel corpus filtering for low-resource conditions task</title>
		<author>
			<persName><forename type="first">Grant</forename><surname>Erdmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Gwinnup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A convolutional encoder model for neural machine translation</title>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann N</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02344</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Webinterpret submission to the wmt2019 shared task on parallel corpus filtering</title>
		<author>
			<persName><forename type="first">Jesús</forename><surname>González-Rubio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective parallel corpus mining using bilingual sentence embeddings</title>
		<author>
			<persName><forename type="first">Qinlan</forename><surname>Mand Y Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yinfei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Hernand Ez Abrego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yun-Hsuan</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName><surname>Kurzweil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
				<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Two new evaluation datasets for low-resource machine translation: Nepali-english and sinhala-english</title>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Guzmán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng-Jen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc'aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01382</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">An unsupervised system for parallel corpus filtering</title>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Hangya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Fraser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="895" to="900" />
		</imprint>
	</monogr>
	<note>Shared Task Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dual conditional cross-entropy filtering of noisy parallel corpora</title>
		<author>
			<persName><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Shared Task Papers</title>
				<meeting>the Third Conference on Machine Translation: Shared Task Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="888" to="895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the impact of various types of noise on neural machine translation</title>
		<author>
			<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Neural Machine Translation and Generation</title>
				<meeting>the 2nd Workshop on Neural Machine Translation and Generation</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="74" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Machine Translation Summit</title>
				<meeting>the Tenth Machine Translation Summit<address><addrLine>MT Summit X), Phuket, Thailand</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ondřej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions</title>
				<meeting>the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume the Demo and Poster Sessions<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="177" to="180" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Findings of the wmt 2018 shared task on parallel corpus filtering</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mikel</forename><forename type="middle">L</forename><surname>Forcada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Shared Task Papers</title>
				<meeting>the Third Conference on Machine Translation: Shared Task Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="726" to="739" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Six challenges for neural machine translation</title>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Neural Machine Translation</title>
				<meeting>the First Workshop on Neural Machine Translation</meeting>
		<imprint>
			<publisher>Vancouver. Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reinforcement learning based curriculum optimization for neural machine translation</title>
		<author>
			<persName><forename type="first">Gaurav</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Cherry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2054" to="2061" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">Anoop</forename><surname>Kunchukuttan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratik</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<title level="m">The IIT Bombay English-Hindi Parallel Corpus</title>
				<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Noisy parallel corpus filtering through projected word embeddings</title>
		<author>
			<persName><forename type="first">Murathan</forename><surname>Kurfalı</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robertöstling</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Measuring sentence parallelism using mahalanobis distances: The nrc unsupervised submissions to the wmt18 parallel corpus filtering shared task</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Larkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darlene</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="913" to="920" />
		</imprint>
	</monogr>
	<note>Shared Task Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Accurate semantic textual similarity for cleaning noisy parallel corpora using semantic machine translation evaluation metric: The nrc supervised submissions to the parallel corpus filtering task</title>
		<author>
			<persName><forename type="first">Chi-Kiu</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Darlene</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Larkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyril</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Littell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="921" to="929" />
		</imprint>
	</monogr>
	<note>Shared Task Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Alibaba submission to the wmt18 parallel corpus filtering task</title>
		<author>
			<persName><forename type="first">Jun</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyu</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yangbin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Boxing</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="930" to="935" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
				<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)<address><addrLine>Minneapolis</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Utfpr at wmt 2018: Minimalistic supervised corpora filtering for machine translation</title>
		<author>
			<persName><forename type="first">Gustavo</forename><surname>Paetzold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="936" to="940" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Filtering of noisy parallel corpora based on hypothesis generation</title>
		<author>
			<persName><forename type="first">Zuzanna</forename><surname>Parcheta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Germán</forename><surname>Sanchis-Trilles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Casacuberta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The language demographics of Amazon Mechanical Turk</title>
		<author>
			<persName><forename type="first">Ellie</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ann</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitry</forename><surname>Kachaev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
				<imprint>
			<date type="published" when="2014-02" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="79" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Systran participation to the wmt2018 shared task on parallel corpus filtering</title>
		<author>
			<persName><forename type="first">Minh</forename><forename type="middle">Quang</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josep</forename><surname>Crego</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="947" to="951" />
		</imprint>
	</monogr>
	<note>Shared Task Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tilde&apos;s parallel corpus filtering methods for wmt</title>
		<author>
			<persName><forename type="first">Marcis</forename><surname>Pinnis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="952" to="958" />
		</imprint>
	</monogr>
	<note>Shared Task Papers. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A call for clarity in reporting bleu scores</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
				<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="186" to="191" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">United Nations General Assembly resolutions: A sixlanguage parallel corpus</title>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Rafalovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Dale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth Machine Translation Summit (MT Summit XII). International Association for Machine Translation</title>
				<meeting>the Twelfth Machine Translation Summit (MT Summit XII). International Association for Machine Translation</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">MT detection in web-scraped parallel corpora</title>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Rarrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Quirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Machine Translation Summit (MT Summit XIII)</title>
				<meeting>the 13th Machine Translation Summit (MT Summit XIII)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="422" to="430" />
		</imprint>
	</monogr>
	<note>International Association for Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mining the web for bilingual text</title>
		<author>
			<persName><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Association of Computational Linguistics (ACL)</title>
				<meeting>the 37th Annual Meeting of the Association of Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The rwth aachen university filtering system for the wmt 2018 parallel corpus filtering task</title>
		<author>
			<persName><forename type="first">Nick</forename><surname>Rossenbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunsu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miguel</forename><surname>Graã §a</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Gokrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation</title>
				<meeting>the Third Conference on Machine Translation<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="959" to="967" />
		</imprint>
	</monogr>
	<note>Shared Task Papers</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Prompsit&apos;s submission to wmt 2018 parallel corpus filtering shared task</title>
		<author>
			<persName><forename type="first">M</forename><surname>Víctor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Sánchez-Cartagena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergio</forename><forename type="middle">Ortiz</forename><surname>Bañón</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gema</forename><surname>Rojas</surname></persName>
		</author>
		<author>
			<persName><surname>Ramírez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Shared Task Papers</title>
				<meeting>the Third Conference on Machine Translation: Shared Task Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="955" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Parallel corpus filtering based on fuzzy string matching</title>
		<author>
			<persName><forename type="first">Sukanta</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Asif</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Unsupervised corpus filtering and mining</title>
		<author>
			<persName><forename type="first">Felipe</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><forename type="middle">R</forename><surname>Costa-Jussà</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The sentence-aligned european patent corpus</title>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Täger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference of the European Association for Machine Translation (EAMT)</title>
				<meeting>the 15th International Conference of the European Association for Machine Translation (EAMT)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="177" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Parallel corpus refinement as an outlier detection algorithm</title>
		<author>
			<persName><forename type="first">Kaveh</forename><surname>Taghipour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shahram</forename><surname>Khadivi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jia</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Machine Translation Summit (MT Summit XIII)</title>
				<meeting>the 13th Machine Translation Summit (MT Summit XIII)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="414" to="421" />
		</imprint>
	</monogr>
	<note>ternational Association for Machine Translation</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Parallel data, tools and interfaces in opus</title>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012)</title>
				<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC-2012)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="L12" to="1246" />
		</imprint>
	</monogr>
	<note>Istanbul, Turkey. European Language Resources Association (ELRA). ACL Anthology Identifier</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Parallel corpora for medium density languages</title>
		<author>
			<persName><forename type="first">Dániel</forename><surname>Varga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Péter</forename><surname>Halácsy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">András</forename><surname>Kornai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Nagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Amsterdam Studies In The Theory And History Of Linguistic Science Series 4</title>
				<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">292</biblScope>
			<biblScope unit="page">247</biblScope>
		</imprint>
	</monogr>
	<note>László Németh, and Viktor Trón</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The university of helsinki submission to the wmt19 parallel corpus filtering task</title>
		<author>
			<persName><forename type="first">Raúl</forename><surname>Vázquez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Umut</forename><surname>Sulubacak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jörg</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Machine Translation (WMT)</title>
				<meeting>the Fourth Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Watermarking the outputs of structured prediction with an application in statistical machine translation</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Venugopal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Talbot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franz</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1363" to="1372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Denoising neural machine translation training with trusted data and online data selection</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taro</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Macduff</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tetsuji</forename><surname>Nakagawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ciprian</forename><surname>Chelba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
				<meeting>the Third Conference on Machine Translation: Research Papers<address><addrLine>Belgium, Brussels</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="133" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Dynamic data selection for neural machine translation</title>
		<author>
			<persName><forename type="first">Arianna</forename><surname>Marlies Van Der Wees</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christof</forename><surname>Bisazza</surname></persName>
		</author>
		<author>
			<persName><surname>Monz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1411" to="1421" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Zipporah: a fast and scalable data cleaning system for noisy webcrawled parallel corpora</title>
		<author>
			<persName><forename type="first">Hainan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2935" to="2940" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
