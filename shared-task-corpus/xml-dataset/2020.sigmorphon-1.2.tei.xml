<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The SIGMORPHON 2020 Shared Task on Multilingual Grapheme-to-Phoneme Conversion</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kyle</forename><surname>Gorman</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Graduate Center</orgName>
								<orgName type="institution">City University of New York † Johns Hopkins University ‡ Jericho High School</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lucas</forename><forename type="middle">F E</forename><surname>Ashby</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Graduate Center</orgName>
								<orgName type="institution">City University of New York † Johns Hopkins University ‡ Jericho High School</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aaron</forename><surname>Goyzueta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Graduate Center</orgName>
								<orgName type="institution">City University of New York † Johns Hopkins University ‡ Jericho High School</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Arya</forename><forename type="middle">D</forename><surname>Mccarthy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Graduate Center</orgName>
								<orgName type="institution">City University of New York † Johns Hopkins University ‡ Jericho High School</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shijie</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Graduate Center</orgName>
								<orgName type="institution">City University of New York † Johns Hopkins University ‡ Jericho High School</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Daniel</forename><surname>You</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">The Graduate Center</orgName>
								<orgName type="institution">City University of New York † Johns Hopkins University ‡ Jericho High School</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The SIGMORPHON 2020 Shared Task on Multilingual Grapheme-to-Phoneme Conversion</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.18653/v1/P17</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the design and findings of the SIGMORPHON 2020 shared task on multilingual grapheme-to-phoneme conversion. Participants were asked to submit systems which consume a sequence of graphemes then emit output a sequence of phonemes representing the pronunciation of that grapheme sequence in one of fifteen languages. Nine teams submitted a total of 23 systems, at best achieving an 18% relative reduction in word error rate (macro-averaged over languages), versus strong neural sequence-to-sequence baselines. To facilitate error analysis, we publicly release the complete outputs for all systems-a first for the SIGMORPHON workshop.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Speech technologies such as automatic speech recognition and text-to-speech synthesis require mappings between written words and their pronunciations. Even recent attempts to do away with explicit pronunciation models via "end-to-end" systems (e.g., <ref type="bibr" target="#b53">Watts et al. 2013</ref><ref type="bibr" target="#b4">, Chan et al. 2016</ref><ref type="bibr" target="#b46">, Sotelo et al. 2017</ref><ref type="bibr" target="#b5">, Chiu et al. 2018</ref><ref type="bibr" target="#b38">, Pino et al. 2019</ref>) must induce an implicit mapping of this sort. For open-vocabulary applications, these mappings must generalize to unseen words, and so must be expressed as mappings between sequences of graphemes-i.e., glyphsand phonemes or phones-i.e., sounds. <ref type="bibr">1</ref> For some languages, this mapping is sufficiently consistent that a literate, linguisticallysophisticated speaker can simply enumerate the necessary rules; this sequence of rules can then be compiled into a finite-state transducer (e.g., <ref type="bibr" target="#b47">Sproat 1996</ref><ref type="bibr" target="#b3">, Black et al. 1998</ref>). However, rulebased systems require linguistic expertise to develop and maintain, and may be brittle or inaccurate. Therefore, modern speech engines usually treat grapheme-to-phoneme conversion as a machine learning problem, either using generative models expressed as weighted finite-state transducers (e.g., <ref type="bibr" target="#b49">Taylor 2005</ref><ref type="bibr" target="#b1">, Bisani and Ney 2008</ref><ref type="bibr" target="#b54">, Wu et al. 2014</ref><ref type="bibr" target="#b32">, Novak et al. 2016</ref> or discriminative models based on conditional random fields <ref type="bibr" target="#b22">(Lehnen et al. 2013)</ref>, recurrent neural networks (e.g., <ref type="bibr" target="#b40">Rao et al. 2015</ref><ref type="bibr" target="#b56">, Yao and Zweig 2015</ref><ref type="bibr" target="#b12">, van Esch et al. 2016</ref><ref type="bibr" target="#b21">, Lee et al. 2020</ref> or transformers <ref type="bibr" target="#b58">(Yolchuyeva et al. 2019)</ref>.</p><p>While the grapheme-to-phoneme conversion (or G2P) task is crucial to speech technology, the vast majority of published research focuses on English or a few other highly-resourced, globally hegemonic languages for which free pronunciation dictionaries are available. One exception, a recent study by <ref type="bibr" target="#b12">van Esch et al. (2016)</ref>, compares naïve rule-based systems and neural network-based sequence-to-sequence models for 20 languages; unfortunately, the data used in this study is proprietary. Like many other types of language resources, pronunciation dictionaries are expensive to create and maintain, and until recently, free high-quality dictionaries were only available for a small number of languages. This limitation to a handful of languages is unfortunate because, as we discuss below, writing systems are almost as diverse as languages themselves. Therefore, we present a multilingual grapheme-to-phoneme conversion task with data sets, evaluation metrics, and strong baselines. In this we are aided by the recent release of WikiPron <ref type="bibr" target="#b21">(Lee et al. 2020)</ref>, a freely available collection of pronunciation dictionaries. The resulting task, the first of its kind, included data from fifteen languages and scripts, and received 23 submissions from nine teams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>Fifteen language/script pairs were chosen to cover a wide variety of script types. Ten of the scripts are alphabetic systems known to descend from Phoenician (and ultimately from Egyptian hieroglyphs); of these, seven are variants of the Latin script. Two others, the Armenian aybuben and the Georgian mkhedruli, are alphabetic scripts of unknown origin, but may ultimately be modeled on Greek <ref type="bibr" target="#b44">(Sanjian 1996)</ref>. The devanāgarī script used to write Hindi, is an alphasyllabary, in which most glyphs-known traditionally as akṣara-denote consonant and consonant-vowel sequences. Vowels (or their absence) are primarily indicated with diacritics. It too is thought to ultimately descend from Phoenician. Hiragana, one of several scripts used to write Japanese, is a syllabary, in which most glyphs denote entire syllables The glyphs themselves are derived from Chinese characters. Like hiragana, the Korean hangul script is also a syllabary It may have been have been inspired by 'phags-pa, a Tibetan alphabet which is itself a distant cousin of devanāgarī <ref type="bibr" target="#b20">(Ledyard 1966)</ref>.</p><p>It is important to note that languages-and the scripts used to write them-differ enormously in their affordances for grapheme-to-phoneme conversion. Writing systems are, at their core, linguistic analyses, albeit sometimes quite naïve, and (as argued in DeFrancis 1989) explicitly encode details of the phonological and phonetic structure of the language they are used to write. Still, the exact details of these mappings can vary greatly between even closely related languages and/or scripts. Whereas related languages may retain telltale grammatical features across millennia, dozens of languages have abruptly switched from one script to another in just the last century, usually in response to political-rather than linguisticconcerns. It is thus unsurprising that <ref type="bibr" target="#b2">Bjerva and Augenstein (2018)</ref> find grapheme embeddings induced by training G2P systems are poorly correlated with gross phonological typology, and experiments with "polyglot" G2P models (e.g., <ref type="bibr" target="#b35">Peters et al. 2017</ref>) have produced equivocal results.</p><p>While we did not pay particular attention to language families when selecting language family, we note that nine of the languages are Indo-European (though no two are closely related) and none of the remaining six-Adyghe, Georgian, Hungarian, Japanese, Korean, and Vietnameseare known to be genetically related to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>The primary data for the shared task is derived from WikiPron <ref type="bibr" target="#b21">(Lee et al. 2020)</ref>, a massively multilingual resource of grapheme-phoneme pairs extracted from Wiktionary, an online multilingual dictionary. Depending on language and script, these pronunciations may be manually entered by human volunteers-usually working from language-specific pronunciation guidelines-or generated using server-side scripting routines; some languages (e.g., Bulgarian and French) use a mixture of the two approaches. WikiPron is configured to apply case-folding where appropriate. It removes stress and syllable boundary markers and segments pronunciation strings-encoded in the International Phonetic Alphabet-using the segments library <ref type="bibr" target="#b28">(Moran and Cysouw 2018)</ref>.</p><p>For this task, words with multiple pronunciations-both homographs and free pronunciation variants-were excluded, since pronunciations for such words are often selected by a rather different procedure: they are chosen from a small, predetermined set of possible pronunciations using classifiers conditioned on local context (e.g., <ref type="bibr" target="#b15">Gorman et al. 2018)</ref>.</p><p>Training and development data for ten languages-the "development" languages-was released at the start of the task; equivalent data for the five "surprise" languages was released one week before the start the evaluation phase. Table <ref type="table" target="#tab_0">1</ref> provides sample training data pairs for the development and surprise languages.</p><p>As there is considerable variation in the number of available examples for any given language, each languages' data was downsampled to 4,500 examples. We regard as a "medium-resource" setting for this task; these data sets are, for instance, several orders of magnitude smaller than the proprietary G2P data used by <ref type="bibr" target="#b12">van Esch et al. (2016)</ref>. Following similar procedures in other shared tasks (e.g., <ref type="bibr" target="#b7">Cotterell et al. 2017)</ref>, words were sampled according to their frequency in the largest available Wortschatz <ref type="bibr" target="#b13">(Goldhahn et al. 2012</ref>) corpus for that language. These frequencies were smoothed by adding a 0.  was not available for Adyghe, so uniform sampling was used for this language.</p><p>The downsampled data was then randomly split into training (80%; 3,600 examples), development (10%; 450 examples), and testing (10%; 450 examples) shards. For some languages, Wiktionary contains pronunciations for both lemmas (i.e., headwords, citations forms) and inflection variants; for others, pronunciations are only available for lemmas. We hypothesized that cases where one inflectional variant of a lemma is present in the training data and another in the test data-as might occur if the data was split totally at randomwould make the overall task somewhat easier. To forestall this possibility, the splitting procedure was constrained so that all inflectional variants of any given lemma-according to the UniMorph 2 <ref type="bibr" target="#b19">(Kirov et al. 2018</ref>) paradigm tables, also extracted from Wiktionary-are limited to a single shard. For example, since the French word acteur 'actor' occurs in the training shard, so must its plural form acteurs. This additional constraint was applied to all languages but Japanese and Vietnamese, for which no UniMorph data was available. We note that Wiktionary does not generally provide pronunciations for inflectional variants in Japanese, and that Vietnamese is a highly isolating language with no discernable system of inflection <ref type="bibr" target="#b33">(Noyer 1998)</ref>, so this is unlikely to have introduced bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>The primary metric for this task was word error rate (WER); we also report phone error rate (PER). WER This is the percentage of words for which the hypothesized transcription sequence is not identical to the gold reference transcription; lower WER indicates better performance. Following common practice in speech research, we multiply the WER by 100 and display it as a percentage. We choose this as the primary metric for the shared task because we hypothesize that any G2P error, no matter how small, will result in a substantial degradation in subjective quality for downstream speech applications.</p><p>PER This is a more forgiving measure measuring the normalized distance (i.e., in number of insertions, deletions, and substitutions) between the predicted and reference transcriptions. It is computed by summing the minimum edit distancecomputed with the <ref type="bibr" target="#b52">Wagner and Fischer (1974)</ref> algorithm-between prediction and reference transcriptions, and dividing by the sum of the reference transcription lengths. That is, PER := 100 × ∑ n i edits(p, r) ∑ n i |r| where p is the predicted pronunciation sequence, r is the reference sequence, and edits(p, r) is the Levenshtein distance between the two. Once again, we multiply it by 100, though strictly speaking it is not a true percentage because it can hypothetically exceed 100. As with WER, lower PER indicates better performance.</p><p>Participants were provided with two evaluation scripts: one which computes the two metrics for a single language, and another which macroaverages the metrics across all languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Baselines</head><p>Three baselines were made available at the start of the task. To aid reproducibility, participants were also provided with a Conda "environment", a schematic that allows users to reconstruct the exact software environment used to train and evaluate the baselines. Several submissions made use of the baselines for data augmentation or ensemble construction. We make these baseline implementations available under the task1/baselines subdirectory of the shared task repository. 2</p><p>Pair n-gram model The first baseline consists of a pair n-gram model, which be can thought of as a finite-state approximation of a hidden Markov model with states representing graphemes and emissions representing output phones. The model is quite similar to the Phonetisaurus toolkit <ref type="bibr" target="#b32">(Novak et al. 2016</ref>), but here is implemented using the OpenGrm toolkit <ref type="bibr" target="#b41">(Roark et al. 2012</ref><ref type="bibr" target="#b14">, Gorman 2016</ref>; see <ref type="bibr" target="#b21">Lee et al. 2020</ref> for a full description. The sole hyperparameter for this model, Markov model order, is tuned separately for each language using the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoder-decoder LSTM</head><p>The second baseline is a neural network sequence-to-sequence model consisting of a single-layer bidirectional LSTM encoder and a single-layer unidirectional LSTM decoder connected using an attention mechanism <ref type="bibr" target="#b23">(Luong et al. 2015)</ref>. It is implemented using the fairseq library <ref type="bibr" target="#b34">(Ott et al. 2019)</ref>. LSTM-based encoder-decoder models have been claimed to outperform pair n-gram G2P models, both in monolingual (e.g., <ref type="bibr">Rao et al. 2015, Yao and</ref><ref type="bibr" target="#b56">Zweig 2015)</ref> and multilingual (e.g., <ref type="bibr" target="#b12">van Esch et al. 2016</ref><ref type="bibr" target="#b21">, Lee et al. 2020</ref>) evaluations, though these prior studies use substantially more training data than is available in this task. During training, we perform 4,000 updates to minimize label-smoothed crossentropy <ref type="bibr" target="#b48">(Szegedy et al. 2016</ref>) with a smoothing rate of .1. We use the Adam optimizer (Kingma and Ba 2015) with a learning rate of α = .001 and weight decay coefficients of β = (.9, .98), and clip norms exceeding 1.0. We use the development set to tune-for each language-batch size (256, 512, 1024), dropout (.1, .2, .3), and the size of the encoder and decoder modules. A module is said to be "small" when it has a 128-dimension embedding layer and a 512-unit hidden layer, and "large" when it has a 256-dimension embedding layer and a 1024-unit hidden layer. In both cases, the decoder shares a single embedding layer for both inputs and outputs. Altogether, this defines a 36element hyperparameter grid. During tuning, we employ a form of early stopping; we save a checkpoint every 5 epochs, and then use the checkpoint that achieves the lowest WER on the development set. We use a beam of size 5 for decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Encoder-decoder transformer</head><p>The third baseline is a transformer, a neural sequence-tosequence models that replaces hidden layer recurrence with layers of multi-head self-attention <ref type="bibr" target="#b50">(Vaswani et al. 2017)</ref>. Once again, it is implemented using fairseq. Here the model consists of four encoder layers and four decoder layers, both with pre-layer normalization, tuned for character-level tasks <ref type="bibr" target="#b55">(Wu et al. 2020</ref>). The hyperparameter grid, tuning procedures, and beam size are the same as for the LSTM model above, except that learning rate is decayed on an inverse squareroot schedule after a 1,000-update linear warm-up period. While most participants chose to compare their results to the transformer and not the LSTM in system description papers, the transformer was outperformed by the LSTM baseline in most setting with the hyperparameter exploration budget.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">System descriptions</head><p>Below we provide brief descriptions of submissions to the shared task.</p><p>CLUZH The Institute of Computational Linguistics at the University of Zurich submitted a single system (Makarov and Clematide 2020) extending earlier work <ref type="bibr" target="#b24">(Makarov and Clematide 2018)</ref> on imitation learning-based transducers that output a sequence of edit actions rather than a target string itself. To adapt to the G2P task, where input (grapheme) and output (phone) vocabularies are largely disjoint, they add a substitution action. The costs of each edit action are drawn from a weighted finite state transducer (WFST). The authors suggest that external lexical information such as part of speech, etymology (borrowing particularly) and morphological segmentation would improve systems. During preprocessing, they decompose Korean hangul characters into their constituent jamo, each corresponding roughly to a single phoneme.</p><p>CU One team from the University of Colorado Boulder (Prabhu and Kann 2020) ensembled several transformer models created with different random seeds using majority voting. They also experiment with a form of multi-task learning: they train a "bidirectional" model to do both grapheme-tophoneme and phoneme-to-grapheme prediction.</p><p>CUZ A second team from the University of Colorado Boulder (Ryan and Hulden 2020) uses a "slice-and-shuffle" data augmentation strategy. First, they perform character-level one-to-one alignment between graphemes and phonemes. Then they concatenate frequent subsequence pairs to each other to create nonce training examples. Their submission is an LSTM model with a bidirectional encoder trained on this augmented data. While they also developed transformer models, these did not finish training in time for submission. Results for their transformer system, not reported here, are included in their system description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DeepSPIN Researchers at the Instituto Superior</head><p>Técnico and Unbabel produced four submissions <ref type="bibr" target="#b36">(Peters and Martins 2020)</ref> based on sparse attention models. Each submission consists of a single multilingual neural model in which separate learned "language embeddings" are concatenated to all encoder and decoder states, rather than prepending a language-identification token to the input sequence. Their submissions either use LSTM-or transformer-based encoder-decoder sequence-to-sequence models with different values of a hyperparameter enforcing sparsity in the final layer <ref type="bibr" target="#b37">(Peters et al. 2019)</ref>. Like CLUZH, they preprocess Korean hangul characters, decomposing them into constituent jamo, each corresponding roughly to a single phoneme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IMS A single submission from the Institut für</head><p>Maschinelle Sprachverarbeitung at the University of Stuttgart <ref type="bibr" target="#b59">(Yu et al. 2020</ref>) uses self-training <ref type="bibr" target="#b57">(Yarowsky 1995)</ref> and ensembles of the baseline models. The components of the ensemble are selected using a genetic algorithm. They report that their data augmentation does not affect performance substantially, except in a simulated lowresource setting with 200 training examples. They romanize Japanese and Korean texts as a preprocessing step, and they use external word frequency lists.</p><p>NSU The Novosibirsk State University team did not provide a system description.</p><p>UA The submissions from the University of Alberta <ref type="bibr">(Hauer et al. 2020</ref>) either use a non-neural discriminative string transduction model (DTLM; <ref type="bibr" target="#b31">Nicolai et al. 2018)</ref>, or tranformers. They leverage both grapheme-to-phoneme and phoneme-tographeme models to filter candidates for data augmentation, enforcing a cyclic consistency constraint. They further show strong performance in a simulated low-resource scenario with 100 training examples. They note that the DTLM system is much faster to train than transformer models. Their six submissions vary the amount of training data and use either DTLM, a transformer, or a transformer with data augmentation. UBCNLP The University of British Columbia submitted two systems <ref type="bibr" target="#b51">(Vesik et al. 2020)</ref>. One is a multilingual model akin to <ref type="bibr" target="#b35">Peters et al. (2017)</ref>, in which a language-identification token is prepended to the input sequence. They also ensemble multiple checkpoints. Their second submission adds self-training on Wikipedia text; they report that this data augmentation strategy does not improve scores.</p><p>UZH For all three of their submissions, the team from the Department of Informatics at the University of Zurich (ElSaadany and Suter 2020) used a single set of encoder-decoder parameters shared across all languages. UZH-1 is a large transformer model with large embedding, hidden layers, and batches, with a high dropout probability. UZH-2 augments this model with WikiPron data for six other languages. UZH-3 is an ensemble of the previous two models which selects from the predictions of the two component models using whichever model's prediction has a higher posterior probability. The ensemble outperformed the component models for most languages. During preprocessing they also decompose Korean hangul characters into their constituent jamo; they report this results in a 46% relative word error reduction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Results</head><p>We now review baseline and submission results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Baseline results</head><p>Baseline results are shown in Table <ref type="table" target="#tab_2">2</ref>. The encoder-decoder LSTM <ref type="bibr" target="#b21">(Lee et al. 2020</ref>) performed best for nine out of fifteen languages; the transformer was the strongest for four languages, and for the remaining two-Modern Greek and Hungarian-there was a virtual tie between the two neural network baselines. The pair n-gram model was outperformed by the neural baselines on all languages, and by 10 or more points WER in Bulgarian, Georgian, and Korean. This suggest that this model is no longer competitive with powerful discriminative neural methods, at least in this medium-resource G2P task.</p><p>While this task was not designed explicitly to compare LSTM and transformer sequence-tosequence models, it does suggest an advantage for LSTM models. However, we speculate that additional training data, or a more generous hyperparameter tuning budget, might favor transformer models. Indeed, anticipating the results below, the one team that directly compared transformer and LSTM systems, DeepSPIN, achieved the third best submission overall using a transformer.</p><p>We also note that for four languages, the baseline system that achieves the best WER does not achieve the best PER, though the two metrics produce the same one-best ranking for the remaining eleven languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Submission results</head><p>Table <ref type="table" target="#tab_4">3</ref> shows, for each language, the system or systems that achieved the best WER, as well as the best baseline WER. For all fifteen languages, at least one team outperformed the baselines, sometimes quite substantially. Six of the nine teams achieved the best WER on at least one language. More detailed per-language, per-submission results are available online. <ref type="bibr">3</ref> Table <ref type="table" target="#tab_5">4</ref> gives the macro-averaged WER and PER for the three baselines, and for the best overall submission from each team. As expected, the strongest baseline is the LSTM model. Across all submissions, the IMS team achieves both the lowest average WER, a 3% absolute (18% relative) word error reduction over the LSTM baseline, and the lowest overall PER, a 1% absolute (31% relative) phone error reduction over the LSTM baseline. The CLUZH and DeepSPIN-3 submissions achieve second and third place, respectively; the CU, UCBNLP, and UZH teams also submitted systems that outperform the LSTM baseline's WER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Discussion</head><p>When this task was initially proposed, there was some concern that the submissions-if not the baselines themselves-would easily achieve perfect or near-perfect performance on some languages. This was not the case. Even on the "easiest" language, the best submission has .89% WER, and for three languages, no submission achieves an error rate below 20%.</p><p>At the same time, we observe a large range of error rates across languages. It is tempting to speculate that word and/or phone error rates actually represent differences in difficulty. Insofar as this is correct, we can begin to ask what makes a language "hard to pronounce", much like how <ref type="bibr" target="#b27">Mielke et al. (2019)</ref> ask what makes a language "hard to language-model".</p><p>One thing that may make a language hard to pronounce is data sparsity. Consider the case of Korean, which has by far the highest baseline error rate of all fifteen languages. Three features of Korean and of hangul conspire to make this task particularly challenging. First, hangul is a syllabary, and therefore necessarily has a much larger graphemic inventory than an alphabet or alphasyllabary. A whopping 889 unique hangul characters appear across the 4,500 words used for this task. <ref type="bibr">4</ref> Secondly, hangul is a relatively deep or abstract orthography (in the sense of <ref type="bibr" target="#b42">Rogers 2005)</ref>; it operates at a roughly-morphophonemic level whereas Lithuanian and Hungarian, for example, are is roughly phonemic. Third, Korean has many phonological processes that operate across syllable boundaries. Since the effect of these processes is not indicated by the highly abstract, morphophonemic orthography, they can only be learned by observing the targeted syllable bigrams during training. <ref type="bibr" target="#b21">Lee et al. (2020)</ref>   to the LSTM baseline and observe errors caused by underapplication of these coda-onset cluster rules. It is unsurprising then that several submissions achieved substantial gains by either romanizing hangul or decomposing it into its constituent jamo during preprocessing, since both techniques reduce the size of the input vocabulary.</p><p>The results suggest that G2P technologies are not yet language-agnostic (in the sense of Bender 2009). However, some caution is in order here: inter-language differences in word error rate may also reflect inconsistencies in the WikiPron data itself. During the task, participants reported apparent transcription inconsistencies in the Bulgarian, Georgian, and Lithuanian Wiktionary data. If these inconsistencies are due to overly-narrow allophonic transcriptions, one might suspect that they can be learned by sufficiently sophisticated sequence-to-sequence models. However, if they represent free variation, inconsistent application of the transcription guidelines, or even typographical errors, they inflate error rates and increase the risk of overfitting. In response to this, we have begun development of quality assurance software for WikiPron, including a phone-based whitelisting approach. We anticipate that manual error analysis will reveal errors in the Wiktionary data, similar to the large number of test data er-rors identified by  for the 2017 CoNLL-SIGMORPHON morphological inflection task. To encourage this sort of error analysis, for the first time in the history of the SIGMOR-PHON workshop, we publicly release the predictions made by all 23 submissions. 5 Finally, we plan to apply large-scale consistency-enforcing edits upstream, i.e., to Wiktionary itself.</p><p>While the baselines are somewhat naïve and lack the sophisticated data augmentation and ensembling techniques used by the top submissions, we were pleasantly surprised by the substantial reductions in error achieved by the participating teams. As mentioned above, the best submissions handily outperforms the baselines for all languages. Interestingly, this is true for the most challenging languages-like Korean, where the best submission achieves a 45% relative word error reduction over the baseline-but also for Vietnamese, the language with the lowest baseline WER; there, the best submission achieves an impressive 81% relative word error reduction.</p><p>As mentioned above, top submissions make use of techniques such as preprocessing, data augmentation, ensembling, multi-task learning (e.g., phoneme-to-grapheme conversion), and self-   training. These techniques are commonly used in shared tasks and are essentially task-agnostic. However, we were surprised that few teams made use of task-specific resources such as the PHOIBLE phonemic inventories and feature specifications <ref type="bibr" target="#b29">(Moran and McCloy 2019)</ref> or rule-based G2P systems like Epitran <ref type="bibr" target="#b30">(Mortensen et al. 2018)</ref>.</p><p>Nor do any of the submissions make use of morphological analyzers or lexicons, which were found to be helpful in earlier work (e.g., <ref type="bibr" target="#b6">Coker et al. 1990</ref><ref type="bibr" target="#b10">, Demberg et al. 2007</ref>). We speculate that such resources might further improve performance. Finally we note that submissions make use of unsupervised tokenization techniques such as byte-pair encoding <ref type="bibr" target="#b45">(Schuster and Nakajima 2012)</ref>.</p><p>Finally, we note that several participants expressed interest in a low-resource version of this challenge, and two teams simulated a lowresource setting. We leave the design of a lowresource task for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>SIGMORPHON, under whose auspices this task was conducted, was once known as SIGPHON and was primarily focused on computational phonetics and phonology.</p><p>The shared task on multilingual grapheme-to-phoneme conversion, a uniquely phonological problem, thus represents something of a return to the roots of this special interest group. In this task, nine teams submitted 23 G2P systems for fifteen languages and achieved substantial improvements over the provided baselines. The results suggest many directions for improving G2P systems and the pronunciation dictionaries used to train them.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>3 pseudo-count to the frequency of all WikiPron entries. Wortschatz frequency data Japanese hiragana jpn どちらさま d o̞ t ͡ ɕ i ɾ a̠ s a̠ m a̠ Romanian rum bineînțeles b i n e ɨ n t s e l e s Vietnamese vie duyên phận z w i ə n ˧˧ f ə n ˧˨ ʔ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Languages, language codes, and example training data pairs for the shared task.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results for the three baseline systems.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The best baseline(s) and submission(s) WERs for each language.</figDesc><table><row><cell></cell><cell>WER</cell><cell>PER</cell></row><row><cell>Pair n-gram</cell><cell>22.00</cell><cell>4.92</cell></row><row><cell>LSTM</cell><cell>16.84</cell><cell>3.99</cell></row><row><cell>Transformer</cell><cell>17.51</cell><cell>4.30</cell></row><row><cell>CLUZH</cell><cell>14.13</cell><cell>2.82</cell></row><row><cell>CU-1</cell><cell>14.52</cell><cell>3.24</cell></row><row><cell>CUZ</cell><cell>20.87</cell><cell>5.23</cell></row><row><cell>DeepSPIN-3</cell><cell>14.15</cell><cell>2.92</cell></row><row><cell>IMS</cell><cell>13.81</cell><cell>2.76</cell></row><row><cell>NSU-1</cell><cell cols="2">63.56 20.76</cell></row><row><cell>UA-2</cell><cell>17.47</cell><cell>4.26</cell></row><row><cell>UBCNLP-1</cell><cell>14.99</cell><cell>3.30</cell></row><row><cell>UZH-3</cell><cell>16.34</cell><cell>3.27</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Macro-averaged results for the baselines and the best submission from each team.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We note that the term phoneme is a well-defined object in linguistic theory, and that referring to the elements of transcriptions as phonemes makes strong ontological commitments which may not be appropriate for a given pronunciation dictionary (cf.Lee et al. 2020, fn. 4). Therefore, in what follows we use the term phone, in a pre-theoretical sense, to refer to transcriptions symbols.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/sigmorphon/2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://docs.google.com/spreadsheets/d/ 1g0HyGeVzFrNt2pvNuu8L1voFFQY-0CwjTxGA3VXXNGI/ edit?usp=sharing</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Few syllabaries are so large. For instance, there are only 79 unique hiragana symbols in the Japanese data, but this relative size difference is not surprising given that Korean has a more permissive syllable structure than Japanese.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://drive.google.com/drive/folders/ 1kdawyeI17iGC0jlY_2dZQpK75hpShY_H?usp=sharing</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the contributors to WikiPronespecially Jackson Lee-and to Wiktionary itself. We also thank all those who met for lunch at Florence's mercato centrale to plan this task.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Linguistically naïve != language independent: why NLP needs linguistic typology</title>
		<author>
			<persName><forename type="first">Emily</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics: Virtuous, Vicious or Vacuous?</title>
				<meeting>the EACL 2009 Workshop on the Interaction between Linguistics and Computational Linguistics: Virtuous, Vicious or Vacuous?<address><addrLine>Athens</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="26" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Jointsequence models for grapheme-to-phoneme conversion</title>
		<author>
			<persName><forename type="first">Maximilian</forename><surname>Bisani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="434" to="451" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From phonology to syntax: unsupervised linguistic typology at different levels with language embeddings</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Isabella</forename><surname>Augenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="907" to="916" />
		</imprint>
	</monogr>
	<note>New Orleans</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Issues in building general letter to sound rules</title>
		<author>
			<persName><forename type="first">Alan</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Lenzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Pagel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third ESCA/COCOSDA Workshop on Speech Synthesis</title>
				<meeting><address><addrLine>Jenolan, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="77" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Listen, attend and spell: a neural network for large vocabulary conversational speech recognition</title>
		<author>
			<persName><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="4960" to="4964" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">State-of-the-art speech recognition with sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">Chung-Cheng</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohit</forename><surname>Prabhavalkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Nyugen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ron</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishka</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Gonina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chorowski</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Michiel</forename><surname>Bacchiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting><address><addrLine>Calgary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4774" to="4778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Morphology and rhyming: two powerful alternatives to letter-to-sound rules for speech synthesis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Cecil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">W</forename><surname>Coker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">Y</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName><surname>Liberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESCA Workshop on Speech Synthesis</title>
				<meeting><address><addrLine>Autrans, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page" from="83" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">CoNLL-SIGMORPHON 2017 shared task: universal morphological reinflection in 52 languages</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Géraldine</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL SIGMORPHON 2017</title>
				<meeting>the CoNLL SIGMORPHON 2017</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Jason Eisner, and Mans Hulden</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Shared Task: Universal Morphological Reinflection</title>
		<imprint>
			<biblScope unit="page" from="1" to="30" />
			<pubPlace>Vancouver</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Visible speech: the diverse oneness of writing systems</title>
		<author>
			<persName><forename type="first">John</forename><surname>Defrancis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>University of Hawaii Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Phonological constraints and morphological preprocessing for grapheme-to-phoneme conversion</title>
		<author>
			<persName><forename type="first">Vera</forename><surname>Demberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Möhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
				<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Grapheme-to-phoneme conversion with a multilingual transformer model: a contribution to the SIGMORPHON 2020 Shared Task 1</title>
		<author>
			<persName><forename type="first">Omnia</forename><surname>Elsaadany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Suter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Predicting pronunciations with syllabification and stress with recurrent neural networks</title>
		<author>
			<persName><forename type="first">Mason</forename><surname>Daan Van Esch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kanishka</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTER-SPEECH 2016: 17th Annual Conference of the International Speech Communication Association</title>
				<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2841" to="2845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Building large monolingual dictionaries at the Leipzig Corpora Collection: from 100 to 200 languages</title>
		<author>
			<persName><forename type="first">Dirk</forename><surname>Goldhahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Eckart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uwe</forename><surname>Quasthoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation</title>
				<meeting>the Eighth International Conference on Language Resources and Evaluation<address><addrLine>Istanbul</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="759" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Pynini: a Python library for weighted finite-state grammar compilation</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Gorman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGFSM Workshop on Statistical NLP and Weighted Automata</title>
				<meeting>the SIGFSM Workshop on Statistical NLP and Weighted Automata<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving homograph disambiguation with supervised machine learning</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gleb</forename><surname>Mazovetskiy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vitaly</forename><surname>Nikolaev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation</title>
				<meeting>the Eleventh International Conference on Language Resources and Evaluation<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1349" to="1352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Weird inflects but OK: making sense of morphological generation errors</title>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arya</forename><forename type="middle">D</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miikka</forename><surname>Silfverberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Magdalena</forename><surname>Markowska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</title>
				<meeting>the 23rd Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="140" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Arnob Mallik, and Grzegorz Kondrak. 2020. Lowresource G2P and P2G conversion with synthetic training data</title>
		<author>
			<persName><forename type="first">Bradley</forename><surname>Hauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmad</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixing</forename><surname>Habibi</surname></persName>
		</author>
		<author>
			<persName><surname>Luan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMOR-PHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIGMOR-PHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Adam: a method for stochastic optimization</title>
		<author>
			<persName><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations: Conference Track Proceedings</title>
				<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">UniMorph 2.0: universal morphology</title>
		<author>
			<persName><forename type="first">Christo</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Sylak-Glassman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Géraldine</forename><surname>Walther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekaterina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arya</forename><forename type="middle">D</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 11th Language Resources and Evaluation Conference</title>
				<meeting>the 11th Language Resources and Evaluation Conference<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1868" to="1873" />
		</imprint>
	</monogr>
	<note>Jason Eisner, and Mans Hulden</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">The Korean language reform of 1446: the origin, background, and early history of the Korean alphabet</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gari</surname></persName>
		</author>
		<author>
			<persName><surname>Ledyard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1966" />
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Massively multilingual pronunciation mining with WikiPron</title>
		<author>
			<persName><forename type="first">Jackson</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Elizabeth</forename><surname>Ashby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeonju</forename><surname>Garza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Lee-Sikka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arya</forename><forename type="middle">D</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><surname>Gorman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
				<meeting>the 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4216" to="4221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Structure learning in hidden conditional random fields for grapheme-to-phoneme conversion</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lehnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Yvon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2013: 14th Annual Conference of the International Speech Communication Association</title>
				<meeting><address><addrLine>Lyon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2326" to="2330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Effective approaches to attentionbased neural machine translation</title>
		<author>
			<persName><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1412" to="1421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Imitation learning for neural morphological string transduction</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Makarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2877" to="2882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">CLUZH at SIGMORPHON 2020 shared task on multilingual grapheme-to-phoneme conversion</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Makarov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">SkinAugment: auto-encoding speaker conversions for automatic speech translation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Arya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liezl</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Puzon</surname></persName>
		</author>
		<author>
			<persName><surname>Pino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7924" to="7928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">What kind of language is hard to language-model?</title>
		<author>
			<persName><forename type="first">Sabrina</forename><forename type="middle">J</forename><surname>Mielke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Eisner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4975" to="4989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The Unicode cookbook for linguists: managing writing systems using orthography profiles</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Cysouw</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Language Science Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">PHOIBLE 2.0. Max Planck Institute for the Science of Human History</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Mccloy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Epitran: precision G2P for many languages</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Mortensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Language Resources and Evaluation</title>
				<meeting>the Eleventh International Conference on Language Resources and Evaluation<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2710" to="2714" />
		</imprint>
	</monogr>
	<note>Siddharth Dalmia, and Patrick Littell</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">String transduction with target language models and insertion handling</title>
		<author>
			<persName><forename type="first">Garrett</forename><surname>Nicolai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saeed</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grzegorz</forename><surname>Kondrak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Brussels</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="43" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Phonetisaurus: exploring grapheme-tophoneme conversion with joint n-gram models in the WFST framework</title>
		<author>
			<persName><forename type="first">Josef</forename><forename type="middle">R</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nobuaki</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keikichi</forename><surname>Hirose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="907" to="938" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Vietnamese &apos;morphology&apos; and the definition of word. University of Pennsylvania Working Papers in Linguistics</title>
		<author>
			<persName><forename type="first">Rolf</forename><surname>Noyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="65" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Fairseq: a fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
				<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)<address><addrLine>Minneapolis</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Massively multilingual neural grapheme-tophoneme conversion</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Dehdari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Building Linguistically Generalizable NLP Systems</title>
				<meeting>the First Workshop on Building Linguistically Generalizable NLP Systems<address><addrLine>Copenhagen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="19" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">One-sizefits-all multilingual models</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>André</surname></persName>
		</author>
		<author>
			<persName><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sparse sequence-to-sequence models</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">André</forename><forename type="middle">F T</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1504" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Harnessing indirect training data for end-to-end automatic speech translation: tricks of the trade</title>
		<author>
			<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liezl</forename><surname>Puzon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xutai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arya</forename><forename type="middle">D</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deepak</forename><surname>Gopinath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">16th International Workshop on Spoken Language Translation</title>
				<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Frustratingly easy multilingual grapheme-to-phoneme conversion</title>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Grapheme-to-phoneme conversion using long short-term memory recurrent neural networks</title>
		<author>
			<persName><forename type="first">Kanishka</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuchun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haşim</forename><surname>Sak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Françoise</forename><surname>Beaufays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting><address><addrLine>Brisbane</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4225" to="4229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The OpenGrm open-source finite-state grammar software libraries</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Sproat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyril</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2012 System Demonstrations</title>
				<meeting>the ACL 2012 System Demonstrations<address><addrLine>Jeju Island</addrLine></address></meeting>
		<imprint>
			<publisher>Korea</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="61" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Writing systems: a linguistic approach</title>
		<author>
			<persName><forename type="first">Henry</forename><surname>Rogers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Blackwell</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Data augmentation for transformer-based G2P</title>
		<author>
			<persName><forename type="first">Zach</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mans</forename><surname>Hulden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Armenian alphabet</title>
		<author>
			<persName><forename type="first">Avedis</forename><surname>Sanjian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World&apos;s Writing Systems</title>
				<editor>
			<persName><forename type="first">T</forename><surname>Peter</surname></persName>
			<persName><forename type="first">Williams</forename><surname>Daniels</surname></persName>
			<persName><surname>Bright</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="356" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Japanese and Korean voice search</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaisuke</forename><surname>Nakajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
				<meeting><address><addrLine>Kyoto</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Char2Wav: end-to-end speech synthesis</title>
		<author>
			<persName><forename type="first">Jose</forename><surname>Sotelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Soroush</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kundan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">João</forename><forename type="middle">Felipe</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyle</forename><surname>Kastner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations: Workshop Track Proceedings</title>
				<meeting><address><addrLine>Toulon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Multilingual text analysis for text-to-speech synthesis</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Sproat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="369" to="380" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
				<meeting>IEEE Computer Society Conference on Computer Vision and Pattern Recognition<address><addrLine>Las Vegas</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hidden Markov models for grapheme to phoneme conversion</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTER-SPEECH 2005-EUROSPEECH 2005: 9th European Conference on Speech Communication and Technology</title>
				<meeting><address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1973" to="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uzskoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
				<meeting><address><addrLine>Long Beach</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">One model to pronounce them all: multilingual grapheme-to-phoneme conversion with a transformer ensemble</title>
		<author>
			<persName><forename type="first">Kaili</forename><surname>Vesik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Abdul-Mageed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miikka</forename><surname>Silfverberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The string-to-string correction problem</title>
		<author>
			<persName><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the ACM</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="168" to="173" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Unsupervised and lightlysupervised learning for rapid construction of TTS systems in multiple languages from &apos;found&apos; data: evaluation and analysis</title>
		<author>
			<persName><forename type="first">Oliver</forename><surname>Watts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriana</forename><surname>Stan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshitaka</forename><surname>Mamiya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mircea</forename><surname>Giurgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junichi</forename><surname>Yamagishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simon</forename><surname>King</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth ISCA Workshop on Speech Synthesis</title>
				<meeting><address><addrLine>Barcelona</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="101" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Encoding linear models as weighted finite-state transducers</title>
		<author>
			<persName><forename type="first">Ke</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cyril</forename><surname>Allauzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTER-SPEECH 2014: 15th Annual Conference of the International Speech Communication Association</title>
				<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1258" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Applying the transformer to character-level transduction</title>
		<author>
			<persName><forename type="first">Shijie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mans</forename><surname>Hulden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.10213</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Sequenceto-sequence neural net models for grapheme-tophoneme conversion</title>
		<author>
			<persName><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2015: 16th Annual Conference of the International Speech Communication Association</title>
				<meeting><address><addrLine>Dresden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3330" to="3334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Unsupervised word sense disambiguation rivaling supervised methods</title>
		<author>
			<persName><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd Annual Meeting of the Association for Computational Linguistics</title>
				<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="189" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Transformer based grapheme-tophoneme conversion</title>
		<author>
			<persName><forename type="first">Sevinj</forename><surname>Yolchuyeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Géza</forename><surname>Németh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bálint</forename><surname>Gyires-Tóth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH 2019: 20th Annual Conference of the International Speech Communication Association</title>
				<meeting><address><addrLine>Graz, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2095" to="2099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Ensemble self-training for low-resource languages: grapheme-to-phoneme conversion and morphological inflection</title>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ngoc</forename><forename type="middle">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonas</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIG-MORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
				<meeting>the 17th SIG-MORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology<address><addrLine>Seattle</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
