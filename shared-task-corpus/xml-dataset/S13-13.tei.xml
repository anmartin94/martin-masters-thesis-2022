<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2013 Task 13: Word Sense Induction for Graded and Non-Graded Senses</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
							<email>jurgens@di.uniroma1.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica Sapienza</orgName>
								<orgName type="institution">Università di Roma</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Ioannis Klapaftis Search Technology Center Europe</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2013 Task 13: Word Sense Induction for Graded and Non-Graded Senses</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most work on word sense disambiguation has assumed that word usages are best labeled with a single sense. However, contextual ambiguity or fine-grained senses can potentially enable multiple sense interpretations of a usage. We present a new SemEval task for evaluating Word Sense Induction and Disambiguation systems in a setting where instances may be labeled with multiple senses, weighted by their applicability. Four teams submitted nine systems, which were evaluated in two settings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Word Sense Disambiguation (WSD) attempts to identify which of a word's meanings applies in a given context. A long-standing task, WSD is fundamental to many NLP applications <ref type="bibr" target="#b28">(Navigli, 2009)</ref>. Typically, each usage of a word is treated as expressing only a single sense. However, contextual ambiguity as well as the relatedness of certain meanings can potentially elicit multiple sense interpretations. Recent work has shown that annotators find multiple applicable senses in a given target word context when using fine-grained sense inventories such as WordNet <ref type="bibr" target="#b36">(Véronis, 1998;</ref><ref type="bibr" target="#b26">Murray and Green, 2004;</ref><ref type="bibr" target="#b31">Passonneau et al., 2012b;</ref><ref type="bibr" target="#b16">Jurgens, 2013;</ref><ref type="bibr" target="#b27">Navigli et al., 2013)</ref>. Such contexts would be better annotated with multiple sense labels, weighting each sense according to its applicability <ref type="bibr" target="#b16">Jurgens, 2013)</ref>, in effect allowing ambiguity or multiple interpretations to be explicitly modeled. Accordingly, the first goal of this task is to evaluate WSD systems in a setting where instances may be labeled with one or more senses, weighted by their applicability.</p><p>WSD methods are ultimately defined and potentially restricted by their choice in sense inventory; for example, a sense inventory may have insufficient sense-annotated data to build WSD systems for specific types of text (e.g., social media), or the inventory may lack domain-specific senses. Word Sense Induction (WSI) has been proposed as a method for overcoming such limitations by learning the senses automatically from text. In essence, a WSI algorithm acts as a lexicographer by grouping word usages according to their shared meaning. The second goal of this task is to assess the performance of WSI algorithms when they are able to model multiple meanings of a usage with graded senses.</p><p>Task 12 focuses on disambiguating senses for 50 target lemmas: 20 nouns, 20 verbs, and 10 adjectives (Sec. 2). Since the Task evaluates only unsupervised systems, no training data was provided; however, to enable more comparison, Unsupervised WSD systems were also allowed to participate. Participating systems were evaluated in two settings (Sec. 3), depending on whether they used induced senses or WordNet 3.1 senses for their annotations. The results (Sec. 5) demonstrate a substantial improvement over the competitive most frequent sense baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Description</head><p>This task required participating systems to annotate instances of nouns, verb, and adjectives using Word-Net 3.1 <ref type="bibr">(Fellbaum, 1998)</ref>, which was selected due to its fine-grained senses. Participants could label each instance with one or more senses, weighting We all are relieved to lay aside our fight-or-flight reflexes and to commemorate our births from out of the dark centers of the women, to feel the complexity of our love and frustration with each other, to stretch our cognition to encompass the thoughts of every entity we know. dark%3:00:01:: -devoid of or deficient in light or brightness; shadowed or black dark%3:00:00:: -secret I ask because my practice has always been to allow about five minutes grace, then remove it. ask%2:32:02:: -direct or put; seek an answer to ask%2:32:04:: -address a question to and expect an answer from Table <ref type="table">1</ref>: Example instances with multiple senses due to intended double meanings (top) or contextual ambiguity (bottom). Senses are specified using their WordNet 3.1 sense keys. each by their applicability. Table <ref type="table">1</ref> highlights two example contexts where multiple senses apply. The first example shows a case of an intentional double meaning that evokes both the physical aspect of dark.a as being devoid of light and the causal result of being secret. In contrast, the second example shows a case of multiple interpretations from ambiguity; a different preceding context could generate the alternate interpretations "I ask <ref type="bibr">[you]</ref> because" (sense ask%2:32:04::) or "I ask [the question] because" (sense ask%2:32:02::).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>Three datasets were provided with the task. The trial dataset provided weighted word sense annotations using the data gathered by . The trial dataset consisted of 50 contexts for eight words, where each context was labeled with WordNet 3.0 sense ratings from three untrained lexicographers.</p><p>Due to the unsupervised nature of the task, participants were not provided with sense-labeled training data. However, WSI systems were provided with the ukWaC corpus <ref type="bibr" target="#b7">(Baroni et al., 2009)</ref> to use in inducing senses. Previous SemEval WSI tasks had provided participants with corpora specific to the task's target terms; in contrast, this task opted to use a large corpus to enable WSI methods that require corpuswide statistics, e.g., statistical associations.</p><p>Test data was drawn from the Open American National Corpus <ref type="bibr">(Ide and Suderman, 2004, OANC)</ref> across a variety of genres and from both the spoken and written portions of the corpus, summarized in Table <ref type="table" target="#tab_1">2</ref>. All contexts were manually inspected to ensure that the lemma being disambiguated was of the correct part of speech and had an interpretation that matched at least one WordNet 3.1 sense. This filtering also removed instances that were in a collocation, or had an idiomatic meaning. Ultimately, 4664 contexts were used as test data, with a minimum of 22 and a maximum of 100 contexts per word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sense Annotation</head><p>Recent work proposes to gather sense annotations using crowdsourcing in order to reduce the time and cost of acquiring sense-annotated corpora <ref type="bibr" target="#b8">(Biemann and Nygaard, 2010;</ref><ref type="bibr" target="#b31">Passonneau et al., 2012b;</ref><ref type="bibr" target="#b34">Rumshisky et al., 2012;</ref><ref type="bibr" target="#b16">Jurgens, 2013)</ref>. Therefore, we initially annotated the Task's data using the method of <ref type="bibr" target="#b16">Jurgens (2013)</ref>, where workers on Amazon Mechanical Turk (AMT) rated all senses of a word on a Likert scale from one to five, indicating the sense does not apply at all or completely applies, respectively. Twenty annotators were assigned per instance, with their ratings combined by selecting the most frequent rating. However, we found that while the annotators achieved moderate inter-annotator agreement (IAA), the resulting annotations were not of high enough quality to use in the Task's evaluations. Specifically, for some senses and contexts, AMT annotators required more information about sense distinctions than was feasible to integrate into the AMT setting, which led to consistent but incorrect sense assignments.</p><p>Therefore, the test data was annotated by the two authors, with the first author annotating all instances and the second author annotating a 10% sample of each lemma's instances in order to calculate IAA. IAA was calculated using <ref type="bibr">Krippendorff's α (Krippendorff, 1980;</ref><ref type="bibr" target="#b5">Artstein and Poesio, 2008)</ref>, which is an agreement measurement that adjusts for chance,   <ref type="bibr" target="#b29">(Passonneau et al., 2006)</ref>.</p><p>Table <ref type="table" target="#tab_1">2</ref> summarizes the annotation statistics for the Task's data. The annotation process resulted in far fewer senses per instance in the trial data, which we attribute to using trained annotators. An analysis across the corpora genres showed that the multiplesense annotation rates were similar. Due to the variety of contextual sources, all lemmas were observed with at least two distinct senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>We adopt a two-part evaluation setting used in previous SemEval WSI and WSD tasks <ref type="bibr" target="#b0">(Agirre and Soroa, 2007;</ref><ref type="bibr" target="#b22">Manandhar et al., 2010)</ref>. The first evaluation uses a traditional WSD task that directly compares WordNet sense labels. For WSI systems, their induced sense labels are converted to WordNet 3.1 labels via a mapping procedure. The second evaluation performs a direct comparison of the two sense inventories using clustering comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">WSD Task</head><p>In the first evaluation, we adopt a WSD task with three objectives: (1) detecting which senses are applicable, (2) ranking senses by their applicability, and (3) measuring agreement in applicability ratings with human annotators. Each objectives uses a specific measurement: (1) the Jaccard Index, (2) positionally-weighted Kendall's τ similarity, and (3) a weighted variant of Normalized Discounted Cumulative Gain, respectively. Each measure is bounded in [0, 1], where 1 indicates complete agreement with the gold standard. We generalize the traditional definition of WSD Recall such that it measures the average score for each measure across all instances, including those not labeled by the system. Systems are ultimately scored using the F1 measure between each objective's measure and Recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Transforming Induced Sense Labels</head><p>In the WSD setting, induced sense labels may be transformed into a reference inventory (e.g., Word-Net 3.1) using a sense mapping procedure. We follow the 80/20 setup of <ref type="bibr" target="#b22">Manandhar et al. (2010)</ref>, where the corpus is randomly divided into five partitions, four of which are used to learn the sense mapping; the sense labels for the held-out partition are then converted and compared with the gold standard. This process is repeated so that each partition is tested once. For learning the sense mapping function, we use the distribution mapping technique of <ref type="bibr" target="#b15">Jurgens (2012)</ref>, which takes into account the sense applicability weights in both labelings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Jaccard Index</head><p>Given two sets of sense labels for an instance, X and Y , the Jaccard Index is used to measure the agreement:</p><formula xml:id="formula_0">|X∩Y | |X∪Y | .</formula><p>The Jaccard Index is maximized when X and Y use identical labels, and is minimized when the sets of sense labels are disjoint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Positionally-Weighted Kendall's τ</head><p>Rank correlations have been proposed for evaluating a system's ability to order senses by applicability; in previous work, both  and <ref type="bibr" target="#b15">Jurgens (2012)</ref> propose rank correlation coefficients that assume all positions in the ranking are equally important. However, in the case of graded sense evaluation, often only a few senses are applicable, with the applicability ratings of the remaining senses being relatively inconsequential. Therefore, we consider an alternate rank scoring based on <ref type="bibr" target="#b18">Kumar and Vassilvitskii (2010)</ref>, which weights the penalty of reordering the lower positions less than the penalty of reordering the first ranks.</p><p>Kendall's τ distance, K, is a measure of the number of item position swaps required to make two sequences identical. <ref type="bibr" target="#b18">Kumar and Vassilvitskii (2010)</ref> extend this distance definition using a variable penalty function δ for the cost of swapping two positions, which we denote K δ . By using an appropriate δ, K δ can be biased towards the correctness of higher ranks by assigning a smaller δ to lower ranks. Because K δ is a distance measure, its value range will be different depending on the number of ranks used. Therefore, to convert the measure to a similarity we normalize the distance to [0, 1] by dividing by the maximum K δ distance and then subtracting the distance from one. Given two rankings x and y where x is the reference by which y is to be measured, we may compute the normalized similarity using</p><formula xml:id="formula_1">K sim δ = 1 − K δ (x, y) K max δ (x)</formula><p>.</p><p>(1) Equation 1 has its maximal value of one when ranking y is identical to ranking x, and its minimal value of zero when y is in the reverse order as x. We refer to this value as the positionally-weighted Kendall's τ similarity, K sim δ . As defined, K sim δ does not account for ties. Therefore, we arbitrarily break ties in a deterministic fashion for both rankings. Second, we define δ to assign higher cost to the first ranks: the cost to move an item into position i, δ i , is defined as n−(i+1) n , where n is the number of senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.4">Weighted NDCG</head><p>To compare the applicability ratings for sense annotations, we recast the annotation process in an Information Retrieval setting: Given an example context acting as a query over a word's senses, the task is to retrieve all applicable senses, ranking and scoring them by their applicability. <ref type="bibr" target="#b25">Moffat and Zobel (2008)</ref> propose using Discounted Cumulative Gain (DCG) as a method to compare a ranking against a baseline. Given (1) a gold standard weighting of the k senses applicable to a context, where w i denotes the applicability for sense i in the gold standard, and (2) a ranking of the k senses by some method, the DCG may be calculated as <ref type="bibr">i+1)</ref> . DCG is commonly normalized to [0, 1] so that the value is comparable when computed on rankings with different k and weight values. To normalize, the maximum value is calculated by first computing the DCG on the ranking when the k items are sorted by their weights, referred as the Ideal DCG (IDCG), and then normalizing as N DCG = DCG IDCG . The DCG only considers the weights assigned in the gold standard, which potentially masks importance differences in the weights assigned to the senses. Therefore, we propose weighting the DCG by the relative difference in the two weights. Given an alternate weighting of the k items, denoted asŵ i ,</p><formula xml:id="formula_2">k i=1 2 w i +1 −1 log 2 (</formula><formula xml:id="formula_3">W DCG = k i=1 min(w i ,ŵ i ) max(w i ,ŵ i ) 2 w i +1 − 1 log 2 (i) . (<label>2</label></formula><formula xml:id="formula_4">)</formula><p>The key impact in Equation 2 comes from weighting an item's contribution to the score by its relative deviation in absolute weight. A set of weights that achieves an equivalent ranking may have a low WDCG if the weights are significantly higher or lower than the reference. Equation 2 may be normalized in the same way as the DCG. We refer to this final normalized measure as the Weighted Normalized Discounted Cumulative Gain (WNDCG).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sense Cluster Comparisons</head><p>Sense induction can be viewed as an unsupervised clustering task where usages of a word are grouped into clusters, each representing uses of the same meaning. In previous SemEval tasks on sense induction, instances were labeled with a single sense, which yields a partition over the instances into disjoint sets. The proposed partition can then be compared with a gold-standard partition using many existing clustering comparison methods, such as the V-Measure <ref type="bibr" target="#b33">(Rosenberg and Hirschberg, 2007)</ref> or paired FScore . Such cluster comparison methods measure the degree of similarity between the sense boundaries created by lexicographers and those created by WSI methods.</p><p>In the present task, instances are potentially labeled both with multiple senses and with weights reflecting the applicability. This type of sense labeling produces a fuzzy clustering: An instance may belong to one or more sense clusters with its cluster membership relative to its weight for that sense. Formally, we refer to (1) a solution where the sets of instances overlap as a cover and (2) a solution where the sets overlap and instances may have partial memberships in a set as fuzzy cover.</p><p>We propose two new fuzzy measures for comparing fuzzy sense assignments: Fuzzy B-Cubed and Fuzzy Normalized Mutual Information. The two measures provide complementary information. B-Cubed summarizes the performance per instance and therefore provides an estimate of how well a system would perform on a new corpus with a similar sense distribution. In contrast, Fuzzy NMI is measured based on the clusters rather than the instances, thereby providing a performance analysis that is independent of the corpus sense distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Fuzzy B-Cubed</head><p>Bagga and Baldwin (1998) proposed a clustering evaluation known as B-Cubed, which compares two partitions on a per-item basis.  later extended the definition of B-Cubed to compare overlapping clusters (i.e., covers). We generalize B-Cubed further to handle the case of fuzzy covers. B-Cubed is based on precision and recall, which estimate the fit between two clusterings, X and Y at the item level. For an item i, precision reflects how many items sharing a cluster with i in X appear in its cluster in Y ; conversely, recall measures how many items sharing a cluster in Y with i also appear in its cluster in X. The final B-Cubed value is the harmonic mean of the two scores.</p><p>To generalize B-Cubed to fuzzy covers, we adopt the formalization of , who define item-based precision and recall functions, P and R, in terms of a correctness function, C → {0, 1}. For notational brevity, let avg be a function that returns the mean value of a series, and µ x (i) denote the set of clusters in clustering X of which item i is a member. B-Cubed precision and recall may therefore calculated over all n items:</p><formula xml:id="formula_5">B-Cubed Precision = avg i [ avg j =i∈∪µy(i) P (i, j)] (3) B-Cubed Recall = avg i [ avg j =i∈∪µx(i) R(i, j)]. (4)</formula><p>When comparing partitions, P and R are defined as 1 if two items cluster labels are identical. To generalize B-Cubed for fuzzy covers, we redefine P and R to account for differences in the partial cluster membership of items. Let X (i) denote the set of clusters of which i is a member, and w k (i) denote the membership weight of item i in cluster k in X. We therefore define C with respect to X of two items as</p><formula xml:id="formula_6">C(i, j, X) = k∈ X (i)∪ X (j) 1−|w k (i)−w k (j)|. (5)</formula><p>Equation 5 is maximized when i and j have identical membership weights in the clusters of which they are members. Importantly, Equation <ref type="formula">5</ref>generalizes to the correctness operations both when comparing partitions and covers, as defined by . Item-based Precision and Recall are then defined using Equation <ref type="formula">5</ref>as P (i, j, X) = Min(C(i,j,X),C(i,j,Y ))</p><formula xml:id="formula_7">C(i,j,X) and R(i, j, X) = Min(C(i,j,X),C(i,j,Y )) C(i,j,Y )</formula><p>, respectively. These fuzzy generalizations are used in Equations 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Fuzzy Normalized Mutual Information</head><p>Mutual information measures the dependence between two random variables. In the context of clustering evaluation, mutual information treats the sense labels as random variables and measures the level of agreement in which instances are labeled with the same senses <ref type="bibr" target="#b9">(Danon et al., 2005)</ref>. Formally, mutual information is defined as I(X; Y ) = H(X)−(H(X|Y ) where H(X) denotes the entropy of the random variable X that represents a partition, i.e., the sets of instances assigned to each sense. Typically, mutual information is normalized to [0, 1] in order to facilitate comparisons between multiple clustering solutions on the same scale <ref type="bibr" target="#b21">(Luo et al., 2009)</ref>, with M ax(H(X), H(Y )) being the recommended normalizing factor <ref type="bibr" target="#b37">(Vinh et al., 2010)</ref>.</p><p>In its original formulation Mutual information is defined only to compare non-overlapping cluster partitions. Therefore, we propose a new definition of mutual information between fuzzy covers using extension of <ref type="bibr" target="#b19">Lancichinetti et al. (2009)</ref> for calculating the normalized mutual information between covers. In the case of partitions, a clustering is represented as a discrete random variable whose states denote the probability of being assigned to each cluster. In the fuzzy cover setting, each item may be assigned to multiple clusters and no longer has a binary assignment to a cluster, but takes on a value in [0, 1]. Therefore, each cluster X i can be represented separately as a continuous random variable, with the entire fuzzy cover denoted as the variable X 1...k , where the ith entry of X is the continuous random variable for cluster i. However, by modeling clusters using continuous domain, differential entropy must be used for the continuous variables; importantly, differential entropy does not obey the same properties as discrete entropy and may be negative.</p><p>To avoid calculating entropy in the continuous domain, we therefore propose an alternative method of computing mutual information based on discretizing the continuous values of X i in the fuzzy setting. For the continuous random variable X i , we discretize the value by dividing up probability mass into discrete bins. That is, the support of X i is partitioned into disjoint ranges, each of which represents a discrete outcome of X i . As a result, X i becomes a categorical distribution over a set of weights ranges {w 1 , . . . , w n } that denote the strength of membership in the fuzzy set. With respect to sense annotation, this discretization process is analogous to having an annotator rate the applicability of a sense for an instance using a Likert scale instead of using a rational number within a fixed bound.</p><p>Discretizing the continuous cluster membership ratings into bins allows us to avoid the problematic interpretation of entropy in the continuous domain while still expanding the definition of mutual information from a binary cluster membership to one of degrees. Using the definition of X i and Y j as a categorical variables over discrete ratings, we may then estimate the entropy and joint entropy as follows.</p><formula xml:id="formula_8">H(X i ) = n i=1 p(w i )log 2 p(w i )<label>(6)</label></formula><p>where p(w i ) is the probability of an instance being labeled with rating w i Similarly, we may define the joint entropy of two fuzzy clusters as</p><formula xml:id="formula_9">H(X k , Y l ) = n i=1 m j=1 p(w i , w j )log 2 p(w i , w j ) (7)</formula><p>where p(w i , w j ) is the probability of an instance being labeled with rating w i in cluster X k and w j in cluster Y l , and m denotes the number of bins for Y l . The conditional entropy between two clusters may then be calculated as</p><formula xml:id="formula_10">H(X k |Y l ) = H(X k , Y l ) − H(Y l ).</formula><p>Together, Equations 6 and 7 may be used to define I(X, Y ) as in the original definition. We then normalize using the method of <ref type="bibr" target="#b24">McDaid et al. (2011)</ref>.</p><p>Based on the limited range of fuzzy memberships in [0, 1], we selected uniformly distributed bins in [0, 1] at 0.1 intervals when discretizing the membership weights for sense labelings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Baselines</head><p>Task 12 included multiple baselines based on modeling different types of WSI and WSD systems. Due to space constraints, we include only the four most descriptive here: (1) Semcor MFS which labels each instance with the most frequent sense of that lemma in SemCor, (2) Semcor Ranked Senses baseline, which labels each instance with all of the target lemma's senses, ranked according to their frequency in SemCor, using weights n−i+1 n , where n is the number of senses and i is the rank, (3) 1c1inst which labels each instance with its own induced sense and (4) All-instances, One sense which labels all instances with the same induced sense. The first two baselines directly use WordNet 3.1 senses, while the last two use induced senses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Participating Systems</head><p>Four teams submitted nine systems, seven of which used induced sense inventories. AI-KU submitted three WSI systems based on a lexical substitution method; a language model is built from the target word's contexts in the test data and the ukWaC corpus and then Fastsubs <ref type="bibr" target="#b38">(Yuret, 2012)</ref> is used to identify lexical substitutes for the target. Together, the contexts of the target and substitutes are used to build a distributional model using the S-CODE algorithm <ref type="bibr" target="#b23">(Maron et al., 2010)</ref>. The resulting contextual distributions are then clustered using K-means to identify word senses. The University of Melbourne (Unimelb) team submitted two WSI systems based on the approach of <ref type="bibr" target="#b20">Lau et al. (2012)</ref>. Their systems use a Hierarchical Dirichlet Process <ref type="bibr" target="#b35">(Teh et al., 2006)</ref>   like other teams, the Unimelb systems were trained on a Wikipedia corpus instead of the ukWaC corpus. The University of Sussex (UoS) team submitted two WSI systems that use dependency-parsed features from the corpus, which are then clustered into senses using the MaxMax algorithm <ref type="bibr" target="#b13">(Hope and Keller, 2013)</ref>; the resulting fine-grained clusters are then combined based on their degree of separability. The La Sapienza team submitted two Unsupervised WSD systems based applying Personalized Page Rank <ref type="bibr" target="#b1">(Agirre and Soroa, 2009</ref>) over a WordNet-based network to compare the similarity of each sense with the similarity of the context, ranking each sense according to its similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>Table <ref type="table" target="#tab_3">3</ref> shows the main results for all instances. Additionally, we report the number of induced clusters used to label each sense as #Cl and the number of resulting WordNet 3.1 senses for each sense with #S. As in previous WSD tasks, the MFS baseline was quite competitive, outperforming all systems on detecting which senses were applicable, measured using the Jaccard Index. However, most systems were able to outperform the MFS baseline on ranking senses and quantifying their applicability. Previous cluster comparison evaluations often faced issues with the measures being biased either towards the 1c1inst baseline or labeling all instances with the same sense. However, Table <ref type="table" target="#tab_3">3</ref>   systems are capable of performing well in both the Fuzzy NMI and Fuzzy B-Cubed measures, thereby avoiding the extreme performance of either baseline. An analysis of the systems' results showed that many systems labeled instances with a high number of senses, which could have been influenced by the trial data having significantly more instances labeled with multiple senses than the test data. Therefore, we performed a second analysis that partitioned the test set into two sets: those labeled with a single sense and those with multiple senses. For single-sense set, we modified the test setting to have systems also label instances with a single sense:</p><p>(1) the sense mapping function for WSI systems (Sec. 3.1.1) was modified so that after the mapping,  only the highest-weighted WordNet 3.1 sense was used, and (2) the La Sapienza system output was modified to retain only the highest weighted sense.</p><p>In this single-sense setting, systems were evaluated using the standard WSD Precision and Recall measures; we report the F1 measure of Precision and Recall. The remaining subset of instances annotated with multiple senses were evaluated separately. Table <ref type="table" target="#tab_5">4</ref> shows the systems' performance on single-sense instances, revealing substantially increased performance and improvement over the MFS baseline for WSI systems. Notably, the performance of the best sense-remapped WSI systems surpasses the performance of many supervised WSD systems in previous WSD evaluations <ref type="bibr">(Kilgarriff, 2002;</ref><ref type="bibr">Mihalcea et al., 2004;</ref><ref type="bibr" target="#b32">Pradhan et al., 2007;</ref><ref type="bibr" target="#b2">Agirre et al., 2010)</ref>. This performance suggests that WSI systems using graded labels provide a way to leverage huge amounts of unannotated corpus data for finding sense-related features in order to train semi-supervised WSD systems.</p><p>Table <ref type="table" target="#tab_7">5</ref> shows the performance on the subset of instances that were annotated with multiple senses. We note that in this setting, the mapping procedure transforms the All-Instances One Sense baseline into the average applicability rating for each sense in the test corpus. Notably, the La Sapienza systems sees a significant performance increase in this setting; their systems label each instance with all of the lemma's senses, which significantly de-grades performance in the most common case where only a single sense applies. However, when multiple senses are known to be present, their method for quantifying sense applicability appears closest to the gold standard judgments. Furthermore, the majority of WSI systems are able to surpass all four baselines on identifying which senses are present and quantifying their applicability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have introduced a new evaluation setting for WSI and WSD systems where systems are measured by their ability to detect and weight multiple applicable senses for a single context. Four teams submitted nine systems, annotating a total of 4664 contexts for 50 words from the OANC. Many systems were able to surpass the competitive MFS baseline. Furthermore, when WSI systems were trained to produce only a single sense label, the performance of resulting semi-supervised WSD systems surpassed that of many supervised systems in previous WSD evaluations. Future work may assess the impact of graded sense annotations in a task-based setting. All materials have been released on the task website. <ref type="bibr">1</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Test data used in Task 12, divided according to source type</figDesc><table><row><cell>ranging in (−1, 1] for interval data, where 1 indi-</cell></row><row><cell>cates perfect agreement and -1 indicates systematic</cell></row><row><cell>disagreement; two random annotations have an ex-</cell></row><row><cell>pected α of zero. We treat each sense and instance</cell></row><row><cell>combination as a separate item to rate. The total IAA</cell></row><row><cell>for the dataset was 0.504, and on individual words,</cell></row><row><cell>ranged from 0.903 for number.n to 0.00 for win.v.</cell></row><row><cell>While this IAA is less than the 0.8 recommended by</cell></row><row><cell>Krippendorff (2004), it is consistent with the IAA</cell></row><row><cell>distribution for the sense annotations of MASC on</cell></row><row><cell>other parts of the OANC corpus: Passonneau et al.</cell></row><row><cell>(2012a) reports an α of 0.88 to -0.02 with the MASI</cell></row><row><cell>statistic</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance on the five evaluation measures for all system and selected baselines. Top system performances are marked in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>System performance in the single-sense setting. Top system performances are marked in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>System performance on all instances labeled with multiple senses. Top system performances are marked in bold.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Rebecca Passonneau for her feedback and suggestions for target lemmas used in this task. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semeval-2007 task 2: Evaluating word sense induction and discrimination systems</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Workshop on Semantic Evaluations</title>
				<meeting>the Fourth International Workshop on Semantic Evaluations</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Personalizing PageRank for Word Sense Disambiguation</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aitor</forename><surname>Soroa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EACL</title>
				<meeting>EACL</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="33" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">SemEval-2010 task 17: All-words word sense disambiguation on specific domains</title>
		<author>
			<persName><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Oier López De Lacalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piek</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval-2010. ACL</title>
				<meeting>SemEval-2010. ACL</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A comparison of extrinsic clustering evaluation metrics based on formal constraints</title>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Javier</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felisa</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="461" to="486" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The role of named entities in web people search</title>
		<author>
			<persName><forename type="first">Javier</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
				<meeting>EMNLP</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="534" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Inter-coder agreement for computational linguistics</title>
		<author>
			<persName><forename type="first">Ron</forename><surname>Artstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="596" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Algorithms for scoring coreference chains</title>
		<author>
			<persName><forename type="first">Amit</forename><surname>Bagga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Breck</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Linguistic Coreference Workshop at LREC</title>
				<meeting>the Linguistic Coreference Workshop at LREC</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="563" to="566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The WaCky wide web: A collection of very large linguistically processed webcrawled corpora. Language Resources and Evaluation</title>
		<author>
			<persName><forename type="first">Marco</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Silvia</forename><surname>Bernardini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adriano</forename><surname>Ferraresi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eros</forename><surname>Zanchetta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="209" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Crowdsourcing wordnet</title>
		<author>
			<persName><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valerie</forename><surname>Nygaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 5th International Conference of the Global WordNet Association (GWC-2010)</title>
				<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Comparing community structure identification</title>
		<author>
			<persName><forename type="first">Leon</forename><surname>Danon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Albert</forename><surname>Díaz-Guilera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jordi</forename><surname>Duch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Arenas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Mechanics: Theory and Experiment</title>
		<imprint>
			<biblScope unit="issue">09</biblScope>
			<biblScope unit="page">P09008</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graded word sense assignment</title>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="440" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Investigations on word senses and word usages</title>
		<author>
			<persName><forename type="first">Katrin</forename><surname>Erk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Gaylord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
				<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">WordNet: An Electronic Lexical Database</title>
		<editor>Christine Fellbaum</editor>
		<imprint>
			<date type="published" when="1998" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">MaxMax: A Graph-Based Soft Clustering Algorithm Applied to Word Sense Induction</title>
		<author>
			<persName><forename type="first">David</forename><surname>Hope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Keller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CICLing</title>
				<meeting>CICLing</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="368" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The american national corpus first release</title>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keith</forename><surname>Suderman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Language Resources and Evaluation Conference</title>
				<meeting>the Fourth Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1681" to="1684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An Evaluation of Graded Sense Disambiguation using Word Sense Induction</title>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of *SEM, the First Joint Conference on Lexical and Computational Semantics. ACL</title>
				<meeting>*SEM, the First Joint Conference on Lexical and Computational Semantics. ACL</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Embracing Ambiguity: A Comparison of Annotation Methodologies for Crowdsourcing Word Sense Labels</title>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL). ACL. Adam Kilgarriff</title>
				<meeting>the North American Chapter of the Association for Computational Linguistics (NAACL). ACL. Adam Kilgarriff</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL-SIGLEX SENSEVAL-2 Workshop</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Content Analysis: An Introduction to Its Methodology</title>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Krippendorff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<pubPlace>Sage, Beverly Hills, CA. Klaus Krippendorff; Sage, Thousand Oaks, CA</pubPlace>
		</imprint>
	</monogr>
	<note>Content Analysis: An Introduction to Its Methodology. second edition</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Generalized distances between rankings</title>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on World Wide Web (WWW)</title>
				<meeting>the 19th International Conference on World Wide Web (WWW)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="571" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Detecting the overlapping and hierarchical community structure in complex networks</title>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Lancichinetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Santo</forename><surname>Fortunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">János</forename><surname>Kertész</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">33015</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Word sense induction for novel sense detection</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Jey Han Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diana</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for computational</title>
				<meeting>the 13th Conference of the European Chapter of the Association for computational</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Information-theoretic distance measures for clustering validation: Generalization and normalization</title>
		<author>
			<persName><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guoxing</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junjie</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhongzhi</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1249" to="1262" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">SemEval-2010 task 14: Word sense induction &amp; disambiguation</title>
		<author>
			<persName><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Klapaftis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><forename type="middle">S</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
				<meeting>the 5th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="63" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sphere embedding: An application to part-ofspeech induction</title>
		<author>
			<persName><forename type="first">Yariv</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Lamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elie</forename><surname>Bienenstock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of Advances in Neural Information Processing Systems (NIPS)</title>
				<meeting>Advances in Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Normalized mutual information to evaluate overlapping community finding algorithms</title>
		<author>
			<persName><forename type="first">Aaron</forename><forename type="middle">F</forename><surname>Mcdaid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Hurley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1110.2515</idno>
	</analytic>
	<monogr>
		<title level="m">Senseval-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text</title>
				<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="25" to="28" />
		</imprint>
	</monogr>
	<note>The Senseval-3 English lexical sample task</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Rank-biased precision for measurement of retrieval effectiveness</title>
		<author>
			<persName><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Lexical knowledge and human disagreement on a wsd task</title>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Craig</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="222" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semeval-2013 task 12: Multilingual word sense disambiguation</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniele</forename><surname>Vanilla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
				<meeting>the 7th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Word Sense Disambiguation: A Survey</title>
		<author>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="69" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Inter-annotator agreement on a multilingual semantic annotation task</title>
		<author>
			<persName><forename type="first">Rebecca</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC)</title>
				<meeting>the Fifth International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1951" to="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The MASC word sense sentence corpus</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Collin</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christiane</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Fellbaum</surname></persName>
		</author>
		<author>
			<persName><surname>Ide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC</title>
				<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Multiplicity and word sense: evaluating and learning from multiply labeled word sense annotations. Language Resources and Evaluation</title>
		<author>
			<persName><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vikas</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ansaf</forename><surname>Salleb-Aouissi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Ide</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">SemEval-2007 task 17: English lexical sample, SRL, and all-words</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sameer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th International Workshop on Semantic Evaluations. ACL</title>
				<meeting>the 4th International Workshop on Semantic Evaluations. ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Vmeasure: A conditional entropy-based external cluster evaluation measure</title>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julia</forename><surname>Hirschberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL). ACL</title>
				<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL). ACL</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Word sense inventories by non-experts</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nick</forename><surname>Botchan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophie</forename><surname>Kushkuley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC)</title>
				<meeting>the 8th International Conference on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Hierarchical dirichlet processes</title>
		<author>
			<persName><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">J</forename><surname>Beal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">476</biblScope>
			<biblScope unit="page" from="1566" to="1581" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A study of polysemy judgments and inter-annotator agreement</title>
		<author>
			<persName><forename type="first">Jean</forename><surname>Véronis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Program and advanced papers of the Senseval workshop</title>
				<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Information theoretic measures for clusterings comparison: Variants, properties, normalization and correction for chance</title>
		<author>
			<persName><forename type="first">Julien</forename><surname>Nguyen Xuan Vinh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Epps</surname></persName>
		</author>
		<author>
			<persName><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2837" to="2854" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">FASTSUBS: An Efcient Admissible Algorithm for Finding the Most Likely Lexical Substitutes Using a Statistical Language Model</title>
		<author>
			<persName><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing Research Repository</title>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
