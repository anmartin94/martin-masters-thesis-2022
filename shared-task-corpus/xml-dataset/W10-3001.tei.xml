<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
							<email>rfarkas@inf.u-szeged.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Research Group on Artificial Intelligence</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Veronika</forename><surname>Vincze</surname></persName>
							<email>vinczev@inf.u-szeged.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">György</forename><surname>Móra</surname></persName>
							<email>gymora@inf.u-szeged.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">János</forename><surname>Csirik</surname></persName>
							<email>csirik@inf.u-szeged.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Research Group on Artificial Intelligence</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">György</forename><surname>Szarvas</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Ubiquitous Knowledge Processing Lab</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The CoNLL-2010 Shared Task was dedicated to the detection of uncertainty cues and their linguistic scope in natural language texts. The motivation behind this task was that distinguishing factual and uncertain information in texts is of essential importance in information extraction. This paper provides a general overview of the shared task, including the annotation protocols of the training and evaluation datasets, the exact task definitions, the evaluation metrics employed and the overall results. The paper concludes with an analysis of the prominent approaches and an overview of the systems submitted to the shared task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Every year since 1999, the Conference on Computational Natural Language Learning (CoNLL) provides a competitive shared task for the Computational Linguistics community. After a fiveyear period of multi-language semantic role labeling and syntactic dependency parsing tasks, a new task was introduced in 2010, namely the detection of uncertainty and its linguistic scope in natural language sentences.</p><p>In natural language processing (NLP) -and in particular, in information extraction (IE) -many applications seek to extract factual information from text. In order to distinguish facts from unreliable or uncertain information, linguistic devices such as hedges (indicating that authors do not or cannot back up their opinions/statements with facts) have to be identified. Applications should handle detected speculative parts in a different manner. A typical example is protein-protein interaction extraction from biological texts, where the aim is to mine text evidence for biological entities that are in a particular relation with each other.</p><p>Here, while an uncertain relation might be of some interest for an end-user as well, such information must not be confused with factual textual evidence (reliable information).</p><p>Uncertainty detection has two levels. Automatic hedge detectors might attempt to identify sentences which contain uncertain information and handle whole sentences in a different manner or they might attempt to recognize in-sentence spans which are speculative. In-sentence uncertainty detection is a more complicated task compared to the sentence-level one, but it has benefits for NLP applications as there may be spans containing useful factual information in a sentence that otherwise contains uncertain parts. For example, in the following sentence the subordinated clause starting with although contains factual information while uncertain information is included in the main clause and the embedded question.</p><p>Although IL-1 has been reported to contribute to Th17 differentiation in mouse and man, it remains to be determined {whether therapeutic targeting of IL-1 will substantially affect IL-17 in RA}.</p><p>Both tasks were addressed in the CoNLL-2010 Shared Task, in order to provide uniform manually annotated benchmark datasets for both and to compare their difficulties and state-of-the-art solutions for them. The uncertainty detection problem consists of two stages. First, keywords/cues indicating uncertainty should be recognized then either a sentence-level decision is made or the linguistic scope of the cue words has to be identified. The latter task falls within the scope of semantic analysis of sentences exploiting syntactic patterns, as hedge spans can usually be determined on the basis of syntactic patterns dependent on the keyword.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The term hedging was originally introduced by <ref type="bibr" target="#b11">Lakoff (1972)</ref>. However, hedge detection has received considerable interest just recently in the NLP community. <ref type="bibr" target="#b13">Light et al. (2004)</ref> used a handcrafted list of hedge cues to identify speculative sentences in MEDLINE abstracts and several biomedical NLP applications incorporate rules for identifying the certainty of extracted information <ref type="bibr" target="#b3">(Friedman et al., 1994;</ref><ref type="bibr" target="#b1">Chapman et al., 2007;</ref><ref type="bibr" target="#b0">Aramaki et al., 2009;</ref><ref type="bibr" target="#b2">Conway et al., 2009)</ref>. The most recent approaches to uncertainty detection exploit machine learning models that utilize manually labeled corpora. <ref type="bibr" target="#b14">Medlock and Briscoe (2007)</ref> used single words as input features in order to classify sentences from biological articles (FlyBase) as speculative or non-speculative based on semi-automatically collected training examples. <ref type="bibr" target="#b18">Szarvas (2008)</ref> extended the methodology of <ref type="bibr" target="#b14">Medlock and Briscoe (2007)</ref> to use n-gram features and a semi-supervised selection of the keyword features. <ref type="bibr" target="#b7">Kilicoglu and Bergler (2008)</ref> proposed a linguistically motivated approach based on syntactic information to semi-automatically refine a list of hedge cues. <ref type="bibr" target="#b4">Ganter and Strube (2009)</ref> proposed an approach for the automatic detection of sentences containing uncertainty based on Wikipedia weasel tags and syntactic patterns.</p><p>The BioScope corpus <ref type="bibr" target="#b21">(Vincze et al., 2008</ref>) is manually annotated with negation and speculation cues and their linguistic scope. It consists of clinical free-texts, biological texts from full papers and scientific abstracts. Using BioScope for training and evaluation, <ref type="bibr" target="#b15">Morante and Daelemans (2009)</ref> developed a scope detector following a supervised sequence labeling approach whileÖzgür and Radev (2009) developed a rule-based system that exploits syntactic patterns.</p><p>Several related works have also been published within the framework of The BioNLP'09 Shared Task on Event Extraction <ref type="bibr" target="#b10">(Kim et al., 2009)</ref>, where a separate subtask was dedicated to predicting whether the recognized biological events are under negation or speculation, based on the GENIA event corpus annotations <ref type="bibr" target="#b8">(Kilicoglu and Bergler, 2009;</ref><ref type="bibr" target="#b20">Van Landeghem et al., 2009)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Uncertainty Annotation Guidelines</head><p>The shared task addressed the detection of uncertainty in two domains. As uncertainty detection is extremely important for biomedical information extraction and most existing approaches have targeted such applications, participants were asked to develop systems for hedge detection in biological scientific articles. Uncertainty detection is also important, e.g. in encyclopedias, where the goal is to collect reliable world knowledge about real-world concepts and topics. For example, Wikipedia explicitly declares that statements reflecting author opinions or those not backed up by facts (e.g. references) should be avoided (see 3.2 for details). Thus, the community-edited encyclopedia, Wikipedia became one of the subjects of the shared task as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hedges in Biological Scientific Articles</head><p>In the biomedical domain, sentences were manually annotated for both hedge cues and their linguistic scope. Hedging is typically expressed by using specific linguistic devices (which we refer to as cues in this article) that modify the meaning or reflect the author's attitude towards the content of the text. Typical hedge cues fall into the following categories:</p><p>• auxiliaries: may, might, can, would, should, could, etc.</p><p>• verbs of hedging or verbs with speculative content: suggest, question, presume, suspect, indicate, suppose, seem, appear, favor, etc.</p><p>• adjectives or adverbs: probable, likely, possible, unsure, etc.</p><p>• conjunctions: or, and/or, either . . . or, etc.</p><p>However, there are some cases where a hedge is expressed via a phrase rather than a single word. Complex keywords are phrases that express uncertainty together, but not on their own (either the semantic interpretation or the hedging strength of its subcomponents are significantly different from those of the whole phrase). An instance of a complex keyword can be seen in the following sentence:</p><p>Mild bladder wall thickening {raises the question of cystitis}.</p><p>The expression raises the question of may be substituted by suggests and neither the verb raises nor the noun question convey speculative meaning on their own. However, the whole phrase is speculative therefore it is marked as a hedge cue.</p><p>During the annotation process, a min-max strategy for the marking of keywords (min) and their scope (max) was followed. On the one hand, when marking the keywords, the minimal unit that expresses hedging and determines the actual strength of hedging was marked as a keyword. On the other hand, when marking the scopes of speculative keywords, the scope was extended to the largest syntactic unit possible. That is, all constituents that fell within the uncertain interpretation were included in the scope. Our motivation here was that in this way, if we simply disregard the marked text span, the rest of the sentence can usually be used for extracting factual information (if there is any). For instance, in the example above, we can be sure that the symptom mild bladder wall thickening is exhibited by the patient but a diagnosis of cystitis would be questionable.</p><p>The scope of a speculative element can be determined on the basis of syntax. The scopes of the BioScope corpus are regarded as consecutive text spans and their annotation was based on constituency grammar. The scope of verbs, auxiliaries, adjectives and adverbs usually starts right with the keyword. In the case of verbal elements, i.e. verbs and auxiliaries, it ends at the end of the clause or sentence, thus all complements and adjuncts are included. The scope of attributive adjectives generally extends to the following noun phrase, whereas the scope of predicative adjectives includes the whole sentence. Sentential adverbs have a scope over the entire sentence, while the scope of other adverbs usually ends at the end of the clause or sentence. Conjunctions generally have a scope over the syntactic unit whose members they coordinate. Some linguistic phenomena (e.g. passive voice or raising) can change scope boundaries in the sentence, thus they were given special attention during the annotation phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Wikipedia Weasels</head><p>The chief editors of Wikipedia have drawn the attention of the public to uncertainty issues they call weasel 1 . A word is considered to be a weasel word if it creates an impression that something important has been said, but what is really communicated is vague, misleading, evasive or ambiguous. Weasel words do not give a neutral account of facts, rather, they offer an opinion without any backup or source. The following sentence does not specify the source of information, it is just the vague term some people that refers to the holder of this opinion: Some people claim that this results in a better taste than that of other diet colas (most of which are sweetened with aspartame alone).</p><p>Statements with weasel words usually evoke questions such as Who says that?, Whose opinion is this? and How many people think so?.</p><p>Typical instances of weasels can be grouped in the following way (we offer some examples as well):</p><p>• Adjectives and adverbs elements referring to uncertainty: probable, likely, possible, unsure, often, possibly, allegedly, apparently, perhaps, etc. elements denoting generalization: widely, traditionally, generally, broadlyaccepted, widespread, etc.</p><p>qualifiers and superlatives: global, superior, excellent, immensely, legendary, best, (one of the) largest, most prominent, etc. elements expressing obviousness: clearly, obviously, arguably, etc.</p><p>• Auxiliaries may, might, would, should, etc.</p><p>• Verbs verbs with speculative content and their passive forms: suggest, question, presume, suspect, indicate, suppose, seem, appear, favor, etc. passive forms with dummy subjects: It is claimed that . . . It has been mentioned . . . It is known . . . there is / there are constructions: There is evidence/concern/indication that. . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Numerically vague expressions / quantifiers</head><p>certain, numerous, many, most, some, much, everyone, few, various, one group of, etc. Experts say . . . Some people think . . . More than 60% percent . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>• Nouns</head><p>speculation, proposal, consideration, etc. Rumour has it that . . . Common sense insists that . . . However, the use of the above words or grammatical devices does not necessarily entail their being a weasel cue since their use may be justifiable in their contexts.</p><p>As the main application goal of weasel detection is to highlight articles which should be improved (by reformulating or adding factual issues), we decided to annotate only weasel cues in Wikipedia articles, but we did not mark their scopes.</p><p>During the manual annotation process, the following cue marking principles were employed. Complex verb phrases were annotated as weasel cues since in some cases, both the passive construction and the verb itself are responsible for the weasel. In passive forms with dummy subjects and there is / there are constructions, the weasel cue included the grammatical subject (i.e. it and there) as well. As for numerically vague expressions, the noun phrase containing a quantifier was marked as a weasel cue. If there was no quantifier (in the case of a bare plural), the noun was annotated as a weasel cue. Comparatives and superlatives were annotated together with their article. Anaphoric pronouns referring to a weasel word were also annotated as weasel cues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task Definitions</head><p>Two uncertainty detection tasks (sentence classification and in-sentence hedge scope detection) in two domains (biological publications and Wikipedia articles) with three types of submissions (closed, cross and open) were given to the participants of the CoNLL-2010 Shared Task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Detection of Uncertain Sentences</head><p>The aim of Task1 was to develop automatic procedures for identifying sentences in texts which contain unreliable or uncertain information. In particular, this task is a binary classification problem, i.e. factual and uncertain sentences have to be distinguished.</p><p>As training and evaluation data</p><p>• Task1B: biological abstracts and full articles (evaluation data contained only full articles) from the BioScope corpus and</p><p>• Task1W: paragraphs from Wikipedia possibly containing weasel information were provided. The annotation of weasel/hedge cues was carried out on the phrase level, and sentences containing at least one cue were considered as uncertain, while sentences with no cues were considered as factual. The participating systems had to submit a binary classification (certain vs. uncertain) of the test sentences while marking cues in the submissions was voluntary (but participants were encouraged to do this).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">In-sentence Hedge Scope Resolution</head><p>For Task2, in-sentence scope resolvers had to be developed. The training and evaluation data consisted of biological scientific texts, in which instances of speculative spans -that is, keywords and their linguistic scope -were annotated manually. Submissions to Task2 were expected to automatically annotate the cue phrases and the left and right boundaries of their scopes (exactly one scope must be assigned to a cue phrase).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation Metrics</head><p>The evaluation for Task1 was carried out at the sentence level, i.e. the cue annotations in the sentence were not taken into account. The F β=1 measure (the harmonic mean of precision and recall) of the uncertain class was employed as the chief evaluation metric. The Task2 systems were expected to mark cueand corresponding scope begin/end tags linked together by using some unique IDs. A scope-level F β=1 measure was used as the chief evaluation metric where true positives were scopes which exactly matched the gold standard cue phrases and gold standard scope boundaries assigned to the cue word. That is, correct scope boundaries with incorrect cue annotation and correct cue words with bad scope boundaries were both treated as errors.</p><p>This scope-level metric is very strict. For instance, the requirement of the precise match of the cue phrase is questionable as -from an application point of view -the goal is to find uncertain text spans and the evidence for this is not so important. However, the annotation of cues in datasets is essential for training scope detectors since locating the cues usually precedes the identification of their scope. Hence we decided to incorporate cue matches into the evaluation metric.</p><p>Another questionable issue is the strict boundary matching requirement. For example, including or excluding punctuations, citations or some bracketed expressions, like (see Figure <ref type="figure">1</ref>) from a scope is not crucial for an otherwise accurate scope detector. On the other hand, the list of such ignorable phenomena is arguable, especially across domains. Thus, we considered the strict boundary matching to be a straightforward and unambiguous evaluation criterion. Minor issues like those mentioned above could be handled by simple post-processing rules. In conclusion we think that the uncertainty detection community may find more flexible evaluation criteria in the future but the strict scope-level metric is definitely a good starting point for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Closed and Open Challenges</head><p>Participants were invited to submit results in different configurations, where systems were allowed to exploit different kinds of annotated resources. The three possible submission categories were:</p><p>• Closed, where only the labeled and unlabeled data provided for the shared task were allowed, separately for each domain (i.e. biomedical train data for biomedical test set and Wikipedia train data for Wikipedia test set). No further manually crafted resources of uncertainty information (i.e. lists, annotated data, etc.) could be used in any domain.</p><p>On the other hand, tools exploiting the manual annotation of linguistic phenomena not related to uncertainty (such as POS taggers and parsers trained on labeled corpora) were allowed.</p><p>• Cross-domain was the same as the closed one but all data provided for the shared task were allowed for both domains (i.e. Wikipedia train data for the biomedical test set, the biomedical train data for Wikipedia test set or a union of Wikipedia and biomedical train data for both test sets).</p><p>• Open, where any data and/or any additional manually created information and resource (which may be related to uncertainty) were allowed for both domains.</p><p>The motivation behind the cross-domain and the open challenges was that in this way, we could assess whether adding extra (i.e. not domainspecific) information to the systems can contribute to the overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Datasets</head><p>Training and evaluation corpora were annotated manually for hedge/weasel cues and their scope by two independent linguist annotators. Any differences between the two annotations were later resolved by the chief annotator, who was also responsible for creating the annotation guidelines and training the two annotators. The datasets are freely available 2 for further benchmark experiments at http://www.inf.u-szeged.hu/ rgai/conll2010st. Since uncertainty cues play an important role in detecting sentences containing uncertainty, they are tagged in the Task1 datasets as well to enhance training and evaluation of systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Biological Publications</head><p>The biological training dataset consisted of the biological part of the BioScope corpus <ref type="bibr" target="#b21">(Vincze et al., 2008)</ref>, hence it included abstracts from the GE-NIA corpus, 5 full articles from the functional genomics literature (related to the fruit fly) and 4 articles from the open access BMC Bioinformatics website. The automatic segmentation of the documents was corrected manually and the sentences (14541 in number) were annotated manually for hedge cues and their scopes.</p><p>The evaluation dataset was based on 15 biomedical articles downloaded from the publicly available PubMedCentral database, including 5 random articles taken from the BMC Bioinformatics journal in October 2009, 5 random articles to which the drosophila MeSH term was assigned and 5 random articles having the MeSH terms human, blood cells and transcription factor (the same terms which were used to create the Genia corpus). These latter ten articles were also published in 2009. The aim of this article selection procedure was to have a theme that was close to the training corpus. The evaluation set contained 5003 sentences, out of which 790 were uncertain. These texts were manually annotated for hedge cues and their scope. To annotate the training and the evaluation datasets, the same annotation principles were applied.</p><p>For both Task1 and Task2, the same dataset was provided, the difference being that for Task1, only hedge cues and sentence-level uncertainty were given, however, for Task2, hedge cues and their scope were marked in the text. For the selection of the Wikipedia paragraphs used to construct the training and evaluation datasets, we exploited the weasel tags added by the editors of the encyclopedia (marking unsupported opinions or expressions of a non-neutral point of view). Each paragraph containing weasel tags (5874 different ones) was extracted from the history dump of English Wikipedia. First, 438 randomly selected paragraphs were manually annotated from this pool then the most frequent cue phrases were collected. Later on, two other sets of Wikipedia paragraphs were gathered on the basis of whether they contained such cue phrases or not. The aim of this sampling procedure was to provide large enough training and evaluation samples containing weasel words and also occurrences of typical weasel words in non-weasel contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Wikipedia Datasets</head><p>Each sentence was annotated manually for weasel cues. Sentences were treated as uncertain if they contained at least one weasel cue, i.e. the scope of weasel words was the entire sentence (which is supposed to be rewritten by Wikipedia editors).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Unlabeled Data</head><p>Unannotated but pre-processed full biological articles (150 articles from the publicly available Pub-MedCentral database) and 1 million paragraphs from Wikipedia were offered to the participants as well. These datasets did not contain any manual annotation for uncertainty, but their usage permitted data sampling from a large pool of in-domain texts without time-wasting pre-processing tasks (cleaning and sentence splitting).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Data Format</head><p>Both training and evaluation data were released in a custom XML format. For each task, a separate XML file was made available containing the whole document set for the given task. Evaluation datasets were available in the same format as training data without any sentence-level certainty, cue or scope annotations.</p><p>The XML format enabled us to provide more detailed information about the documents such as segment boundaries and types (e.g. section titles, figure captions) and it is the straightforward format to represent nested scopes. Nested scopes have overlapping text spans which may contain cues for multiple scopes (there were 1058 occurrences in the training and evaluation datasets together). The XML format utilizes id-references to determine the scope of a given cue. Nested constructions are rather complicated to represent in the standard IOB format, moreover, we did not want to enforce a uniform tokenization.</p><p>To support the processing of the data files, reader and writer software modules were developed and offered to the participants for the uCompare  framework. uCompare provides a universal interface (UIMA) and several text mining and natural language processing tools (tokenizers, POS taggers, syntactic parsers, etc.) for general and biological domains. In this way participants could configure and execute a flexible chain of analyzing tools even with a graphical UI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Submissions and Results</head><p>Participants uploaded their results through the shared task website, and the official evaluation was performed centrally. After the evaluation period, the results were published for the participants on the Web. A total of 23 teams participated in the shared task. 22, 16 and 13 teams submitted output for Task1B, Task1W and Task2, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Results</head><p>Tables 1, 2 and 3 contain the results of the submitted systems for Task1 and Task2. The last name of the first author of the system description paper (published in these proceedings) is used here as a system name 3 . The last column contains the type of submission. The system of <ref type="bibr" target="#b9">Kilicoglu and Bergler (2010)</ref> is the only open submission. They adapted their system introduced in <ref type="bibr" target="#b7">Kilicoglu and Bergler (2008)</ref> to the datasets of the shared task.</p><p>Regarding cross submissions,  and <ref type="bibr" target="#b5">Ji et al. (2010)</ref> managed to achieve a noticeable improvement by exploiting cross-domain 3Ö zgür did not publish a description of her system. data.  extended the biological cue word dictionary of their system -using it as a feature for classification -by the frequent cues of the Wikipedia dataset, while <ref type="bibr" target="#b5">Ji et al. (2010)</ref> used the union of the two datasets for training (they have reported an improvement from 47.0 to 58.7 on the Wikipedia evaluation set after a postchallenge bugfix). higher precision than recall. There may be two reasons for this. The systems may have applied only reliable patterns, or patterns occurring in the evaluation set may be imperfectly covered by the training datasets. The most intense participation was on Task1B. Here, participants applied various precision/recall trade-off strategies. For instance, <ref type="bibr" target="#b19">Tang et al. (2010)</ref> achieved a balanced precision/recall configuration, while  achieved third place thanks to their superior precision. Tables <ref type="table">4 and 5</ref> show the cue-level performances, i.e. the F-measure of cue phrase matching where true positives were strict matches. Note that it was optional to submit cue annotations for Task1 (if participants submitted systems for both Task2 and Task1B with cue tagging, only the better score of the two was considered).</p><p>It is interesting to see that <ref type="bibr" target="#b16">Morante et al. (2010)</ref> who obtained the best results on Task2 achieved a medium-ranked F-measure on the cue-level (e.g. their result on the cue-level is lower by 4% com-pared to , while on the scopelevel the difference is 13% in the reverse direction), which indicates that the real strength of the system of <ref type="bibr" target="#b16">Morante et al. (2010)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Approaches</head><p>The approaches to Task1 fall into two major categories. There were six systems which handled the task as a classical sentence classification problem and employed essentially a bag-of-words feature representation (they are marked as BoW in Table <ref type="table" target="#tab_3">6</ref>). The remaining teams focused on the cue phrases and sought to classify every token if it was a part of a cue phrase, then a sentence was predicted as uncertain if it contained at least one recognized cue phrase. Five systems followed a pure token classification approach (TC) for cue detection while others used sequential labeling techniques (usually Conditional Random Fields) to identify cue phrases in sentences (SL). The feature set employed in Task1 systems typically consisted of the wordform, its lemma or stem, POS and chunk codes and about the half of the participants constructed features from the dependency and/or constituent parse tree of the sentences as well (see Table <ref type="table" target="#tab_3">6</ref> for details).</p><p>It is interesting to see that the top ranked systems of Task1B followed a sequence labeling approach, while the best systems on Task1W applied a bag-of-words sentence classification. This may be due to the fact that biological sentences have relatively simple patterns. Thus the context of the cue words (token classification-based approaches used features derived from a window of the token in question, thus, they exploited the relationship among the tokens and their contexts) can be utilized while Wikipedia weasels have a diverse nature. Another observation is that the top systems in both Task1B and Task1W are the ones which did not derive features from syntactic parsing.</p><p>Each Task2 system was built upon a Task1 system, i.e. they attempted to recognize the scopes for the predicted cue phrases (however, <ref type="bibr" target="#b22">Zhang et al. (2010)</ref> have argued that the objective functions of Task1 and Task2 cue detection problems are different because of sentences containing multiple hedge spans).</p><p>Most systems regarded multiple cues in a sentence to be independent from each other and formed different classification instances from them. There were three systems which incorporated information about other hedge cues (e.g. their distance) of the sentence into the feature space and <ref type="bibr" target="#b22">Zhang et al. (2010)</ref> constructed a cascade system which utilized directly the predicted scopes (it processes cue phrases from left to right) during predicting other scopes in the same sentence.</p><p>The identification of the scope for a certain cue was typically carried out by classifying each token in the sentence. Task2 systems differ in the number of class labels used as target and in the machine learning approaches applied. Most systems -following <ref type="bibr" target="#b15">Morante and Daelemans (2009)</ref> -used three class labels (F)IRST, (L)AST and NONE. Two participants used four classes by adding (I)NSIDE, while three systems followed a binary classification approach (SCOPE versus NONSCOPE). The systems typically included a post-processing procedure to force scopes to be continuous and to include the cue phrase in question. The machine learning methods applied can be again categorized into sequence labeling (SL)  Entropy Guided Transformation Learning (ETL), Averaged Perceptron (AP), k-nearest neighbour (KNN); Feature selection: gathering phrases from the training corpus using statistical thresholds (statistical); Features: orthographical information about the token (ortho), lemma or stem of the token (stem), Part-of-Speech codes (POS), syntactic chunk information (chunk), dependency parsing (dep), position inside the document or section information (docpos) and token classification (TC) approaches (see Table <ref type="table" target="#tab_5">7</ref>). The feature sets used here are the same as for Task1, extended by several features describing the relationship between the cue phrase and the token in question mostly by describing the dependency path between them.  The way of identifying scopes: predicting first/last tokens (FL), first/inside/last tokens (FIL), just inside tokens (I); Multiple Hedges: the system applied a mechanism for handling multiple hedges inside a sentence and token classification (TC) approaches (see Table <ref type="table" target="#tab_5">7</ref>). The feature sets used here are the same as for Task1, extended by several features describing the relationship between the cue phrase and the token in question mostly by describing the dependency path between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions</head><p>The CoNLL-2010 Shared Task introduced the novel task of uncertainty detection. The challenge consisted of a sentence identification task on uncertainty (Task1) and an in-sentence hedge scope detection task (Task2). In the latter task the goal of automatic systems was to recognize speculative text spans inside sentences.</p><p>The relatively high number of participants indicates that the problem is rather interesting for the Natural Language Processing community. We think that this is due to the practical importance of the task for (principally biomedical) applications and because it addresses several open research questions. Although several approaches were introduced by the participants of the shared task and we believe that the ideas described in this proceedings can serve as an excellent starting point for the development of an uncertainty detector, there is a lot of room for improving such systems. The manually annotated datasets and software tools developed for the shared task may act as benchmarks for these future experiments (they are freely available at http://www.inf. u-szeged.hu/rgai/conll2010st).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>2186 paragraphs collected from Wikipedia archives were also offered as Task1 training data (11111 sentences containing 2484 uncertain ones). The evaluation dataset contained 2346 Wikipedia paragraphs with 9634 sentences, out of which 2234 were uncertain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>is the accurate detection of scope boundaries.</figDesc><table><row><cell>Name</cell><cell>P / R / F</cell><cell></cell></row><row><cell>Tang</cell><cell>63.0 / 25.7 / 36.5</cell><cell></cell></row><row><cell>Li</cell><cell cols="2">76.1 / 21.6 / 33.7</cell></row><row><cell>Ozgür</cell><cell>28.9 / 14.7 / 19.5</cell><cell></cell></row><row><cell cols="2">Morante 24.6 / 7.3 / 11.3</cell><cell></cell></row><row><cell cols="3">Table 4: Wikipedia cue-level results.</cell></row><row><cell>Name</cell><cell>P / R / F</cell><cell>type</cell></row><row><cell>Tang</cell><cell>81.7 / 81.0 / 81.3</cell><cell>C</cell></row><row><cell>Zhou</cell><cell>83.1 / 78.8 / 80.9</cell><cell>C</cell></row><row><cell>Li</cell><cell>87.4 / 73.4 / 79.8</cell><cell>C</cell></row><row><cell>Rei</cell><cell>81.4 / 77.4 / 79.3</cell><cell>C</cell></row><row><cell>Velldal</cell><cell>81.2 / 76.3 / 78.7</cell><cell>C</cell></row><row><cell>Zhang</cell><cell>82.1 / 75.3 / 78.5</cell><cell>C</cell></row><row><cell>Ji</cell><cell>78.7 / 76.2 / 77.4</cell><cell>C</cell></row><row><cell>Morante</cell><cell>78.8 / 74.7 / 76.7</cell><cell>C</cell></row><row><cell>Kilicoglu</cell><cell>86.5 / 67.7 / 76.0</cell><cell>O</cell></row><row><cell>Vlachos</cell><cell>82.0 / 70.6 / 75.9</cell><cell>C</cell></row><row><cell>Zhao</cell><cell>76.7 / 73.9 / 75.3</cell><cell>X</cell></row><row><cell cols="2">Fernandes 79.2 / 64.7 / 71.2</cell><cell>C</cell></row><row><cell>Zhao</cell><cell>63.7 / 74.1 / 68.5</cell><cell>C</cell></row><row><cell cols="2">Täckström 66.9 / 58.6 / 62.5</cell><cell>C</cell></row><row><cell>Ozgür</cell><cell>49.1 / 57.8 / 53.1</cell><cell>C</cell></row><row><cell cols="3">Table 5: Biological cue-level results (type ∈ {Closed(C), Cross(X), Open(O)}).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 :</head><label>6</label><figDesc>System architectures overview for Task1. Approaches: sequence labeling (SL), token classification (TC), bag-of-words model (BoW); Machine learners:</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 :</head><label>7</label><figDesc>System architectures overview for Task2. Approaches: sequence labeling (SL), token classification (TC), hand-crafted rules (HC); Machine learners: Entropy Guided Transformation Learning (ETL), Averaged Perceptron (AP), k-nearest neighbour (KNN);</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://en.wikipedia.org/wiki/Weasel_ word</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">under the Creative Commons Attribute Share Alike license</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank Joakim Nivre and Lluís Márquez for their useful suggestions, comments and help during the organisation of the shared task.</p><p>This work was supported in part by the National Office for Research and Technology (NKTH, http://www.nkth.gov.hu/) of the Hungarian government within the framework of the projects TEXTREND, BELAMI and MASZEKER.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TEXT2TABLE: Medical Text Summarization System Based on Named Entity Recognition and Modality Identification</title>
		<author>
			<persName><forename type="first">Eiji</forename><surname>Aramaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yasuhide</forename><surname>Miura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masatsugu</forename><surname>Tonoike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoko</forename><surname>Ohkuma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hiroshi</forename><surname>Mashuichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kazuhiko</forename><surname>Ohe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP 2009 Workshop</title>
				<meeting>the BioNLP 2009 Workshop<address><addrLine>Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="185" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ConText: An Algorithm for Identifying Contextual Features from Clinical Text</title>
		<author>
			<persName><forename type="first">Wendy</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">N</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL Workshop on BioNLP</title>
				<meeting>the ACL Workshop on BioNLP</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
	<note>Dowling</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using Hedges to Enhance a Disease Outbreak Report Text Mining System</title>
		<author>
			<persName><forename type="first">Mike</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Son</forename><surname>Doan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nigel</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP 2009 Workshop</title>
				<meeting>the BioNLP 2009 Workshop<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="142" to="143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A General Natural-language Text Processor for Clinical Radiology</title>
		<author>
			<persName><forename type="first">Carol</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">O</forename><surname>Alderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">J</forename><surname>Austin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">B</forename><surname>Cimino</surname></persName>
		</author>
		<author>
			<persName><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="174" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Finding Hedges by Chasing Weasels: Hedge Detection Using Wikipedia Tags and Shallow Linguistic Features</title>
		<author>
			<persName><forename type="first">Viola</forename><surname>Ganter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Suntec, Singapore, August. Association for Computational Linguistics</title>
				<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="173" to="176" />
		</imprint>
	</monogr>
	<note>Proceedings of the ACL-IJCNLP 2009 Conference Short Papers</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detecting Hedge Cues and their Scopes with Average Perceptron</title>
		<author>
			<persName><forename type="first">Feng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="139" to="146" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">U-Compare: Share and Compare Text Mining Tools with UIMA</title>
		<author>
			<persName><forename type="first">Yoshinobu</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">A</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Mccrohon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lawrence</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun'ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1997" to="1998" />
			<date type="published" when="2009-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recognizing Speculative Language in Biomedical Research Articles: A Linguistically Motivated Perspective</title>
		<author>
			<persName><forename type="first">Halil</forename><surname>Kilicoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Bergler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing</title>
				<meeting>the Workshop on Current Trends in Biomedical Natural Language Processing<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Syntactic Dependency Based Heuristics for Biological Event Extraction</title>
		<author>
			<persName><forename type="first">Halil</forename><surname>Kilicoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Bergler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task</title>
				<meeting>the BioNLP 2009 Workshop Companion Volume for Shared Task<address><addrLine>Boulder, Colorado, June</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="119" to="127" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A High-Precision Approach to Detecting Hedges and Their Scopes</title>
		<author>
			<persName><forename type="first">Halil</forename><surname>Kilicoglu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Bergler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Overview of BioNLP&apos;09 Shared Task on Event Extraction</title>
		<author>
			<persName><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshinobu</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun'ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task</title>
				<meeting>the BioNLP 2009 Workshop Companion Volume for Shared Task<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Linguistics and natural logic</title>
		<author>
			<persName><forename type="first">George</forename><surname>Lakoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantics of Natural Language</title>
				<meeting><address><addrLine>Dordrecht. Reidel</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1972" />
			<biblScope unit="page" from="545" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting Rich Features for Detecting Hedges and Their Scope</title>
		<author>
			<persName><forename type="first">Xinxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianping</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="36" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Language of Bioscience: Facts, Speculations, and Statements in Between</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Xin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Padmini</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the HLT-NAACL 2004 Workshop: Biolink 2004, Linking Biological Literature, Ontologies and Databases</title>
				<meeting>the HLT-NAACL 2004 Workshop: Biolink 2004, Linking Biological Literature, Ontologies and Databases</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Weakly Supervised Learning for Hedge Classification in Scientific Literature</title>
		<author>
			<persName><forename type="first">Ben</forename><surname>Medlock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL</title>
				<meeting>the ACL<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="992" to="999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning the Scope of Hedge Cues in Biomedical Texts</title>
		<author>
			<persName><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP 2009 Workshop</title>
				<meeting>the BioNLP 2009 Workshop<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="28" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Memory-based Resolution of Insentence Scopes of Hedge Cues</title>
		<author>
			<persName><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Van Asch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Detecting Speculations and their Scopes in Scientific Text</title>
		<author>
			<persName><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Arzucanözgür</surname></persName>
		</author>
		<author>
			<persName><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1398" to="1407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hedge Classification in Biomedical Texts with a Weakly Supervised Selection of Keywords</title>
		<author>
			<persName><forename type="first">György</forename><surname>Szarvas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL-08: HLT</title>
				<meeting>ACL-08: HLT<address><addrLine>Columbus, Ohio</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008-06" />
			<biblScope unit="page" from="281" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A Cascade Method for Detecting Hedges and their Scope in Natural Language Text</title>
		<author>
			<persName><forename type="first">Buzhou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixi</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="25" to="29" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Analyzing Text in Search of Bio-molecular Events: A High-precision Machine Learning Framework</title>
		<author>
			<persName><forename type="first">Sofie</forename><surname>Van Landeghem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yvan</forename><surname>Saeys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bernard</forename><forename type="middle">De</forename><surname>Baets</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yves</forename><surname>Van De Peer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task</title>
				<meeting>the BioNLP 2009 Workshop Companion Volume for Shared Task<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="128" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The Bio-Scope Corpus: Biomedical Texts Annotated for Uncertainty, Negation and their Scopes</title>
		<author>
			<persName><forename type="first">Veronika</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">György</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">György</forename><surname>Móra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">János</forename><surname>Csirik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">S9</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Hedge Detection and Scope Finding by Sequence Labeling with Procedural Feature Selection</title>
		<author>
			<persName><forename type="first">Shaodian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Baoliang</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="70" to="77" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to Detect Hedges and their Scope Using CRF</title>
		<author>
			<persName><forename type="first">Qi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yong</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="64" to="69" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploiting Multi-Features to Detect Hedges and Their Scope in Biomedical Texts</title>
		<author>
			<persName><forename type="first">Huiwei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Degen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zezhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuansheng</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task</title>
				<meeting>the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="56" to="63" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
