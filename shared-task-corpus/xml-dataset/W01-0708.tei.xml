<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Introduction to the CoNLL-2001 Shared Task: Clause Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2001-07-15">15 Jul 2001</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
							<email>erikt@uia.ua.ac.be</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CNTS -Language Technology Group Seminar für</orgName>
								<orgName type="institution">Sprachwissenschaft University of Antwerp Universität Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CNTS -Language Technology Group Seminar für</orgName>
								<orgName type="institution">Sprachwissenschaft University of Antwerp Universität Tübingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hervé</forename><surname>Déjean</surname></persName>
							<email>dejean@sfs.nphil.uni-tuebingen.de</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CNTS -Language Technology Group Seminar für</orgName>
								<orgName type="institution">Sprachwissenschaft University of Antwerp Universität Tübingen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Introduction to the CoNLL-2001 Shared Task: Clause Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2001-07-15">15 Jul 2001</date>
						</imprint>
					</monogr>
					<idno type="arXiv">arXiv:cs/0107016v1[cs.CL]</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-09-19T02:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the CoNLL-2001 shared task: dividing text into clauses. We give background information on the data sets, present a general overview of the systems that have taken part in the shared task and briefly discuss their performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CoNLL-2001 shared task aims at discovering clause boundaries with machine learning methods. Why clauses? Clauses are structures used in applications such as Text-to-Speech conversion <ref type="bibr" target="#b5">(Ejerhed, 1988</ref>), text-alignment (Papageorgiou, 1997) and machine translation <ref type="bibr" target="#b8">(Leffa, 1998)</ref>. <ref type="bibr" target="#b5">Ejerhed (1988)</ref> described clauses as a natural structure above chunks:</p><p>It is a hypothesis of the author's current clause-by-clause processing theory, that a unit corresponding to the basic clause is a stable and easily recognizable surface unit and that is is also an important partial result and building block in the construction od a richer linguistic representation that encompasses syntax as well as semantics and discourse structure <ref type="bibr">(Ejerhed, 1988, page 220)</ref> The goal of this shared task is to evaluate automatic methods, especially machine learning methods, for finding clause boundaries in text. We have selected a training and test corpus for performing this evaluation. The task has been divided in three parts in order to allow basic machine learning methods to participate in this task by processing the data in a bottom-up fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task description</head><p>Defining clause boundaries is not trivial <ref type="bibr" target="#b8">(Leffa, 1998)</ref>. In this task, the gold standard clause segmentation is provided by the Penn Treebank <ref type="bibr" target="#b9">(Marcus et al., 1993)</ref>. The guidelines of the Penn Treebank describe in detail how sentences are segmented into clauses <ref type="bibr" target="#b1">(Bies et al., 1995)</ref>.</p><p>Here is an example of a sentence and its clauses obtained from Wall Street Journal section 15 of the Penn Treebank <ref type="bibr" target="#b9">(Marcus et al., 1993)</ref>:</p><p>(S Coach them in (S-NOM handling complaints) (SBAR-PRP so that (S they can resolve problems immediately) )</p><p>. )</p><p>The clauses of this sentence have been enclosed between brackets. A tag next to the open bracket denotes the type of the clause.</p><p>In the CoNLL-2001 shared task, the goal is to identify clauses in text. Since clauses can be embedded in each other, this task is considerably more difficult than last year's task, recognizing non-embedded text chunks. For that reason, we have disregarded type and function information of the clauses: every clause has been tagged with S rather than with an elaborate tag such as SBAR-PRP. Furthermore, the shared task has been divided in three parts: identifying clause starts, recognizing clause ends and finding complete clauses. The results obtained for the first two parts can be used in the third part of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data and Evaluation</head><p>This CoNLL shared task works with roughly the same sections of the Penn Treebank as the widely used data set for base noun phrase recog-nition (Ramshaw and <ref type="bibr">Marcus, 1995)</ref>: WSJ sections 15-18 of the Penn Treebank as training material, section 20 as development material for tuning the parameter of the learner and section 21 as test data 1 . The data sets contain tokens (words and punctuation marks), information about the location of sentence boundaries and information about clause boundaries. Additionally, a part-of-speech (POS) tag and a chunk tag was assigned to each token by a standard POS tagger <ref type="bibr" target="#b2">(Brill, 1994)</ref> and a chunking program . We used these POS and chunking tags rather than the Treebank ones in order to make sure that the performance rates obtained for this data are realistic estimates for data for which no Treebank tags are available. In the clause segmentation we have only included clauses in the Treebank which had a label starting with S thus disregarding clauses with label RRC or FRAG. All clause labels have been converted to S.</p><p>Different schemes for encoding phrase information have been used in the data:</p><p>• B-X, I-X and O have been used for marking the first word in a chunk of type X, a non-initial word in an X chunk and a word outside of any chunk, respectively (see also <ref type="bibr" target="#b16">Tjong Kim Sang and Buchholz (2000)</ref>).</p><p>• S, E and X mark a clause start, a clause end and neither a clause start nor a clause end, respectively. These tags have been used in the first and second part of the shared task.</p><p>• (S*, *S) and * denote a clause start, a clause end and neither a clause start nor a clause end, respectively. The first two can be used in combination with each other. For example, (S*S) marks a word where a clause starts and ends, and *S)S) marks a word where two clauses end. These tags are used in the third part of the shared task.</p><p>The first two phrase encodings were inspired by the representation used by Ramshaw and Marcus (1995). Here is an example of the clause encoding schemes:</p><p>1 These clause data sets are available at http://lcg-www.uia.ac.be/conll2001/clauses/ Coach S X (S* them X X * in X X * handling S X (S* complaints X E *S) so S X (S* that X X * they S X (S* can X X * resolve X X * problems X X * immediately X E *S)S)</p><p>. X E *S)</p><p>Three tags can be found next to each word, respectively denoting the information for the first, second and third part of the shared task. The goal of this task is to predict the test data segmentation as well as possible with a model built from the training data. The performance in this task is measured with three rates. First, the percentage of detected starts, ends or clauses that are correct (precision). Second, the percentage of starts, ends or clauses in the data that were found by the learner (recall). And third, the F β=1 rate which is equal to (β 2 +1)*precision*recall / (β 2 *precision+recall) with β=1 (van <ref type="bibr" target="#b18">Rijsbergen, 1975</ref>). The latter rate has been used as the target for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Six systems have participated in the shared task. Two of them used boosting and the others used techniques which were connectionist, memory-based, statistical and symbolic. <ref type="bibr" target="#b14">Patrick and Goyal (2001)</ref> applied the AdaBoost algorithm for boosting the performance of decision graphs. The latter are an extension of decision trees: they allow tree nodes to have more than one parent. The boosting algorithm improves the performance of the decision graphs by assigning weights to the training data items based on how accurately they have been classified. <ref type="bibr" target="#b7">Hammerton (2001)</ref> used a feed-forward neural network architecture, long short-term memory, for predicting embedded clause structures. The network processes sentences wordby-word. Memory cells in its hidden layer enable it to remember states with information about the current clause.  <ref type="formula">2001</ref>) evaluated a memory-based learner while using different combinations of features describing items which needed to be classified. His learner was well suited for identifying clause starts and clause ends but less suited for the predicting complete clauses. Therefore he used heuristic rules for converting the part one and two results of the shared task to results for the third part. <ref type="bibr" target="#b10">Molina and Pla (2001)</ref> have applied a specialized Hidden Markov Model (HMM) to the shared task. They interpreted the three parts of the shared task as tagging problems and made the HMM find the most probable sequence of tags given an input sequence. In the third part  of the task they limited the number of possible output tags and used rules for fixing bracketing problems. <ref type="bibr" target="#b3">Carreras and Màrquez (2001)</ref> converted the clausing task to a set of binary decisions which they modeled with decision trees which are combined by AdaBoost. The system uses features which in some cases contain relevant information about a complete sentence. It produces a list of clauses from which the ones with the highest confidence scores will be presented as output.</p><p>We have derived baseline scores for the different parts of the shared task by evaluating a system that assigns one clause to every sentence. Each of these clauses completely covers a sentence. All participating systems perform above the baselines.</p><p>In the development data for part 1 of the shared task, at 30 times all five participating systems (Hammerton's only did part 3 of the shared task) predicted a clause start at a position where there was none. About half of these were in front of the word to. The situation in which all five systems missed a clause start occurred 205 times at positions with different suc- Table <ref type="table">3</ref>: The performance of the six systems while processing the development data and the test data for part 3 of the shared task: recognizing complete clauses. The baseline results have been obtained by a system that assumes that every sentence consists of one clause which contains the complete sentence.</p><p>ceeding words. It seems that many of these errors were caused by a missing comma immediately before the clause start.</p><p>In three cases, the five systems unanimously found an end of a clause where there was none in the development data of part 2 of the shared task. All these occurred at the end of 'sentences' which consisted of a single noun phrase or a single adverbial phrase. In 205 cases all five systems missed a clause end. These errors often occurred right before punctuation signs.</p><p>It is hard to make a similar overview for part 3 of the shared task. Therefore we have only looked at the accuracies of two clause tags: (S(S* (starting two clauses) and *S)S) (ending two clauses). Never did more than three of the six systems correctly predicted the start of two clauses. The best performing system for this clause tag was the one of Carreras and Màrquez with about 52% recall. Three of the systems did not find back any of the double clause starts and the average recall score of the six was 21%. The end of two clauses was correctly predicted by all six systems about 0.5% of the times it occurred. Again, the system of Carreras and Màrquez was best with 63% recall while the average system found back 33%.</p><p>The six result tables show that the system of Carreras and Màrquez clearly outperforms the other five systems on all parts of the shared task. They were the only one to use input features that contained information of a complete sentence and it seems that this was a good choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>There have been some earlier studies in identifying clauses. <ref type="bibr" target="#b0">Abney (1990)</ref> used a clause filter as a part of his CASS parser. It consists of two parts: one for recognizing basic clauses and one for repairing difficult cases (clauses without subjects and clauses with additional VPs). <ref type="bibr" target="#b6">Ejerhed (1996)</ref> showed that a parser can benefit from automatically identified clause boundaries in discourse. <ref type="bibr" target="#b12">Papageorgiou (1997)</ref> used a set of hand-crafted rules for identifying clause boundaries in one text. Leffa (1998) wrote a set of clause identification rules and applied them to a small corpus. The performance was very good, with recall rates above 90%. <ref type="bibr" target="#b11">Orȃsan (2000)</ref> used a memory-based learner with post-processing rules for predicting clause boundaries in Susanne corpus. His system obtained F rates of about 85 for this particular task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Concluding Remarks</head><p>We have presented the CoNLL-2001 shared task: clause identification. The task was split in three parts: recognizing clause starts, finding clause ends and identifying complete, possibly embedded, clauses. Six systems have participated in this shared task. They used various machine learning techniques, boosting, connectionist methods, decision trees, memorybased learning, statistical techniques and symbolic methods. On all three parts of the shared task the boosted decision tree system of Carreras and Màrquez (2001) performed best. It obtained an F β=1 rate of 78.63 for the third part of the shared task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Carreras &amp; Màr. 95.77% 92.08% 93.89 Patrick &amp; Goyal 94.84% 87.33% 90.93 * 2 Tjong Kim Sang 92.94% 86.87% 89.80 *</figDesc><table><row><cell>development 1</cell><cell>precision recall</cell><cell>F β=1</cell></row><row><cell>Molina &amp; Pla</cell><cell cols="2">90.11% 88.80% 89.45 *</cell></row><row><cell>Déjean</cell><cell cols="2">94.08% 84.59% 89.08</cell></row><row><cell>baseline</cell><cell cols="2">96.32% 38.08% 54.58</cell></row><row><cell>test part 1</cell><cell>precision recall</cell><cell>F β=1</cell></row><row><cell cols="3">Carreras &amp; Màr. 93.96% 89.59% 91.72</cell></row><row><cell cols="3">Tjong Kim Sang 92.91% 85.08% 88.82 *</cell></row><row><cell>Molina &amp; Pla</cell><cell cols="2">89.54% 86.01% 87.74 *</cell></row><row><cell>Déjean</cell><cell cols="2">93.76% 81.90% 87.43</cell></row><row><cell>Patrick &amp; Goyal</cell><cell cols="2">89.79% 84.88% 87.27 *</cell></row><row><cell>baseline</cell><cell cols="2">98.44% 36.58% 53.34</cell></row><row><cell cols="3">Table 1: The performance of five systems while</cell></row><row><cell cols="3">processing the development data and the test</cell></row><row><cell cols="3">data for part 1 of the shared task: finding clause</cell></row><row><cell cols="3">starts. The baseline results have been obtained</cell></row><row><cell cols="3">by a system that assumes that every sentence</cell></row><row><cell cols="3">consists of one clause which contains the com-</cell></row><row><cell>plete sentence.</cell><cell></cell><cell></cell></row><row><cell cols="3">Déjean (2001) predicted clause boundaries</cell></row><row><cell cols="3">with his symbolic learner ALLiS (Architecture</cell></row><row><cell cols="3">for Learning Linguistic Structure). It is based</cell></row><row><cell cols="3">on theory refinement, which means that it</cell></row><row><cell cols="3">adapts grammars. The learner selects a set</cell></row><row><cell cols="3">of rules based on their prediction accuracy of</cell></row><row><cell cols="3">classes in a training corpus. Tjong Kim Sang</cell></row><row><cell>(</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Carreras &amp; Màr. 91.27% 89.00% 90.12 Tjong Kim Sang 83.80% 80.44% 82.09</figDesc><table><row><cell>development 2</cell><cell>precision recall</cell><cell>F β=1</cell></row><row><cell>Patrick &amp; Goyal</cell><cell cols="2">80.12% 83.03% 81.55 *</cell></row><row><cell>Molina &amp; Pla</cell><cell cols="2">78.65% 78.97% 78.81 *</cell></row><row><cell>Déjean</cell><cell cols="2">99.28% 51.73% 68.02</cell></row><row><cell>baseline</cell><cell cols="2">96.32% 51.86% 67.42</cell></row><row><cell>test part 2</cell><cell>precision recall</cell><cell>F β=1</cell></row><row><cell cols="3">Carreras &amp; Màr. 90.04% 88.41% 89.22</cell></row><row><cell cols="3">Tjong Kim Sang 84.72% 79.96% 82.28</cell></row><row><cell>Patrick &amp; Goyal</cell><cell cols="2">80.11% 83.47% 81.76 *</cell></row><row><cell>Molina &amp; Pla</cell><cell cols="2">79.57% 77.68% 78.61 *</cell></row><row><cell>Déjean</cell><cell cols="2">99.28% 48.90% 65.47</cell></row><row><cell>baseline</cell><cell cols="2">98.44% 48.90% 65.34</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: The performance of five systems while</cell></row><row><cell>processing the development data and the test</cell></row><row><cell>data for part 2 of the shared task: identifying</cell></row><row><cell>clause ends. The baseline results have been ob-</cell></row><row><cell>tained by a system that assumes that every sen-</cell></row><row><cell>tence consists of one clause which contains the</cell></row><row><cell>complete sentence.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Performances on lines with a * suffix are different from those in the paper version of the CoNLL-2001 proceedings.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank SIGNLL for giving us the opportunity to organize this shared task and our colleagues of the Seminar für Sprachwissenschaft in Tübingen, CNTS -Language Technology Group in Antwerp, and the ILK group in Tilburg for valuable discussions and comments. This research has been funded by the European TMR network Learning Computational Grammars 3 .</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rapid Incremental Parsing with Repair</title>
		<author>
			<persName><forename type="first">Steven</forename><surname>Abney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th New OED Conference: Electronic Text Research</title>
				<meeting>the 8th New OED Conference: Electronic Text Research<address><addrLine>Ontario</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
		<respStmt>
			<orgName>University of Waterloo</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Bracketing Guidelines for Treebank II Style Penn Treebank Project</title>
		<author>
			<persName><forename type="first">Ann</forename><surname>Bies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Fergusson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karen</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Macintyre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Some advances in rule-based part of speech tagging</title>
		<author>
			<persName><forename type="first">Eric</forename><surname>Brill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94)</title>
				<meeting>the Twelfth National Conference on Artificial Intelligence (AAAI-94)<address><addrLine>Seattle, Washington</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Boosting Trees for Clause Splitting</title>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lluís</forename><surname>Màrquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2001</title>
				<meeting>CoNLL-2001<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using ALLiS for Clausing</title>
		<author>
			<persName><surname>Hervé Déjean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2001</title>
				<meeting>CoNLL-2001<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding clauses in unrestricted text by finitary and stochastic methods</title>
		<author>
			<persName><forename type="first">Eva</forename><surname>Ejerhed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the second Conference on Applied Natural Language Processing</title>
				<meeting>the second Conference on Applied Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="219" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Finite state segmentation of discourse into clauses</title>
		<author>
			<persName><forename type="first">Eva</forename><surname>Ejerhed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ECAI &apos;96 Workshop on Extended finite state models of language. ECAI &apos;96</title>
				<meeting>the ECAI &apos;96 Workshop on Extended finite state models of language. ECAI &apos;96<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Clause identification with Long Short-Term Memory</title>
		<author>
			<persName><forename type="first">James</forename><surname>Hammerton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2001</title>
				<meeting>CoNLL-2001<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Clause Processing in Complex Sentences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vilson</surname></persName>
		</author>
		<author>
			<persName><surname>Leffa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC&apos;98</title>
				<meeting>LREC&apos;98<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Building a large annotated corpus of English: the Penn Treebank</title>
		<author>
			<persName><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clause Detection using HMM</title>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ferran</forename><surname>Pla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2001</title>
				<meeting>CoNLL-2001<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A hybrid method for clause splitting in unrestricted English texts</title>
		<author>
			<persName><forename type="first">Constantin</forename><surname>Orȃsan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACIDCA&apos;2000</title>
				<meeting>ACIDCA&apos;2000<address><addrLine>Monastir, Tunisia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Clause recognition in the framework of alignment</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">V</forename><surname>Papageorgiou</surname></persName>
		</author>
		<ptr target="http://lcg-www.uia.ac.be/" />
	</analytic>
	<monogr>
		<title level="m">Recent Advances in Natural</title>
				<editor>
			<persName><forename type="first">R</forename><surname>Mitkov</surname></persName>
			<persName><forename type="first">N</forename><surname>Nicolov</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Language Processing</title>
		<imprint>
			<publisher>John Benjamins Publishing Company</publisher>
			<pubPlace>Amsterdam/Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Text Chunking Using Transformation-Based Learning</title>
		<author>
			<persName><forename type="first">Jon</forename><forename type="middle">D</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third ACL Workshop on Very Large Corpora</title>
				<editor>
			<persName><forename type="first">France</forename><surname>Toulouse</surname></persName>
			<persName><forename type="first">A</forename><surname>Lance</surname></persName>
			<persName><forename type="first">Mitchell</forename><forename type="middle">P</forename><surname>Ramshaw</surname></persName>
			<persName><surname>Marcus</surname></persName>
		</editor>
		<meeting>the Third ACL Workshop on Very Large Corpora<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note>Proceedings of CoNLL-2001</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Memory-Based Clause Identification</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Tjong Kim</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2001</title>
				<meeting>CoNLL-2001<address><addrLine>Toulouse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2000 Shared Task: Chunking</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Buchholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL-2000 and LLL-2000</title>
				<meeting>the CoNLL-2000 and LLL-2000<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Text Chunking by System Combination</title>
		<author>
			<persName><forename type="first">Erik</forename><forename type="middle">F</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Tjong Kim</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL-2000 and LLL-2000</title>
				<meeting>CoNLL-2000 and LLL-2000<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval. Buttersworth</title>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
