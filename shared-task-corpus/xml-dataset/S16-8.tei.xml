<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2016 Task 8: Meaning Representation Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jonathan</forename><surname>May</surname></persName>
							<email>jonmay@isi.edu</email>
							<affiliation key="aff0">
								<address>
									<addrLine>June 16-17</addrLine>
									<postCode>2016</postCode>
									<settlement>San Diego</settlement>
									<region>California</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Information Sciences Institute University of Southern California</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2016 Task 8: Meaning Representation Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this report we summarize the results of the SemEval 2016 Task 8: Meaning Representation Parsing. Participants were asked to generate Abstract Meaning Representation (AMR) <ref type="bibr" target="#b1">(Banarescu et al., 2013)</ref> graphs for a set of English sentences in the news and discussion forum domains. Eleven sites submitted valid systems. The availability of state-of-the-art baseline systems was a key factor in lowering the bar to entry; many submissions relied on CAMR <ref type="bibr" target="#b19">(Wang et al., 2015b;</ref><ref type="bibr" target="#b18">Wang et al., 2015a</ref>) as a baseline system and added extensions to it to improve scores. The evaluation set was quite difficult to parse, particularly due to creative approaches to word representation in the web forum portion. The top scoring systems scored 0.62 F1 according to the Smatch (Cai and Knight, 2013) evaluation heuristic. We show some sample sentences along with a comparison of system parses and perform quantitative ablative studies.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Abstract Meaning Representation (AMR) is a compact, readable, whole-sentence semantic annotation <ref type="bibr" target="#b1">(Banarescu et al., 2013)</ref>. It includes entity identification and typing, PropBank semantic roles <ref type="bibr" target="#b12">(Kingsbury and Palmer, 2002)</ref>, individual entities playing multiple roles, as well as treatments of modality, negation, etc. AMR abstracts in numerous ways, e.g., by assigning the same conceptual structure to fear (v), fear (n), and afraid (adj). Figure <ref type="figure">1</ref> gives an example.</p><p>With the recent public release of a sizeable corpus of English/AMR pairs (LDC2014T12), there has (f / fear-01 :polarity "-" :ARG0 ( s / soldier ) :ARG1 ( d / die-01 :ARG1 s ))</p><p>The soldier was not afraid of dying. The soldier was not afraid to die. The soldier did not fear death.</p><p>Figure <ref type="figure">1</ref>: An Abstract Meaning Representation (AMR) with several English renderings. Example borrowed from <ref type="bibr" target="#b15">Pust et al. (2015)</ref>.</p><p>been substantial interest in creating parsers to recover this formalism from plain text. Several parsers were released in the past couple of years <ref type="bibr" target="#b8">(Flanigan et al., 2014;</ref><ref type="bibr" target="#b19">Wang et al., 2015b;</ref><ref type="bibr" target="#b21">Werling et al., 2015;</ref><ref type="bibr" target="#b18">Wang et al., 2015a;</ref><ref type="bibr" target="#b0">Artzi et al., 2015;</ref><ref type="bibr" target="#b15">Pust et al., 2015)</ref>. This body of work constitutes many diverse and interesting scientific contributions, but it is difficult to adequately determine which parser is numerically superior, due to heterogeneous evaluation decisions and the lack of a controlled blind evaluation. The purpose of this task, therefore, was to provide a competitive environment in which to determine one winner and award a trophy to said winner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Training Data</head><p>LDC released a new corpus of AMRs (LDC2015E86), created as part of the DARPA DEFT program, in August of 2015. The new corpus, which was annotated by teams at SDL, LDC, and the University of Colorado, and supervised by Ulf Hermjakob at USC/ISI, is an extension of pre-vious releases (LDC2014E41 and LDC2014T12). It contains 19,572 sentences (subsuming, in turn, the 18,779 AMRs from LDC2014E41 and the 13,051 AMRs from LDC2014T12), partitioned into training, development, and test splits, from a variety of news and discussion forum sources. The AMRs in this corpus have changed somewhat from their counterparts in LDC2014E41, consistent with the evolution of the AMR standard. They now contain wikification via the :wiki attribute, they use new (as of July 2015) PropBank framesets that are unified across parts of speech, they have been deepened in a number of ways, and various corrections have been applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Other Resources</head><p>We made the following resources available to participants:</p><p>• The aforementioned AMR corpus (LDC2015E86), which included automatically generated AMR-English alignments over tokenized sentences.</p><p>• The tokenizer (from Ulf Hermjakob) used to produce the tokenized sentences in the training corpus.</p><p>• The AMR specification, used by annotators in producing the AMRs. 1</p><p>• A deterministic, input-agnostic trivial baseline 'parser' courtesy of Ulf Hermjakob.</p><p>• The JAMR parser <ref type="bibr" target="#b8">(Flanigan et al., 2014)</ref> as a strong baseline. We provided setup scripts to process the released training data but otherwise provided the parser as is.</p><p>• An unsupervised AMR-to-English aligner <ref type="bibr" target="#b14">(Pourdamghani et al., 2014)</ref>.</p><p>• The same Smatch  scoring script used in the evaluation.</p><p>• A Python AMR manipulation library, from Nathan Schneider.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Data</head><p>For the specific purposes of this task, DEFT commissioned and LDC released an additional set of English sentences along with AMR annotations 2 that had not been previously seen. This blind evaluation set consists of 1,053 sentences in a roughly 50/50 discussion forum/newswire split. The distribution of sentences by source is shown in Table <ref type="table">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Task Definition</head><p>We deliberately chose a single, simple task. Participants were given English sentences and had to return an AMR graph (henceforth, 'an AMR') for each sentence. AMRs were scored against a gold AMR with the Smatch heuristic F1-derived tool and metric. Smatch ) is calculated by matching instance, attribute, and relation tuples to a reference AMR (See Section 7.2). Since variable naming need not be globally consistent, heuristic hill-climbing is done to search for the best match in sub-exponential time. A trophy was given to the team with the highest Smatch score under consistent heuristic conditions. 3</p><p>6 Participants and Results 11 teams participated in the task. <ref type="bibr">4</ref> Their systems and scores are shown in Table <ref type="table" target="#tab_1">2</ref>. Below are brief descriptions of each of the various systems, based on summaries provided by the system authors. Readers are encouraged to consult individual system description papers for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">CAMR-based systems</head><p>A number of teams made use of the CAMR system from <ref type="bibr" target="#b18">Wang et al. (2015a)</ref>. These systems proved among the highest-scoring and had little variance from each other in terms of system score.</p><p>6.1.1 Brandeis / cemantix.org / RPI <ref type="bibr" target="#b20">(Wang et al., 2016)</ref> This team, the originators of CAMR, started with their existing AMR parser and experimented with three sets of new features: 1) rich named entities, 2) a verbalization list, and 3) semantic role labels. They also used the RPI Wikifier to wikify the concepts in the AMR graph. <ref type="bibr" target="#b4">(Brandt et al., 2016)</ref> This team attempted to improve AMR parsing by exploiting preposition semantic role labeling information retrieved from a multi-layer feed-forward neural network. Prepositional semantics was included as features into CAMR. The inclusion of the features modified the behavior of CAMR when creating meaning representations triggered by prepositional semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.2">ICL-HD</head><p>6.1.3 RIGA <ref type="bibr" target="#b2">(Barzdins and Gosko, 2016)</ref> Besides developing a novel character-level neural translation based AMR parser, this team also extended the Smatch scoring tool with the C6.0 rule-based classifier to produce a human-readable report on the error patterns frequency observed in the scored AMR graphs. They improved CAMR by adding to it a manually crafted wrapper fixing the identified CAMR parser errors. A small further gain was achieved by combining the neural and CAMR+wrapper parsers in an ensemble.</p><p>6.1.4 M2L <ref type="bibr" target="#b16">(Puzikov et al., 2016)</ref> This team attempted to improve upon CAMR by using a feed-forward neural network classification algorithm. They also experimented with various ways of enriching CAMR's feature set. Unlike ICL-HD and RIGA they were not able to benefit from feed-forward neural networks, but were able to benefit from feature enhancements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Other Approaches</head><p>The other teams either improved upon their existing AMR parsers, converted existing semantic parsing tools and pipelines into AMR, or constructed AMR parsers from scratch with novel techniques. <ref type="bibr" target="#b17">(Rao et al., 2016)</ref> This team developed a novel technique for AMR parsing that uses the Learning to Search (L2S) algorithm. They decomposed the AMR prediction problem into three problems-that of predicting the concepts, predicting the root, and predicting the relations between the predicted concepts. Using L2S allowed them to model the learning of concepts and relations in a unified framework which aims to minimize the loss over the entire predicted structure, as opposed to minimizing the loss over concepts and relations in two separate stages. <ref type="bibr" target="#b9">(Flanigan et al., 2016)</ref> This team's entry is a set of improvements to JAMR <ref type="bibr" target="#b8">(Flanigan et al., 2014)</ref>. The improvements are: a novel training loss function for structured prediction, new sources for concepts, improved features, and improvements to the rule-based aligner in <ref type="bibr" target="#b8">Flanigan et al. (2014)</ref>. The overall architecture of the system and the decoding algorithms for con-   <ref type="bibr" target="#b5">(Butler, 2016)</ref> No use was made of the training data provided by the task. Instead, existing components were combined to form a pipeline able to take raw sentences as input and output meaning representations. The components are a part-of-speech tagger and parser trained on the Penn Parsed Corpus of Modern British English to produce syntactic parse trees, a semantic role labeler, and a named entity recognizer to supplement obtained parse trees with word sense, functional and named entity information. This information is passed into an adapted Tarskian satisfaction relation for a Dynamic Semantics that is used to transform a syntactic parse into a predicate logic based meaning representation, followed by conversion to the required Penman notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.1">CLIP@UMD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.2">CMU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6.2.4</head><p>The Meaning Factory <ref type="bibr" target="#b3">(Bjerva et al., 2016)</ref> This team employed an existing open-domain semantic parser, Boxer <ref type="bibr" target="#b7">(Curran et al., 2007)</ref>, which produces semantic representations based on Discourse Representation Theory. As the meaning representations produced by Boxer are considerably different from AMRs, the team used a hybrid conversion method to map Boxer's output to AMRs. This process involves lexical adaptation, a conver-sion from DRT-representations to AMR, as well as post-processing of the output. 6.2.5 UCL+Sheffield <ref type="bibr" target="#b11">(Goodman et al., 2016)</ref> This team developed a novel transition-based parsing algorithm using exact imitation learning, in which the parser learns a statistical model by imitating the actions of an expert on the training data. They used the imitation learning algorithm DAG-GER to improve the performance, and applied an alpha-bound as a simple noise reduction technique. <ref type="bibr" target="#b13">(Peng and Gildea, 2016)</ref> This team applied a synchronous-graphgrammar-based approach for string-to-AMR parsing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.6">UofR</head><p>They applied Markov Chain Monte Carlo (MCMC) algorithms to learn Synchronous Hyperedge Replacement Grammar (SHRG) rules from a forest that represents likely derivations consistent with a fixed string-to-graph alignment (extracted using an automatic aligner). They make an analogy of string-to-AMR parsing to the task of phrase-based machine translation and came up with an efficient algorithm to learn graph grammars from string-graph pairs. They proposed an effective approximation strategy to resolve the complexity issue of graph compositions. Then they used the Earley algorithm with cube-pruning for AMR parsing given new sentences and the learned SHRG.</p><p>6.2.7 CU-NLP <ref type="bibr" target="#b10">(Foland and Martin, 2016)</ref> This parser does not rely on a syntactic pre-parse, or heavily engineered features, and uses five recurrent neural networks as the key architectural components for estimating AMR graph structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Result Ablations</head><p>We conduct several ablations to attempt to empirically determine what aspects of the AMR parsing task were more or less difficult for the various systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Impact of Wikification</head><p>The AMR standard has recently been expanded to include wikification and the data used in this task reflected that expansion. Since this is a rather recent change to the standard and requires some kind of global external knowledge of, at a minimum, Wikipedia's ontology, we suspected performance on :wiki attributes would suffer. To measure the effect of wikification, we performed two ablation experiments, the results of which are in Figure <ref type="figure" target="#fig_2">2</ref>. In the first ("no wiki"), we removed :wiki attributes and their values from reference and system sets before scoring. In the second ("bad wiki"), we replaced the value of all :wiki attributes with a dummy entry to artificially create systems that did not get any wikification correct.</p><p>The "no wiki" ablations show that the inclusion of wikification into the AMR standard had a very small impact on overall system scores. No system's score changed by more than 0.01 when wikification was removed, indicating that systems appear to wikify about as well as they handle the rest of AMR's attributes. The "bad wiki" ablations show performance drop when wikification is corrupted of around 0.02 to 0.03 for six of the systems, and a negligible performance drop for the remaining systems. This result indicates that the systems with a performance drop are doing a fairly good job at wikification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Performance on different parts of the AMR</head><p>In this set of ablations we examine systems' relative performance on correctly identifying instances, attributes, and relations of the AMRs. Instances are the labeled nodes of the AMR. In the example AMR of Figure <ref type="figure">1</ref>, the instances are fear-01, soldier, and die-01. To match an instance one must simply match the instance's label. <ref type="bibr">5</ref> Attributes are labeled string properties of nodes. In the example AMR, there is a polarity attribute attached to the fear-01 instance with a value of "-." There is also an implicit attribute of "TOP" attached to the root node of the graph, with the node's instance as the attribute value. To match an attribute one must match the attribute's label and value, and the attribute's instance must be aligned with the corresponding instance in the reference graph.</p><p>Relations are labeled edges between two instances. In the example AMR, the relations (f, s, ARG0), (f, d, ARG1), and (d, s, ARG1) exist. To match a relation, the labeled edge between two nodes of the hypothesis must match the label of the edge between the correspondingly aligned nodes of the reference graph.</p><p>It should not be surprising that systems tend to perform best at instance matching and worst at relation matching. Note, however, that the best performing systems on instances and relations were not the overall best performing systems. Ablation results can be seen in Table <ref type="table" target="#tab_3">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Performance on different data sources</head><p>As discussed in Section 8, less formal sentences, sentences with misspellings, and sentences with non-standard representations of meaning were the hardest to parse. We ablate the results by domain of origin in Table <ref type="table" target="#tab_5">4</ref>. While the strongest-performing systems tended to perform best across ablations, we note that the machine-translated and informal corpora were overall the hardest sections to parse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Qualitative Comparison</head><p>In this section we examine some of the sentences that the systems found particularly easy or difficult to parse.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Easiest Sentences</head><p>The easiest sentence to parse in the eval corpus was the sentence "I was tempted." <ref type="bibr">6</ref> It has a gold AMR of:</p><p>(t / tempt-01 :ARG1 (i / i))</p><p>The mean score for this sentence was 0.977. All submitted systems except one parsed it perfectly.</p><p>Another sentence that was quite easy to parse was the sentence "David Cameron is the prime minister of the United Kingdom." 7 Two systems parsed it perfectly and a third omitted wikification but was otherwise perfect. Figure <ref type="figure" target="#fig_3">3</ref> shows a detailed comparison of each system's performance on the sentence. In general we see that shorter sentences from the familiar and formal news domain are parsed best by the submitted systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Hardest Sentences</head><p>Five sentences were unable to be parsed in any way by any system. 8 They are shown below, along with their AMRs: Data noise was another confounding factor. In the next example, 9 which had an average score of 0.17, parsers were confused both by the misspelling ("lie" for "like") and by the quoted title, which all systems except UCL+Sheffield, tried to parse for meaning. <ref type="bibr">6</ref> nyt eng 20130426 0143.23. 7 bolt-eng- <ref type="bibr">DF-200-192446-3811676 0094.5. 8 nyt eng 20131029 0042.18, web1-eng-DF-225-195996-5376307 0002.3, web1-eng-DF-233-195474-1207335 0002.1, web1-eng-DF-233-195474-1207335 0010.2, and web1-eng-DF-183-195729-5441907 0001 3. 9</ref> bolt-eng-DF-170-181122-8787556 0049 6.</p><p>Why not a title lie "School Officials Screw over Rape Victim?" (t / title-01 :polarity -:ARG1-of (r / resemble-01 :ARG2 (t2 / title-01 :wiki "A_Rape_on_Campus" :name (n2 / name :op1 "School" :op2 "Officials" :op3 "Screw" :op4 "Over" :op5 "Rape" :op6 "Victim"))) :ARG1-of (c / cause-01 :ARG0 (a / amr-unknown)))</p><p>We note that all of these difficult sentences are not conceptually hard for humans to parse. Humans have far less difficulty in resolving errors or processing non-standard tokenization than do computers.</p><p>9 There Can Be Only One?</p><p>We intended to award a single trophy to the single best system, according to the narrow evaluation conditions (balanced F1 via Smatch 2.0.2 with 5 restarts, to two decimal places). However, the top two systems, Brandeis/cemantix.org/RPI and RIGA, scored identically according to that metric. Hoping to elicit some consistent difference between the systems, we ran Smatch with 20 restarts, looked at four decimal places, and re-ran five times. Each system scored a mean of 0.6214 with standard deviation of 0.00013. We thus capitulate in the face of overwhelming statistics and award the inaugural trophy to both teams, equally. 10</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusion</head><p>The results of this competition and the interest in participation in it demonstrate that AMR parsing is a difficult, competitive task. The large number of systems using released code lowered the bar to entry significantly but may have led to a narrowing of diversity in approaches. Low-level irregularities such as creative tokenization and misspellings befuddled the systems. We hope to conduct another AMR parsing competition in the future, in the biomedical domain, and also conduct a generation competition.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>E</head><label></label><figDesc>-mail: mward(at)statesman.com. (e / email-address-entity :value "mward@statesman.com") x (s / string-entity :value "x") * sigh * (s / sigh-01) Yes_it_is. (y / yes) M E D I A A D V I S O R Y (a / advise-01 :ARG1 (m / media))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Comparison of regular systems ('With wiki'), systems and references with all wikification removed ('No wiki'), and systems with wikification corrupted ('Bad wiki').(b) Removing wikification from hypothesis and reference raises scores by less than 0.01 Smatch in seven systems.Corrupting wikification in the hypothesis lowers scores by 0.015 or more in six systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Ablations of :wiki attribute.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: A comparison of parser performance on the sentence "David Cameron is the Prime Minister of the United Kingdom."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Main Results: Mean of five runs of Smatch</cell></row><row><cell>2.0.2 with five restarts per run is shown; Standard</cell></row><row><cell>deviation of F1 was about 0.0002 per system.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Ablation of instances, attributes, and relations.</figDesc><table><row><cell>cept identification and relation identification are un-</cell></row><row><cell>changed from Flanigan et al. (2014).</cell></row><row><cell>6.2.3 Dynamic Power</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Ablation of Smatch scores by text source. AP wire ('apw') data was the easiest to parse, Web forum ('web1') and Xinhua ('xin') were the hardest.</figDesc><table><row><cell>(c3 / minister</cell><cell cols="2">:mod (c1 / prime)</cell><cell cols="2">:ARG0 (c2 / have-org-role-91</cell><cell cols="2">:ARG2 c3)</cell><cell cols="2">:mod (c0 / person</cell><cell cols="2">:name (n0 / name :op1 "David"</cell><cell cols="2">:op2 "Cameron"))</cell><cell>:ARG1 (c4 / country</cell><cell>:name (n1 / name :op1 "United"</cell><cell>:op2 "Kingdom")))</cell></row><row><cell cols="2">(x6 / have-org-role-91</cell><cell cols="2">:ARG0 (x1 / person</cell><cell cols="2">:wiki "David_Cameron"</cell><cell cols="2">:name (n / name :op1 "David"</cell><cell cols="2">:op2 "Cameron"))</cell><cell cols="2">:ARG1 (x9 / country</cell><cell>:wiki "United_Kingdom"</cell><cell>:name (n1 / name :op1 "United"</cell><cell>:op2 "Kingdom"))</cell><cell>:ARG2 (m / minister)</cell><cell>:mod (x5 / prime))</cell><cell>(b) Brandeis / cemantix.org / RPI (0.95) (prime not mod of minister)</cell></row><row><cell cols="2">(h / have-org-role-91</cell><cell cols="2">:ARG0 (p / person</cell><cell cols="2">:wiki "David_Cameron"</cell><cell cols="2">:name (n / name :op1 "David"</cell><cell cols="2">:op2 "Cameron"))</cell><cell cols="2">:ARG1 (c / country</cell><cell>:wiki "United_Kingdom"</cell><cell>:name (n2 / name :op1 "United"</cell><cell>:op2 "Kingdom"))</cell><cell>:ARG2 (m / minister</cell><cell>:mod (p2 / prime)))</cell><cell>(a) Gold / CMU / RIGA (1.0) (M2L = 0.95; missing wiki)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/kevincrawfordknight/ amr-guidelines/blob/master/amr.md.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">LDC2015R33 for just the sentences, and LDC2015R36 for sentences with their AMRs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Four random restarts.4  A twelfth team, CUCLEAR, participated but produced invalid AMRs that could not be scored.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">That is, correctly generating a multi-set of instances with the same labels as those in the reference is sufficient for a perfect score. The task of correctly generating instances that are in proper relation to each other is handled by the relations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">Funding for trophies graciously provided by the Jelinek-Mercer Institute for Semantic Translation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Many thanks to the AMR creation team: Kira Griffitt, Ulf Hermjakob, Kevin Knight, and Martha Palmer. Thanks also to the SemEval organizers: Steven Bethard, Daniel Cer, Marine Carpuat, David Jurgens, Preslav Nakov, and Torsten Zesch. We also gratefully acknowledge the participating teams' efforts. This work was sponsored by DARPA DEFT (FA8750-13-2-0045).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Erratum</head><p>Subsequent to the camera-ready deadline for this document it was determined that changes between Smatch versions 2.0 and 2.0.2 led to quoted and nonquoted items in AMRs being judged non-identical; in previous versions they were judged identical and the change in 2.0.2 was not intended to alter this behavior. CU-NLP saw a significant increase in overall F1 as a result of the fix, while the other systems were not affected. Thanks to William Foland for identifying the bug. This version also fixes some attribution errors.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Broad-coverage CCG semantic parsing with AMR</title>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-09" />
			<biblScope unit="page" from="1699" to="1710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Abstract Meaning Representation for sembanking</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
				<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-08" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">RIGA at SemEval-2016 task 8: Impact of Smatch extensions and character-level neural translation on AMR parsing accuracy</title>
		<author>
			<persName><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Didzis</forename><surname>Gosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Meaning Factory at SemEval-2016 task 8: Producing AMRs with Boxer</title>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Bjerva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hessel</forename><surname>Haagsma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ICL-HD at SemEval-2016 task 8: Meaning representation parsing -augmenting AMR parsing with a preposition semantic role labeling neural network</title>
		<author>
			<persName><forename type="first">Lauritz</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Grimm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">DynamicPower at SemEval-2016 task 8: Processing syntactic parse trees with a dynamic semantics core</title>
		<author>
			<persName><forename type="first">Alastair</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013-08" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Linguistically motivated large-scale NLP with C&amp;C and Boxer</title>
		<author>
			<persName><forename type="first">James</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions</title>
				<meeting>the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume the Demo and Poster Sessions<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A discriminative graph-based parser for the Abstract Meaning Representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
				<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="1426" to="1436" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">CMU at SemEval-2016 task 8: Graph-based AMR parsing with infinite ramp loss</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Flanigan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CU-NLP at SemEval-2016 task 8: AMR parsing using LSTMbased recurrent neural networks</title>
		<author>
			<persName><forename type="first">William</forename><surname>Foland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">UCL+Sheffield at SemEval-2016 task 8: Imitation learning for AMR parsing with an alphabound</title>
		<author>
			<persName><forename type="first">James</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Naradowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">From Treebank to Propbank</title>
		<author>
			<persName><forename type="first">Paul</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Language Resources and Evaluation</title>
				<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">UofR at SemEval-2016 task 8: Learning synchronous hyperedge replacement grammar for AMR parsing</title>
		<author>
			<persName><forename type="first">Xiaochang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Gildea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Aligning English strings with Abstract Meaning Representation graphs</title>
		<author>
			<persName><forename type="first">Nima</forename><surname>Pourdamghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
				<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-10" />
			<biblScope unit="page" from="425" to="429" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Parsing English into Abstract Meaning Representation using syntaxbased machine translation</title>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Marcu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="1143" to="1154" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">M2L at SemEval-2016 task 8: AMR parsing with neural networks</title>
		<author>
			<persName><forename type="first">Yevgeniy</forename><surname>Puzikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daisuke</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sadao</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Clip@umd at SemEval-2016 task 8: Parser for Abstract Meaning Representation using learning to search</title>
		<author>
			<persName><forename type="first">Sudha</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yogarshi</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Boosting transition-based AMR parsing with refined actions and auxiliary analyzers</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
				<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="857" to="862" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A transition-based algorithm for AMR parsing</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015-05" />
			<biblScope unit="page" from="366" to="375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">CAMR at SemEval-2016 task 8: An extended transition-based AMR parser</title>
		<author>
			<persName><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust subgraph generation improves Abstract Meaning Representation parsing</title>
		<author>
			<persName><forename type="first">Keenon</forename><surname>Werling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gabor</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
				<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="982" to="991" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
