<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2019 Task 9: Suggestion Mining from Online Reviews and Forums</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sapna</forename><surname>Negi</surname></persName>
							<email>sapna.negi1@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Genesys Telecommunication Laboratories Galway</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Tobias</forename><surname>Daudert</surname></persName>
							<email>tobias.daudert@insight-centre.org</email>
							<affiliation key="aff1">
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paul</forename><surname>Buitelaar</surname></persName>
							<email>paul.buitelaar@insight-centre.org</email>
							<affiliation key="aff2">
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2019 Task 9: Suggestion Mining from Online Reviews and Forums</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the pilot SemEval task on Suggestion Mining. The task consists of subtasks A and B, where we created labeled data from feedback forum and hotel reviews respectively. Subtask A provides training and test data from the same domain, while Subtask B evaluates the system on a test dataset from a different domain than the available training data. 33 teams participated in the shared task, with a total of 50 members. We summarize the problem definition, benchmark dataset preparation, and methods used by the participating teams, providing details of the methods used by the top ranked systems. The dataset is made freely available to help advance the research in suggestion mining, and reproduce the systems submitted under this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>State of the art opinion mining systems provide numerical summaries of sentiments and tend to overlook additional descriptive and potentially useful content present in the opinionated text. We stress that such content also encompass information like suggestions, tips, and advice, which is otherwise explicitly sought by the stakeholders. For example, hotel reviews often contain room tips, i.e., which room should be preferred in a hotel. Likewise, tips on restaurants, shops, sightseeing, etc. are also present within the hotel reviews. On the other hand, platforms like Tripadvisor 1 , which collect hotel and restaurant related opinions, request the reviewers to fill up the room tips section in addition to the hotel review. Likewise, sentences expressing advice, tips, and recommendations relating to a target entity can often be present in text available from different types of data sources, like blogs, microblogs, discussions, etc. Such sentences can be collectively referred to as suggestions. With the increasing availability of opinionated text, methods for automatic detection of suggestions can be employed for different use cases. Some example use cases are the extraction of suggestions for brand improvement, the extraction of tips and advice for customers, the extraction of the expressions of recommendations from unstructured data in order to aid recommender systems, or the summarisation of suggestion forums where suggestion providers often tend to provide context in their responses (Figure <ref type="figure">1</ref>) which gets repetitive over a large number of responses relating to the same entity. The task of automatic identification of suggestions in a given text is referred to as suggestion mining <ref type="bibr" target="#b2">(Brun and Hagege, 2013)</ref>.</p><p>Studies performed on suggestion mining have defined it as a sentence classification task, where class prediction has to be made on each sentence of a given text, classes being suggestion and non suggestion <ref type="bibr" target="#b18">(Negi, 2016)</ref>. State of the art opinion mining systems have mostly focused on identifying sentiment polarity of the text. Therefore, suggestion mining remains a very less explored problem as compared to sentiment analysis, specially in the context of recent advancements in neural network based approaches for feature learning and transfer learning.</p><p>As suggestion mining is still an emerging research area, it lacks benchmark datasets and well defined annotation guidelines. A few early works were mostly rule based methods, mainly targeted towards the use case of extracting suggestions for product improvements <ref type="bibr" target="#b2">(Brun and Hagege, 2013;</ref><ref type="bibr" target="#b29">Ramanand et al., 2010;</ref><ref type="bibr" target="#b16">Moghaddam, 2015)</ref>. In our prior work, we performed early investigations on the problem definition and datasets, aiming for the statistical methods which also require benchmark train datasets in addition to the evaluation Figure <ref type="figure">1</ref>: A post from the suggestion forum for Microsoft developers datasets <ref type="bibr" target="#b21">(Negi and Buitelaar, 2015;</ref>. A few other works also evaluated statistical classifiers <ref type="bibr" target="#b33">(Wicaksono and Myaeng, 2012;</ref><ref type="bibr" target="#b8">Dong et al., 2013)</ref>, which employed mostly manually identified features, however only two other works <ref type="bibr" target="#b33">(Wicaksono and Myaeng, 2012;</ref><ref type="bibr" target="#b8">Dong et al., 2013)</ref> provided their datasets. Suggestion mining still lacks well defined annotation guidelines, a multi-domain and cross-domain approach to the problem and benchmark datasets, which we address in our recent work <ref type="bibr" target="#b22">(Negi et al., 2018)</ref>. Therefore, we introduce this pilot shared task to disseminate suggestion mining benchmarks and evaluate state of the art methods for text classification on domain specific and cross domain training scenarios. The datasets released as a part of the shared task include the domains hotel reviews and software developers suggestion forum (see Table <ref type="table" target="#tab_1">1</ref>).</p><p>Suggestion mining faces similar text processing challenges as other sentence or short text classification tasks related to opinion mining and subjectivity analysis, such as stance detection <ref type="bibr" target="#b17">(Mohammad et al., 2016)</ref>, or tweet sentiment classification <ref type="bibr" target="#b30">(Rosenthal et al., 2015)</ref>. Some of the observed challenges in suggestion mining are elaborated below:</p><p>• Class imbalance: Usually, suggestions tend to appear sparsely among opinionated text, which leads to higher data annotation costs and results in a class distribution bias in the trained models.</p><p>• Figurative expressions: Text from social media and other sources usually contains figurative use of language, which demands pragmatic understanding from the models. For example, 'Try asking for extra juice at breakfast -its 22 euros!!!!!' is more of a sarcasm than a suggestion. Therefore, a sentence framed as a typical suggestions may not always be a suggestion and vice versa. A variety of linguistic strategies used in suggestions also make this task interesting from a computational linguistics perspective and labeled datasets can be leveraged for linguistic studies as well.</p><p>• Context dependency: In some cases, context plays a major role in determining whether a sentence is a suggestion or not. For example, 'There is a parking garage on the corner of the Forbes showroom.' can be labeled as a suggestion (for parking space) when it appears in a restaurant review and a human annotator gets to read the full review. However, the same sentence would not be labeled as a suggestion if the text is aimed to describe the surroundings of the Forbes showroom.</p><p>• Long and complex sentences: Often, a suggestion is expressed in either one part of a sentence, or it is elaborated as a long sentence, like, 'I think that there should be a nice feature where you can be able to slide the status bar down and view all the push notifications that you got but you didn't view, just like  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>The early rule based approaches towards suggestion mining assumed that suggestions are always expressed using standard expressions like 'I recommend', 'I suggest that', 'You should', and created small evaluation datasets which were labeled in-house <ref type="bibr" target="#b2">(Brun and Hagege, 2013;</ref><ref type="bibr" target="#b29">Ramanand et al., 2010)</ref>. Only two of the previous studies released training datasets, which cover travel discussion forums <ref type="bibr" target="#b34">(Wicaksono and Myaeng, 2013)</ref> and microblogs <ref type="bibr" target="#b8">(Dong et al., 2013)</ref>, while the review datasets from the previous works remain proprietary <ref type="bibr" target="#b29">(Ramanand et al., 2010;</ref><ref type="bibr" target="#b16">Moghaddam, 2015)</ref>. In our recent work, we perform a qualitative analysis of datasets from different sources, which includes investigation of linguistic properties of suggestions, relationship between sentiments and suggestions, and a laymans perception of suggestions <ref type="bibr" target="#b19">(Negi, 2019)</ref>. We also observed a low inter-annotator agreement in labeling sentences as suggestions and non-suggestions, and formulate a typology for sentences in context to suggestion detection, and design an annotation procedure based on this typology <ref type="bibr" target="#b22">(Negi et al., 2018;</ref><ref type="bibr" target="#b19">Negi, 2019)</ref>. For this shared task, we extend datasets from our previous studies, following the same task description and annotation method.</p><p>The Oxford dictionary defines suggestion as, An idea or plan put forward for consideration, and some of the listed synonyms of suggestions are proposal, proposition, recommendation, advice, hint, tip, clue. Many linguistic studies define how suggestions should be expressed in a standard use of language. However, in the context of text mining, we are dealing with user generated text on the web, which can be associated with multiple contexts, like the end user, domain etc. We observed in our layman annotation study, context may affect an annotator's judgment. In the absence of context, different annotators associate different contexts to a candidate sentence. We observed that the following concepts form an integral part of defining a suggestion in the context of suggestion mining and proposed an empirically driven and context-based definition of suggestions.</p><p>• Surface structure: Different surface structures <ref type="bibr" target="#b4">(Chomsky, 1957;</ref><ref type="bibr" target="#b5">Crystal, 2011)</ref> can be used to express the underlying intention of giving the same suggestion. For example, The nearby food outlets serve fresh local breakfast and are also cheaper and You can also have breakfast at the nearby food outlets which are cheaper and equally good.</p><p>• Context: When dealing with specific use cases, context plays an important role in distinguishing a suggestion from a nonsuggestion. Context may be present within a given sentence. It can be a set of values corresponding to different variables that are provided explicitly and in addition to a given sentence. One or more of the following variables can constitute the context: Domain: In this work, we refer to the source of a text as domain, which should not be considered in-line with the standard definition of domain. For example, in this shared task, we used hotel and suggestion forum domains.</p><p>Source text: The text in the entire source document to which a sentence belongs may also serve as a context, giving an insight into the discourse where the suggestion appeared. Application or use case: Suggestions may sometimes be sought only around a specific topic, for example, room tips from hotel reviews. Suggestions can also be selectively mined for a certain class of users, for example, suggestions for future customers. All non-relevant suggestions in the data may be regarded as non-suggestions in this case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Given that</head><p>• s denotes the surface structure of a sentence,</p><p>• C denotes additional context provided with s, where the context can be a set of values corresponding to certain variables, and</p><p>• a(s, C) denotes the annotation agreement for the sentence, and t denotes a threshold value for the annotation agreement, we write S(s, C) to denote the suggestion function, which is defined as</p><formula xml:id="formula_0">S(s, C) = Suggestion, if a(s, C) ≥ t N on-suggestion, if a(s, C) &lt; t.</formula><p>(1) Depending on the choice of C, and, hence, on the value of a(s, C), we identify four categories of sentences that a suggestion mining system is likely to encounter.</p><p>Explicit suggestions. Explicit suggestions are sentences for which S always outputs Suggestion, whether C is the empty set or not. They are like the direct and conventionalised forms of suggestions as defined by <ref type="bibr" target="#b15">(Martínez Flor, 2005)</ref>. It may also be the case that such sentences have a strong presence of context within their surface form, as in illustrated by If you do end up here, be sure to specify a room at the back of the hotel.</p><p>Explicit non-suggestions. These are the sentences for which S always outputs Nonsuggestion, whether C is the empty set or not. For example, Just returned from a 3 night stay.</p><p>Implicit suggestions. These are sentences for which S outputs Non-suggestion only when C is the empty set. Typically, implicit suggestions do not posses the surface form of suggestions but the additional context helps the readers to identify them as suggestions.</p><p>For example, There is a parking garage on the corner of Forbes, so its pretty convenient is labeled as a suggestion by the annotators when the context is revealed as that of a restaurant review. A sentence such as Malahide is a pleasant village-turneddormitory-town near the airport can be considered as a suggestion given that it is obtained from a travel discussion thread for Dublin. These kind of sentences are observed to have a lower inter annotator agreement than the above two categories.</p><p>Implicit non-suggestions. These are sentences for which S outputs Suggestion only when C is an empty set. Typically, an implicit nonsuggestion posses the surface form of suggestions but the context leads readers to identify them as non-suggestions. Such sentences may contain sarcasm. Examples include Do not advertise if you don't know how to cook appearing in a restaurant review and The iPod is a very easy to use MP3 player, and if you can't figure this out, you shouldn't even own one appearing in a MP3 player review.</p><p>The proposed categories provide the flexibility to change the scope of classes in a well defined manner, as well as to define context as per the application and use case. Based on the above four categoriese can define the scope of suggestion and non-suggestion classes for suggestion mining tasks. For open domain and cross domain suggestion mining, we proposed to limit the scope of suggestions to the explicit suggestions. Therefore, we set the definition of suggestion for this shared task as:</p><p>Let s be a sentence. If s is an explicit suggestion, assign the label Suggestion. Otherwise, assign the label Non-suggestion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset Annotation</head><p>A two phase annotation methodology, as proposed in our previous works <ref type="bibr" target="#b22">(Negi et al., 2018;</ref><ref type="bibr" target="#b19">Negi, 2019)</ref> is followed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Phase 1: Crowdsourced Annotations</head><p>This phase is performed using paid crowdsourcing, where each sentence is annotated by multiple layman annotators, and the set of annotators do not necessarily remain the same for all the sentences. We used Figure Eight 4 to collect layman annotations.</p><p>Annotators were also provided with the context, i.e. source text from where the sentence is extracted. They were simply asked to choose to label a sentence as suggestions if it contained expressions of suggestion, advice, tip, and recommendation. We aimed to collect implicit and explicit suggestions in this phase.</p><p>For quality control, before being allowed to perform a job, the annotators were presented with a set of test sentences which are similar to the actual questions except that their answers have already been provided by us to the system. We also submitted the explanation behind the correct answer. This way the test questions serve two purposes: test the annotators competency and understanding of the job, and train the annotator for the job. Crowdflower recommends certain best practices to prepare effective test questions. <ref type="bibr">5</ref> . We submitted 30 test questions for each dataset. Each starting annotator was presented with 10 test questions, and only the annotators achieving an accuracy of 70% or more were allowed to proceed with the job. If an annotator passed the test and started the job, the remaining unseen test questions were presented to them in between the regular sentences without being notified. One sentence out of every 8 was a hidden test question. The accuracy score of a contributor on test questions is referred to as Trust score in a job. If an annotator's trust score dropped below a certain threshold during the course of the annotation, the system did not allow them to proceed further with the job. This threshold score was set to 70% in our case.</p><p>In addition to the hidden test questions, a minimum time for each annotator to stay on one page of the job was set. We set this time to 40 seconds (5 seconds on average for each sentence).</p><p>If annotators appeared to be faster than that, they were automatically removed from the job. We restricted access to annotators from countries where English is a popular language and that are also likely to have a large crowdsourcing workforce. Most of the annotators came from Australia, Canada, Germany, India, Ireland, the United Kingdom, and the USA.</p><p>Annotation agreement: Crowdflower's confidence score describes the level of agreement between multiple contributors and the confidence in the validity of the result at the same time, we used a threshold confidence score of 0.6. However, it can be the case that a sentence is very ambiguous and cannot achieve the confidence score even after a large number of workers answered it. A maximum limit to the number of annotators is set in such case, and no further judgements are collected even if the threshold confidence is not reached. We set this limit to 5 annotators. Sentences that do not pass the confidence threshold of 0.6 are not included in the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Phase 2: Expert Annotations</head><p>This phase is performed by two in-house expert annotators, who are provided with the detailed annotation guidelines as compared to the phase 1 annotation guidelines, and the annotators are familiar with the problem definition and the task at hand. However, the annotators are not provided with the source text in this case. Phase 2 of the annotation is only applied to sentences that were labeled as suggestions in Phase 1, which drastically reduces the number of annotations to be performed in Phase 2. Annotation Agreement: The inter-annotator agreement for Phase 2 was calculated by having two annotators label a subset of sentences for each domain (50 sentences). Cohen's kappa coefficient was used to measure the inter-annotator agreement. The remainder of the data instances were annotated by only one annotator. The fol-  An implicit way of expressing the suggestion could be The cup cakes from the bakery next door were delicious.</p><p>• The suggestion should have the intent of benefiting a stakeholder and should not be mere sarcasm or a joke. For example, If the player doesn't work now, you can run it over with your car would not pass this test.</p><p>Following are some of the scenarios of conflicting judgments observed in this phase of annotation:</p><p>• In the case of suggestion forums for specific domains, like a software developer forum, domain knowledge is required to distinguish an implicit non-suggestion from an explicit suggestion. Consider, for example, the two sentences, It needs to be an integrated part of the phones functionality, that is why I put it in Framework and Secondly, you need to limit the number of apps that a publisher can submit with a particular key word. The first sentence is a description of already existing functionality and is a context sentence in the original post, while the second is suggestion for a new feature.</p><p>• No concrete mention of what is being advised such as in It'd be great if you would work on a solution to improve the situation.</p><p>• At times, there was a confusion between information (fact) or suggestion (opinion). For example, You can get a ticket that covers 6 of the National Gallery sites for only about US$10.</p><p>In the final dataset, the sentences that are labeled as suggestions in Phase 2 of the annotation process are labeled as suggestions, while all other sentences are labeled as non-suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">SemEval 2019 Shared Task</head><p>This is the pilot shared task on suggestion mining, the task is set as a binary sentence classification task, where the classes are suggestion and non-suggestion. As explained previously, explicit suggestions are deemed as the suggestion class, and rest of the sentences are considered as non-suggestions. The task is further split into two subtasks, named as A and B. Participating teams were to participate in at-least one of the two subtasks.</p><p>Datasets: Table <ref type="table" target="#tab_3">2</ref> lists the details of the currently datasets released under this task and the inter-annotator agreement in the phase 2 of annotations. The class distribution is retained as obtained from a random sample of the source dataset used for annotation. Software suggestion forum: The sentences for this dataset were scraped from the Uservoice platform <ref type="bibr">6</ref> . Uservoice provides customer engagement tools tobrands, and therefore hosts dedicated suggestion forums for certain prod-ucts. The Feedly mobile application forum and the Windows developer forum are openly accessible. A sample of posts were scraped and split into sentences using the Stanford CoreNLP toolkit. Many suggestions are in the form of requests, which is less frequent in other domains. The text contains highly technical vocabulary related to the software which is being discussed. Hotel reviews: <ref type="bibr" target="#b32">Wachsmuth et al. (2014)</ref> provide a large dataset of hotel reviews collected from the TripAdvisor website 7 . They segmented the reviews into statements so that each statement has only one sentiment label and have manually labeled the sentiments. Statements are equivalent to sentences, and comprise of one or more clauses. We further annotated these segments as suggestion and non-suggestion. Sub-Task A: Train and test dataset belong to the same domain. The provided domain is suggestion forum sentences for software developers. Title of the posts are excluded, which are at times summary of the suggestion. Sub-Task B: No training dataset is provided, and the test dataset belongs to a different domain than the subtask A, i.e. hotel reviews. The participants could use the training dataset from subtask A. Participants were not allowed to use the trial test set for subtask B as a training dataset, however they were allowed to use trial test set as a validation dataset. Additional resources: Participants were allowed to use additional language resources, with one exception. Participants will be prohibited from using additional hand labeled training datasets for any of the domain. F1 score for the suggestion class is: F1 sugg = 2 * (P sugg * R sugg ) / (P sugg + R sugg )</p><p>Baseline System A rule based classifier is employed using the existing rules from some of the related works, the rules which were dependent on the domain specific variables were excluded from the baseline. Table <ref type="table">4</ref> provides the rules used in the baseline system.</p><p>Trial vs Test phase: A trial test dataset was released prior to the final test/evaluation dataset. The class distribution in the trial set was deliberately balanced in order to not bias the participants towards a specific class distribution for the evaluation phase, and keep the class distribution of trial set different from that of the final test set. This was because the trial test dataset labels were released prior to the final evalaution phase, and it was used as a validation dataset by the participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Participating Systems</head><p>A total of 33 teams participated in the evaluation phase, where all teams participated in the subtask A, and 16 of these also participated in subtask B. This number is lower than the trial phase submissions, where a total of 50 teams submitted their results on trial test dataset. Out of 33, 20 teams also submitted their system description papers. A summary of these 20 systems is provided in Table <ref type="table" target="#tab_5">3</ref>, listing results and corresponding methods.</p><p>The highest F-score achieved was reasonably high i.e. 0.78 for subtask A, given a very low number of suggestion sentences in the test dataset 2. The highest F-score for subtask B was 0.858, where the ratio of suggestion and non-suggestion sentences in the test set was higher than subtask A.</p><p>Top 3 systems: BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> pre-trained language model remains the common method in the top three systems submitted in subtask A, which is one of the state of the art statistical language models. However, the most interesting results are provided by the best performing system in subtask B, which uses a rule based classifier, where rules comprise of both words and POS tags. The devised rule-based classifier <ref type="bibr">(Potamias et al., 2019)</ref> assigns confidence scores to sentences on the basis of lexical patterns organised in pre-specified categories and lexical lists corresponding to each subtask. This rule based system also performed fairly well in subtask A, where it achieved rank 5.</p><p>Transfer and Unsupervised Learning: While a variety of pre-trained word embeddings and language models were employed, BERT remains the most popular means of transfer learning in the submitted systems, where 7 out of top 13 systems for subtask A used BERT.  Keywords and phrases needs to, need to suggest, recommend, if, i wish, go for,should have, would, could have been i would like, i'd like, i would love, I'd love, love to see there should be, I wish, allow us to Syntactic clues If a modal verb or a base form of verb is present in the sentence. Eg, I would prefer the unit to have a simple on off switch. Table <ref type="table">4</ref>: Rules for the baseline system domain specific unlabeled data, i.e. hotel reviews, and were ranked as 3 and 5. All other submissions for subtask B relied on pre-trained word embeddings and language models.</p><p>Class Imbalance: Given that there was a major difference in the class distribution between training, trial test, and final test datasets, a minority of the top ten systems explicitly handle class imbalance by methods like oversampling (team MIDAS) and assigning weights to the predicted probability which are in proportion to the class distribution of the training data (team Yimmon). Other top 10 systems performed fairly well without any additional configuration for class imbalance in their classifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Types of Classifiers:</head><p>All systems except two used statistical classifiers, with most of them using neural network classifiers. Classifier ensembles also remain a favoured approach among the top ten systems. The neural network classifiers clearly outperformed SVM, Naive Bayes and Logistic regression. For subtask B, rule based classifier seem to do fairly well. The state of the art deep learning classifiers achieved a similar performance without any manual feature engineering, as compared to the carefully hand crafted rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Summary</head><p>We organised the pilot shared task on suggestion mining, which was framed as a binary text classification task, with two subtasks representing domain dependent and cross-domain/open domain evaluation. The task achieved a high level of participation, and most importantly a wide coverage in terms of methods and algorithms. The approaches covered automatically learned rule, carefully crafted linguistic features and rules, SOTA neural network classifiers, and SOTA transfer learning approaches. This shared task acted as a catalyst in pushing forward the state of the art for Suggestion Mining which otherwise received We plan to extend the task in future years with larger datasets, and the problem framed as the extraction of suggestion sentences from source texts in place of sentence classification. The problem definition here a better availability of document level context as compared to the sentence level context.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Evaluation Metrics: Classification performance of the submitted systems if evaluated on the basis of F-1 score for the positive class, i.e. the suggestion class, which ranges from 0 to 1. Precision suggestion (P sugg ): The fraction of instances which are actually suggestions out of the ones which are predicted as suggestions. P sugg = True Positives / (True Positives + False Positives) Recall suggestion (R sugg ): The fraction of suggestion class instances which are correctly identified out of the total number of suggestions. R sugg = True Positives / (True Positives + False Negatives)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Examples of suggestions found in reviews and the labels assigned to the suggestion sentences</figDesc><table><row><cell>android and IOS, but the best part is that it</cell></row><row><cell>fixes many problems like when people wanted</cell></row><row><cell>a short cut to turn WiFi on and off and data</cell></row><row><cell>on and off so that would be a nice feature to</cell></row><row><cell>have 2'. This poses challenges to the training</cell></row><row><cell>of algorithms in terms of learning effective</cell></row><row><cell>features, as well as for certain pre-processing</cell></row><row><cell>steps like part of speech tagging.</cell></row><row><cell>Investigating the development of high perfor-</cell></row><row><cell>mance suggestion mining systems could drive the</cell></row><row><cell>engagement of both, commercial entities (like</cell></row><row><cell>brand owners) as well as the research communi-</cell></row><row><cell>ties, working on problems such as opinion mining,</cell></row><row><cell>supervised learning, or representation learning. A</cell></row><row><cell>suggestion mining component can empower both,</cell></row><row><cell>public and private sectors, to extract and lever-</cell></row><row><cell>age suggestions which are constantly expressed on</cell></row><row><cell>various online platforms like Twitter 2 , TripAdvi-</cell></row><row><cell>sor, or Reddit 3 for developing innovative services</cell></row><row><cell>and products.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Details of released datasets</figDesc><table><row><cell>lowing guidelines were provided to the annotators</cell></row><row><cell>in Phase 2 :</cell></row><row><cell>• The intent of giving a suggestion and the sug-</cell></row><row><cell>gested action or recommended entity should</cell></row><row><cell>be explicitly stated in the sentence. Try the</cell></row><row><cell>cup cakes at the bakery next door is a positive</cell></row><row><cell>example. Other explicit forms of this sugges-</cell></row><row><cell>tion could be: I recommend the cup cakes at</cell></row><row><cell>the bakery next door or You should definitely</cell></row><row><cell>taste the cup cakes from the bakery next door.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>A summary of systems which are available as system description papers.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.tripadvisor.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.twitter.com 3 https://www.reddit.com</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Earlier known as Crowdflower. https://www. figure-eight.com/ 5 https://success.crowdflower. com/hc/en-us/articles/ 213078963-Test-Question-Best-Practices</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">https://www.uservoice.com/ 7 https://www.tripadvisor.com/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Suggestion miner at semeval-2019 task 9: Suggestion detection in online forum using word graph</title>
		<author>
			<persName><forename type="first">Usman</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Humera</forename><surname>Liaquat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luqman</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Syed Jawad</forename><surname>Hussain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Midas at semeval-2019 task 9: Suggestion mining from online reviews using ulmfit</title>
		<author>
			<persName><forename type="first">Sarthak</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debanjan</forename><surname>Mahata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laiba</forename><surname>Mehnaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simra</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haimin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaman</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><surname>Rajiv Ratn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karan</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><surname>Uppal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Suggestion mining: Detecting suggestions for improvement in users comments</title>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Brun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><surname>Hagege</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Research in Computing Science</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ds at semeval-2019 task 9: From suggestion mining with neural networks to adversarial cross-domain classification</title>
		<author>
			<persName><forename type="first">Tobias</forename><surname>Cabanski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019)</title>
				<meeting>the 13th International Workshop on Semantic Evaluation (SemEval-2019)<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Syntactic Structures. Mouton and Co</title>
		<author>
			<persName><forename type="first">Noam</forename><surname>Chomsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1957" />
			<pubPlace>The Hague</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A Dictionary of Linguistics and Phonetics. The Language Library</title>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
				<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ynu dyx at semeval-2019 task 9: A stacked bilstm model for suggestion mining classific</title>
		<author>
			<persName><forename type="first">Yunxia</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaobing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuejie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The automated acquisition of suggestions from tweets</title>
		<author>
			<persName><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yajuan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-Seventh AAAI Conference on Artificial Intelligence</title>
				<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hybrid rnn at semeval-2019 task 9: Blending information sources for domain-independent suggestion mining</title>
		<author>
			<persName><forename type="first">Aysu</forename><surname>Ezen-Can</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethem</forename><forename type="middle">F</forename><surname>Can</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dbms-ku at semeval-2019 task 9: Exploring machine learning approaches in classifying text as suggestion or nonsuggestion</title>
		<author>
			<persName><forename type="first">Al</forename><surname>Tirana Noor Fatyanosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maulana</forename><surname>Hafiz Akbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Masayoshi</forename><surname>Siagian</surname></persName>
		</author>
		<author>
			<persName><surname>Aritsugi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Olenet at semeval-2019 task 9: Bert based multiperspective models for suggestion mining</title>
		<author>
			<persName><forename type="first">Liu</forename><surname>Jiaxiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wang</forename><surname>Shuohuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sun</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wut at semeval-2019 task 9: Domainadversarial neural networks for domain adaptation in suggestion mining</title>
		<author>
			<persName><forename type="first">Mateusz</forename><surname>Klimaszewski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piotr</forename><surname>Andruszkiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Lijunyi at semeval-2019 task 9: An attention-based lstm model and ensemble of different models for suggestion mining from online reviews and forums</title>
		<author>
			<persName><forename type="first">Junyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyan</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Inria at semeval-2019 task 9: Suggestion mining using svm with handcrafted features</title>
		<author>
			<persName><forename type="first">Ilia</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Villemonte De La</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clergerie</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A theoretical review of the speech act of suggesting: Towards a taxonomy for its use in flt. Revista alicantina de estudios ingleses</title>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Flor</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2005-11" />
			<biblScope unit="page" from="167" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Beyond sentiment analysis: mining defects and improvements from customer feedback</title>
		<author>
			<persName><forename type="first">Samaneh</forename><surname>Moghaddam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="400" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Saif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svetlana</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parinaz</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaodan</forename><surname>Sobhani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><surname>Cherry</surname></persName>
		</author>
		<title level="m">Semeval-2016 task 6: Detecting stance in tweets</title>
				<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="31" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Suggestion mining from opinionated text</title>
		<author>
			<persName><forename type="first">Sapna</forename><surname>Negi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sentiment Analysis in Social Networks</title>
				<editor>
			<persName><forename type="first">Alberto</forename><surname>Pozzi</surname></persName>
			<persName><forename type="first">Elisabetta</forename><surname>Fersini</surname></persName>
			<persName><forename type="first">Enza</forename><surname>Messina</surname></persName>
			<persName><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Suggestion mining from text</title>
		<author>
			<persName><forename type="first">Sapna</forename><surname>Negi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>NUI Galway</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A study of suggestions in opinionated texts and their automatic detection</title>
		<author>
			<persName><forename type="first">Sapna</forename><surname>Negi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Asooja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shubham</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics</title>
				<meeting>the Fifth Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="170" to="178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Towards the extraction of customer-to-customer suggestions from reviews</title>
		<author>
			<persName><forename type="first">Sapna</forename><surname>Negi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
				<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon,Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2159" to="2167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Open domain suggestion mining: Problem definition and datasets</title>
		<author>
			<persName><forename type="first">Sapna</forename><surname>Negi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Maarten De Rijke</surname></persName>
		</author>
		<author>
			<persName><surname>Buitelaar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.02179</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Team taurus at semeval-2019 task 9: Expert-informed pattern recognition for suggestion mining</title>
		<author>
			<persName><forename type="first">Nelleke</forename><surname>Oostdijk</surname></persName>
		</author>
		<author>
			<persName><surname>Hans Van Halteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Thisiscompetition at semeval-2019 task 9: Bert is unstable for outof-domain samples</title>
		<author>
			<persName><forename type="first">Cheoneum</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hyeon-Gu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reinald</forename><surname>Kim Amplayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harksoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jungyun</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Changki</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Nl-fiit at semeval-2019 task 9: Neural model ensemble for suggestion mining</title>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Pecar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marian</forename><surname>Simko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><surname>Bielikova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ynuhpcc at semeval-2019 task 9: Using a bert and cnnbilstm-gru model for suggestion mining</title>
		<author>
			<persName><forename type="first">Yue</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuejie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ntua-islab at semeval-2019 task 9: Mining suggestions in the wild</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation (SemEval-2019)</title>
				<meeting>the 13th International Workshop on Semantic Evaluation (SemEval-2019)<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Rolandos Alexandros Potamias, Alexandros Neofytou, and Georgios Siolas</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Zoho at semeval-2019 task 9: Semi-supervised domain adaptation using tri-training for suggestion mining</title>
		<author>
			<persName><forename type="first">Sai</forename><surname>Prasanna</surname></persName>
		</author>
		<author>
			<persName><surname>Sri Ananda Seelan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Wishful thinking -finding suggestions and &apos;buy&apos; wishes from product reviews</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ramanand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krishna</forename><surname>Bhavsar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niranjan</forename><surname>Pedanekar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</title>
				<meeting>the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="54" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Semeval-2015 task 10: Sentiment analysis in twitter</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svetlana</forename><surname>Kiritchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alan</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="451" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ssn-sparks at semeval-2019 task 9: Mining suggestions from online reviews using deep learning techniques on augmented data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rajalakshmi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Angel</forename><surname>Deborah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Milton</forename><surname>Rajendram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirnalinee T T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A review corpus for argumentation analysis</title>
		<author>
			<persName><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Trenkmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Engels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tsvetomira</forename><surname>Palakarska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th International Conference on Computational Linguistics and Intelligent Text Processing</title>
				<meeting>the 15th International Conference on Computational Linguistics and Intelligent Text Processing<address><addrLine>Kathmandu, Nepal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">8404</biblScope>
			<biblScope unit="page" from="115" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mining advices from weblogs</title>
		<author>
			<persName><forename type="first">Alfan</forename><surname>Farizki Wicaksono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung-Hyon</forename><surname>Myaeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM International Conference on Information and Knowledge Management, CIKM &apos;12</title>
				<meeting>the 21st ACM International Conference on Information and Knowledge Management, CIKM &apos;12</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2347" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Automatic extraction of advice-revealing sentences for advice mining from online forums</title>
		<author>
			<persName><forename type="first">Alfan</forename><surname>Farizki Wicaksono</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sung-Hyon</forename><surname>Myaeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Conference on Knowledge Capture, K-CAP &apos;13</title>
				<meeting>the Seventh International Conference on Knowledge Capture, K-CAP &apos;13</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="97" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">2019. m y at semeval2019 task 9: Exploring bert for suggestion mining</title>
		<author>
			<persName><forename type="first">Masahiro</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshiyuki</forename><surname>Sekiya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint/>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Zqm at semeval-2019 task9: A single layer cnn based on pre-trained model for suggestion mining</title>
		<author>
			<persName><forename type="first">Qimin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Linmao</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Yimmon at semeval-2019 task 9: Suggestion mining with hybrid augmented approaches</title>
		<author>
			<persName><forename type="first">Yimeng</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
				<meeting>the 13th International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>SemEval-2019</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
