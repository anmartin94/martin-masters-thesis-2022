<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SemEval-2016 Task 12: Clinical TempEval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
							<email>bethard@cis.uab.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Alabama at Birmingham Birmingham</orgName>
								<address>
									<postCode>35294</postCode>
									<region>AL</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
							<email>guergana.savova@childrens.harvard.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Harvard Medical School Boston</orgName>
								<address>
									<postCode>02115</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wei-Te</forename><surname>Chen</surname></persName>
							<email>weite.chen@colorado.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Colorado</orgName>
								<address>
									<addrLine>Boulder Boulder</addrLine>
									<postCode>80309</postCode>
									<region>CO</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
							<email>leon.derczynski@sheffield.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="institution">University of Sheffield Sheffield</orgName>
								<address>
									<postCode>S1 4DP</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
							<email>jamesp@cs.brandeis.edu</email>
							<affiliation key="aff4">
								<orgName type="institution">Brandeis University Waltham</orgName>
								<address>
									<postCode>02453</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Brandeis University Waltham</orgName>
								<address>
									<postCode>02453</postCode>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SemEval-2016 Task 12: Clinical TempEval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-08-25T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Clinical TempEval 2016 evaluated temporal information extraction systems on the clinical domain. Nine sub-tasks were included, covering problems in time expression identification, event expression identification and temporal relation identification. Participant systems were trained and evaluated on a corpus of clinical and pathology notes from the Mayo Clinic, annotated with an extension of TimeML for the clinical domain. 14 teams submitted a total of 40 system runs, with the best systems achieving near-human performance on identifying events and times. On identifying temporal relations, there was a gap between the best systems and human performance, but the gap was less than half the gap of Clinical TempEval 2015.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The TempEval shared tasks have, since 2007, provided a focus for research on temporal information extraction <ref type="bibr" target="#b24">(Verhagen et al., 2007;</ref><ref type="bibr" target="#b25">Verhagen et al., 2010;</ref><ref type="bibr" target="#b23">UzZaman et al., 2013)</ref>. Participant systems compete to identify critical components of the timeline of a text, including time expressions, event expressions and temporal relations. However, the Temp-Eval campaigns to date have focused primarily on in-document timelines derived from news articles. In recent years, the community has moved toward testing such information extraction systems on clinical data <ref type="bibr">(Sun et al., 2013;</ref> to broaden our understanding of the language of time beyond newswire expressions and structure.</p><p>Clinical TempEval focuses on discrete, welldefined tasks which allow rapid, reliable and repeatable evaluation. Participating systems are expected to take as input raw text, for example: April 23, 2014: The patient did not have any postoperative bleeding so we'll resume chemotherapy with a larger bolus on Friday even if there is slight nausea.</p><p>The systems are then expected to output annotations over the text, for example, those shown in Figure <ref type="figure" target="#fig_0">1</ref>. That is, the systems should identify the time expressions, event expressions, attributes of those expressions, and temporal relations between them.</p><p>Clinical TempEval 2016 addressed one of the major challenges in Clinical TempEval 2015: data distribution. Because Clinical TempEval is based on real patient notes from the Mayo Clinic, participants go through a lengthy authorization process involving a data use agreement and an interview. For Clinical TempEval 2016, we streamlined this process and were able to authorize data access for more than twice as many participants as Clinical TempEval 2015. And since all the training and evaluation data distributed for Clinical TempEval 2015 was used as the training data for Clinical TempEval 2016, participants had more than a year to work on their systems. The result was that four times as many teams participated.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The Clinical TempEval corpus was based on a set of 600 clinical notes and pathology reports from cancer patients at the Mayo Clinic. These notes were manually de-identified by the Mayo Clinic to replace names, locations, etc. with generic placeholders, but time expressions were not altered. The notes were then manually annotated by the THYME project (thyme.healthnlp.org) using an extension of ISO-TimeML for the annotation of times, events and temporal relations in clinical notes <ref type="bibr" target="#b20">(Styler et al., 2014b)</ref>. This extension includes additions such as new time expression types (e.g., PREPOSTEXP for expressions like postoperative), new EVENT attributes (e.g., DE-GREE=LITTLE for expressions like slight nausea), and an increased focus on temporal relations of type CONTAINS (a.k.a. INCLUDES).</p><p>The annotation procedure was as follows:</p><p>1. Annotators identified time and event expressions, along with their attributes 2. Adjudicators revised and finalized the time and event expressions and their attributes 3. Annotators identified temporal relations between pairs of events and events and times 4. Adjudicators revised and finalized the temporal relations More details on the corpus annotation process are documented in a separate article <ref type="bibr" target="#b19">(Styler et al., 2014a)</ref>.</p><p>Because the data contained incompletely de-identified clinical data (the time expressions were retained), participants were required to sign a data use agreement with the Mayo Clinic to obtain the raw text of the clinical notes and pathology reports. <ref type="bibr">1</ref> The event, time and temporal relation annotations were distributed separately from the text, in an open source repository 2 using the Anafora standoff format <ref type="bibr" target="#b5">(Chen and Styler, 2013)</ref>.</p><p>The corpus was split into three portions: Train (50%), Dev (25%) and Test (25%). Patients were sorted by patient number (an integer arbitrarily assigned by the de-identification process) and stratified across these splits. The Train and Dev portions were released to participants for training and tuning their systems. The Test portion was reserved for evaluation of the systems. Table <ref type="table" target="#tab_2">1</ref> shows the number of documents, event expressions (EVENT annotations), time expressions (TIMEX3 annotations) and narrative container relations (TLINK annotations with TYPE=CONTAINS attributes) in the Train, Dev, and Test portions of the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Tasks</head><p>Nine tasks were included (the same as those of Clinical TempEval 2015), grouped into three categories:  The evaluation was run in two phases:</p><formula xml:id="formula_0">â€¢</formula><p>1. Systems were provided access only to the raw text, and were asked to identify time expressions, event expressions and temporal relations 2. Systems were provided access to the raw text and the manual event and time annotations, and were asked to identify only temporal relations</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Metrics</head><p>All of the tasks were evaluated using the standard metrics of precision (P ), recall (R) and F 1 :</p><formula xml:id="formula_1">P = |S âˆ© H| |S| R = |S âˆ© H| |H| F 1 = 2 â€¢ P â€¢ R P + R</formula><p>where S is the set of items predicted by the system and H is the set of items annotated by the humans. Applying these metrics only requires a definition of what is considered an "item" for each task.</p><p>â€¢ For evaluating the spans of event expressions or time expressions, items were tuples of (begin, end) character offsets. Thus, systems only received credit for identifying events and times with exactly the same character offsets as the manually annotated ones. â€¢ For evaluating the attributes of event expressions or time expressions -Class, Contextual Modality, Degree, Polarity and Type -items were tuples of (begin, end, value) where begin and end are character offsets and value is the value that was given to the relevant attribute. Thus, systems only received credit for an event (or time) attribute if they both found an event (or time) with the correct character offsets and then assigned the correct value for that attribute. â€¢ For relations between events and the document creation time, items were tuples of (begin, end, value), just as if it were an event attribute. Thus, systems only received credit if they found a correct event and assigned the correct relation (BEFORE, OVERLAP, BEFORE-OVERLAP or AFTER) between that event and the document creation time. In the second phase of the evaluation, when manual event annotations were provided as input, only recall (which in this case is equivalent to standard classification accuracy) is reported. â€¢ For narrative container relations, items were tuples of ((begin 1 , end 1 ), (begin 2 , end 2 )), where the begins and ends corresponded to the character offsets of the events or times participating in the relation. Thus, systems only received credit for a narrative container relation if they found both events/times and correctly assigned a CONTAINS relation between them.</p><p>For event and time attributes, we also measure how accurately a system predicts the attribute values on just those events or times that the system predicted. The goal here is to allow a comparison across systems for assigning attribute values, even when different systems produce different numbers of events and times. This metric is calculated by dividing the F 1 on the attribute by the F 1 on identifying the spans:</p><formula xml:id="formula_2">A = attribute F 1 span F 1</formula><p>For narrative container relations, the P and R definitions were modified to take into account temporal closure, where additional relations are deterministically inferred from other relations (e.g., A CONTAINS B and B CONTAINS C, so A CONTAINS C):  <ref type="bibr">et al., 2013)</ref>, following the intuition that precision should measure the fraction of system-predicted relations that can be verified from the human annotations (either the original human annotations or annotations inferred from those through closure), and that recall should measure the fraction of human-annotated relations that can be verified from the system output (either the original system predictions or predictions inferred from those through closure).</p><formula xml:id="formula_3">P = |S âˆ© closure(H)| |S| R = |closure<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Baseline Systems</head><p>Two rule-based systems were used as baselines to compare the participating systems against.</p><p>memorize For all tasks but the narrative container task, a memorization baseline was used.</p><p>To train the model, all phrases annotated as either events or times in the training data were collected. All exact character matches for these phrases in the training data were then examined, and only phrases that were annotated as events or times greater than 50% of the time were retained. For each phrase, the most frequently annotated type (event or time) and attribute values for instances of that phrase were determined.</p><p>To predict with the model, the raw text of the test data was searched for all exact character matches of any of the memorized phrases, preferring longer phrases when multiple matches overlapped. Wherever a phrase match was found, an event or time with the memorized (most frequent) attribute values was predicted. closest For the narrative container task, a proximity baseline was used. Each time expression was predicted to be a narrative container, containing only the closest event expression to it in the text. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Human Agreement</head><p>We also provide two types of human agreement on the task, measured with the same evaluation metrics as the systems:</p><p>ann-ann Inter-annotator agreement between the two independent human annotators who annotated each document. This is the most commonly reported type of agreement, and often considered to be an upper bound on system performance. adj-ann Inter-annotator agreement between the adjudicator and the two independent annotators. This is usually a better bound on system performance in adjudicated corpora, since the models are trained on the adjudicated data, not on the individual annotator data.</p><p>Precision and recall are not reported in these scenarios since they depend on the arbitrary choice of one annotator as human (H) and the other as system (S).</p><p>Note that since temporal relations between events and the document creation time were annotated at the same time as the events themselves, agreement for this task is only reported in phase 1 of the evaluation. Similarly, since narrative container relations were only annotated after events and times had been adjudicated, agreement for this task is only reported in phase 2 of the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Time Expressions</head><p>Table <ref type="table" target="#tab_6">2</ref> shows results on the time expression tasks. The UTHealth systems achieved the best results on almost all time-related tasks. For finding times, while one system had comparable precision to UTHealth (0.836 UTHealth vs. 0.840 LIMSI), no system had competitive recall (0.757 UTHealth vs. 0.714 from the next best, UtahBMI), and thus the UTHealth system consistently outperformed the other systems in F 1 . The results were similar for jointly finding times and assigning them a time class, though a couple systems (HITACHI, GUIR) did have more accurate predictions for the time class when scored only on the times that they were able to find (0.971 UTHealth vs. 0.975 HITACHI vs. 0.989 GUIR).</p><p>Compared to human agreement, the UTHealth and UtahBMI systems exceeded the inter-annotator agreement on times of 0.731, but even UTHealth's F 1 of 0.795 did not reach the annotator-adjudicator agreement of 0.830, and the results were similar for jointly finding times and assigning their classes (0.772 vs. 0.807). Nonetheless, these 0.025 and 0.035 gaps between the top system and the human agreement are smaller than the 0.051 and 0.038 gaps observed in Clinical TempEval 2015 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Event Expressions</head><p>Table <ref type="table" target="#tab_7">3</ref> shows results on the event expression tasks. Again, UTHealth dominated the field, achieving the highest score on almost every event-related task. However, the gap to the second place team was much smaller for events than it was for times: only a 0.011  and class (DATE, TIME, DURATION, QUANTIFIER, PREPOSTEXP or SET). The best system score from each column is in bold.</p><p>Systems marked with â€  were submitted after the competition deadline and are not considered official.</p><p>gap between UTHealth's 0.903 F 1 and UtahBMI's 0.892. The gap was even smaller if we look at precision and recall separately: a 0.007 gap between UTHealth's 0.915 precision and UTA's 0.908, and a 0.005 gap between UTHealth's 0.891 precision and UtahBMI's 0.886. The results were similar for most of the attributes, though the precision gaps were larger (1.1-1.4) and the recall gaps were smaller (0.3-0.7).</p><p>Compared to human agreement, UTHealth, UtahBMI, Cental, GUIR, and UTA all exceeded inter-annotator agreement on identifying events, and UTHealth and UtahBMI exceeded inter-annotator agreement on all of the attributes. None of the systems reached the level of annotator-adjudicator agreement: even UTHealth's F 1 on events of 0.903 had a gap of 0.019 from the annotator-adjudicator agreement of 0.922, and the results were similar for event attributes: 0.049 for modality, 0.021 for degree, 0.029 for polarity, 0.024 for type. These gaps are almost all bigger than the gaps observed in Clinical Temp-Eval 2015: 0.005 for event spans, 0.031 for modality, 0.007 for degree, 0.012 for polarity, 0.030 for type. However, Clinical TempEval 2016's human agreement was substantially higher, with all annotatoradjudicator agreement above 0.90, while in Clinical TempEval 2015, annotator-adjudicator agreement ranged from 0.853 to 0.880.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Temporal Relations</head><p>Table <ref type="table" target="#tab_8">4</ref> shows performance on the temporal relation tasks. In both phase 1 (where systems were provided only the raw text) and phase 2 (where systems were provided the manually annotated events and times), the UTHealth system was again the top system for most tasks. For relating events to the document creation time, the UTHealth system had the best precision, recall, and F 1 (0.766, 0.746, and 0.756) in phase   1, and the second best score (0.835 vs. UtahBMI's 0.843) in phase 2. For finding narrative container relations, the UTHealth system had the best recall (0.471 in phase 1, 0.559 in phase 2), and though other systems (UtahBMI, VUACLTL, LIMSI-COT, and KULeuven-LIIR) had higher precisions, the recall gap from UTHealth to the next system was large (0.203 in phase 1 and 0.088 in phase 2) and thus UTHealth had the best F 1 in both phases (0.479 in phase 1, 0.573 in phase 2). Compared to human agreement, UTHealth and UtahBMI exceeded inter-annotator agreement on relations to the document time (while still leaving a gap of 0.088 to the annotator-adjudicator agreement), but no participant system was near the human agreement for narrative containers (a gap of 0.078 from inter-annotator agreement and a gap of 0.244 from annotator-adjudicator agreement). For relations to the document time, the 0.088 gap between systems and annotator-adjudicator agreement is slightly larger than the 0.059 of Clinical TempEval 2015, but for narrative container relations the 0.244 gap is much smaller than the 0.412 of Clinical TempEval 2015. As with other tasks, human agreement is higher this year (0.844 and 0.817 in 2016 vs. 0.761 and 0.672 in 2015), which may explain the larger gap for document time relations. The smaller gap for narrative container relations despite the increased human agreement suggests that major improvements have been made to the systems for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Discussion</head><p>The results of Clinical TempEval 2016 suggest that current state-of-the-art systems are close to solving most event and time related tasks. For all of these tasks, the gap between system performance and human performance was less than 0.05, and for half the tasks (time spans, event spans, event degree, event type) it was 0.025 or less.</p><p>The temporal relation tasks were more difficult. Systems trying to predict the temporal relation between an event and the time at which the document was written lagged about 0.09 behind human performance. And systems trying to predict narrative containers (whether one event or time contains another) lagged about 0.25 behind human performance, even when provided human-annotated events and times.</p><p>Nonetheless, the latter result was a major improvement over Clinical TempEval 2015, where the gap on narrative containers was more than 0.4.</p><p>While there was variability across the subtasks in the rankings of teams, UTHealth and UtahBMI were always at the top of the lists. Both of these systems relied on structured learning models (UTHealth used HMM support vector machines; UtahBMI used conditional random fields) with a wide variety of features (lexical, morphological, syntactic, and many others). We can thus infer that such approaches hold promise for temporal information extraction. However, these two teams were also among the first to make it through the data use agreement process, so their success may in part reflect the advantage of having more time for experimentation and feature engineering on the training data.</p><p>Overall, Clinical TempEval 2016 represented a major step forward from Clinical TempEval 2015. It saw a much greater breadth of participating systems (14 teams in 2016 vs. 3 teams in 2015), with the top systems maintaining 2015's high performance on the event and time tasks, while making major progress on the harder temporal relation tasks. Future plans for Clinical TempEval target the robustness of these systems: instead of testing on only colon cancer notes from the Mayo Clinic (the same domain as the training set), systems will be tested on other types of medical conditions and notes from other institutions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example Clinical TempEval annotations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>0.797 0.815 0.764 0.729 0.746 0.915 0.830 0.793 0.811 0.995 CDE-IIITH-dl 0.838 0.786 0.811 0.779 0.731 0.754 0.930 0.834 0.783 0.807 0.995 brundlefly 0.883 0.660 0.755 0.819 0.612 0.701 0.928 0.878 0.657 0.752 0.996 Baseline: memorize 0.878 0.834 0.855 0.810 0.770 0.789 0.923 0.874 0.831 0.852 0.996 GUIR â€  0.891 0.872 0.881 0.836 0.818 0.827 0.939 0.887 0.868 0.877 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Number of documents, event expressions, time expres-</figDesc><table><row><cell>sions and narrative container relations in Train, Dev, and Test</cell></row><row><cell>portions of the THYME data. Both Train and Dev were released</cell></row><row><cell>as part of Clinical TempEval 2015.</cell></row><row><cell>following components:</cell></row><row><cell>-The span (character offsets) of the expres-</cell></row><row><cell>sion in the text</cell></row><row><cell>-Class: DATE, TIME, DURATION, QUAN-</cell></row><row><cell>TIFIER, PREPOSTEXP or SET</cell></row><row><cell>â€¢ Identifying event expressions (EVENT annota-</cell></row><row><cell>tions in the THYME corpus) consisting of the</cell></row><row><cell>following components:</cell></row><row><cell>-The span (character offsets) of the expres-</cell></row><row><cell>sion in the text</cell></row><row><cell>-Contextual Modality: ACTUAL, HYPO-</cell></row><row><cell>THETICAL, HEDGED or GENERIC</cell></row><row><cell>-Degree: MOST, LITTLE or N/A</cell></row><row><cell>-Polarity: POS or NEG</cell></row><row><cell>-Type: ASPECTUAL, EVIDENTIAL or N/A</cell></row><row><cell>â€¢ Identifying temporal relations between events</cell></row><row><cell>and times, focusing on the following types:</cell></row><row><cell>-Relations between events and the doc-</cell></row><row><cell>ument creation time (BEFORE, OVER-</cell></row><row><cell>LAP, BEFORE-OVERLAP or AFTER), rep-</cell></row><row><cell>resented by DOCTIMEREL annotations.</cell></row><row><cell>-Narrative container relations (Pustejovsky</cell></row><row><cell>and Stubbs, 2011), which indicate that an</cell></row><row><cell>event or time is temporally contained in</cell></row><row><cell>(i.e., occurred during) another event or</cell></row><row><cell>time, represented by TLINK annotations</cell></row><row><cell>with TYPE=CONTAINS.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>LIMSI-COT (Tourille et al., 2016)  submitted 2 runs for phase 2, the first based on support vector ma-chines with lexical, syntactic, structural, and UMLS features, and the second based on replacing the lexical features with word embeddings. ULISBOA<ref type="bibr" target="#b1">(Barros et al., 2016)</ref> submitted 2 runs for each phase, based on the IBEnt framework's support vector machines with lexical and morphological features (https://github.</figDesc><table><row><cell>com/AndreLamurias/IBEnt), and rule-based</cell><cell></cell></row><row><cell>extensions to Stanford CoreNLP (Manning et</cell><cell></cell></row><row><cell>al., 2014). The runs differed on how rules were</cell><cell></cell></row><row><cell>incorporated for each subtask.</cell><cell>6 Participating Systems</cell></row><row><cell>UtahBMI (AAl Abdulsalam et al., 2016) submit-</cell><cell></cell></row><row><cell>ted 2 runs for each phase, the first based on</cell><cell>14 research teams submitted a total of 40 runs:</cell></row><row><cell>conditional random fields and the second based</cell><cell>brundlefly (Fries, 2016) submitted 1 run for phase</cell></row><row><cell>on support vector machines. Both runs used</cell><cell>1 based on recurrent neural networks, word em-</cell></row><row><cell>lexical, morphological, syntactic, shape, charac-</cell><cell>beddings, and logistic regression, and 1 run for</cell></row><row><cell>ter pattern, character n-gram, section type, and</cell><cell>phase 2 run based on the DeepDive framework</cell></row><row><cell>gazetteer features.</cell><cell>(http://deepdive.stanford.edu).</cell></row><row><cell>UTA-MLNLP (Li and Huang, 2016) submitted 2</cell><cell>CDE-IIITH (Chikka, 2016) submitted 2 runs for</cell></row><row><cell>runs for each phase, based on a neural network</cell><cell>each phase, the first based on deep learning mod-</cell></row><row><cell>with a different window size for each run.</cell><cell>els, and the second based on conditional random</cell></row><row><cell>UTHealth (Lee et al., 2016) submitted 2 runs for</cell><cell>fields and support vector machines.</cell></row><row><cell>each phase, based on linear and structural</cell><cell>Cental (Hansart et al., 2016) submitted 1 run for</cell></row><row><cell>(HMM) support vector machines using lexical,</cell><cell>phase 1, based on conditional random fields and</cell></row><row><cell>morphological, syntactic, discourse, and word</cell><cell>lexical resources.</cell></row><row><cell>representation features. The runs differed on the</cell><cell>GUIR (Cohan et al., 2016) submitted 2 runs for</cell></row><row><cell>features included.</cell><cell>phase 1 and 1 run for phase 2, based on con-</cell></row><row><cell>VUACLTL (Caselli and Morante, 2016) submitted</cell><cell>ditional random fields and logistic regression</cell></row><row><cell>2 runs for each phase, based on conditional</cell><cell>with lexical, morphological, syntactic, depen-</cell></row><row><cell>random fields with morpho-syntactic, lexical,</cell><cell>dency, and domain specific features, combined</cell></row><row><cell>UMLS, and DBpedia features. The first run was</cell><cell>with pattern matching rules.</cell></row><row><cell>a two-step approach to temporal relations, the</cell><cell>HITACHI (Sarath P R et al., 2016) submitted 2 runs</cell></row><row><cell>second, a one step approach.</cell><cell>for the time portion of phase 1, based on en-</cell></row><row><cell></cell><cell>sembles of rule-based and machine learning sys-</cell></row><row><cell></cell><cell>tems with lexical, syntactic and morphological</cell></row><row><cell></cell><cell>features. The second run included 50% more</cell></row><row><cell></cell><cell>training data than the first.</cell></row><row><cell></cell><cell>KULeuven-LIIR (Leeuwenberg and Moens, 2016)</cell></row><row><cell></cell><cell>submitted 2 runs for phase 2, based on</cell></row><row><cell></cell><cell>the cTAKES-temporal machine-learning model</cell></row><row><cell></cell><cell>(Lin et al., 2015), with additional features.</cell></row><row><cell></cell><cell>LIMSI (Grouin and Moriceau, 2016) submitted 2</cell></row><row><cell></cell><cell>runs for each phase, based on conditional ran-</cell></row><row><cell></cell><cell>dom fields with lexical, morphological, and</cell></row></table><note>word cluster features, and the rule-based Heidel-Time<ref type="bibr" target="#b18">(StrÃ¶tgen and Gertz, 2013)</ref>.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>System performance and annotator agreement on TIMEX3 tasks: identifying the time expression's span (character offsets)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>System performance and annotator agreement on EVENT tasks: identifying the event expression's span (character offsets),</figDesc><table><row><cell>contextual modality (ACTUAL, HYPOTHETICAL, HEDGED or GENERIC), degree (MOST, LITTLE or N/A), polarity (POS or NEG)</cell></row><row><cell>and type (ASPECTUAL, EVIDENTIAL or N/A). The best system score from each column is in bold. Systems marked with  â€  were</cell></row><row><cell>submitted after the competition deadline and are not considered official.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>System performance and annotator agreement on temporal relation tasks: identifying relations between events and the document creation time (DOCTIMEREL), and identifying narrative container relations (CONTAINS). The best system score from each column is in bold. Systems marked with â€  were submitted after the competition deadline and are not considered official.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Details on the process: http://thyme.healthnlp.org/ 2 https://github.com/stylerw/thymedata</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The project described was supported in part by R01LM010090 (THYME) from the National Library Of Medicine. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">UtahBMI at SemEval-2016 Task 12: Extracting temporal information from clinical text</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)</title>
				<editor>
			<persName><forename type="first">Abdulrahman</forename><surname>Khalifa Aal Abdulsalam</surname></persName>
			<persName><forename type="first">Sumithra</forename><surname>Velupillai</surname></persName>
			<persName><forename type="first">Stephane</forename><surname>Meystre</surname></persName>
		</editor>
		<meeting>the 10th International Workshop on Semantic Evaluation (SemEval-2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="1256" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">ULISBOA at SemEval-2016 Task 12: Extractions of temporal expressions, clinical events and relations using IBEnt</title>
		<author>
			<persName><forename type="first">Marcia</forename><surname>Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">AndrÃ©</forename><surname>LamÃºrias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">GonÃ§alo</forename><surname>FigueirÃ³</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Antunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joana</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexandre</forename><surname>Pinheiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Francisco</forename><surname>Couto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m">Proceedings of the 9th International Workshop on Semantic Evaluation</title>
				<meeting>the 9th International Workshop on Semantic Evaluation<address><addrLine>Denver, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06" />
			<biblScope unit="page" from="806" to="814" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">VUACLTL at SemEval-2016 Task 12: A crf pipeline to clinical temporal</title>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roser</forename><surname>Morante</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Anafora: A webbased general purpose annotation tool</title>
		<author>
			<persName><forename type="first">Wei-Te</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Will</forename><surname>Styler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 NAACL HLT Demonstration Session</title>
				<meeting>the 2013 NAACL HLT Demonstration Session<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="14" to="19" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">CDE-IIITH at SemEval-2016 Task 12: Extraction of temporal information from clinical documents using machine learning techniques</title>
		<author>
			<persName><forename type="first">Chikka</forename><surname>Veera Raghavendra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">GUIR at SemEval-2016 Task 12: Temporal information extraction from clinical narratives</title>
		<author>
			<persName><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Meurer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nazli</forename><surname>Goharian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Brundlefly at SemEval-2016 Task 12: Recurrent neural networks vs. joint inference for clinical temporal information extraction</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Fries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">LIMSI at SemEval-2016 Task 12: machine-learning and temporal information to identify clinical events and time expressions</title>
		<author>
			<persName><forename type="first">Cyril</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">VÃ©ronique</forename><surname>Moriceau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cental at SemEval-2016 Task 12: A linguistically fed CRF model for medical and temporal information extraction</title>
		<author>
			<persName><forename type="first">Charlotte</forename><surname>Hansart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Damien</forename><forename type="middle">De</forename><surname>Meyere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Watrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>AndrÃ© Bittar, and CÃ©drick Fairon. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">UTHealth at SemEval-2016 Task 12: Temporal information extraction from clinical notes -uthealth&apos;s system for the 2016 clinical tempeval challenge</title>
		<author>
			<persName><forename type="first">Hee-Jin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hua</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaoyun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sungrim</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">KULeuven-LIIR at SemEval-2016 Task 12: Detecting narrative containment in clinical records</title>
		<author>
			<persName><forename type="first">Artuur</forename><surname>Leeuwenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie-Francine</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">UTA MLNLP at SemEval-2016 Task 12</title>
		<author>
			<persName><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)</title>
				<meeting>the 10th International Workshop on Semantic Evaluation (Se-mEval 2016)<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multilayered temporal modeling for the clinical domain</title>
		<author>
			<persName><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana K</forename><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Stanford CoreNLP natural language processing toolkit</title>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mihai</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
				<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="55" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Increasing informativeness in temporal annotation</title>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amber</forename><surname>Stubbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Linguistic Annotation Workshop</title>
				<meeting>the 5th Linguistic Annotation Workshop<address><addrLine>Portland, Oregon, USA, June</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="152" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hitachi at SemEval-2016 Task 12: Extraction of temporal information for the 2016 clinical tempeval challenge</title>
		<author>
			<persName><forename type="first">P R</forename><surname>Sarath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manikandan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoshiki</forename><surname>Niwa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multilingual and cross-domain temporal tagging</title>
		<author>
			<persName><forename type="first">Jannik</forename><surname>StrÃ¶tgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="298" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Temporal annotation in the clinical domain</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">F</forename><surname>Styler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><surname>Iv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Finan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piet</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brad</forename><surname>De Groen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Erickson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="143" to="154" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">THYME annotation guidelines, 2. Weiyi Sun, Anna Rumshisky, and Ozlem Uzuner</title>
		<author>
			<persName><forename type="first">William</forename><forename type="middle">F</forename><surname>Styler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guergana</forename><surname>Iv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martha</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName><surname>Pustejovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O'</forename><surname>Tim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Piet</forename><forename type="middle">C</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><surname>De Groen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="806" to="813" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>Evaluating temporal relations in clinical text: 2012 i2b2 challenge</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">LIMSI-COT at SemEval-2016 Task 12: Temporal relation identification for the clinical tempeval challenge</title>
		<author>
			<persName><forename type="first">Julien</forename><surname>Tourille</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Ferret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">AurÃ©lie</forename><surname>NÃ©vÃ©ol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xavier</forename><surname>Tannier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation</title>
				<meeting>the 10th International Workshop on Semantic Evaluation<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Temporal evaluation</title>
		<author>
			<persName><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
				<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA, June</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="351" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations</title>
		<author>
			<persName><forename type="first">Naushad</forename><surname>Uzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hector</forename><surname>Llorens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation</title>
				<meeting>the Seventh International Workshop on Semantic Evaluation<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM)</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">SemEval-2007 Task 15: TempEval Temporal Relation Identification</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Gaizauskas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Schilder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Hepple</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Graham</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)</title>
				<meeting>the Fourth International Workshop on Semantic Evaluations (SemEval-2007)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="75" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">SemEval-2010 Task 13: TempEval-2</title>
		<author>
			<persName><forename type="first">Marc</forename><surname>Verhagen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roser</forename><surname>Sauri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><surname>Pustejovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Workshop on Semantic Evaluation</title>
				<meeting>the 5th International Workshop on Semantic Evaluation<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-07" />
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
