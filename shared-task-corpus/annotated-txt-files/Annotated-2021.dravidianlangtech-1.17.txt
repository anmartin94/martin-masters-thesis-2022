title
Findings of the Shared Task on Offensive Language Identification in Tamil, Malayalam, and Kannada
abstract
Detecting offensive language in social media in local languages is critical for moderating user-generated content. Thus, the field of offensive language identification for under-resourced languages like Tamil, Malayalam and Kannada is of essential importance. As user-generated content is often code-mixed and not well studied for underresourced languages, it is imperative to create resources and conduct benchmark studies to encourage research in under-resourced Dravidian languages. We created a shared task on offensive language detection in Dravidian languages. We summarize the dataset for this challenge which are openly available at https://competitions.codalab. org/competitions/27654, and present an overview of the methods and the results of the competing systems.1 also called Damili or Dramili or Tamil-Brahmi 2 Keeladi-Book-English-18- 09-2019.pdf   

Introduction
The dawn of social media helped to bridge the gap between the borders and paved the way for the people to communicate or express their opinions more easily than any other time in human history (Edosomwan et al., 2011). But with this advent of social media, the platforms like YouTube, Facebook, and Twitter not only helped information sharing and networking but also became the place that target, defame and marginalize people merely on the basis of their physical appearance, religion or sexual orientation (Keipi et al., 2016;Benikova et al., 2018;Pamungkas et al., 2020). Social media has moulded itself into its specialised tool with which the people are verbally threatened and cornered not for what they have done but for who they are (Maitra and McGowan, 2012;Patton et al., 2013). Undoubtedly, the infiltration depth and width of this 'digital wonder' equipped the erstwhile 'invisible and socially paralysed' communities to play cards, if not extravagantly noticeable (Barnidge et al., 2019).
Research in hate speech detection (Kumar et al., 2018) or offensive language detection (Zampieri et al., 2020;Mandl et al., 2020) using Natural Language Processing (NLP) has significantly improved in recent years. However, the work on underresourced languages is still limited (Chakravarthi, 2020). For example, under-resourced languages such as Tamil, Malayalam, and Kannada lack tools and datasets (Chakravarthi et al., 2020a,c;Mahesan, 2019, 2020a,b). Recently, shared sentiment analysis for Tamil and Malayalam by Chakravarthi et al. (2020d) and offensive language identification in Tamil and Malayalam by Chakravarthi et al. (2020b) paved the wave for more research on Dravidian languages. Tamil, Malayalam and Kannada belong to the Dravidian language family and are spoken by some 220 million people in the Indian subcontinent, Singapore and Sri Lanka (Krishnamurti, 2003). It is essential to create NLP systems such as hate speech detection or offensive language detection in local languages since most user-generated content is in such languages.
The Dravidian language family is reported as being approximately 4500 years old by Bayesian phylogenetic analysis of cognate-coded lexical data (Kolipakam et al., 2018). The Dravidian languages scripts are first attested in the 580 BCE as Tamili 1 script inscribed on the pottery of Keezhadi, Sivagangai and Madurai district of Tamil Nadu, India (Sivanantham and Seran, 2019) 2 by Tamil Nadu State Department of Archaeology and Archaeological Survey of India. The modern Dravidian languages have its own scripts evolved from Tamili scripts. The scripts are alpha-syllabic, belonging to a family of the abugida writing systems that are partially alphabetic and partially syllable-based (Albert et al., 1985;Rajendran, 2004). The writing system of Tamili was explained in the old grammar text Tolkappiyam which dates are various proposed between 9th century BCE to 6nd century BCE (Pillai, 1904;Swamy, 1975;Zvelebil, 1991;Takahashi, 1995) and in the Jaina work Samavayanga Sutta and Pannavana Sutta, these two Jain works date to 3rd-4th century BCE (Salomon, 1998).
Up until around the 15th-century CE, Malayalam was the west coast dialect of Tamil (Blackburn, 2006). Due to geographical isolation by the steep Western Ghats from the main speech community, the dialect eventually evolved into a distinct language by the 15th century (Sekhar, 1951). The first literary work in Malayalam was Ramacaritam ("Deeds of Rama") was written using Tamil Grantha script which was used to write Pali, Prakrit and foreign words in Tamil (Andronov, 1996). The first printed work in an Indian language and script was a Roman Catholic catechism translated by Henrique which is Thambiran Vanakkam (Doctrina Christam en Lingua Malauar Tamul in Portuguese) on 20 October 1,578 CE at Quilon, Venad (present day Kerala) (George, 1972). Similarly, Kannada also split from Tamil by 9th century CE; for example, Taayviru is a term of Kannada origin and is found in a Tamil inscription from the 4th-century CE. The Kappe Arabhatta record of 700 CE is the oldest extant form of Kannada poetry in the Tripadi metre, it is based in part on Kavyadarsha (Rawlinson, 1930;Hande et al., 2020).
However, user-generated content is often adopted to Roman script for typing due to historical reason and modern computer keyboard layouts. Hence, the majority of user-generated data for these Dravidian languages are code-mixed Jose et al., 2020). Due to the growth of social media platforms across the world and the possibility of writing content without any moderation, users write content in multilingual code-switching without grammatical restrictions and using non-native scripts (Chakravarthi et al., 2019). In linguistics, code-switching is switching between two or more language in the same utterance. This explosion of code-mixed user-generated content in the social media platforms aroused interest in NLP. In this paper, we dicuss about the offensive language identification shared task for Tamil, Malayalam and Kannada languages and the participant's submissions.

Task Description
<TASK>Offensive language identification for Dravidian languages at different levels of complexity</TASK> were developed following the work of (Zampieri et al., 2019). It was customized to our annotation method from three-level hierarchical annotation schema. A new category Not in intended language was added to include comments written in a language other than the Dravidian languages. Annotations decision for offensive language categories were split into six labels to simplify the annotation process.
• Not Offensive: Comment/post does not have offence, obscenity, swearing, or profanity.
• Offensive Untargeted: Comment/post have offence, obscenity, swearing, or profanity not directed towards any target. These are the comments/posts which have inadmissible language without targeting anyone.
• Offensive Targeted Individual: Comment/post have offence, obscenity, swearing, or profanity which targets an individual.
• Offensive Targeted Group: Comment/post have offence, obscenity, swearing, or profanity which targets a group or a community.
• Offensive Targeted Other: Comment/post have offence, obscenity, swearing, or profanity which does not belong to any of the previous two classes.
• Not in indented language: If the comment is not in the intended language. For example, in the Malayalam task, if the sentence does not contain Malayalam written in Malayalam script or Latin script, then it is not Malayalam.
Sample of not-offensive comments in our dataset provided for the participants is given below with the corresponding English glosses..   This is an example of Offensive Targeted Individual. Mr. Ghibran is a popular music composer in Tamil films, and the author tries to insult him.
• Malayalam-English: Verupikkal manju ullathu ozhichal baki ellam super aanu ee padam.
English: "Except the presence of disgusting Manju, everything is super in this movie"
This is an example of Offensive Targeted Individual. Mrs. Manju Warrier is a popular actress in South Indian films, and the author tries to discredit her by clearly mentioning that her presence is disgusting.
• Malayalam-English: Nalla trailer nu okke keri dislike adikunne ethelum thanthayillathavanmar aayirikum. poyi chavinedey... English: "Those who dislike any trailers will probably be assholes. Go to hell..."
This is an example of Offensive Untargeted comment. This text have inadmissible language without targeting anyone.

Dataset
Data was compiled from different film trailers of Tamil, Kannada, and Malayalam languages from YouTube comments in the year 2019. The YouTube Comment Scraper tool 3 was used to collect comments from YouTube social media. These comments were utilized to make the datasets for offensive language identification shared task. We collected comments that contain code-mixing at various levels of the text, with enough representation for each sentiment in all the three languages. Langdetect library 4 was used to detect different languages apart and eliminate the unintended languages. Our dataset contains different types of real-time code-mixing due to that fact that data was collected from social media. The dataset contains all forms of code-mixing ranging from purely monolingual texts in native languages to mixing of scripts, words, morphology, inter-sentential and intra-sentential switches.
Dataset statistics (number of words, vocabulary size, number of comments, number of sentences, and average number of words per sentences) are given in Table 1 and class-wise distribution is given in Table 2. From the Table 1 we can see that vocabulary size is very big for Tamil and Malayalam this is due to the code mixing and complex morphology of these languages. Table 2 shows that all languages have the not-offensive class in the majority. In the case of Tamil, 71% of the total comments are not offensive, while Malayalam has 85% non-offensive comments. But there is no consistent trends observable amongst offensive classes across the languages.

Training Phase
In the first phase, data is released for training and or development of offensive language detection models. Participants were given training data and validation dataset for preliminary evaluations or tuning of hyper-parameters. They were also given the option to perform cross-validation on the training data. In total, 119 participant register for the task and downloaded the data.

Evaluation Phase
In the second phase, test sets for evaluation are released for all three languages. Each participating team submitted their generated prediction for evaluation. Predictions are submitted via Google form to the organizing committer to evaluate the systems. CodaLab is an established platform to organize shared-tasks. However, we faced issues with running evaluation, so we choose to evaluate manually. The metrics used for evaluation is the weighted average F1 score.

Systems
System Descriptions
• Dowlagar and Mamidi ( 2021) used a pretrained multilingual BERT transformer model with transliteration and class balancing loss for offensive content identification. They have ranked 2nd in Malayalam-English and 4th in Tamil-English languages.
• Li (2021) participated in all three of offensive language identification. They explored multilingual models based on XLM-RoBERTa and multilingual BERT trained on mixed data of three code-mixed languages. They solved the class-imbalance problem existed in the training data by class weights and class combination. Their model achieved a weighted average F1 scores of 0.75 (ranked 4th), 0.94 (ranked 4th) and 0.72 (ranked 3rd) on offensive language identification in code-mixed Tamil-English language, Malayalam-English language and Kannada-English language, respectively.
• Yasaswini et al. (2021) used various transfer learning-based models to classify a given post or comment in Tamil, Malayalam, and Kannada. They have fine-tuned transformer models to get better performance. The relatively high F1-scores of 0.9603, 0.7895 on Malayalam, Tamil were achieved by ULMFiT and 0.7277 on Kannada was achieved by Distil-BERT models.
• Vasantharajan and Thayasivam ( 2021) participated in Tamil, Kannada, and Malayalam language using the BERT fine-tuning strategies.
Their model got a 0.96 F1-score for Malayalam, 0.73 F1-score for Tamil, and 0.70 F1score for Kannada. Moreover, in the view of multilingual models, this modal ranked 3rd and achieved favorable results and confirmed the model as the best among all systems submitted to these shared tasks in these three languages. They got 2nd, 5th, 6th ranks in the leader-board for the Malayalam, Kannada, and Tamil test set respectively.
• Huang and Bai ( 2021) used the multilingual BERT model to complete in all three languages. For all three language data sets, they combined the Tf-Idf algorithm and the multilingual BERT model's output and introduced the CNN block as a shared layer.  Team-Name Precision Recall F1 Score Rank hate-alert (Saha et al., 2021) 0.97 0.97 0.97 MUCS (Balouchzahi et al., 2021) 0.97 0.97 0.97 indicnlp@kgp (Kedia and Nandy, 2021) 0.97 0.97 0.97 bitions (Tula et al., 2021) 0.97 0.97 0.97 hypers (Vasantharajan and Thayasivam, 2021)   (Garain et al., 2021) 0.77 0.43 0.54  (Saha et al., 2021) 0.76 0.76 0.74 indicnlp@kgp (Kedia and Nandy, 2021) 0.71 0.74 0.72 Codewithzichao (Li, 2021) 0.7 0.75 0.72 IIITK (Ghanghor et al., 2021) 0.7 0.75 0.72 e8ijs 0.7 0.74 0.71 NLP@CUET (Sharif et al., 2021) 0  (Yasaswini et al., 2021) 0.46 0.48 0.47 Simon (Que et al., 2021) 0.6 0.3 0.33 resentation from Transformers) for sentence embedding and a Softmax classifier. The language-agnostic representation based classification helped obtain good performance for all the three languages, out of which results for the Malayalam language are good enough to obtain a third position among the participating teams.
• K et al. (2021) implemented three deep neural network architectures such as a hybrid network with a Convolutional layer, a Bidirectional Long Short-Term Memory network (Bi-LSTM) layer and a hidden layer, a network containing a Bi-LSTM and another with a Bidirectional Recurrent Neural Network (Bi-RNN). In addition to that, they incorporated a cost-sensitive learning approach to deal with the problem of class imbalance in the training data. Among the three models, the hybrid network exhibited better training performance, and they submitted the predictions based on the same. Their proposed models gained a weighted F1 score of 0.76 (for Tamil), 0.93 (for Malayalam ), and 0.71 (for Kannada) with a rank of 3rd , 5th and 4th respectively.
• Dave et al. (2021) used TF-IDF character ngrams and pretrained MuRIL embeddings for text representation and Logistic Regression and Linear SVM for classification. Their best approach achieved ninth, third and eighth with weighted F1 score of 0.64, 0.95 and 0.71 in Kannada, Malayalam and Tamil on the test dataset respectively.
• Saha et al. (2021) presented an exhaustive exploration of different transformer models, also provided a genetic algorithm technique for ensembling different models. Their ensembled models trained separately for each language secured the first position in Tamil, the second position in Kannada, and the first position in Malayalam sub-tasks.
• Yang (2021) only participate in one of the language task-Malayalam. They used the transformer-based language model with BiGRU-Attention to complete this task. They ranked 5th in this task with a weighted average F1 score of 0.93 on the private leader board.
• Awatramani ( 2021) participated for Tamil language. They used mBERT-cased and XLM-RoBERTa. Their system was ranked 3 rd in the task leaderboard achieving an F1-score 0.76 for detecting offensive Tamil YouTube comments.
• Nair and Fernandes ( 2021) used Indic-BERT to generate word embeddings which is then fed into a 4-layer Multi Layer Perceptron (MLP) which does the multi-class classification task and achieve an F1 score of 0.85 for Malayalam language.
• Andrew ( 2021) did language-specific preprocessing before using several machine learning algorithms. For the Tamil language, they achieve a precision of 0.54, a recall of 0.73 and an F1-score of 0.61, a precision of 0.94, a recall of 0.94 and an F1-score of 0.93 for the Malayalam language and a precision of 0.66, a recall of 0.67 and an F1-score of 0.63 for the Kannada language.
• Que et al. (2021) used the XLM-Roberta model for pre-training for the Kannada language. They scored a very low score of 0.33 weighted • Tula et al. (2021) proposed a multilingual ensemble based model from ULMFiT, Distilm-BERT, and IndicBERT. Their model is able to handle both code-mixed data as well as instances where the script used is mixed (for instance, Tamil and Latin). They ranked number one for Malayalam dataset and ranked 4th and 5th for Tamil and Kannada, respectively.
• Jayanthi and Gupta ( 2021) system is an ensemble of mBERT and XLM-RoBERTa models which leverage task-adaptive pre-training of multilingual BERT models with a masked language modeling objective. They ranked 1st
for Kannada, 2nd for Malayalam and 3rd for Tamil.
• B and Silvia A ( 2021) described an automatic offensive language identification from Dravidian languages with various machine learning algorithms. They achieved F1 scores of 0.95 for Malayalam, 0.7 for Kannada and 0.73 for task2-Tamil on the test-set.
• Garain et al. (2021) used IndicBERT and BERT architectures, to facilitate identification of offensive languages for Kannada-English, Malayalam-English, and Tamil-English codemixed language pairs extracted from social media. F1 score for language pair Kannada-English as 0.62, 0.71, and 0.66, respectively, for language pair Malayalam-English as 0.77, 0.43, and 0.53, respectively, and for Tamil-English as 0.71, 0.74, and 0.72, respectively.
• Balouchzahi et al. (2021) Two models, namely, COOLI-ensemble and COOLI-Keras were trained with the char sequences extracted from the sentences combined with words as features. Out of the two proposed models, the COOLI-Ensemble model (best among our models) obtained the first rank for the Ma-En language pair with 0.97 weighted F1-and fourth and sixth rank with a 0.75 and a 0.69 weighted F1-score for Ta-En and Kn-En language pairs respectively.
• Kedia and Nandy (2021)  

Results and Discussion
The offensive language identification shared task was organized for three languages Tamil, Malayalam, and Kannada. Many participants connecting to all three languages had submitted their solutions as described in the previous section. Here in this section, we'll be highlighting the results of all three  6 shows the overall results and teams which are placed in the top three positions.
The team hate-alert (Saha et al. (2021)) came at the first position in Tamil and Malayalam languages and second in Kannada as well, and the team indicnlp@kgp (Kedia and Nandy (2021)) came second in Tamil, first in Malayalam, and third in Kannada. The team SJ-AJ (Jayanthi and Gupta ( 2021)) came at the first position in Kannada and third and second in Tamil and Malayalam respectively.As per the F1-scores apart from Malayalam, the other two languages got scores around 0.75, whereas 0.97 was the former's score. As the vocabulary size of Malayalam is more, it has produced better results compared to Tamil (which is having the maximum), and Kannada, where vocabulary is less but has got similar results to that of Tamil.

Conclusion
We presented the results of the first shared task on Offensive Language Identification in Tamil, Malayalam, and Kannada relying on a thoroughly annotated data set based on human judgements. The task setup provided an opportunity to test model in multilingual scenarios along with code-mixing phenomenon. However, several teams reach high performance in all three languages. We found out that the type of embedding strongly influence the results. We hope this task and dataset will intrigue and facilitate further research on under-resourced Dravidian languages.

