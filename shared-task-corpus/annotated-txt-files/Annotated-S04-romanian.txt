title
An Evaluation Exercise for <TASK>Romanian Word Sense Disambiguation</TASK>
abstract
This paper presents the task definition, resources, participating systems, and comparative results for a Romanian Word Sense Disambiguation task, which was organized as part of the SENSEVAL-3 evaluation exercise. Five teams with a total of seven systems were drawn to this task.

Introduction
SENSEVAL is an evaluation exercise of the latest word-sense disambiguation (WSD) systems. It serves as a forum that brings together researchers in WSD and domains that use WSD for various tasks. It allows researchers to discuss modifications that improve the performance of their systems, and analyze combinations that are optimal.
Since the first edition of the SENSEVAL competitions, a number of languages were added to the original set of tasks. Having the WSD task prepared for several languages provides the opportunity to test the generality of WSD systems, and to detect differences with respect to word senses in various languages.
This year we have proposed a Romanian WSD task. Five teams with a total of seven systems have tackled this task. We present in this paper the data used and how it was obtained, and the performance of the participating systems.

Open Mind Word Expert
The sense annotated corpus required for this task was built using the Open Mind Word Expert system (Chklovski and Mihalcea, 2002), adapted to Roma-nian 1 .
To overcome the current lack of sense tagged data and the limitations imposed by the creation of such data using trained lexicographers, the Open Mind Word Expert system enables the collection of semantically annotated corpora over the Web.
Sense tagged examples are collected using a Webbased application that allows contributors to annotate words with their meanings.
The tagging exercise proceeds as follows. For each target word the system extracts a set of sentences from a large textual corpus. These examples are presented to the contributors, who are asked to select the most appropriate sense for the target word in each sentence. The selection is made using checkboxes, which list all possible senses of the current target word, plus two additional choices, "unclear" and "none of the above." Although users are encouraged to select only one meaning per word, the selection of two or more senses is also possible. The results of the classification submitted by other users are not presented to avoid artificial biases.

Sense inventory
For the Romanian WSD task, we have chosen a set of words from three parts of speech -nouns, verbs and adjectives. Table 1 presents the number of words under each part of speech, and the average number of senses for each class.
The senses were (manually) extracted from a Romanian dictionary (Dicţionarul EXplicativ al limbii române -DEX (Coteanu et al., 1975)  and their dictionary definitions were incorporated in the Open Mind Word Expert. For each annotation task, the contributors could choose from this list of 39 words. For each chosen word, the system displays the associated senses, together with their definitions, and a short (1-4 words) description of the sense. After the user gets familiarized with these senses, the system displays each example sentence, and the list of senses together with their short description, to facilitate the tagging process.
For the coarse grained WSD task, we had the option of using the grouping provided by the dictionary. A manual analysis however showed that some of the senses in the same group are quite distinguishable, while others that were separated were very similar.
For example, for the word circulatie (roughly, circulation). The following two senses are grouped in the dictionary: 2a. movement, travel along a communication line/way 2b. movement of the sap in plants or the cytoplasm inside cells Sense 2a fits better with sense 1 of circulation: 1. the event of moving about while sense 2b fits better with sense 3: 3. movement or flow of a liquid, gas, etc. within a circuit or pipe.
To obtain a better grouping, a linguist clustered the similar senses for each word in our list of forty. The average number of senses for each class is almost halved.
Notice that Romanian is a language that uses diacritics, and the the presence of diacritics may be crucial for distinguishing between words. For example peste without diacritics may mean fish or over. In choosing the list of words for the Romanian WSD task, we have tried to avoid such situations. Although some of the words in the list do have diacritics, omitting them does not introduce new ambiguities.

Corpus
Examples are extracted from the ROCO corpus, a 400 million words corpus consisting of a collection of Romanian newspapers collected on the Web over a three years period (1999)(2000)(2001)(2002).
The corpus was tokenized and part-of-speech tagged using RACAI's tools (Tufis, 1999). The tokenizer recognizes and adequately segments various constructs: clitics, dates, abbreviations, multiword expressions, proper nouns, etc. The tagging followed the tiered tagging approach with the hidden layer of tagging being taken care of by Thorsten Brants' TNT (Brants, 2000). The upper level of the tiered tagger removed from the assigned tags all the attributes irrelevant for this WSD exercise. The estimated accuracy of the part-of-speech tagging is around 98%.

Sense Tagged Data
While several sense annotation schemes have been previously proposed, including single or dual annotations, or the "tag until two agree" scheme used during SENSEVAL-2, we decided to use a new scheme and collect four tags per item, which allowed us to conduct and compare inter-annotator agreement evaluations for two-, three-, and four-way agreement. The agreement rates are listed in Table 3. The two-way agreement is very high -above 90% -and these are the items that we used to build the annotated data set. Not surprisingly, four-way agreement is reached for a significantly smaller number of cases. While these items with four-way agreement were not explicitly used in the current evaluation, we believe that this represents a "platinum standard" data set with no precedent in the WSD research community, which may turn useful for a range of future experiments (for bootstrapping, in particular).     In addition to sense annotated examples, participants have been also provided with a large number of unlabeled examples. However, among all participating systems, only one system -described in (Serban and Tȃtar 2004) -attempted to integrate this additional unlabeled data set into the learning process.

Participating Systems
Five teams participated in this word sense disambiguation task. Table 4 lists the names of the participating systems, the corresponding institutions, and references to papers in this volume that provide detailed descriptions of the systems and additional analysis of their results.
There were no restrictions placed on the number of submissions each team could make. A total number of seven submissions was received for this task. Table 5 shows all the submissions for each team, and gives a brief description of their approaches.

Results and Discussion
Table 6 lists the results obtained by all participating systems, and the baseline obtained using the "most frequent sense" (MFS) heuristic. The table lists precision and recall figures for both fine grained and coarse grained scoring.
The performance of all systems is significantly higher than the baseline, with the best system performing at 72.7% (77.1%) for fine grained (coarse grained) scoring, which represents a 35% (38%) error reduction with respect to the baseline.
The best system (romanian-swat hk-bo) relies on a Maximum Entropy classifier with boosting, using local context (neighboring words, lemmas, and their part of speech), as well as bag-of-words features for surrounding words.
Not surprisingly, several of the top performing systems are based on combinations of multiple sclassifiers, which shows once again that voting

