title
Findings of the Shared Task on Troll Meme Classification in Tamil
abstract
The internet has facilitated its user-base with a platform to communicate and express their views without any censorship. On the other hand, this freedom of expression or free speech can be abused by its user or a troll to demean an individual or a group. Demeaning people based on their gender, sexual orientation, religious believes or any other characteristics -trolling-could cause significant distress in the online community. Hence, the content posted by a troll needs to be identified and dealt with before causing any more damage. Amongst all the forms of troll content, memes are most prevalent due to their popularity and ability to propagate across cultures. A troll uses a meme to demean, attack or offend its targetted audience. In this shared task, we provide a resource (TamilMemes) that could be used to train a system capable of identifying a troll meme in the Tamil language. In our TamilMemes dataset, each meme has been categorized into either a "troll" or a "not troll" class. Along with the meme images, we also provided the Latin transcripted text from memes. We received ten system submissions from the participants, which were evaluated using the weighted average F1-score. The system with the weighted average F1-score of 0.55 secured the first rank.

Introduction
We have seen a rise in the usage of memes on the internet. Memes could come in many forms and languages, but we emphasize on the image with text (IWT) memes (Du et al., 2020) in the Tamil language. IWT memes are inherently multimodal as their meaning is not understood when just the image or the text considered in isolation; hence, both image and text should be considered. These memes can propagate and mutate through cultures like the selfish gene (Dawkins, 2016). Propagation and mutation of memes ensure widespread on the internet; hence they could be weaponized by trolls (Mandl et al., 2020). Trolls are individuals or users on the internet who tend to attack or offend other individuals or groups in a demeaning manner (Tomaiuolo et al., 2020).
A meme used by troll -troll meme-could come in any languages, and since languages are representative of cultures, a meme in one language could represent a culture. In this shared task, we provide the TamilMemes dataset  that consists of 2,969 memes to the participants. Additionally, we also provided the text (caption) associated with each meme. The text has been transcripted in Latin by a native Tamil speaker, which was later evaluated and corrected by the expert.
Tamil (ISO 639-3: tam) is an official language in Tamil Nadu, Puducherry, Sri Lanka, Singapore and a recognised minority language in Malaysia and South Africa with a 75 million speaker base (Chakravarthi et al., 2018;Mahesan, 2019, 2020a,b). Tamil inscription in pottery from Kodumanal and Porunthal 1 2 was the oldest inscription in India dating to 580 BCE then Asoka inscription in Prakrit, Greek and Aramaic dating to 260 BCE (Mahadevan, 2002;Rajakumar and Bharathi, 2012). In Sanskrit, the oldest known inscriptions are from the 1st century CE, such as Dhana's Ayodhya Inscription and Ghosundi-Hathibada. The first book printed in India in an Indian language was Tampiran Vanakkam in Tamil on 1578 CE, a 16-page translation of the Portuguese "Doctrina Christam" (Balachandran, 2005). In the modern Tamil script, there are 12 vowels, 18 consonants and one special character, theāytam (Chakravarthi, 2020b). The vowels and consonants combine in order to form 216 compound characters, giving a total of 247 characters. However, Tamil is often transcribed in Latin Script by a multilingual speaker on social media platforms (Chakravarthi, 2020a). This behaviour could be attributed to the ease or comfort in scripting Tamil in Latin script (Chakravarthi et al., 2019;Hande et al., 2020). Also, these multilingual speakers tend to switch to another language such as English. This phenomenon, also known as code-mixing or codeswitching is commonly observed amongst multilingual speakers (Jose et al., 2020;. A great deal of work and resources (Chakravarthi et al., 2020a,c) has been created for Dravidian languages but the multimodal aspect of code-mixed content in the form of meme remains unexplored.
In recent years, we have seen a rise in awareness of tackling multimodal offensive (Sharma et al., 2020) or hate (Kiela et al., 2020) content in memes in the English language, but other under-resourced languages remain unexplored. Our "Troll Meme Classification in Tamil" task aims to promote research in multimodal troll meme classification in under-resourced Tamil language. Moreover, this task provides a unique opportunity to study the effect of code-switching or code-mixing in the English transcript of Tamil  in association with the image from the meme.

Task Description
The goal of the "Troll Meme Classification in Tamil" shared task was to <TASK>classify if a given meme is a "troll" or "not-troll" based on the image and text associated with the meme in the Tamil language</TASK>. The text from the meme is written in either the Tamil grammar and English lexicon or English grammar and Tamil lexicon. However, for consistency, we transcripted the text in Latin.
Troll meme is a meme, which consists of offensive text and non-offensive images, offensive images with non-offensive text, sarcastically offensive text with non-offensive images, or sarcastic images with offensive text to provoke, distract and has digressive or off-topic content with intend to demean or offend particular people, group or race, otherwise, a not-troll meme . Figure 1 shows examples of a troll and nottroll meme from the TamilMeme dataset. Example 1 is a troll meme targeted towards the potato chip brand called "Lays". In this example, an image is harmless with just a picture of the potato chips  packet, but the translation of the text is "If you buy one packet air, then 5 chips free" which is offensive for the brand. The translation of Example 2 would be "Sorry my friend (girl)". This example does not contain any provoking or offensive image or text and hence, it is a not-troll meme.
Previously, we developed this TamilMemes dataset and treated the task of identifying a troll meme as an image classification problem. Since the text associated with the meme acts as a context of the image, we enhanced our TamilMemes dataset by providing the text as a separate modality for the shared task. We expected our participant to approach the task in a multimodal way. 

Rank Team
Precision Recall F1-score 1 Codewithzichao (Li, 2021) 0.57 0.60 0.55 2 IIITK (Ghanghor et al., 2021) 0  

Evaluation
Table 1 shows the class distribution in the training and test set for the TamilMemes dataset. We provided a training set of 2,500 memes (with the Latin scripted text) to the participants. Later, we evaluated all the systems on the held-out or test set of 667 memes. We considered a weighted average version of the F1-score as a primary evaluation metric by taking class imbalance into the account.
The weighted average F1-score 3 is calculated by averaging the support-weighted mean F1 score perclass.

Methodology
In system submissions, we saw a variety of methodologies used by the participants which were as simple as Logistic Regression (Wright, 1995) and as complex as BERT (Devlin et al., 2018). By keeping multimodality in mind, most of the participants implemented a method that could leverage both text and image. Mostly, the image part has been processed using Convolutional Neural Network (CNN) such as ResNet152 (He et al., 2016) or the custom residual networks while the text has been processed RNN (LSTM (Hochreiter and Schmidhuber, 1997)), transformer (BERT, ROBERTA (Liu et al., 2019)). However, in one exceptional case, one participant has used a transformer for processing both modalities.
• Li ( 2021) utilized a transformer-based approach that leverages the pre-trained BERT and ResNet152 model to derive the text and image features. The novelty of the work
3 Weighted average F-1 score is calculated with the help of the sklearn classification report utility comes from the implementation of multimodal attention which considers the whole text caption in the context of the image by mapping both image and text features in the same semantic space. Their model achieved a 0.55 weighted average F1 score and ranked first in the shared task.
• Ghanghor et al. (2021) utilized a transformerbased approach to identify the troll and nottroll Tamil meme. The state of the art text classifier (BERT) and image (CNN) classifiers were used to extract useful attention features.
Their system submission for Tamil troll meme classification achieved a 0.54 weighted average F1 score.
• Hossain et al. (2021) utilized a systematic text-based, image-based and multimodal approach to identify a troll meme. The paper laid out a detailed investigation into the problem presented in the shared task by capturing visual and textual features using CNN, VGG16 (Simonyan and Zisserman, 2014), Inception (Szegedy et al., 2017), m-BERT, XLM-RoBERTa, XLNet (Yang et al., 2019). Multimodal features were extracted by combining image (CNN, ResNet50, Inception) and text (BiLSTM) (Zhou et al., 2016) features using an early fusion technique. But the results showed that the text-based approach with XLNet achieved the highest weighted F1-score of 0.58, and enabled their system implementation to secure 3rd rank.
• Silvia A and B ( 2021) used traditional NLP approaches such as Multilayer perceptron (MLP (Haykin and Network, 2004)), Random forest (RF) (Breiman, 2001) and K-nearest neighbour (KNN ) (Cunningham and Delany, 2020) on the text features derived from tf-idf, count vector and mBERT embeddings. The paper opts for a text-based approach over the multimodal approach and achieved a weighted average F1-score of 0.50.
• Que et al. (2021) used a text-based approach to deal with the multimodal issue of identifying troll memes. Here the author trains XLM-Roberta in combination with the custom CNN on the text modality and achieves a weighted average F1-score of 0.49.
• J and HS ( 2021) utilized ResNet-50 to identify if a given meme is a troll or not based on the visual features. However, no text modality has been used as a feature while training the system. Their system achieved a weighted average F1-score of 0.48 and ranked sixth.
• Hegde et al. ( 2021) utilized a transformerbased approach to identify the troll and nottroll Tamil meme. The state of the art text (mBERT) and image (Vision transformer) (Dosovitskiy et al., 2020) classifiers were used to extract useful attention features. They achieve a weighted average F1-score of 0.46 and ranked seventh.
• Huang and Bai ( 2021) used a BiGRU (Dey and Salem, 2017) and custom CNN to capture text and image features, which later are concatenated to form a multimodal representation of a meme. They ranked ninth with a weighted average F1-score of 0.40.
• Mishra and Saumya ( 2021) used a hybrid approach that combines text and image features using CNN and BiLSTM. Their proposed model obtained 10th rank in the shared task and reported a weighted F1-score of 0.30.

Results and Discussion
We have received 10 submissions for the shared task. Table 2 shows that the maximum weighted average F1-score could only reach 0.55, which is less.
While the submissions claimed that the evaluation metric exceeded the validation set, the poor performance on the test set point towards overfitting. Overfitting is commonly seen when complex models with large numbers of parameters are trained on small datasets.
In this shared task, we provided 2,967 samples which might be less for the data-hungry models such as BERT and it's predecessor such as ROBERTa, XLM-RoBERTa. Moreover, due to the high dimensionality presented by the images, the traditional machine learning models such as logistic regression, Naive Bayes are not able to generalize. The poor performance of the traditional machine learning model shows that they are rather too simple to learn useful features from the high dimensional data presented in the form of image and text. Furthermore, the Tamil text (could be with or without code-mixed) from the meme is transcripted in the Latin script leaves little room for using pre-trained models (e.g. multilingual BERT) which are primarily trained in English or zero-shot transferred to other languages written in their native script. Hence, such multilingual models need to be finetuned on the more code-mixed, transliterated data. In the case of images, the visual features have been captured using a CNN pre-trained on the imagenet weights.
In the previous study, we observed that the visual features captured by such CNNs tend to be less useful for identifying a troll Tamil meme. The same effect has been observed in the system submitted to the shared task. Overall, we need a robust approach that takes into account all the aspects of this multimodal classification problem -lack of data, high dimensionality, low resource language processing and code-mixing.

Conclusion
In the "Troll Meme Classification in Tamil" shared task, we presented a unique multimodal classification problem by providing a newly improved TamilMeme dataset which now has Tamil text (in the form of transcripted Latin text) from memes. This task was not only a multimodal classification problem but also posed challenges such as natural language processing of low-resourced language, transcripted code-mixed text. The submissions received from the participants showed multiple ways to approach the problem and we hope that their contribution along with our enriched dataset will kindle the research in this less explored area. 

