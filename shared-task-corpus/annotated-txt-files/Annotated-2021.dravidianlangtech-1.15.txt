title
Findings of the Shared Task on Machine Translation in Dravidian languages
abstract
This paper presents an overview of the shared task on machine translation of Dravidian languages. We presented the shared task results at the EACL 2021 workshop on Speech and Language Technologies for Dravidian Languages. This paper describes the datasets used, the methodology used for the evaluation of participants, and the experiments' overall results. As a part of this shared task, we <TASK>organized four sub-tasks corresponding to machine translation of the following language pairs: English to Tamil, English to Malayalam, English to Telugu and Tamil to Telugu</TASK> which are available at https://competitions.codalab. org/competitions/27650. We provided the participants with training and development datasets to perform experiments, and the results were evaluated on unseen test data. In total, 46 research groups participated in the shared task and 7 experimental runs were submitted for evaluation. We used BLEU scores for assessment of the translations.

Introduction
In this paper, we present the results of the shared task on machine translation of Dravidian languages of the Workshop on Speech and Language Technologies for Dravidian Languages held at EACL 2021. The shared task features four sub-tasks: a translation task from English to Tamil, English to Telugu, English to Malayalam and Tamil to Telugu. They all closely related languages and are underresourced now. They are mutually intelligible since speakers of Dravidian (Tamil) languages can readily understand each other without prior familiarity or special effort (Krishnamurti, 2016;Thavareesan and Mahesan, 2019).
The performance of our tasks was evaluated using automatic measures BLEU (Papineni et al., 2002). This shared task's primary objectives are to further state of the art in machine translation of low resource languages belonging to the Dravidian (Tamil) language family. The training data, development data and test data, and results are available publicly 1 . We hope the datasets released as a part of this task will contribute positively towards forwarding research in the machine translation of under-resourced languages.

Related Work
Machine translation of under resource languages is an open and an active research area. In this day and age when translation systems are increasingly being built upon neural network-based architectures Luong et al., 2015;Wu et al., 2016), the development of such systems for under-resourced languages is a challenging task due to the lack of availability of resources. Multilingual extensions to these architectures have been proposed (Firat et al., 2016;Ha et al.;Johnson et al., 2017) which have been shown to improve on low-resource languages. Recent studies have also extended this to a massively multilingual setting (Aharoni et al., 2019). Gu et al. (2018) demonstrated a transfer learning-based approach by utilizing shared lexical and sentence level representations across multiple source languages, thereby developing a system that performs well in low resource scenarios. Xia et al. (2019) propose a general framework for data augmentation in low-resource machine translation that not only uses target-side monolingual data but also pivots through a related high-resource language HRL. Zoph et al. (2016)'s key idea is first to train a high-resource language pair (the parent model), then transfer some of the learned parameters to the low-resource pair (the child model) to initialize and constrain training. Kocmi and Bojar (2018) propose a transfer learning-based method, wherein they train a "parent" model with a high-resource language pair followed by which they train on a "child" model on a corpus of a low-resource language pair. It was observed that this model is better than the models trained on just the low-resource languages. Zoph et al. (2016) propose a transfer learning-based method, wherein they train a parent model trained on a high-resource language pair, followed by which they transfer some of parameters to a child model that they subsequently train on the low-resource language pair. Lakew et al. (2017) leverage the use of duality of translations generated by the system for zero-shot; these translations are used along with the parallel data to train the neural network. Ojha et al. (2020) show the results of the LoResMT 2020 shared task. This workshop was held along with AACL and reported good BLEU scores in case of the low-resource Bhojpuri-Hindi language pair. Koehn et al. (2019) focussed on the translation of the low resource language pairs Nepali-English and Sinhala-English. They reported the results of these translation tasks for statistical as well as phrase-based methods. Chakravarthi et al. (2019c) created a multimodal corpora for Dravidian languages. M (2013) developed a statistical machine translation system for English-Tamil using transfer based on computational linguistics. Kumar et al. (2014) proposed a factored statistical machine translation system for English to the Tamil language. Kumar et al. (2019) conducted the Machine Translation for Indian Languages shared task in 2017. As a part of this shared task, organizers have released the parallel corpora for English-Tamil and English-Malayalam.

For
Dravidian language translation, Chakravarthi et al. (2018, 2019b, 2020a) created a machine translation to improve WordNet entries. Krishnamurthy (2019) demonstrate a transfer learning based translation system and a divergence index to calculate the success rate of the system. Chandramma et al. (2017) propose a multi-layer neural network based approach wherein they use n-grams extracting from connecting phrases of the phrase table for the task of machine translation on Kannada-Telugu language pair. Chakravarthi et al. (2019aChakravarthi et al. ( , 2020b; Chakravarthi (2020) studied the utilisation of orthographic information to improve the machine translation for Dravidian languages.

Dravidian Languages
Tamil is an official language in Tamil Nadu, Puducherry, Sri Lanka and Singapore (Thavareesan and Mahesan, 2020a,b). Tamil was the first to be listed as a classical language of India, one of 22 scheduled languages in India's Constitution, and is one of the world's longest-surviving classical languages. In Jain Samavayanga Sutta (3rd-4th century BCE) and Pannavana Sutta, a script called Damili (Tamili) is listed as the seventeenth of eighteen scripts in India, an early mention of a script for writing the Tamil language (Salomon, 1998). Similarly, Lipisala Samdarshana Parivarta, the tenth chapter of the Lalitavistara Sutta (3rd century CE) a Sanskrit text, mentions Siddhartha (later Gautam Buddha) learning Dravida-script (Tamil Script) and Dakshinya-script (Southern Tamil Script) along with other sixty two scripts. Tamil was called Damil in Jain Prakrit, Dramil in Buddhist Pali, and Dravida in Sanskrit (Caldwell, 1875;Oberlies, 2011). The Tamil scripts are first attested in the 580 BCE as Tamili 2 script inscribed 3 on the pottery of Keezhadi, Sivagangai and Madurai district of Tamil Nadu, India (Sivanantham and Seran, 2019) 4 by Tamil Nadu State Department of Archaeology and Archaeological Survey of India. The writing systems of Tamili was explained in the old grammar text Tolkappiyam dates between 8000 BCE to 580BCE (Takahashi, 1995;Pillai, 1904;Swamy, 1975;Albert et al., 1985;Rajendran, 2004).
Malayalam was Tamil's west coast dialect until about the 15th-century CE (Blackburn, 2006). The dialect gradually developed into a different language in the 16th century (Sekhar, 1951)   (Rawlinson, 1930;Hande et al., 2020). Dravidian is the name for the Tamil languages or Tamil people in Sanskrit, and all the current Dravidian languages were called a branch of Tamil in old Jain, Bhraminic, and Buddhist literature (Caldwell, 1875).
4 Task Description and Dataset

Task
The shared task was hosted on Codalab. Four translation sub-tasks were organized as a part of this task: English to Tamil, English to Malayalam, English to Telugu and Tamil to Telugu. Participants were given a choice to participate in the sub-tasks they wanted to. Training, development and test datasets of parallel sentences for each language pair were provided to all the participants. The task was to train/develop machine translation systems for the given languages. For evaluation, the participants translated the test data using the translation systems and the results were submitted to the organizers of the workshop. The submissions were evaluated by comparing them with the gold standard test set translations available, for which BLEU scores were used as the metric to rank the participants and subsequently the results were returned to the participants.

Dataset
The datasets were collected from the repository of Opensubtitles released in 2018 and available at Opus 5 and consisted of bilingual parallel corpora for each of the four language pairs. We created the training, development and test datasets in the following way: each of the bilingual corpora were divided into three sub-corpora according to the following criterion: the first 2,000 sentence pairs were compiled as the test corpora while the next 2,000 sentence pairs were used for the development set and the remaining data was compiled as the training dataset. The English-Malayalam training data had 382,868 sentence pairs, the one for English-Tamil had 28,417 sentence pairs, the English-Telugu training set had 23,222 sentence pairs whereas the Tamil-Telugu dataset had 17,155 sentence pairs.

System Description
A summary of the results of the shared task can be found in Tables 1. To evaluate the performance of the submitted systems, we calculated BLEU scores for each of these systems. We have listed out the short description of participants systems, for more details please refer their paper.
â€¢ Xie (2021) adopted two methods to improve the overall performance: (1) multilingual translation, they used a shared encoderdecoder multilingual translation model han-

Language Pairs Team Name Rank
English -Telugu GX (Xie, 2021) 1 IRLAB-DAIICT (Prajapati et al., 2021) 2 MUCS Shared Task (Hegde et al., 2021) 3
English -Tamil GX (Xie, 2021) 1 Spartans 2 IRLAB-DAIICT (Prajapati et al., 2021) 3
English -Malayalam GX (Xie, 2021) 1 Spartans 2 IRLAB-DAIICT (Prajapati et al., 2021) 3
Tamil -Telugu GX (Xie, 2021) 1 MUCS Shared Task (Hegde et al., 2021) 2 IRLAB-DAIICT (Prajapati et al., 2021) 3 â€¢ Prajapati et al. (2021) propose a neural machine translation model that tries to learn the parameters Î¸ by maximizing the conditional probability P (a|b; Î¸) (a = target language, b = source language). The encoder learns a hidden representation for each input sentence which is further decoded by the decoder and translations are generated. They propose that the individual units in the encoder/decoder architecture can be GRUs or LSTMs alongside as self attention mechanism. 

Results and Discussion
Based on the results reported for the test sets by the top 3 teams in each language translation sub-task as shown in Table 1 the submitted systems are ranked for each translation language pair, as shown in Table 2.
Using the System descriptions along with information from Tables 1 and 2, the system rankings can be summarized as follows:
â€¢ In the English-Telugu translation, the system submitted by (Xie, 2021) is ranked number 1, with a BLEU score of 38.86, followed by (Prajapati et al., 2021) with a score of 6.25 and (Hegde et al., 2021) with a score of 0.29.
â€¢ For the English-Tamil and English-Malayalam translation, (Xie, 2021)'s is again ranked number 1 with BLEU scores of 36.66 and 19.84 respectively, followed by Spartans with scores of 28.27 and 15.31. (Hegde et al., 2021) is ranked number 3 with scores of 1.66 and 19.84 respectively.
â€¢ Finally, in the Tamil-Telugu translation, the system submitted by (Xie, 2021) is again ranked number 1, with a BLEU score of 35.29, followed by (Hegde et al., 2021) with a score of 0.43 and (Prajapati et al., 2021) with a score of 0.0.
The reason for the variation in results among language pair tasks is due the following reasons as reported in the System descriptions:
â€¢ In Xie (2021), the system does not give good scores due the variation in the test set for English -Malayalam when compared with the development set where the BLEU score for the checkpoint average is 25.87.
â€¢ Prajapati et al. (2021) report that the overall translation quality of the test set is not as good as that of the validation data due to the variation in data in terms of sentence complexity and length when compared to the validation data.
â€¢ The reason for lower BLEU scores on the test set is due to the complexity of translation due to the presence of special characters, morphological richness of the language pairs and also due to the test set sentences being longer in length, according to Hegde et al. (2021) To summarize, the systems submitted by the teams have shown improvement when additional data corpora were used and when additional preprocessing steps and/or layers/mechanisms were added. The teams reported that the overall system scores for the test set are not good when compared to the validation set, due to the complexity of the test set in terms of longer length sentences and morphological richness in the language pairs.

Conclusion
This paper described the shared task of machine translation of Dravidian (Tamil) languages to be presented at the first workshop on Speech and Language Technologies for Dravidian Technologies and summarized the results of this workshop. The best performing systems submitted to this workshop achieved good performance in terms of BLEU scores inspite of the lack of data available for training. This is a promising result in that such similar techniques can be applied to other under resourced languages. We would like to conclude by saying that we hope to continue to conduct this workshop over the coming years, and therefore continue to contribute to the development of language technology for under-resourced Dravidian (Tamil) languages.


